{"model_update_steps": 2565, "method_class": "mir", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', learning_rate=3e-05, local_adapt_lr=3e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/0930_MixedAllErrors_T=100_mir_M=U+I_rs=32_rq=3_candidate=256_mode=none_seed=2021_ckpts/memory_dict.pkl', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=3, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0930_MixedAllErrors_T=100_mir_M=U+I_rs=32_rq=3_candidate=256_mode=none_seed=2021_ckpts/', replay_candidate_size=256, replay_frequency=3, replay_size=32, save_all_ckpts=0, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=100, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='exp_results/data_streams/mrqa.nq_train.memory.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "art and furnishings", "impulse turbine", "adaptive", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "the 50 fund", "ned sherrin", "the Mandate of Heaven", "Tar Baby", "enlightenment", "poseidon", "the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho ( including the communities of Parma, Wilder, Greenleaf, and Notus )", "2009", "the direction from which the wind is blowing", "john mortimer", "oxygen", "seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "the Glasgow-Euston overnight mail train", "Steve Carell", "omen of good or bad luck", "power blackouts"], "metric_results": {"EM": 0.875, "QA-F1": 0.9138392857142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_triviaqa-validation-3915", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-7369"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion", "john Leslie", "Queen Elizabeth II", "The Dallas Lovers' Song", "the anterolateral system", "1966", "for scientific observation", "john Cameron", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "the final revelation of God the Final Testament", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs", "the great heroism or of the most conspicuous courage in circumstances of extreme danger", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "the check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.125, "QA-F1": 0.18157436433298502}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["from the Italian pignatta", "originally designated HU - 1", "idealism and philanthropy", "mariette", "Virginia Wade", "Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York", "Rotherham United", "John Bercow", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years", "islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "Charlie", "gallantry", "Kathleen Turner", "Isaac Newton", "Superman", "2010"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8270833333333334}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-338", "before_prediction": "numb3rs", "after_prediction": "Charlie"}, {"id": "mrqa_squad-validation-10410", "before_prediction": "Galileo", "after_prediction": "Isaac Newton"}], "retained_ids": ["mrqa_naturalquestions-validation-4684", "mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-1924", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2096"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.49999999875}, {"timecode": 2, "before_eval": {"predictions": ["Kronprins Harald", "sports, among them cricket, rallying, football, rugby union and boxing", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "technological advances to work from their homes", "one of the membership who is no longer an exempt", "Bothtec", "Terry Reid", "information about climate change based on published sources", "Elgar", "North America", "Andr\u00e9 3000", "rookies", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "in the 1970s", "Georges Bizet", "Matt Winer", "1689", "Pacific"], "metric_results": {"EM": 0.125, "QA-F1": 0.2845157497731027}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.8235294117647058, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.13333333333333333, 0.0, 1.0, 0.0, 0.2, 0.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.3333333333333333, 0.6666666666666666, 0.4, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "It was never affiliated with any particular denomination", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "catherine de\u2019 Medici", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Masaharu Iwata", "Spencer Davis Group", "non-peer-reviewed sources", "Enigma Variations", "physiographically a part of the continent of North America", "OutKast", "rookies", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the Soviet Union and its satellite states", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "Pacific"], "metric_results": {"EM": 0.875, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "Masaharu Iwata"}], "retained_ids": ["mrqa_squad-validation-4019", "mrqa_squad-validation-194", "mrqa_squad-validation-4283"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113"], "unfixed_ids": ["mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-5180"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 3, "before_eval": {"predictions": ["id", "is not involved in this venture", "id", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006", "Least of the Great Powers", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "bums", "baze", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "has trouble distinguishing between carbon dioxide and oxygen", "is a British sitcom, broadcast in the United Kingdom from 1982 to 1984", "cement City, Texas", "The Renewable Heat Incentive scandal", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "for control purposes", "bamboula", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000", "al - khimar", "proteins were more complex than DNA", "bile duct or artery", "berenice Abbott"], "metric_results": {"EM": 0.09375, "QA-F1": 0.13191964285714286}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.1, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "Staten Island", "splash", "2005\u20132010", "G20", "efferent nerves", "max bygraves", "polar bear", "lester piggott", "\"do not disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo", "callable bonds", "2.26 GHz quad - core Snapdragon 800", "over 10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museum"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9975961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6341", "before_prediction": "2.26 GHz quad - core Snapdragon 800 processor", "after_prediction": "2.26 GHz quad - core Snapdragon 800"}], "retained_ids": ["mrqa_hotpotqa-validation-5662", "mrqa_squad-validation-5517"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.6666666644444444}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "Nijmegen", "December 9, 2016", "NASA discontinued the manned Block I program", "British progressive folk-rock band Gryphon", "1898", "month", "A rather solitary leader, one with his people but set apart, even in his childhood, when he was raised by the pharaoh\u2019s daughter as if he were an Egyptian prince", "museum", "tetanus", "bounding", "1934", "Alex O'Loughlin", "Eddie Leonski", "Jack", "a mixture of phencyclidine and cocaine", "bunker", "1934", "Reverse - Flash", "All Hallows'Day", "1934", "Azerbaijan", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America", "speech", "Michael E. Mann", "A steam turbine", "Splodgenessabounds"], "metric_results": {"EM": 0.25, "QA-F1": 0.3156135531135531}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.2857142857142857, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-8700", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "unmanned Saturn V flights", "Gryphon", "1898", "june", "a son of Amram and Jochebed, of the tribe of Levi", "40.58 latitude and -73.99 longitude", "lacerations", "bounding the time or space used by the algorithm", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine", "bunker", "lathers up their faces and suddenly tips the chair back, pitching them off. If the fall hasn't killed them, he drags their bodies through an underground tunnel to the premises of his lover Mrs. Margery Lovett", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "Azerbaijan", "new converts", "CeCe Drake", "cricket", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8203125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7253", "before_prediction": "tetanus", "after_prediction": "lacerations"}, {"id": "mrqa_squad-validation-1688", "before_prediction": "bounding", "after_prediction": "bounding the time or space used by the algorithm"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"}], "retained_ids": ["mrqa_naturalquestions-validation-1277", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-5654", "mrqa_squad-validation-3126", "mrqa_triviaqa-validation-5168"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-8700", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-1575"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.6249999992187499}, {"timecode": 5, "before_eval": {"predictions": ["lickenham", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "a soft wool fabric with a colorful swirled pattern of curved shapes", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "2 : 44 p.m. EDT", "swanee or swannee whistle", "sunflower oil", "to start fires, hunt, and bury their dead", "India", "Parietal cells ( also known as oxyntic or delomorphous cells )", "placental", "September 13, 1994", "gun", "imperial rule", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "lazing", "A study by the World Institute for Development Economics Research at United Nations University", "entropy increases", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "deaths, injuries, and structural collapses", "to house a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18473336304218657}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "cardiac", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "bury their dead", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotreme", "September 13, 1994", "president Garfield", "Ming", "1787", "defiant speech", "Mark Twain", "sunny afternoon", "The three richest people in the world possess more financial assets than the lowest 48 nations combined", "nonconservative forces", "death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9270833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-816", "before_prediction": "imperial rule", "after_prediction": "Ming"}], "retained_ids": ["mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-1718"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020", "mrqa_squad-validation-7554"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "prevent the flame from being blown out", "Illinois", "2010", "duneville", "island in the Mediterranean Sea", "90-60's", "unaided school", "dolph Camilli", "the times sign or the dimension sign", "BAFTA Television Award", "Juice Newton", "1960", "HTTP Secure ( HTTPS )", "late summer", "south-central Kansas on the Arkansas River", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "dads", "dune", "horan", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land", "near Grande Comore, Comoros Islands", "\u20b9 \u200d5L '' ( for `` rupees 5 lakhs '' )", "Norwegian", "fossil fuels"], "metric_results": {"EM": 0.09375, "QA-F1": 0.14773065476190478}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film directors", "capillary action", "2008", "1996", "north carolina", "menorca", "70", "independent schools", "boston braves", "the symbol \u00d7", "Best Supporting Actress", "Emily Blunt", "Super Bowl LII,", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "wichita", "the simplest", "for its popular beaches", "japan", "true", "red admiral", "o", "left coronary artery", "10 %", "boston", "concentrated in the leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "the Norwegian language", "Carbon dioxide ( CO )"], "metric_results": {"EM": 0.875, "QA-F1": 0.9}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1679", "before_prediction": "2010", "after_prediction": "1996"}, {"id": "mrqa_naturalquestions-validation-1618", "before_prediction": "Juice Newton", "after_prediction": "Emily Blunt"}], "retained_ids": ["mrqa_naturalquestions-validation-5582"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919"], "unfixed_ids": ["mrqa_triviaqa-validation-4966", "mrqa_naturalquestions-validation-6644"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.3333333322222222}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules", "The U.S. Army Chaplain insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs", "Ray Milland", "Armenia", "the last book accepted into the Christian biblical canon", "Beyonc\u00e9", "% IACS", "gallantry", "16 million", "post\u2013World War II", "cattle are slaughtered for meat before the age of three years, except where they are needed ( castrated ) as work oxen for haulage", "1998", "Ben Keaton", "23.1", "18 - season career", "family member", "long-term environmental changes", "William Powell Lear", "the unbalanced centripetal force felt by any object", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "to represent'a voyage of adventure'on which the programme would set out", "Abraham Gottlob Werner", "marlborough", "present-day Charleston, South Carolina", "a \"quiescent\" stance towards Israel, focusing on preaching, education and social services, and benefiting from Israel's \"indulgence\" to build up a network of mosques and charitable organizations", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "XIX Corps"], "metric_results": {"EM": 0.125, "QA-F1": 0.20811988256841196}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.09523809523809525, 0.0, 0.0, 0.28571428571428575, 0.07692307692307693, 0.23529411764705882, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "a few", "right", "Kairi in the video game series \" Kingdom Hearts\".", "public high schools lost their accreditation", "Lost Weekend", "Russia", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george Cross", "the most popular show at the time", "the late 1950s", "as work oxen for haulage", "2011", "a priest", "most abundant", "2001", "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting", "over-fishing and long-term environmental changes", "8-track cartridge", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george III", "the Charleston Orange district", "quiescent", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.8125, "QA-F1": 0.893455615942029}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3898", "before_prediction": "post\u2013World War II", "after_prediction": "the late 1950s"}, {"id": "mrqa_squad-validation-1863", "before_prediction": "family member", "after_prediction": "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting"}], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_squad-validation-4318"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_squad-validation-7799", "mrqa_squad-validation-358", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "unfixed_ids": ["mrqa_triviaqa-validation-1293", "mrqa_naturalquestions-validation-98", "mrqa_hotpotqa-validation-1142", "mrqa_triviaqa-validation-781"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.49999999875}, {"timecode": 8, "before_eval": {"predictions": ["analysis of algorithms and computability theory", "georgeppe Antonio 'Nino' Farina", "45.3", "6.4 nanometers apart", "the eighth and eleventh episodes of the season", "Carl Edwards", "400 games", "adrenal glands", "liberal arts or `` liberal pursuits '' ( Latin liberalia studia )", "the Forest of Bowland in Lancashire", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "St. Louis County, Missouri, United States", "1868", "2018", "a professional association football club based in the city Sheffield, South Yorkshire, England", "law firm", "Pottawatomie County", "owaita, an Aldabra giant tortoise", "Newton's Law of Gravitation", "The church tower", "eastEnders star Danny Dyer becomes London Underground station announcer for the day", "Toronto", "wales", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychotherapeutic", "Quentin Coldwater", "acidic bogs"], "metric_results": {"EM": 0.0625, "QA-F1": 0.24093501984126986}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.25, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.25, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "after_eval": {"predictions": ["computability theory", "Formula One World Championship", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidneys", "artes liberales", "Swiss of England", "Edward IV of England", "Eureka", "1828", "2018", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "general relativity (GR )", "The church tower", "walford east", "Montreal", "foreigner", "110 miles", "Kona coast", "liberal conservative", "gold rushes", "six", "no contest", "freudian psychoanalysis", "New York", "acidic"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9375905797101449}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-6991", "mrqa_squad-validation-5313"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "unfixed_ids": ["mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-3161", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-4268", "mrqa_triviaqa-validation-7767"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.999999995}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "sweetened sheeps\u2019 milk ricotta cream", "photosynthesis", "high-dress ball held at Devonshire House in 1897 to celebrate Queen Victoria's diamond jubilee", "to deliver a speech to the crowd at the Values Voter Summit", "The Daily Stormer", "spin triplet state", "water", "president", "the local, municipal level", "George, Margrave of Brandenburg-Ansbach", "Kamba version", "3D computer-animated comedy film", "Brown Square Station", "acting", "C. W. Grafton", "LED illuminated display", "British", "IPod Classic", "My Sassy Girl", "drain the body of used up and broken down components in a liquid and gaseous state", "The Edge of Night", "non-combustible substances that corrode, such as iron", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd ) book of prayers", "the root respiration", "organic carbon", "death", "medium and heavy- Duty diesel trucks", "testes"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27116800771692073}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.0, 0.0, 0.3333333333333333, 0.17391304347826086, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-1327", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentinian", "a report", "cake", "consumes ATP and oxygen, releases CO2, and produces no sugar", "images of different animals and humans performimg various actions", "1600 Pennsylvania Avenue", "The Daily Stormer", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "citizens", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation /\u02c8k\u025bnj\u0259", "3D computer-animated comedy", "Worcester Cold Storage and Warehouse Co. fire", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP", "other living organisms", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9891328828828829}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-832", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-133", "mrqa_squad-validation-5940"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4520", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-1327", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_triviaqa-validation-2703", "mrqa_squad-validation-8259", "mrqa_naturalquestions-validation-754"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.9999999980000001}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744)", "yellow fever", "three legal systems", "Las Vegas, Nevada", "a status line", "globetrotters", "Anthony Bellew", "the fictional town of Ramelle", "1987", "1987", "menhirs", "a strict and elaborate set of rules designed by Victoria, Duchess of Kent, along with her attendant, Sir John Conroy, concerning the upbringing of the Duchess's daughter, the future Queen Victoria", "the base 10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "1987 Kon-Tiki expedition", "the MGM Grand Garden Garden Special Events Center", "a virtual museum dedicated to Italian fashion designer Valentino", "Ronnie Hillman", "all-encompassing definition of the term", "1987", "more than 60", "Eagle Ridge Mall", "England team that won the 1966 World Cup", "reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Ron Howard", "the shooter must be at least 18 or 21 years old ( or have a legal guardian present )", "Ward", "novelist and poet", "Jamestown", "Monet", "tree growth stages"], "metric_results": {"EM": 0.125, "QA-F1": 0.28431186868686864}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.5, 0.0, 0.0, 0.8, 1.0, 0.5, 0.0, 0.7272727272727273, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8333333333333333, 0.2222222222222222, 0.0, 0.18181818181818182, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["Pope, Alexander (1688-1744) (DNB00)", "Hampton's hump and Hampton's line", "Scots law", "Las Vegas", "a status line", "the best known globetrotters", "cruiserweight", "over the Merderet in the fictional town of Ramelle", "mussolini", "victor Hugo", "menhirs", "British Royal Family", "the base 10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "Thor Heyerdahl", "the MGM Grand Garden Special Events Center", "Valentino", "C. J. Anderson", "a maze of semantical problems and grammatical niceties", "joseph Smith", "60 %", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "jacuzzi", "the classical element fire", "Barney Fife", "at least 18 or 21 years old ( or have a legal guardian present )", "Ann", "writer", "Virginia", "Rouen Cathedral", "carbon related emissions"], "metric_results": {"EM": 0.8125, "QA-F1": 0.853409090909091}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6639", "before_prediction": "Monet", "after_prediction": "Rouen Cathedral"}], "retained_ids": ["mrqa_naturalquestions-validation-8006", "mrqa_triviaqa-validation-4791", "mrqa_squad-validation-3525"], "fixed_ids": ["mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_triviaqa-validation-3515", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "unfixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_naturalquestions-validation-10205", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-1451", "mrqa_naturalquestions-validation-8617"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.7499999981250001}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "Traumnovelle", "a Gender pay gap in favor of males in the labor market", "Treaty on the Functioning of the European Union (TFEU )", "ice melting", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "kangaroo", "the length of suspended roadway between the bridge's towers", "Luas", "handguns", "catfood", "the Bulgars, and especially the Seljuk Turks", "coket", "Volkswagen Beetle", "Dyess", "Maastricht Treaty", "gloriana", "infection, irritation, or allergies", "the most - visited paid monument in the world", "Town House Galleria", "catfish aquaculture", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "James and D.J. Looney as Young Sparrow and DJ Dragon Nutz", "Kuwait", "a co-op of grape growers", "mann on a mission", "nabucodonosor", "1951", "Los Angeles Lakers", "the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "the chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.0625, "QA-F1": 0.18861421462524403}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.28571428571428575, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22222222222222224, 0.25]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "Dan Dares", "span", "Dublin", "duke of Edinburgh", "King Crimson", "Pechenegs, the Bulgars, and especially the Seljuk Turks", "Alamo", "tunisia", "arkansas", "Canada", "britten", "infection", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "atomic number 53", "American - bluegrass - based band Evermoist", "Kuwait", "An agricultural cooperative", "mann on a mission", "giuseppe verdi", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean F kernel ( 1497 -- 1558 ), a French physician", "chest"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8298611111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2852", "mrqa_triviaqa-validation-7703"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-6442"], "unfixed_ids": ["mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-5487", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.8, "instant_retention_rate": 0.999999995}, {"timecode": 12, "before_eval": {"predictions": ["British rock group Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "August 31, 2014", "The stability, security, and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade", "Minos and Kokalos", "18 November", "cienfuegos", "byker grove", "New South Wales", "Johnson", "gi LaBelle", "bolognese", "Orwell", "Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \" Regnum Bohemia\"", "Gregg Popovich", "secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "adaptive immune system", "Mexican drug lord", "a musician", "nodel", "December 1, 1969", "american", "jK Rowling", "California State Automobile Association", "\"alone\"", "Cinderella", "the crew noticed a strange odor in their spacesuits, which delayed the sealing of the hatch", "due to a lack of understanding of the legal ramifications"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2952936446782355}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.15384615384615385, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.34782608695652173, 0.0, 1.0, 0.0, 1.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.11764705882352941, 0.3076923076923077, 0.0, 0.2666666666666667, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.8571428571428571]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "sport fencing", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cuban cigars", "byker grove", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Czech Kingdom", "Bob Hill", "secularism and secular nationalism", "creative reasons", "immunological memory", "uncle", "Originally a musician", "thumbelina", "1973", "maryland", "john buchan", "regional tourism groups", "\"alone\" after \"faith\"", "Cinderella", "communications problems", "lack of understanding of the legal ramifications, or due to a fear of seeming rude"], "metric_results": {"EM": 0.96875, "QA-F1": 0.984375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2372", "before_prediction": "\"alone\"", "after_prediction": "\"alone\" after \"faith\""}], "retained_ids": ["mrqa_hotpotqa-validation-4826", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-4165"], "fixed_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7999999984}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Jason Lee as Buddy Pine / Incredi - Boy / Syndrome", "Napoleon's army", "ring", "3.7 percent of the entire student population", "increasing inequality harms economic growth. High and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "matt Willis and Charlie Quirke", "Little Golden Lion award", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "9", "paddington", "amyotrophic lateral sclerosis (ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "October 17, 1938", "Torah or Bible", "the western coast of Italy", "first and only U.S. born world grand prix champion", "brass band parades", "mid November", "Facebook", "beigel", "real-life story of Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Seattle", "King George's War", "he cheated on Miley", "rock music subgenres had emerged, including hybrids like blues rock, folk rock, country rock, raga rock, and jazz - rock", "Fort Saint Anthony", "daguerreotypes", "infrequent rain"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2708309315985946}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.17391304347826084, 0.0, 0.3333333333333333, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.0, 1.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.28571428571428575, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.2, 0.09523809523809525, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_triviaqa-validation-6913"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "two years", "3.7", "negative effect", "Garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "nine", "Michael Hordern", "Lou Gehrig's Disease", "\"Odorama\"", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "the quintessential New Orleans art form -- a jazz funeral without a body", "late November or early December", "Facebook bought", "the middle of the 19th century", "Tim \"Ripper\" Owens", "Issaquah", "King George's War", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "a pinhole or lens", "infrequent rain"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8573717948717949}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2779", "before_prediction": "Facebook", "after_prediction": "Facebook bought"}], "retained_ids": ["mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-10168", "mrqa_hotpotqa-validation-3669", "mrqa_squad-validation-2656"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_triviaqa-validation-7638", "mrqa_naturalquestions-validation-9897", "mrqa_triviaqa-validation-2896", "mrqa_triviaqa-validation-6913"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "American sympathizer", "maryland", "FX option", "electromagnetic waves", "Wahhabi/ Salafi", "thumbraskelion", "Children in Need", "Surveyor 3 unmanned lunar probe", "the end of January 1981", "gonadotropin - releasing hormone ( GnRH )", "baptismal theology", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "\u00a31 million", "slowing the vehicle", "Cheyenne rivers", "( sometimes) absence", "Hanna- Barbera", "Cortina d'Ampezzo", "efficient and effective management of money ( funds )", "Latium", "anthropomorphic personification", "garland", "Timo Hildebrand", "public sector ( also called the state sector )", "2 February 1940", "lack of access to education", "a god of the Ammonites", "sclera", "Uncle Fester", "James MacArthur"], "metric_results": {"EM": 0.125, "QA-F1": 0.20419372294372293}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/ Salafi Jihad extremist militant", "joseph Lee", "Dimensions in Time", "Apollo 12", "1981", "estrogen", "baptism", "that priest whose name was Martin Luther", "brian clough", "slowing the vehicle", "Belle Fourche and Cheyenne", "organisms", "Hanna- Barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Kur\u00e1nyi", "The public sector ( also called the state sector )", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.875, "QA-F1": 0.9032738095238095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7836", "before_prediction": "Children in Need", "after_prediction": "Dimensions in Time"}], "retained_ids": ["mrqa_hotpotqa-validation-970", "mrqa_naturalquestions-validation-727", "mrqa_naturalquestions-validation-6019"], "fixed_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": ["mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-6023"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "San Antonio", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "jupiter (now known as the Galilean moons)", "a friend and publicist", "michael ondaatje", "masons'marks", "Theodore Haynes", "Gateshead", "Motown, Philly soul, and Earth, Wind & Fire ( particularly `` That's the Way of the World '' )", "uterus", "after the Spanish -- American War in the 1898 Treaty of Paris", "professional wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "lenny", "Curtiss JN-4", "art", "chimpanzee", "March 15, 1945", "absolute temperature", "whistlebl-blowing", "Sam Waterston", "bicuspid", "his brother, Menelaus", "3 December", "tallahassee", "prefabricated housing projects", "brian garland", "WOTV"], "metric_results": {"EM": 0.09375, "QA-F1": 0.13256302521008403}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 0.0, 0.47058823529411764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Royce da 5'9\" ( Bad) and Eminem ( Evil)", "galileo Galilei", "editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "roof", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "1898", "martial artist", "Spanish", "stunt performances", "fred astaire", "postage stamp", "belgium", "Chimpanzees (or chimps)", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolar", "Aegisthus", "25 November 2015", "florida", "an Eastern Bloc city", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.9375, "QA-F1": 0.953125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-413", "before_prediction": "3 December", "after_prediction": "25 November 2015"}], "retained_ids": ["mrqa_hotpotqa-validation-3456", "mrqa_hotpotqa-validation-2957"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": ["mrqa_hotpotqa-validation-5188"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 16, "before_eval": {"predictions": ["galileo", "cow's milk cheese", "benedict", "on the lateral side of the tibia", "fergus Mor of Dalriada", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "October 29, 1985", "Amway", "Mauritius", "George Stigler", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "Golden Globe Award for Best Supporting Actor", "Tanzanian Legal System and Legal Research", "Chad", "GMAT Sentence Correction (SC)", "The main fa\u00e7ade, built from red brick and Portland stone, stretches 720 feet (220 m) along Cromwell Gardens and was designed by Aston Webb after winning a competition in 1891 to extend the museum", "allowing a child to go through a torturous treatment to gain information", "Fulham, Greater London, England", "French, English and Spanish", "Tom Baker", "U.S. Marshals", "What's Up (TV series)", "a FDA registered and AABB accredited distributor of human blood, platelets, and plasma for hospitals, non-transfusion facilities, and group-purchasing organizations", "Mars rover", "Stanislaw August Poniatowski", "polynomial algebra", "Michael J. Fox", "The three wise monkeys", "sheepskin and Merino Wool products", "Honolulu County, Hawaii, United States, on the island of Oahu"], "metric_results": {"EM": 0.03125, "QA-F1": 0.10972106094388703}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 0.33333333333333337, 0.30769230769230765]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "after_eval": {"predictions": ["a glitzy drag club on the French Riviera", "belgium", "blessed", "leg", "d\u00f9n Chailleann", "North Sea", "the three African countries of Botswana, Namibia and South Africa", "British Golfers", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio's \"The Show Band Show\"", "republic of tanzania", "niger", "Florida's Everglades", "the top row of windows", "Sam's soul is not with him", "London", "French, English and Spanish", "dave Lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "Mars rover", "Poland", "matrices", "Michael J. Fox", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7976495726495726}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2445"], "fixed_ids": ["mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_squad-validation-9319", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "unfixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_triviaqa-validation-4055", "mrqa_naturalquestions-validation-7144", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.7096774193548387, "instant_retention_rate": 0.9999999900000002}, {"timecode": 17, "before_eval": {"predictions": ["soft cheese", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "radioactive rubidium - 85", "Lula", "sovereign states", "president of the United States Senate", "\"Teach the Controversy\" campaign", "Sam's captured parents", "Australian", "30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Roy Spencer", "\"antiforms\"", "second half of the third season", "\"Veyyil\" (2006)", "Grace Nail Johnson", "Mick Jagger", "prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "teachers who specialize in one subject", "a line of longitude ) in a geographical coordinate system at which longitude is defined to be 0 \u00b0", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat of the National Basketball Association (NBA)", "33", "dactylosphaera vitifoliae", "The Annual Conference Cabinet, which is composed of the Area Provost/ Dean (if one is appointed) and the several District Superintendents of the Districts of the Annual Conference", "hockey player Hannah Macleod", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3176047563547564}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.8, 0.0, 0.08333333333333334, 0.0, 1.0, 0.0, 0.0, 0.40909090909090906, 0.0, 0.16, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.2857142857142857, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.23076923076923078, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845", "rubidium - 85", "James Zeebo", "the Peace of Westphalia of 1648, a stepping stone in the development of the modern state system", "vice president of the United States", "The Discovery Institute (DI) is a politically conservative non-profit think tank based in Seattle, Washington, best known for its advocacy of the pseudoscientific principle of intelligent design (ID)", "Ravage and the Decepticon Rampage", "Velichko Todorov Tsochev) is a Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower", "a private liberal arts college", "Roy Spencer", "\"antiforms\"", "the fifth and sixth seasons", "Veyyil", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Cartoon Network", "Presiding Officer", "the Phoenix Suns", "33-member", "vitis", "Annual Conference Cabinet", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.84375, "QA-F1": 0.84375}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-113", "before_prediction": "\"Teach the Controversy\" campaign", "after_prediction": "The Discovery Institute (DI) is a politically conservative non-profit think tank based in Seattle, Washington, best known for its advocacy of the pseudoscientific principle of intelligent design (ID)"}, {"id": "mrqa_hotpotqa-validation-5787", "before_prediction": "second half of the third season", "after_prediction": "the fifth and sixth seasons"}], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-3573"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-501"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.6666666655555555}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "social networking support", "400 metres", "Vili Fualaau and Mary Kay Letourneau, a student and teacher who made news for their sexual relationship", "the entertainment division", "curved path from a point A to a point B", "12", "the Great Exhibition of 1851", "King Edward I to Henry VIII", "sandy lyle", "dundee", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "lithgow Palace in Scotland", "\"Grindhouse\"", "davenport", "digital transmission modes", "the Swiss- Austrian border", "lithium-ion battery", "821", "V On Demand content which was not previously carried by cable", "liquid", "Kim Hyun-ah", "the races of highest'social efficiency'", "transposition", "the \" King of Cool\"", "American delegation from the Paris Peace Conference", "davis", "the fifth season", "dors", "Hockey Club Davos", "Michael Crawford", "a lightning strike"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2412202380952381}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.2, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.16666666666666666, 0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666665, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "harmoniously", "500 metres", "Piper", "ABC News", "displacement", "five", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "chego Garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay", "Spy Kids", "venus Williams", "Olivia", "Baden-W\u00fcrttemberg", "Tesla", "821", "basic channels", "pressure", "Hyuna", "the races of highest'social efficiency", "transposed", "the \" King of Cool\"", "President Wilson and the American delegation from the Paris Peace Conference", "socrates", "thirteenth", "violet", "HC Davos", "Michael Patrick Smith", "Iltutmish"], "metric_results": {"EM": 0.875, "QA-F1": 0.9364583333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4415", "before_prediction": "lithium-ion battery", "after_prediction": "Tesla"}, {"id": "mrqa_squad-validation-9827", "before_prediction": "American delegation from the Paris Peace Conference", "after_prediction": "President Wilson and the American delegation from the Paris Peace Conference"}], "retained_ids": ["mrqa_triviaqa-validation-5036", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-4068"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "unfixed_ids": ["mrqa_triviaqa-validation-5996", "mrqa_squad-validation-9841"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "director Norman Macdonnell and writer John Meston", "aragon", "11.1", "trans-Pacific flight", "Sharman Joshi", "sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "prime", "Ana", "Cherry Hill", "Season 4", "venus cheney", "venus davis", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name.", "blackstar", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "In 1889, following the Local Government Act 1888", "Nicki Minaj", "slave of duty", "Huguenot", "formula one championship", "friedrich Engels (1820 - 1895)", "Tara Strong (born Tara Lyn Charendoff", "William the Conqueror", "Ben Gurion International Airport", "two", "Mainland Greece", "taking blood samples from patients and correctly cataloging them for lab analysis", "the Guinness World Records for his work on the episode \" Fight at the Museum\" in the fourth season of the \" Kickin' It\" TV series at age 16", "Southern Progress Corporation"], "metric_results": {"EM": 0.21875, "QA-F1": 0.297048957986458}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.25, 1.0, 0.8, 0.0, 0.0, 0.0, 0.08333333333333334, 0.0, 1.0, 0.18181818181818182, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.07692307692307693, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "chameleon", "Star Plus", "piety", "1889", "Sir Mix - a-Lot", "slave of duty", "surnames", "portier", "marx marx", "Teen Titans Go!", "Norman invaders", "Tel Aviv", "two", "peninsula", "taking blood", "youngest TV director ever", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.875, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3049", "before_prediction": "Indian", "after_prediction": "Star Plus"}, {"id": "mrqa_hotpotqa-validation-2627", "before_prediction": "Southern Progress Corporation", "after_prediction": "Sunset Publishing Corporation"}], "retained_ids": ["mrqa_hotpotqa-validation-2943", "mrqa_squad-validation-5538", "mrqa_hotpotqa-validation-5710", "mrqa_triviaqa-validation-2015", "mrqa_naturalquestions-validation-7881"], "fixed_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "unfixed_ids": ["mrqa_triviaqa-validation-1995", "mrqa_triviaqa-validation-4068"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.7142857132653061}, {"timecode": 20, "before_eval": {"predictions": ["steam turbines with reduction gearing ( although the Turbinia has direct turbines to propellers with no reduction gearbox)", "Robert Smigel", "the Sackler Centre for arts education", "black on both Sides", "kaleidoscope", "Vancouver", "Apollo", "ribosomal", "kookaburra", "six", "CCH Pounder as Loretta Wade, medical examiner", "I Swear", "Kozunak ( Bulgarian : \u043a\u043e\u0437\u0443\u043d\u0430\u043a, Bulgarian pronunciation : ( kozu\u02c8nak ) )", "Belfast", "barycenter", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "trust God's word", "maryland", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "\" My Love from the Star\" (2013)", "San Jose", "sea wasp", "Hawaii", "a \"teleforce\" weapon", "Thunderbird", "giving Super Bowl ever", "65 years of age or older", "b.J. Hunnicutt"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28018162393162394}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.1111111111111111, 0.4444444444444445, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.888888888888889, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "prints and architectural drawings", "Mos Def", "Sir David Brewster", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Mercury astronaut", "Ribosomes", "kookaburra", "six-time", "CCH Pounder as Loretta Wade, medical examiner", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "Gerry Adams", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "mother tongues", "trust God's word", "Turkish Writer Orhan Pamuk", "CMYKOG process", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "upper chamber", "a \"teleforce\" weapon", "Native American", "giving Super Bowl", "29.7%", "Hawkeye Pierce"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8732638888888888}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5091", "before_prediction": "kaleidoscope", "after_prediction": "Sir David Brewster"}], "retained_ids": ["mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-2407", "mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-2280", "mrqa_squad-validation-1521"], "fixed_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272"], "unfixed_ids": ["mrqa_naturalquestions-validation-1279", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-1906", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8333333319444445}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier", "various registries", "James Blundell", "Yazoo", "22 April 1894", "the remnants of very massive stars with gravity so strong that not even light can escape", "tired from his daily labour (defatigus diurno labore) who at night enters his bedchamber (sub noctem intrat in cubiculum suum) and whose sleep is interrupted by dreams", "cede", "Willie Nelson and Kris Kristofferson", "ill. (some col.)", "a public and private", "a French pirate", "Lewis", "Charles Dickens", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "there must be infinitely many primes", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1960s", "huldra", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "James Bond", "4 in ( 10 cm )", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "quarterback", "Larry Gatlin & the Gatlin Brothers Band"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18370766512576692}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.4210526315789474, 1.0, 1.0, 0.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.25, 0.15384615384615385]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-192", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "transfused", "alison moyet", "1926", "black holes are the remnants of very massive stars with gravity so strong that not even light can escape", "dreams", "they viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auction", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "an independent, non-profit, ECOSOC non-governmental organization", "carbohydrates", "2001", "exceeds any given number", "alastair burnet", "padlocking the gates", "1969", "R\u00e5", "Great Lakes", "Protestant", "casino royale", "4 in", "oh so Sharp", "Western Atlantic ctenophore Mnemiopsis leidyi", "\"Menace II Society\"", "backup to Dan Marino as a member of the Miami Dolphins", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.875, "QA-F1": 0.9052884615384615}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3627", "before_prediction": "proteins", "after_prediction": "carbohydrates"}], "retained_ids": ["mrqa_naturalquestions-validation-5897", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_triviaqa-validation-192", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-4648"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "first Thursday in May", "MSC Crociere S. p.A.", "alison marx", "his friends, Humpty Dumpty and Kitty Softpaws", "The centre-right Liberal Party of Australia", "Royalists", "depolarization of the cardiac muscle begins at the sinus node", "either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "captain of the 4th department", "alibris", "Augustus Waters", "1619", "alison davis", "\u2018expensive damaging'", "June 11, 1973", "Kenya", "critical quotations", "boudicca", "an active supporter of the League of Nations", "Cargill", "Cinemark Theatres", "\"The Gang\"", "3 October 1990", "September 21, 2017", "heavy", "daedalus", "oldest son", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.15625, "QA-F1": 0.29544327200577203}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 0.4444444444444445, 0.6666666666666665, 0.33333333333333337, 0.14285714285714288, 0.15, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5714285714285715, 0.0, 0.1818181818181818, 0.0, 0.5, 0.0, 0.2, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Humpty Dumpty", "National Party of Australia", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "smersh", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1619", "tony blair", "often damaging", "July 26, 1959", "Masai Mara", "chronological collection of critical quotations", "edward i", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "pig", "Dexter", "Manhattan Project", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.9375, "QA-F1": 0.953125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1328", "before_prediction": "Development of Substitute Materials", "after_prediction": "Manhattan Project"}], "retained_ids": ["mrqa_hotpotqa-validation-3944", "mrqa_naturalquestions-validation-190", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "unfixed_ids": ["mrqa_triviaqa-validation-6872"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion in growth to the country's economy over five years", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "j Javier (Luna)", "red lead primer and a lead - based topcoat", "Dreamland", "Academy Award for Best Animated Feature", "European Union institutions", "flew on one Space Shuttle mission, STS-134 as a Mission Specialist", "nine", "CAL IPSO", "celandine", "Ulbricht", "Ronnie Schell", "artemisinin- Based therapy", "Mumbai, Maharashtra", "east", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "possibly 1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "southern part of Nigeria", "benanga", "Incudomalleolar joint ( more correctly called incudomallear joint )", "bobby riggs", "Leucippus", "Santa Clara", "benjamin barenboim", "political power generated by wealth", "log-space reductions", "Ted Ginn Jr. on the Denver 35-yard line on their second offensive play"], "metric_results": {"EM": 0.15625, "QA-F1": 0.34682115270350566}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [0.33333333333333337, 0.0, 0.0, 0.4444444444444445, 0.0, 0.25, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.3636363636363636, 0.6666666666666666, 0.0, 0.2, 0.0, 0.8235294117647058, 0.0, 1.0, 0.8, 0.0, 1.0, 0.4, 0.4]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-327", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "after_eval": {"predictions": ["$105 billion", "kissing disease", "17 nm vs 25 nm", "1937 Austin Seven Ruby Open Top Tourer", "Dirty Dancing", "red", "Steeplechase Park", "Best Animated Feature", "member states", "381.6 days", "nine", "NASA's", "yellow", "Khrushchev", "Jack Cassidy", "malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall which can be daily occurrence lasting till September", "Kananga", "Incudomalleolar joint", "moffitt", "Leucippus", "Santa Clara Marriott", "Var. II", "political power", "the bound on the complexity of reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.78125, "QA-F1": 0.8546626984126984}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 0.4444444444444445, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-789", "before_prediction": "Academy Award for Best Animated Feature", "after_prediction": "Best Animated Feature"}], "retained_ids": ["mrqa_squad-validation-542", "mrqa_naturalquestions-validation-4048", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-7481"], "fixed_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-327", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-6781"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.7999999984}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt's plan called for three major offensive actions involving large numbers of regular troops, supported by the provincial militias, aimed at capturing the heartlands of New France", "alchemy", "WBC and lineal titles", "moluccas", "Kentucky Derby", "Albany ( in the Quarto version )", "Israeli troop withdrawal from parts of the Sinai Peninsula", "1971", "The Lord of the Rings: The Return of the King", "Peyton Manning", "Instagram's own account", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program and learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "bingo", "Eugene", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter", "Fa Ze YouTubers", "nine", "Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor Conventual", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts", "Jon M. Chu", "the Space Shuttle \"Discovery\" on STS-51-C.", "it will retreat to its den and winter will persist for six more weeks", "prime minister of France"], "metric_results": {"EM": 0.125, "QA-F1": 0.2615597579693324}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.6486486486486487, 0.0, 0.0, 0.5, 0.7692307692307693, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5957446808510638, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Albany", "multilateral", "1990", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "31", "He is from Pago Pago, American Samoa and played college football at Oregon.", "comparable to the seven Wonders of the World", "2p + 1 with p prime", "coupe", "FaZe Rug", "dante", "Mongols and a Muslim", "along the coast, the settlements were growing into the interior", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.875, "QA-F1": 0.9371706674473068}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-5399", "before_prediction": "1971", "after_prediction": "1990"}, {"id": "mrqa_squad-validation-6204", "before_prediction": "Muslim", "after_prediction": "Mongols and a Muslim"}], "retained_ids": ["mrqa_squad-validation-67", "mrqa_squad-validation-4417"], "fixed_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.49999999875}, {"timecode": 25, "before_eval": {"predictions": ["synchronized skating", "slave", "over 50 million singles worldwide", "secessionists of the Confederate States, who advocated for states'rights to expand slavery", "between 1923 and 1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "france", "iteratively", "geese", "the move from the manufacturing sector to the service sector", "Brisbane", "Colin Baker and Sylvester McCoy", "August 14, 1848", "lower rates of health and social problems", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "A Chorus Line", "2,664", "on the inside of the chassis right beneath the volume buttons that allows it to bend very easily with pressure added in the right place", "through a chute beneath his or her feet", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning services, support services, property services, catering services, security services and facility management services", "Symphony No. 7 in A major, Op. 92", "gironde", "1603", "above the two personal physicians of the Emperor", "flute", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.   Came to believe that a Power greater than ourselves could restore us to sanity.", "Cubs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.4080234549806918}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.3333333333333333, 0.25, 0.33333333333333337, 0.4615384615384615, 0.923076923076923, 0.0, 1.0, 0.0, 0.923076923076923, 0.3636363636363636, 0.4444444444444445, 0.6, 1.0, 1.0, 0.10526315789473684, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastics", "slave", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "buck Barrow", "iteratively", "geese", "in effect", "pacific", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "life expectancy is lower", "juveniles are capable of reproduction", "breaded chicken patty", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "bendgate", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde", "1603", "Ranked positions", "nutcracker", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball team"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-2098", "mrqa_naturalquestions-validation-6545"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3977", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "unfixed_ids": ["mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-5762", "mrqa_triviaqa-validation-6091"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.9999999983333333}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "true history of the Kelly Gang", "Waialua District of the island of O\u02bb ahu, City and County of Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "john Litweiler", "tennis", "4,000", "Khagan", "Heathcliff", "canal", "spice", "He was voiced by Phil Hartman and first appeared in the second season episode \"Homer vs. Lisa and the 8th Commandment\"", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "A portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre", "Albany High School for Educating People of Color", "Rashtrapati Bhavan", "a non-commissioned officer in the United States Army's premier special operations unit, the 1st Special Forces Operational Detachment- Delta (1SFOD-D) or \" Delta Force\"", "Shaw", "seek jury nullification", "Cee - Lo", "Anglican", "mammy", "king George V class battleship", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "1757"], "metric_results": {"EM": 0.15625, "QA-F1": 0.31531562799945156}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [0.8, 0.19999999999999998, 0.0, 0.33333333333333337, 0.5882352941176471, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.4, 0.5454545454545454, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "an investment technique outlined by Joel Greenblatt", "kelly", "City and County of Honolulu", "1910\u20131940", "those who refuse vetting", "Catch Me Who Can", "jazz", "nell hopman", "3,677 seated", "Khagan", "catherine and heathcliff", "birmingham", "sri lanka", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "Shopping Centre", "Albany High School", "charbagh", "Sergeant First Class", "Anakin Skywalker", "jury nullification", "the closing scene of the final episode of the first season", "The Church of England", "hattie mcdaniel", "scharnhorst", "mcdaniel", "The Niger Delta is the delta of the Niger River sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria. It is typically considered to be located within nine coastal southern Nigerian states", "The economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8851190476190476}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5238095238095238, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7801", "before_prediction": "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "after_prediction": "The Niger Delta is the delta of the Niger River sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria. It is typically considered to be located within nine coastal southern Nigerian states"}, {"id": "mrqa_squad-validation-7319", "before_prediction": "opportunity-based entrepreneurship", "after_prediction": "The economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth"}], "retained_ids": ["mrqa_squad-validation-7435", "mrqa_squad-validation-3176", "mrqa_squad-validation-6148"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_hotpotqa-validation-945"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6689", "mrqa_triviaqa-validation-3393"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.5999999988}, {"timecode": 27, "before_eval": {"predictions": ["b Bones Howe", "kelly geldof", "blackberry and dewberry", "astrolights", "Big Mamie", "tanzania", "Hoffa", "a light sky-blue color caused by absorption in the red", "abbey", "2009", "February 10, 1984", "inner mitochondria membrane", "caillebotte, pissaro, Sisley, Cezanne and Marisot", "Grand Annual Steeplechase at Warrnambool", "The channel which can get carriage on a suitable beam of a satellite at 28 \u00b0 East is entitled to access to BSkyB's EPG", "third season", "the weak and electromagnetic forces", "availability of skilled tradespeople", "hardness", "The Benty Grange helmet and the Guilden Morden boar from the same period", "the Newcastle Polytechnic, established in 1969 and became the University of Northumbria at Newcastle", "kelly clifley", "Lofton", "25 - yard line", "the Swedish astronomer Anders Celsius", "about 7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "that the righteous acts of believers are performed in cooperation with God", "michael mizrachi", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "cete"], "metric_results": {"EM": 0.09375, "QA-F1": 0.24632034632034633}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 0.14285714285714288, 0.125, 0.0, 0.0, 0.375, 0.8, 0.2857142857142857, 1.0, 0.0, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "Big Mamie", "Orinoco", "Teamsters leader", "clear", "A violent system of punishments for offenders was usually enough to put off peasants from causing trouble.", "2009", "Zaza Pachulia", "the inner chloroplast membrane", "Renoir", "sports tourism", "no", "third", "fundamental electroweak interaction", "Cost of construction", "gypsum", "A simple iron boar crest", "polytechnics became new universities", "australia", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yards line", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "peter paul rubens", "badgers"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9663461538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-994", "mrqa_squad-validation-7711", "mrqa_squad-validation-8279"], "fixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_triviaqa-validation-2980", "mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.9999999966666667}, {"timecode": 28, "before_eval": {"predictions": ["thought the Muslim faith as a tool of the devil, he was indifferent to its practice", "Chris Weidman", "nullification", "Harishchandra", "a blind Arab philosopher, poet, and writer", "Professor Eobard Thawne", "plum brandy", "US $10 a week raise over Tesla's US+18 per week salary", "October 25, 1825 - June 3, 1899", "member states on a voluntary basis", "clarinet", "McKinsey's offices in Silicon Valley and India", "acrophobia", "living doll", "Crohn's disease or ulcerative colitis", "Ondemar Dias", "Raya Yarbrough", "Cincinnati", "cruiserweight", "businessmen Charles L. Hutchinson (trustee, treasurer and donor of Hutchinson Commons)", "Old Testament", "australia", "local talent", "Football League", "tony brian", "australia", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "birrattsville", "1332", "dodo bird", "people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "bus driver"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3075603959532531}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.30769230769230765, 0.2857142857142857, 0.8333333333333333, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 1.0, 1.0, 0.2040816326530612, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "after_eval": {"predictions": ["pamphlets", "Anderson Silva", "inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law", "Kusha", "poet, and writer", "Professor Eobard Thawne", "plum brandy", "US$10 a week raise", "1825", "contributed by member states on a voluntary basis", "oboe", "McKinsey's offices", "hyprophobia", "lionel b", "gastroschisis", "Francisco de Orellana", "Bear McCreary", "UMBC", "riddick bowe", "Charles L. Hutchinson", "Song of Songs", "Pullman Brown", "local talent", "Preston North End Football Club", "peter davison", "lillooet", "contemporary accounts were exaggerations", "Lincoln assassination", "1349", "dodo bird", "the belief that by focusing on positive or negative thoughts people can bring negative or negative experiences into their life", "stan butler"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7908110712387029}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.9473684210526315, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-4309", "before_prediction": "Ondemar Dias", "after_prediction": "Francisco de Orellana"}, {"id": "mrqa_squad-validation-8190", "before_prediction": "1332", "after_prediction": "1349"}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-5086", "mrqa_triviaqa-validation-2953"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-4584", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-4308"], "unfixed_ids": ["mrqa_squad-validation-6835", "mrqa_triviaqa-validation-4827", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.6666666666666666, "instant_retention_rate": 0.5999999988}, {"timecode": 29, "before_eval": {"predictions": ["poisonous, toxic, etc.", "886 AD", "used to finance his own projects", "24 Hours of Le Mans", "Kinect", "Beijing", "linebacker Danny Trevathan", "parallelogram rule of vector addition", "ruled against their attempt to prove the law unconstitutional", "o'Connor", "the reactor core", "don mLean", "the bore, and often the stroke", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Yuan society", "Doctor Who Theme", "National Basketball Development League", "gillingham", "St. Mary's County", "Ted Ginn Jr.", "2,615", "Pyeongchang", "athlete", "a password recovery tool for Microsoft Windows", "Homeless Man", "historical contributions to the development of modern architecture and furniture", "Brazil", "Hollingsworth", "either Q or the finite field with p elements", "heartburn", "53%", "photosynthesis"], "metric_results": {"EM": 0.09375, "QA-F1": 0.19655549719887952}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38095238095238093, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705, 0.6666666666666666, 0.16666666666666666, 0.0, 0.0, 0.9333333333333333, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-3103", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_squad-validation-7914", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-9036", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "His patents earned him a considerable amount of money, much of which was used to finance his own projects with varying degrees of success", "Formula One", "360", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "expert scientific testimony", "364", "a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors, when they are loaded with fresh nuclear fuel, whose neutron flux from spontaneous fission is insufficient for a reliable startup, or after prolonged shutdown periods", "van gogh", "cylinder", "production of blood cells", "local administrative structure", "Doctorin' the Tardis", "National Basketball Development League", "kent", "Washington metropolitan area", "Emmanuel Sanders", "The population was 2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using method such as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "south koreans", "arthur", "Q or the finite field with p elements", "heartburn", "53% in Botswana to -40% in Bahrain", "normal grana and thylakoids"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8599107142857143}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.16, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7445", "before_prediction": "53%", "after_prediction": "53% in Botswana to -40% in Bahrain"}], "retained_ids": ["mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-814"], "fixed_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_hotpotqa-validation-3497", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3103", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_squad-validation-7914", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-9036", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_squad-validation-1249", "mrqa_triviaqa-validation-6632", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-4572"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.6666666644444444}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "the Mayor's son", "abraham lincoln", "John Cleese and Connie Booth", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "ABC1", "mikael blomkvist", "demographics and economic ties", "three or more separate periods", "The Kickoff Game", "a rapid drop in your blood sugar", "arctic monkeys", "monza", "Dr. Ian Malcolm", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "A computer program", "The Greens, who won their first lower house seats in 2014, are strongest in inner Melbourne", "marduk", "Hekla", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "pike", "South Pacific off the northeast coast of Australia", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Easy", "Scott Bakula", "K. Kamaraj", "National Lottery", "a Saturn V Moon rocket", "katherine swynford", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12208682216905901}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.10526315789473684, 0.0, 0.4444444444444445, 0.4, 0.12121212121212122, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-2750", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "jurassic park", "all transmissions", "A computer program", "Greens", "babylon", "surtsey", "Kenya's largest source of foreign direct investment", "national network", "South Pacific", "7", "New Jersey", "Netflix", "Spencer Brody ( Zoe McLellan ), a transfer from the NCIS Great Lakes field office, who has worked as a Special Agent Afloat and is keen to leave her past behind as she moves to New Orleans", "indira gandhi", "state-franchised", "skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9652149321266968}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1282", "before_prediction": "Scott Bakula", "after_prediction": "Spencer Brody ( Zoe McLellan ), a transfer from the NCIS Great Lakes field office, who has worked as a Special Agent Afloat and is keen to leave her past behind as she moves to New Orleans"}], "retained_ids": ["mrqa_naturalquestions-validation-9852"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-2750", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608"], "instant_fixing_rate": 0.9666666666666667, "instant_retention_rate": 0.4999999975}, {"timecode": 31, "before_eval": {"predictions": ["Yolanda Sald\u00edvar", "Andreas", "skaters", "football", "Newell Highway", "androids", "15 hands", "shopping mall", "defiant speech", "Andrew Adamson, Kelly Asbury and Conrad Vernon", "waltz", "his own men", "emissions resulting from human activities", "spain", "the RAF, Fighter Command had achieved a great victory in successfully carrying out Sir Thomas Inskip's 1937 air policy of preventing the Germans from knocking Britain out of the war", "reduce growth in relatively poor countries", "Ibrium", "skylab", "Polish-Jewish", "a variety of political groups that supported the Spanish coup of July 1936 against the Second Spanish Republic, including the Falange, the CEDA, and two rival monarchist claimants : the Alfonsists and the Carlists", "is a song by Cole Porter", "surtree", "16,000", "Washington Street", "8 November 1978", "6", "lohan", "his frustration with the atmosphere in the group at that time", "davans", "John Smith", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.3125, "QA-F1": 0.41502149470899463}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.0, 0.07407407407407407, 0.25, 1.0, 0.0, 0.0, 0.07407407407407407, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_triviaqa-validation-743", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "1970", "Newell Highway", "tenth planet", "4", "shopping", "make a defiant speech, or a speech explaining their actions", "Andrew Adamson", "waltz king", "Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage growth", "Ibrium", "come dancing", "Polish", "the Falange", "1936", "1967", "16,000", "Washington Street", "8 November 1978", "2", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "Birmingham", "John Smith", "lusitania", "economic separation"], "metric_results": {"EM": 0.875, "QA-F1": 0.9}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1050", "before_prediction": "football", "after_prediction": "1970"}], "retained_ids": ["mrqa_hotpotqa-validation-5585", "mrqa_hotpotqa-validation-2762", "mrqa_hotpotqa-validation-1444", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-3728", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-4500", "mrqa_triviaqa-validation-4524"], "fixed_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_squad-validation-3106"], "unfixed_ids": ["mrqa_triviaqa-validation-5378", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-743"], "instant_fixing_rate": 0.8636363636363636, "instant_retention_rate": 0.8999999991}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "beer festival", "gender testing", "Jones portrays Dwight's cousin Zeke", "kalium", "In extreme circumstances, a driver may attempt to jackknife the vehicle deliberately in order to halt it following brake failure", "CD4+ and CD8+ (\u03b1\u03b2) T cells", "$52,000", "fruit", "Heading Out to the Highway", "Moonraker", "$12.99", "Michael Oppenheimer", "England national team", "the position of people within the four-class system was not an indication of their actual social power and wealth, but just entailed \"degrees of privilege\" to which they were entitled institutionally and legally", "No Night Today", "Convention", "5,922", "December 5, 1991", "Lockhart", "Philadelphia 76ers", "the Dutch figure of Sinterklaas", "Stern-Plaza", "WBC/WBA heavyweight champion Joe Frazier", "23 March 1991", "Sunday", "Dallas", "Nairobi", "last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29297036749482397}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.08695652173913045, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.1142857142857143, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.8571428571428571, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "after_eval": {"predictions": ["orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "september", "south africa", "Thomas Middleditch", "k", "If a vehicle towing a trailer skids", "T cell", "relatively low salaries", "usa", "Point of Entry", "bridge", "u", "Science Magazine's", "Premier League club Manchester United and the England national team", "lived in poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Sinterklaas", "Potsdam", "Jimmy Ellis", "1991", "may", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9449404761904762}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-572", "before_prediction": "Fomento Econ\u00f3mico Mexicano", "after_prediction": "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V."}, {"id": "mrqa_hotpotqa-validation-5335", "before_prediction": "Stern-Plaza", "after_prediction": "Potsdam"}], "retained_ids": ["mrqa_squad-validation-6744", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-5557"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "unfixed_ids": ["mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.6666666655555555}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\"Boston Herald\" Rumor Clinic", "1967", "legprints in the Sand", "the twelfth most populous city in the United States", "115 home runs", "bridge", "it triggers a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus, causing changes in gene expression", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Tevye", "Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country, hugging the east side of the Mississippi River and its tributaries", "Japan", "ship's wooden deck or side / hull", "Spring city", "Mumbai, India", "Sydney", "2005", "all punishments and granted them salvation", "\"The Doctor's Daughter\"", "september", "leg of the Jackal", "things that are a matter of custom or expectation", "1879", "uncle of Empress Taitu Bitul, consort of Emperor Menelik II of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "emotional contagion", "reno", "passenger space and amenities such as air conditioning, power steering, AM-FM radios, and even power windows and central locking without increasing the price of the vehicle", "Arkansas", "Norway"], "metric_results": {"EM": 0.1875, "QA-F1": 0.25564094779820584}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1081081081081081, 0.08, 0.0, 0.0, 0.12903225806451615, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.15384615384615385, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "after_eval": {"predictions": ["defeat of Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "served in or has ties to the United States Navy", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "St. Lawrence River valley", "emperor", "oakum", "Yunnan- Fu", "London", "Broken Hill and Sydney", "2005", "punishments", "Smith and Jones", "wagons", "Ilich Ramirez Sanchez", "things that are a matter of custom or expectation", "By the end of 1879", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "air conditioning", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-270", "before_prediction": "Spring city", "after_prediction": "Yunnan- Fu"}], "retained_ids": ["mrqa_hotpotqa-validation-1573", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-6878", "mrqa_squad-validation-1903", "mrqa_squad-validation-2147"], "fixed_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "unfixed_ids": ["mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-7387"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.8333333319444445}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "king George VI", "defiance toward the government and unwillingness to stand for its policies", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Germany", "red or pimento peppers", "0.2 inhabitants per square kilometre", "marx marx", "France", "Ian Paisley", "mariveles", "euro", "wings of a Dove", "the United States", "1973", "1886", "2008", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Russell Crowe as Maximus Decimus Meridius", "rotation", "Johnny Darrell", "carotid artery", "a Belgian law requiring all margarine to be in cube shaped packages", "Euler's totient function", "ear canal", "the set of all connected graphs", "Busiest", "red", "Toyota Corona", "American writer and satirist Kurt Vonnegut", "Rapunzel"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11294261294261294}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.5, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman", "Norman Hartnell", "defiance toward the government and unwillingness to stand for its policies", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52/ sq mi", "William Edward Graham Niven", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "Bataan Death March", "lTL", "Madness", "Taft -- Katsura Agreement", "late 1970s", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "the relationship of the number to its corresponding value of Euler's totient function or the sum of divisors function", "earwax", "how graphs are encoded as binary strings", "third", "succulent orange", "large", "Lauren Oliver", "Princess Rapunzel"], "metric_results": {"EM": 0.75, "QA-F1": 0.806712962962963}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8148148148148148, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3982", "mrqa_hotpotqa-validation-1139"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_hotpotqa-validation-3107", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034"], "unfixed_ids": ["mrqa_squad-validation-6673", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3072", "mrqa_naturalquestions-validation-8990", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-7184", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.7333333333333333, "instant_retention_rate": 0.999999995}, {"timecode": 35, "before_eval": {"predictions": ["2% higher", "supply and demand", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "membranes of the body's cells", "butterfly", "Washington Redskins", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "William Howard Ashton", "national security, big oil companies and bribery and corruption at the highest levels of the government of the United States", "high and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Broward County", "Lee Byung-hun", "changing display or audio settings quickly, such as brightness, contrast, or volume", "marston Moor", "from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "the income share of the top 20 percent (the rich) increases, then GDP growth actually declines over the medium term, suggesting that the benefits don't trickle down", "Beauty and the Beast", "South Africa", "Scotty Grainger Jr.", "Alamo", "a seal illegally is broken", "the UMC", "David Draiman", "Roger Allers and Rob Minkoff", "Papua New Guinea", "Ross Bagdasarian", "National Association for the Advancement of Colored People", "1963\u20131989", "september", "John Prescott", "Darrin Stephens", "6500 - 1500 BC"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30712646262518384}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.6666666666666666, 0.28571428571428575, 0.14285714285714288, 0.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4615384615384615, 0.08695652173913045, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["2%", "capital and financial markets", "Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "Orecchiette", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard", "William Howard Ashton", "president harding", "Unemployment", "Miami", "Best Actor prize", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "king charles i", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "South Africa", "Tyler \"Ty\" Mendoza", "texas", "seal", "The United Methodist Church", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "National Association for the Advancement of Colored People", "1963\u20131989", "marlin", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8298076923076922}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.15384615384615385, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4829", "before_prediction": "butterfly", "after_prediction": "Orecchiette"}, {"id": "mrqa_squad-validation-10036", "before_prediction": "the UMC", "after_prediction": "The United Methodist Church"}], "retained_ids": ["mrqa_hotpotqa-validation-2971", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-6450", "mrqa_squad-validation-7610"], "fixed_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "unfixed_ids": ["mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.6666666655555555}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Amber Laura Heard", "planet Uranus", "president rudolf", "Cobham\u2013Edmonds thesis", "human, or humanoid aliens", "Best Male Pop Vocal Performance", "March 2012", "jazz club", "Muhammad Ali", "Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Menorca", "plead guilty to one misdemeanor count and receive no jail time", "dictator", "2", "1898", "first person to find it would inherit his entire fortune and the corporation", "decision problem", "Hexham, Northumberland", "lungs", "That the plague was caused by bad air", "American pint of 16 US fluid ounces ( 473 ml )", "mountain ranges (sub-ranges of the Rocky Mountains)", "red", "The U.S. state of Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571, with exports to other states occurring around 1858.", "nettle", "US $3 per barrel", "flat rate", "love is all around - top of the pops", "to build a nationwide network in the UK", "roughly west through the Netherlands and extended to the southwest, through the English Channel and finally, to the Atlantic Ocean", "Sudan"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2735992561360209}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 0.0, 0.07692307692307691, 0.4444444444444445, 0.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.7272727272727273, 0.2222222222222222, 0.11764705882352941, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-4115", "mrqa_hotpotqa-validation-1884", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-8525", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "jupiter", "rudolph", "Cobham\u2013Edmonds thesis", "teachers", "II", "April", "crescent city", "Raymond Patterson", "Coldplay", "Menorca", "to civil disobedients", "emperors", "2%", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "formal language", "Rusalka", "the right side of the heart", "Miasma theory", "imperial fluid ounces", "mountain ranges", "white", "other states", "nettle", "$12", "20 %", "love is all around", "use in the ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.875, "QA-F1": 0.8794642857142857}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6759", "before_prediction": "plead guilty to one misdemeanor count and receive no jail time", "after_prediction": "to civil disobedients"}, {"id": "mrqa_squad-validation-4877", "before_prediction": "That the plague was caused by bad air", "after_prediction": "Miasma theory"}], "retained_ids": ["mrqa_squad-validation-1758", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-3060", "mrqa_triviaqa-validation-4069"], "fixed_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-4115", "mrqa_hotpotqa-validation-1884", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-8525", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "unfixed_ids": ["mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-5936"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.6666666655555555}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "three of his ribs were broken", "7 December 2000", "Post Alley under Pike Place Market", "mother-of-pearl made between 500 AD and 2000", "February 20, 1978", "haggis", "Walter Mondale", "96", "De Inventione by Marcus Tullius Cicero", "japan", "a black background representing the circle with glossy gold letters", "Jericho in the Levant region, thought to be the world's first town ( settled around 8500 BC and fortified around 6800 BC )", "37 \u00b0 9' 58.23\" latitude, around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Carlos Tevez", "small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "many events and festivals", "Deutscher Tafelwein", "1991", "fifth moon", "7 January 1936", "lifetime protection", "twenty- three", "astronomers Carl Sagan, a prominent contributor to the scientific research of extraterrestrial life, and Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services", "The Republicans, who were loyal to the democratic, left - leaning and relatively urban Second Spanish Republic, in an alliance of convenience with the Anarchists and Communists", "Gheorghe Popescu", "defiant speech, or a speech explaining their actions", "is simply yogurt that has been strained in a cloth, paper bag, or filter to remove the excess liquid", "in Oxford, UK, with Corporate Offices based in Auburn Hills, Michigan"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2465213712296513}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 0.35294117647058826, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.2777777777777778, 0.08695652173913045, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_squad-validation-5451", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524", "mrqa_hotpotqa-validation-5371"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "the Roman Empire", "United States", "gold", "Mesopotamia", "37\u00b0 9' 58.23\"", "woodentop", "Henry", "shared", "sandhill dunnart", "events and festivals", "kabinett", "2010", "avatar", "7 January 1936", "lifetime protection", "twenty-three", "Carl Sagan", "tax base dissipated", "Nationalists", "Pierre Nlend Wom\u00e9", "mistreatment", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.9375, "QA-F1": 0.95}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-4768", "mrqa_hotpotqa-validation-513", "mrqa_hotpotqa-validation-4154", "mrqa_hotpotqa-validation-85", "mrqa_naturalquestions-validation-969"], "fixed_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_squad-validation-5451", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524", "mrqa_hotpotqa-validation-5371"], "unfixed_ids": ["mrqa_triviaqa-validation-3479", "mrqa_hotpotqa-validation-2377"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.9999999980000001}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "buffalo", "slavery", "American Indian allies", "a children's story published by John Newbery in London in 1765", "the longest rotation period ( 243 days ) of any planet in the Solar System", "gathering money from the public", "Thorgan Ganael Francis Hazard", "The army requires officers to purchase and maintain only the blue service uniform.", "Jeff Meldrum", "741 weeks", "Phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "suez", "34", "journalist", "the fact that there is no revising chamber", "garland", "the points of algebro-geometric objects", "most of the items in the collection, unless those were newly accessioned into the collection", "free floating", "strychnine", "The Alta Wind Energy Center in California", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation.", "Lord's", "Eddy Shah", "Jim Cummings", "first heart sound ( S )"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2901943950657186}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.47058823529411764, 1.0, 0.0, 0.25, 0.0, 1.0, 0.15384615384615383, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.3846153846153846, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "after_eval": {"predictions": ["the NP-complete knapsack problem", "Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson", "1958", "Bart Cummings", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \" Jeff\" Meldrum", "741 weeks", "Phil Archer", "French and English", "The Chipettes", "Suez Canal", "60 by West All - Stars ( 2017 )", "a period of 84 hours without sleep or rest", "the fact that there is no revising chamber", "beehive", "ramification", "those were newly accessioned into the collection", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8252394636015326}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [0.5714285714285715, 0.896551724137931, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1862", "before_prediction": "the NP-complete Boolean satisfiability problem", "after_prediction": "the NP-complete knapsack problem"}, {"id": "mrqa_naturalquestions-validation-685", "before_prediction": "slavery", "after_prediction": "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories"}, {"id": "mrqa_squad-validation-1660", "before_prediction": "journalist", "after_prediction": "a period of 84 hours without sleep or rest"}], "retained_ids": ["mrqa_hotpotqa-validation-727", "mrqa_triviaqa-validation-4762", "mrqa_triviaqa-validation-3320"], "fixed_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_squad-validation-9478", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.7692307692307693, "instant_retention_rate": 0.49999999916666665}, {"timecode": 39, "before_eval": {"predictions": ["Republic of China", "Dan Conner", "Berlin", "President John F. Kennedy", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "keskes", "1977", "John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez, popular environmentalist David Suzuki,", "New York City", "a man who makes potions in a traveling show", "2000", "mule, deer, white-tailed deer, moose, elk and caribou", "Fabbrica Italiana Automobili Torino", "the first Sunday in November", "the relative units of force and mass then are fixed", "woman", "two", "August 10, 1933", "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Sochi, Russia", "those who already hold wealth have the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "B. Traven", "the Disney-Pixar film \" Finding Nemo\"", "the subject of unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH\") as well as paranormal and Fortean subjects in general", "oil prices", "wooded areas", "264,152", "The Institute for Advanced Study (IAS) in Princeton, New Jersey, in the United States, is an independent, postdoctoral research center for theoretical research and intellectual inquiry founded in 1930 by American educator Abraham Flexner", "The 7.92\u00d757mm Mauser cartridge was adopted by the German Empire in 1903/1905, and was the German service cartridge in both World Wars.", "high pressure"], "metric_results": {"EM": 0.125, "QA-F1": 0.2944244382566751}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.3333333333333333, 1.0, 0.4, 0.0, 0.8, 1.0, 0.9230769230769231, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.19999999999999998, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.37037037037037035, 0.3636363636363636, 0.6666666666666666, 0.10526315789473684, 0.0, 0.0, 0.0, 0.2285714285714286, 0.2727272727272727, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-489", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["capital of taiwan", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "1980s", "John M. Grunsfeld", "Detroit", "your song", "2003", "every year", "NTV", "the second Sunday of March", "fixed", "agatha christie", "porto", "August 10, 1933", "one - mile - wide", "vancouver", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "Fortean", "inflation", "wooded areas", "247,597", "The Institute for Advanced Study", "German service cartridge", "DC"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9350961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5233", "before_prediction": "Fabbrica Italiana Automobili Torino", "after_prediction": "NTV"}], "retained_ids": ["mrqa_hotpotqa-validation-2243", "mrqa_squad-validation-2493", "mrqa_hotpotqa-validation-2332"], "fixed_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-489", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-1276"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "Sarajevo", "Isabella (Belle) Baumfree", "Vulcan", "14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "The antichrist of 2 Thessalonians 2", "Aristotle", "Charlton Heston", "anti-inflammatory molecules", "vUHMOaD/JVI aiAQBAJA jaMOJOD", "vick", "money", "the U.S. federal government", "son et lumi\u00e8re", "the Karluk Kara-Khanid ruler", "Sochi, Russia", "right", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "NASA immediately convened an accident review board", "vida Goldstein", "shorthand typist", "30", "the Secret Intelligence Service", "100 billion", "et tu, brute", "photolysis", "4.7 / 5.5 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.25, "QA-F1": 0.3131743777056277}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 0.2857142857142857, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "Sarajevo", "Isabella (Belle) Baumfree", "corgi", "every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "the foundations of the Reformation placing them on prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "the force of law, if based on the authority derived from statute or the Constitution itself", "son et lumi\u00e8re", "the Uighurs surrendered peacefully without violently resisting", "Sochi, Russia", "right", "Hudson Bay", "immediately", "new Zealand", "shorthand", "30 Major League Baseball teams and their 160 minor league baseball affiliates", "Secret Intelligence Service", "neurons", "julius caesar", "photolysis", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.75, "QA-F1": 0.8086038501939237}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.375, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5882352941176471, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-4953", "before_prediction": "14th to 17th centuries", "after_prediction": "every year between 1346 and 1671"}], "retained_ids": ["mrqa_squad-validation-395", "mrqa_triviaqa-validation-1571", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-4076", "mrqa_triviaqa-validation-4123", "mrqa_squad-validation-3617", "mrqa_hotpotqa-validation-178"], "fixed_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_squad-validation-8247", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "unfixed_ids": ["mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1859", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791"], "instant_fixing_rate": 0.7083333333333334, "instant_retention_rate": 0.8749999989062499}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Kishore Kumar", "Gaels", "Three-card brag", "d\u00edsir", "cave lion", "Russian film industry", "sediment load", "Washington metropolitan area", "a GTPase responsible for endocytosis in the eukaryotic cell", "User State Migration Tool", "Ordos City China Science Flying Universe Science and Technology Co.", "ferrisbee", "PPG Paints Arena, Pittsburgh, Pennsylvania", "jewry wall museum", "Section 30 of the Teaching Council Act 2001", "Wilbur", "In 1984, Congress passed the National Minimum Drinking Age Act, which required states to raise their ages for purchase and public possession to 21 by October 1986 or lose 10 % of their federal highway funds", "quasars", "Monsoon", "Romansh", "Tudor king", "MIX 94.5", "Q Branch", "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "the division of labour, productivity, and free markets", "Margaret Pellegrini", "Whitney Houston", "Nebula Award", "conservative", "king David", "American singer Elvis Presley"], "metric_results": {"EM": 0.0625, "QA-F1": 0.17346906565656567}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.05, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.1111111111111111, 0.0, 0.33333333333333337, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "Three-card brag", "Idisi", "lion", "The cinema of Russia", "sediment load", "FedExField in Landover, Maryland", "the scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment", "Windows Easy Transfer", "Ordos City", "franscioni", "Duquesne University", "le Leicester", "Section 30", "Paul Lynde", "October 1986", "huge-LQG", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george III", "5AA", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret cra Thatcher", "jonathan", "Hugo Peretti"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8742072000326717}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7547169811320755, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-1592", "mrqa_squad-validation-9355"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_naturalquestions-validation-3058", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "unfixed_ids": ["mrqa_hotpotqa-validation-1391", "mrqa_naturalquestions-validation-10355", "mrqa_triviaqa-validation-4955", "mrqa_triviaqa-validation-684", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-8338", "mrqa_triviaqa-validation-791"], "instant_fixing_rate": 0.7666666666666667, "instant_retention_rate": 0.999999995}, {"timecode": 42, "before_eval": {"predictions": ["Daryl Hannah", "cavatelli, acini di pepe, pastina, orzo, etc.", "boston", "independence from the Duke of Savoy through an alliance between the city-state of Geneva and the Swiss Confederation", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "questions about the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "paid professionals", "mistreatment from government officials", "a large Danish shipping company that operates passenger and freight services across northern Europe", "second vice-captain", "jonathan", "the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position )", "glucose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "public and private collections in the United States and abroad", "one of sixteen personality types", "Thursday", "yellow", "all prescribed medications prior to dispensing and administration to the patient", "jupiter", "navigator and expedition leader", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "\"St. Elmo's Fire\"", "The Private Education Student Financial Assistance", "wood", "to raise money to rebuild St. Peter's Basilica in Rome", "colonies", "two forces, one pointing north, and one pointing east", "Bills", "Jack Murphy Stadium", "hierarchy theorems"], "metric_results": {"EM": 0.09375, "QA-F1": 0.21253390062165217}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.9333333333333333, 0.0, 0.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.7222222222222222, 0.0, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.10526315789473685, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "the ozone generated in contact with the skin", "the American Civil War", "Chartered", "mistreatment from government officials", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "Introverted Sensing ( Si )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "mars", "feats of exploration", "a piston", "rob lowe", "The Private Education Student Financial Assistance", "bow", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9501488095238095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-1429", "mrqa_squad-validation-7034", "mrqa_squad-validation-9452"], "fixed_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "unfixed_ids": ["mrqa_squad-validation-6735", "mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-4842"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.9999999966666667}, {"timecode": 43, "before_eval": {"predictions": ["8 m (50 ft)", "tile", "Indiana", "temple square", "French", "a sailor coming home from a round trip", "domain name www.example.com", "the immune system is less active than normal", "Py", "natural-ing Ingredients- only personal care products", "spider", "Rigoletto", "land area", "third-most abundant element in the universe", "furniture", "169 national organisations governed by the World Organization of the Scout Movement", "brazil", "Nicholas Stone", "Algernod Lanier Washington", "English rock band the Outfield", "Croatia", "Michael Edwards", "railway locomotives", "Michael Todd", "the Moon's ecliptic longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0", "William Hartnell", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "many areas of technology incidental to rocketry and manned spaceflight", "eve", "615 square kilometers", "myrrh"], "metric_results": {"EM": 0.125, "QA-F1": 0.2625401097440571}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.3333333333333333, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7222222222222223, 0.0, 0.8571428571428571, 1.0, 0.4210526315789474, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "after_eval": {"predictions": ["Niagara Falls", "15", "Indiana", "salt lake city", "Italian", "sailor", "subdomain", "recurring and life-threatening infections", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third-most", "IKEA", "169", "mexico", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Plies", "English rock band the Outfield", "tennis", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong", "road engines", "richard burton", "new moon, first quarter, full moon, and third quarter ( also known as last quarter )", "Sergeant Claude Snudge", "Yuan T. Lee", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "mitochondrial Eve", "237", "matthew"], "metric_results": {"EM": 0.875, "QA-F1": 0.9024305555555555}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.1111111111111111, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7641", "before_prediction": "Michael Edwards", "after_prediction": "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong"}], "retained_ids": ["mrqa_triviaqa-validation-7538", "mrqa_naturalquestions-validation-5822", "mrqa_hotpotqa-validation-4624"], "fixed_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "unfixed_ids": ["mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "graduation scales", "2003", "cricket", "sweden", "campaign setting", "2003", "867 feet (265 m)", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7", "Christopher Lee as Count Dooku / Darth Tyranus", "second most commonly named \"dream college\" both for students and parents", "Tikki Tikki Tembo", "other healthcare professionals", "increased patient health outcomes and decreased costs to the health care system", "treble clef", "Gabriel Alberto Azucena", "125 km / h", "the Trinit\u00e0 dei Monti", "December 1, 2009", "Estelle Sylvia Pankhurst", "euro Union", "philosophical advocate and practitioner of the scientific method", "mexico", "Ministry of Corporate Affairs", "Irish", "ancient cult activity as far back as 7th century BCE. Numa Pompilius is believed to have built this temple along with the original Regia and House of the Vestal Virgins in its original form.", "bont\u00eb", "energy-storage molecules ATP and NADPH", "ast Hubble", "Sanctifying Grace", "Christ lag"], "metric_results": {"EM": 0.125, "QA-F1": 0.2768179736929737}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.19999999999999998, 0.0, 1.0, 0.4, 0.0, 0.4, 1.0, 0.15384615384615385, 0.7272727272727273, 0.42857142857142855, 0.0, 0.0, 0.39999999999999997, 0.0, 0.0, 0.5, 0.0, 0.0, 0.8, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "after_eval": {"predictions": ["Wakanda", "more experience and higher education", "2003 for the inter-county competition in England and Wales", "London", "sweden", "published campaign settings", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "the Hebrew name Immanu'el ( \u05e2\u05b4\u05de\u05b8\u05bc\u05e0\u05d5\u05bc\u05d0\u05b5\u05dc \u202c, which means `` God with us. '' )", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Anakin Skywalker", "second most commonly", "ikki tikki tembo-no sa rembo- chari bari ruchi-pembo", "all health care settings", "more integral within the health care system", "music", "Lecrae Devaughn Moore", "Mumbai Rajdhani Express", "Rome", "May 18, 2010", "Sylvia Pankhurst", "mexico", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "hubble", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8445903361344538}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.2857142857142857, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6015", "before_prediction": "King T'Chaka of the African nation Wakanda", "after_prediction": "Wakanda"}, {"id": "mrqa_naturalquestions-validation-10612", "before_prediction": "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "after_prediction": "the Hebrew name Immanu'el ( \u05e2\u05b4\u05de\u05b8\u05bc\u05e0\u05d5\u05bc\u05d0\u05b5\u05dc \u202c, which means `` God with us. '' )"}], "retained_ids": ["mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5696"], "fixed_ids": ["mrqa_squad-validation-2236", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_squad-validation-6319", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "unfixed_ids": ["mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-5022"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.49999999875}, {"timecode": 45, "before_eval": {"predictions": ["mary Ann spillane", "Detroit Lions", "perique", "cut off close by the hip", "death penalty", "stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "mexico", "chr\u00e9tien de Troyes", "Mangal Pandey of the 34th BNI", "Colonia Agrippina", "Hoss", "four of the 50 states of the United States in their full official state names", "salt lake city", "eighth series", "the main road through the gated community of Pebble Beach", "Los Angeles", "Korean", "Henry Mills", "\"LOVE Radio\"", "Miami Marlins", "the court from its members for a three - year term", "richard travolta", "Donald Henkel", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "Cashin' In", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "San Francisco Bay Area at Santa Clara, California", "a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Landing Barge, Kitchen or LBK", "peninsula"], "metric_results": {"EM": 0.125, "QA-F1": 0.19765815781440782}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.15384615384615385, 0.0, 1.0, 0.4166666666666667, 0.16666666666666669, 0.4, 0.07142857142857142, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "after_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke it", "under `` the immortal Hawke ''", "death penalty", "frail Catholic saints", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum", "lorne greene", "Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ), Massachusetts, Pennsylvania, and Virginia", "chamonix", "the eighth series", "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove", "St. Louis", "Canadian", "Gareth", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "radicalize the Islamist movement", "People! and The Carnabeats", "Cashin' In", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8857501194457715}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07692307692307693, 0.0, 0.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-3509"], "fixed_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "unfixed_ids": ["mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.9999999975}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That, East 17 and Boyzone", "transgender", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Galileo Galilei", "quantum electrodynamics (or QED)", "Premier League club Swansea City", "art", "Elizabeth Weber", "a first-person psychological horror adventure game", "hundreds of television and radio channels", "\"Waiting for Guffman\"", "1999", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "The Five Doctors", "a 5% abv pale lager produced by Boon Rawd Brewery", "inefficient, because existing resources would allow for production of more of at least one good without sacrificing the production of any other good", "Chu'Tsai", "Liz", "least onerous", "belfast", "Grissom, White, and Chaffee", "multinational retail corporation", "passion fruit", "Natya Shastra", "salt water marshes", "paris", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "emperor of Austria"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3639948593073593}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.25, 1.0, 0.06666666666666667, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.1818181818181818, 0.2857142857142857, 1.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "after_eval": {"predictions": ["baseball", "that continents `` ploughed '' through the sea.", "take that", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "raphaelite", "Joel", "massively multiplayer online role-playing video game", "hundreds", "\"Waiting for Guffman\"", "2003", "The Watermark business park", "apple", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "lago di como", "Grissom, White, and Chaffee", "multinational retail corporation", "passion fruit", "The Natya Shastra is the foundational treatise for classical dances of India, and this text is attributed to the ancient scholar Bharata Muni.", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "inverting a vessel over a burning candle and surrounding the vessel's neck with water", "vienna"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8494318181818181}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-988", "before_prediction": "Natya Shastra", "after_prediction": "The Natya Shastra is the foundational treatise for classical dances of India, and this text is attributed to the ancient scholar Bharata Muni."}], "retained_ids": ["mrqa_squad-validation-5157", "mrqa_hotpotqa-validation-5221", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128"], "fixed_ids": ["mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_triviaqa-validation-4430"], "unfixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-2914", "mrqa_squad-validation-3523"], "instant_fixing_rate": 0.8260869565217391, "instant_retention_rate": 0.8888888879012344}, {"timecode": 47, "before_eval": {"predictions": ["George Bush", "taghrooda", "Burnley", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "big - name lawyers", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "quit after five months", "leeds", "star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "heathrow", "face-to-face interaction", "William Strauss", "monophyletic", "insects", "specific catechism questions", "a pH indicator, a color marker, and a dye", "about 50% oxygen composition at standard pressure", "belfast", "John Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Western Kentucky", "car crash", "Jude", "mcdonald's", "work in a bridal shop", "Jocelyn Flores", "stagnant wages for the working class amidst rising levels of property income for the capitalist class"], "metric_results": {"EM": 0.3125, "QA-F1": 0.3885240307937676}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5454545454545454, 0.0, 0.10526315789473682]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "horse racing", "New Zealand national team", "Kumbum Monastery or Ta'er Shi near Xining", "Styal Mill", "William Jennings Bryan", "CGI computer animation", "when they enter the army during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form", "260", "piccadilly", "Neighbourhood", "The Washington Post", "tentacles", "insects", "specific catechism questions", "a pH indicator", "about 50% oxygen composition at standard pressure", "belfast", "George Whitefield", "Science and Discovery", "1 were considered a prime", "Campbellsville University", "james dean", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita", "XXXTentacion", "less workers are required in proportion to capital inputs, increasing unemployment (the \"reserve army of labour\")"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8683662280701754}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-5305", "before_prediction": "star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "after_prediction": "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form"}], "retained_ids": ["mrqa_hotpotqa-validation-5788", "mrqa_naturalquestions-validation-2143", "mrqa_triviaqa-validation-1256", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_squad-validation-3685", "mrqa_squad-validation-1609", "mrqa_hotpotqa-validation-4173"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092"], "unfixed_ids": ["mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_triviaqa-validation-4298", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.7727272727272727, "instant_retention_rate": 0.8999999991}, {"timecode": 48, "before_eval": {"predictions": ["Anthony John Herrera", "Good Kid, M.A.a.D City", "Yosemite National Park", "Interventive treatment", "3", "Bishop Reuben H. Mueller", "ry Charles", "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "margaret Thatcher", "UNESCO", "Anfernee Simons and Thon's brother, Matur Maker", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California", "God's grace ( which Cannot be earned) alone can make them just", "annuity", "twin sister", "Buffalo Bill", "justice resides", "French Union", "largely determined by President Woodrow Wilson, who had shown little interest in foreign affairs before entering the White House in 1913", "cappuccino", "halal meat", "Hecuba", "that the basics of Christian faith would not just be learned by rote, \"the way monkeys do it\" but understood", "Wylie Draper", "political role for Islam", "the university's off- Campus rental policies", "Manley MacDonald", "New England Patriots", "famine, and weather"], "metric_results": {"EM": 0.1875, "QA-F1": 0.33702876984126984}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.22222222222222218, 0.0, 1.0, 0.22222222222222224, 0.25, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2666666666666667, 0.4, 0.6666666666666665, 0.4, 0.0, 0.8571428571428571]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "Yosemite National Park", "interventive", "3", "The Methodist Church", "georgia", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "UNESCO", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "not given at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "neutrality", "coffee", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull, as well as painter Manley MacDonald.", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9270833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9860", "before_prediction": "Bishop Reuben H. Mueller", "after_prediction": "The Methodist Church"}], "retained_ids": ["mrqa_triviaqa-validation-3967", "mrqa_naturalquestions-validation-49", "mrqa_triviaqa-validation-2849", "mrqa_squad-validation-8248", "mrqa_naturalquestions-validation-4043"], "fixed_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-2582"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.8333333319444445}, {"timecode": 49, "before_eval": {"predictions": ["Jeeps", "AOL", "Timur", "R.E.M.", "Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna", "12", "fear of people or society", "1937", "improved", "tiltrotor/tilt-wing concept", "electrical transmission equipment and also seemed to think it was better to develop an electrical utility than invent new systems", "Marxist", "variation in plants", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades.", "3,600", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "falcon", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Wisconsin", "uneven trade agreements", "Ugali with vegetables, sour milk, meat, fish or any other stew", "ATP energy", "Nebraska", "Ruth Elizabeth \"Bette\" Davis", "uranium", "7 December 2004"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2628959101035563}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.9655172413793104, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.0, 0.08695652173913043, 0.0, 0.0, 0.1111111111111111, 0.09523809523809525, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna", "at the age of 12", "meat", "1895", "improved markedly", "a biplane capable of taking off vertically", "assigned them to the company in lieu of stock", "communist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "imperialism", "chakula cha jioni or known simply as \"chajio\")", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8940098644046013}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8518", "before_prediction": "Ugali with vegetables, sour milk, meat, fish or any other stew", "after_prediction": "chakula cha jioni or known simply as \"chajio\")"}], "retained_ids": ["mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-1023", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1772"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "unfixed_ids": ["mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.7999999984}, {"timecode": 50, "before_eval": {"predictions": ["basketball", "Igor Stravinsky, Carl Orff, Paul Hindemith, Richard Strauss, Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman express", "The Rock", "Big Machine Records", "The issues of conflicting territorial claims between British and French colonies in North America were turned over to a commission to resolve", "the Hindu sage Valmiki", "Epistle to Ramsay", "every two to six years ( depending on the positions being filled with most positions good for four years )", "dissension and unrest", "association football YouTube channel and website directed at Arsenal supporters", "2016", "Dan Castellaneta", "2007", "Wicked Twister", "arithmetic", "rocket designer and creator of the Atlas ICBM", "shoe", "unclear as to how or whether this connection is relevant on microscales", "supernatural psychological horror", "the House of Representatives", "The Revenant", "evening of the same day", "Blue (Da Ba Dee)", "Constitution", "The Missouri Tigers football program represents the University of Missouri in college football and competes in the Football Bowl Subdivision (FBS) of the National Collegiate Athletic Association (NCAA)", "Dennis C. Stewart", "the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return '' )", "5", "konya", "If the car is slowed initially by manual use of the automatic gear box"], "metric_results": {"EM": 0.125, "QA-F1": 0.3285380213669687}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.4210526315789474, 0.1081081081081081, 0.6666666666666666, 0.0, 1.0, 0.3076923076923077, 0.6666666666666666, 0.0, 0.45454545454545453, 0.0, 0.18181818181818182, 0.0, 0.4, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.4, 0.4, 0.6666666666666666, 0.0, 0.0, 0.8400000000000001, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_naturalquestions-validation-7707", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-118", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_hotpotqa-validation-3545", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239", "mrqa_naturalquestions-validation-3022"], "after_eval": {"predictions": ["basketball", "Igor Stravinsky, Carl Orff", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman", "sherry agonistes", "Big Machine Records", "claimed by both sides", "traditionally ascribed to the Hindu sage Valmiki", "Scots in origin", "every two to six years ( depending on the positions being filled with most positions good for four years )", "Outlaws", "YouTube", "2007", "Daniel Louis Castellaneta", "1994", "Wicked Twister", "subtraction", "rocket", "khrushchev", "coherent theory of quantum gravity", "American supernatural psychological horror film", "raising revenue", "dicaprio", "evening", "Blue", "Constitution", "Faurot Field", "Lorenzo Lamas", "an extended metaphor to compare death with crossing the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return", "5", "konya", "upon braking to a full stop"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7878680115522221}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.1081081081081081, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.9824561403508771, 0.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-290", "before_prediction": "arithmetic", "after_prediction": "subtraction"}], "retained_ids": ["mrqa_triviaqa-validation-7291", "mrqa_hotpotqa-validation-5623", "mrqa_hotpotqa-validation-4497"], "fixed_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-3395", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_hotpotqa-validation-2635", "mrqa_hotpotqa-validation-3545", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-3022"], "unfixed_ids": ["mrqa_naturalquestions-validation-10625", "mrqa_triviaqa-validation-813", "mrqa_naturalquestions-validation-7707", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239"], "instant_fixing_rate": 0.7142857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 51, "before_eval": {"predictions": ["third", "the pulmonary arteries", "a card from a pack of playing cards by Alice", "Los Angeles", "Alex Breckenridge", "seven", "Schr\u00f6dinger equation", "cobalt", "Ashland", "public schools in Alabama, Arkansas, Georgia, Louisiana, Mississippi, Oklahoma, Tennessee and Texas", "Ghostface mask", "Roger Staubach", "AC induction motor and transformer", "Eric Morecambe", "rock band Queens of the Stone Age", "the port of Nueva Espa\u00f1a", "Robert John Day", "1775\u20131795", "Empiricism", "w Somerset maugham", "Pabst Brewing Company", "redistributive", "Peter Dinklage", "ozzie the Owl", "Content", "Saint Peter ( the keeper of the `` keys to the kingdom '' )", "Fourth Home Rule Bill", "t\u00e2n Ni\u00ean", "Gebhard v Consiglio dell\u2019 Ordine degli Avvocati e Procuratori di Milano", "Belarus", "1835", "The Virgin Queen, Gloriana or Good Queen Bess"], "metric_results": {"EM": 0.09375, "QA-F1": 0.24444560225810225}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.4324324324324324, 0.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.4444444444444445, 0.33333333333333337, 0.2666666666666667, 0.5, 0.0, 0.4, 1.0, 0.0, 0.0, 0.4, 0.0, 0.3636363636363636, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.14285714285714288, 1.0, 0.4, 0.4444444444444445]}}, "error_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_hotpotqa-validation-5740", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_hotpotqa-validation-596", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_hotpotqa-validation-2549", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "after_eval": {"predictions": ["three", "the right ventricle", "a card from a pack of playing cards by Alice, yet somehow she is able to talk and is the ruler of the lands in the story, alongside her tiny husband, the King of Hearts", "Riverside", "Emily Perkins", "seven", "Newtonian equations", "caviar", "Ashland is home to Scribner-Fellows State Forest", "the South", "edvard munch", "Roger Thomas Staubach (born February 5, 1942)", "transformer", "Bring Me Sunshine ( 1994) was originally a three-part retrospective in tribute to Eric Morecambe", "rock band", "the Americas", "Bob Day", "1775", "epistemology", "Gauguin", "Miller Brewing", "positive", "Tyrion Lannister ( season 1 -- present ) portrayed by Peter Dinklage", "owls", "information", "Saint Peter", "An Act to provide for the better government of Ireland", "vietnamese new year", "Commission v Italy the Court of Justice", "Belarus", "[O.S. 6 January] 1835", "The Virgin Queen"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-971", "before_prediction": "1775\u20131795", "after_prediction": "1775"}], "retained_ids": ["mrqa_hotpotqa-validation-120", "mrqa_hotpotqa-validation-3033"], "fixed_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_hotpotqa-validation-5740", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_hotpotqa-validation-596", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_hotpotqa-validation-2549", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.6666666644444444}, {"timecode": 52, "before_eval": {"predictions": ["Myllokunmingia", "Edd Kimber, Joanne Wheatley, John Whaite, Frances Quinn, Nancy Birtwhistle, Nadiya Hussain, Candice Brown and Sophie Faldo", "Brenda", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "`` asphyxia '' ( cutting off the oxygen supply )", "guitars", "Carey Mulligan, Matthias Schoenaerts, Michael Sheen, Tom Sturridge and Juno Temple", "The Worm", "a double bottom 5 feet 3 inches ( 1.60 m ) deep supported 300 frames, each between 24 inches ( 61 cm ) and 36 inches ( 91 cm ) apart and measuring up to about 66 feet ( 20 m ) long", "the best five card poker hand from any combination of the seven cards of the five community cards and their own two hole cards", "German hymns", "Bury Football Club", "Al Gore", "Amos McCracken", "the NFC Championship Game", "Tom Robinson", "Buzz", "filming began in September 2000 at Leavesden Film Studios and in London, with production ending in July 2001", "the port city of Aden", "quickly", "about two-thirds the size of cytoplasmic ribosomes ( around 17 nm vs 25 nm)", "The leopard", "the service sector", "Florida", "a distilled, highly alcoholic (45\u201374% ABV / 90\u2013148 U.S. proof) beverage", "a sitcom about two incompetent science teachers who work at a college that specialises in drama", "Bolton", "British", "every aspect of public and private life wherever feasible", "anarchists", "Just under 540,800", "British Sky Broadcasting Group plc"], "metric_results": {"EM": 0.1875, "QA-F1": 0.32474208631281}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.4, 0.21052631578947367, 1.0, 0.16, 0.0, 0.0, 0.3076923076923077, 1.0, 0.0, 0.0909090909090909, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809525, 0.4, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8750000000000001, 1.0, 0.5, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_squad-validation-7240", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-2918", "mrqa_squad-validation-2772"], "after_eval": {"predictions": ["believed to be the Myllokunmingia", "Joanne Wheatley", "Brenda", "arbitrary integers", "cooling", "Les Paul", "Matthias Schoenaerts", "The Worm", "31 March 1909", "seven", "singing of German hymns", "Bury, Greater Manchester, England", "Benazir Bhutto", "American", "Super Bowl", "Tom Robinson", "marv", "14 November 2001", "Aden", "quickly", "around 17 nm", "Panthera pardus", "manufacturing", "Florida", "the green fairy", "david Mitchell", "Rivington Moor", "American", "every aspect of public and private life", "anarchists", "540,800", "BSkyB"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-4073", "mrqa_hotpotqa-validation-4188", "mrqa_naturalquestions-validation-7461", "mrqa_squad-validation-6389", "mrqa_naturalquestions-validation-2425", "mrqa_squad-validation-6709"], "fixed_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_squad-validation-7240", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-2918", "mrqa_squad-validation-2772"], "unfixed_ids": ["mrqa_triviaqa-validation-498"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.9999999983333333}, {"timecode": 53, "before_eval": {"predictions": ["Following the election of the UK Labour Party to government in 1997", "Levi's Stadium", "c 1600", "Professor Moriarty", "Atticus Finch", "1763", "raspberries", "~74,000 (BP = Before Present)", "catherine o'Leary", "Bronwyn Kathleen Bishop", "guidance and intervention from the European empire to aid in the governing of a more evolved social structure", "5", "Missouri", "\"full-fledged colonial rule\"", "a violation of nature", "kairobi", "Richard Attenborough, Nicol Williamson, Derek Jacobi, and John Gielgud", "Adam Smith", "25 June 1932", "gaspare ghiretti", "James A. Garfield", "stop motion animation", "chromosome", "Evey's mother", "10", "a matter of custom or expectation", "Joudeh Al - Goudia family", "Wes Unseld", "1912", "nitrogen dioxide", "flooding and sedimentation", "Daniel Handler"], "metric_results": {"EM": 0.25, "QA-F1": 0.35572448384948385}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.4, 1.0, 0.0, 0.8571428571428571, 0.0]}}, "error_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-169", "mrqa_squad-validation-5390", "mrqa_squad-validation-7700", "mrqa_triviaqa-validation-776", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_triviaqa-validation-2821", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_squad-validation-6877", "mrqa_naturalquestions-validation-678", "mrqa_hotpotqa-validation-5614", "mrqa_triviaqa-validation-177", "mrqa_squad-validation-9354", "mrqa_triviaqa-validation-3268"], "after_eval": {"predictions": ["1997", "two", "c1600", "Professor Moriarty to the Doctor's Sherlock Holmes", "'The Keys of the Kingdom'", "1763", "tart lambics", "~74,000 (BP = Before Present)", "Great Chicago Fire", "Kathryn Jean Martin", "guidance and intervention from the European empire to aid in the governing of a more evolved social structure", "hearts", "american civil war", "formal", "a violation of nature", "kenya", "John Gielgud", "david elgar", "1952", "violin", "Charles Guiteau", "seasonal television specials, particularly its work in stop motion animation", "chromosomes", "Evey's mother", "10", "the desire to prevent things that are indisputably bad", "the Sunni Muslim family", "Westley Sissel Unseld", "1912", "oxygen", "increasing land clearance (Bronze Age agriculture) in the upland areas (central Germany)", "Daniel Handler"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8258928571428572}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3107", "before_prediction": "Atticus Finch", "after_prediction": "'The Keys of the Kingdom'"}, {"id": "mrqa_naturalquestions-validation-9368", "before_prediction": "chromosome", "after_prediction": "chromosomes"}], "retained_ids": ["mrqa_hotpotqa-validation-4571", "mrqa_squad-validation-9144", "mrqa_naturalquestions-validation-1161", "mrqa_hotpotqa-validation-4294", "mrqa_squad-validation-274", "mrqa_naturalquestions-validation-6970"], "fixed_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-169", "mrqa_squad-validation-5390", "mrqa_squad-validation-7700", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_naturalquestions-validation-6485", "mrqa_triviaqa-validation-2821", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_squad-validation-6877", "mrqa_naturalquestions-validation-678", "mrqa_hotpotqa-validation-5614", "mrqa_triviaqa-validation-177"], "unfixed_ids": ["mrqa_triviaqa-validation-776", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-6410", "mrqa_squad-validation-9354", "mrqa_triviaqa-validation-3268"], "instant_fixing_rate": 0.7916666666666666, "instant_retention_rate": 0.7499999990624999}, {"timecode": 54, "before_eval": {"predictions": ["The Christmas Invasion", "warkeeping force", "an expression of Priestley's socialist political principles", "March 9 to 18", "10 November 2017", "Romancing the Stone", "oral mucosa ( a mucous membrane ) lining the mouth and also on the tongue and palates and mouth floor", "The 8th Habit", "Anishinaabeg", "general medical advice and a range of services that are now performed solely by other specialist practitioners, such as surgery and midwifery", "warm and is considered to be the most comfortable climatic conditions of the year", "pierowall", "to foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "22 September 2015", "\"Murder Request\") is a 2015 South Korean crime thriller film directed by Son Yong-ho", "achilles heel", "unexploded mines", "annually in late January or early February", "Marigold Newey", "the duodenum", "curved croissants", "Cuyler Reynolds", "Lacoste, France", "rum", "chiesman", "Black Ravens", "saved something from the disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac, including caches of supplies destined for New France's western forts and furs destined for Europe", "online casinos, where permitted by law", "Americana Manhasset", "\"Shoot Straight from Your Heart\"", "james david", "Kony Ealy"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26712664932573815}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.13333333333333333, 0.7272727272727273, 0.5, 0.2666666666666667, 0.125, 0.0, 0.0, 0.08695652173913042, 0.0, 0.0, 0.4666666666666667, 1.0, 0.2666666666666667, 0.0, 0.0, 0.4444444444444444, 0.0, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0588235294117647, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_hotpotqa-validation-5109", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "after_eval": {"predictions": ["The Christmas Invasion", "purple heart medal", "a scathing critique of the hypocrisies of Victorian / Edwardian English society", "2018 ran from March 9 to 18", "2017", "the Michael Douglas film, The Jewel of the Nile, the sequel to the hit blockbuster film, Romancing the Stone", "the mouth", "The 7 Habits of Highly Effective People", "Odawa", "other herbs not listed", "tropical desert climate", "orkney", "reduce poverty around the world", "22 September 2015", "\"Murder Request\"", "paris", "bees", "as early as January 3, and as late as February 12", "Corinna and seven-time Formula One World Champion Michael Schumacher", "in the duodenum by enterocytes of the Duodenal lining", "tesco", "Cuyler Reynolds", "Lacoste, France", "whiskey", "gloucestershire", "Black Ravens", "recalled and replaced by Jeffery Amherst", "outside of casinos", "Gucci", "Feels Like Love", "wuthering heights", "the Chicago Bears"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9975961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-7812", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-773", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-2058"], "fixed_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_hotpotqa-validation-5109", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "unfixed_ids": ["mrqa_squad-validation-10293"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.9999999980000001}, {"timecode": 55, "before_eval": {"predictions": ["2,000", "John Elway", "France", "relocated to Miami", "Celtic nations", "stromal connective tissue", "tunisia", "across the United States and around the world", "pangea", "a job that few require (low demand)", "octagon", "\"Rock With You\"", "Scott Mosier", "Kujan", "weaving", "art of the book and architecture ; and also including ceramics, metal, glass, and gardens", "sepoys of the Company's army", "DeMarcus Ware as time expired in the half", "Jack Nicholson -- Chinatown as J.J. `` Jake '' Gittes", "Dan Brown", "boxing", "the port city of Kaffa in the Crimea in 1347", "Charbagh structure", "Iranian", "paris", "Landwehr", "often given priority because his work was published first", "as part of a novena", "accommodationism", "Parliamentarians ( `` Roundheads '' )", "Bantu", "a lower index of refraction, typically a cladding of a different glass, or plastic"], "metric_results": {"EM": 0.09375, "QA-F1": 0.21472381784881783}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.4, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.27272727272727276, 0.0, 0.0, 0.0, 0.06666666666666667, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 0.0, 0.0, 1.0, 0.0, 0.36363636363636365]}}, "error_ids": ["mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_hotpotqa-validation-3062", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_squad-validation-7407", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_triviaqa-validation-7689", "mrqa_hotpotqa-validation-4215", "mrqa_squad-validation-3450", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7078"], "after_eval": {"predictions": ["10,000", "John Elway", "England", "gets relocated to Miami", "Brittany, Cornwall, Ireland, Isle of Man, Scotland and Wales", "Stromal cells", "tiger woods", "numerous", "texas", "low demand", "1080", "Martin Scorsese (taxi Driver, Raging Bull, Goodfellas)", "Kevin Smith", "kevin spacey", "edmund cartwright", "book and architecture ; and also including ceramics, metal, glass, and gardens", "sepoys of the Company's army in the garrison town of Meerut, 40 miles northeast of Delhi ( now Old Delhi )", "sacked", "Art Carney", "Tom Hanks", "from boxing, where a boxer who is still on their feet but close to being knocked down can be saved from losing by the bell ringing to indicate the end of the round", "Sicily", "the Persian gardens particularly the Charbagh structure", "German", "Cyclops Skulls", "Menges", "his work was published first", "Good Friday", "separationism", "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' )", "Niger\u2013Congo", "cylinder of glass or plastic that runs along the fiber's length"], "metric_results": {"EM": 0.75, "QA-F1": 0.8810019841269842}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.16666666666666669, 0.9142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.8571428571428572]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-5518", "before_prediction": "2,000", "after_prediction": "10,000"}, {"id": "mrqa_naturalquestions-validation-570", "before_prediction": "Parliamentarians ( `` Roundheads '' )", "after_prediction": "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' )"}], "retained_ids": ["mrqa_squad-validation-378"], "fixed_ids": ["mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_hotpotqa-validation-3062", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_squad-validation-7407", "mrqa_triviaqa-validation-4620", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_hotpotqa-validation-5543", "mrqa_hotpotqa-validation-4215", "mrqa_squad-validation-3450", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_hotpotqa-validation-2699"], "unfixed_ids": ["mrqa_triviaqa-validation-5479", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_naturalquestions-validation-819", "mrqa_triviaqa-validation-7689", "mrqa_naturalquestions-validation-7078"], "instant_fixing_rate": 0.7931034482758621, "instant_retention_rate": 0.3333333322222222}, {"timecode": 56, "before_eval": {"predictions": ["Randy", "1922 to 1991", "predictions that can be tested in various ways", "the city council", "moral conservatism, literalism, and the attempt \"to implement Islamic values in all spheres of life\"", "Tesla demonstrated a series of electrical effects previously performed throughout America and Europe,:76 included using high-voltage, high-frequency alternating current to light a wireless gas-discharge lamp", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "39, Newton was 26", "information in a smartphone - like, hands - free format", "increased their reserves (by expanding their money supplies) in amounts far greater than before", "k Friedrich niet Nietzsche", "transgender", "tunisia", "Robert \"Bumps\" Blackwell, Enotris Johnson, and Little Richard", "five", "teachers' mental and physical health, productivity, and students' performance", "kevinji kita", "d'Artagnan", "when each of the variables is a perfect monotone function of the other", "kevin", "1932", "Angus Stanley King Jr. (born March 31, 1944) is an American politician and attorney who is the junior United States Senator from Maine", "ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid", "former Manchester United and Danish international goalkeeper Peter Schmeichel", "highest commissioned SS rank", "ERINys", "lowest known subaerial volcanic vents in the world, at 45 m ( 150 ft ) or more below sea level", "'X&Y'", "in Egypt, the only part of the country located in Asia", "Alison Steadman", "in the retina of mammalian eyes ( e.g. the human eye )", "financial services and markets"], "metric_results": {"EM": 0.09375, "QA-F1": 0.19806631321576973}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 0.07692307692307691, 0.3636363636363636, 0.0, 0.0, 0.08333333333333333, 0.6666666666666666, 0.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08695652173913045, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_naturalquestions-validation-1787", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-4640", "mrqa_hotpotqa-validation-1912", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "after_eval": {"predictions": ["Donna", "1922 to 1991", "in general there is a continuous process that includes observations about the natural world", "the city council", "Islamism", "Tesla Polyphase System", "8 bytes", "13 years and 48 days", "optical head - mounted display", "Because oil was priced in dollars, oil producers' real income decreased", "nietzsche", "technical director", "percy toplis", "Robert \"Bumps\" Blackwell", "five books", "organizational change, relationships with students, fellow teachers, and administrative personnel, working environment, expectations to substitute", "r-2", "arand de sill\u00e8gue d'Athos", "Pearson's correlation assesses linear relationships", "melbourne", "1932", "March 31, 1944", "organic solvents", "World's Best Goalkeeper", "Reichsf\u00fchrer-SS", "rinys", "a cinder cone volcano in the Danakil Depression, northeast of the Erta Ale Range in Ethiopia", "Coldplay", "in Egypt, the only part of the country located in Asia", "Melanie Walters", "in the fovea centralis", "financial services and markets"], "metric_results": {"EM": 0.71875, "QA-F1": 0.756641604010025}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.631578947368421, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-3372", "before_prediction": "predictions that can be tested in various ways", "after_prediction": "in general there is a continuous process that includes observations about the natural world"}], "retained_ids": ["mrqa_squad-validation-416", "mrqa_hotpotqa-validation-658"], "fixed_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_naturalquestions-validation-1787", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-4640", "mrqa_hotpotqa-validation-1912", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358"], "unfixed_ids": ["mrqa_naturalquestions-validation-7080", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-2701"], "instant_fixing_rate": 0.7241379310344828, "instant_retention_rate": 0.6666666644444444}, {"timecode": 57, "before_eval": {"predictions": ["Saturn", "samuel Johnson", "1.7 billion", "Bathurst is a regional city in the Central Tablelands of New South Wales, Australia.", "April 1948", "In inequality of opportunity", "the use of terms such as penance and righteousness by the Catholic Church in new ways", "FeO (w\u00fcstite) is written as Fe1 \u2212 xO", "chico, Harpo", "materials melted near an impact crater", "a half-penny sales tax", "david paradine", "Neal Dahlen", "paris", "glucose", "Greens", "United States Ship", "reared", "October 15, 1997", "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "modernized the outside of the building", "Greenland shark", "wembroke", "georgia", "tom Sly", "five representatives elected by Single Transferable Vote", "kenpei", "rinald Arthur", "American conservative author and commentator", "kurt gutenbrunner", "Sam the Sham", "three terms"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2612818043884221}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.5882352941176471, 0.0, 0.8571428571428571, 0.35294117647058826, 0.2222222222222222, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.4, 0.3333333333333333]}}, "error_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-2255", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-7226", "mrqa_triviaqa-validation-6053", "mrqa_naturalquestions-validation-4193", "mrqa_triviaqa-validation-5785", "mrqa_triviaqa-validation-7489", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_hotpotqa-validation-3802", "mrqa_hotpotqa-validation-3544", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303", "mrqa_squad-validation-2869", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "after_eval": {"predictions": ["neptune", "james boswell", "1.7 billion", "Bathurst in New South Wales", "in the 1980s", "Inequality of opportunity", "penance and righteousness", "FeO", "marx", "materials melted near an impact crater", "Better Jacksonville Plan", "david frost", "Tom Brady", "gloucestershire", "carbon dioxide", "Labor", "`` United States Ship '' ( USS )", "South Africa", "July 8, 1997", "Book of Job", "modernized the outside", "North Atlantic Ocean and Arctic Ocean", "henry vii", "Treasure Island", "Tommy Sly", "five", "malaysia airlines", "egypt", "son", "veal", "Domingo \"Sam\" Samudio", "two four - year terms"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9206730769230769}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-10657", "before_prediction": "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "after_prediction": "Book of Job"}], "retained_ids": ["mrqa_hotpotqa-validation-1567", "mrqa_squad-validation-4067"], "fixed_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-2255", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-7226", "mrqa_triviaqa-validation-6053", "mrqa_naturalquestions-validation-4193", "mrqa_triviaqa-validation-5785", "mrqa_triviaqa-validation-7489", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_hotpotqa-validation-3802", "mrqa_hotpotqa-validation-3544", "mrqa_triviaqa-validation-6545", "mrqa_squad-validation-2869", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "unfixed_ids": ["mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 58, "before_eval": {"predictions": ["Dutch", "the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "to acquire an advantage without deviating from basic strategy", "the outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall", "Ouseburn valley", "1955", "henry v", "200 horsepower", "Thomas Edison", "Lutheranism", "Night Ranger", "Buzz", "Sarah Winnemucca Hopkins", "mentoring", "levels of economic inequality", "hen Yozhuo", "Enrico Fermi", "Angelina Jolie", "henry", "1979", "mainly civil servants recruited in special university classes", "large areas", "E \u00d7 12", "the medial epicondyle of the humerus from posteriorly, or inferiorly with the elbow flexed", "weight", "john donne", "Liao, Jin, and Song", "`` Central States ''", "pigeons", "electric currents and magnetic fields", "Attack the Block", "William Shakespeare"], "metric_results": {"EM": 0.28125, "QA-F1": 0.328125}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_hotpotqa-validation-5735", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-5104", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-10351", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706", "mrqa_naturalquestions-validation-3470"], "after_eval": {"predictions": ["German", "the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "between 0.5 % and 1 %", "phagosomal", "Ouseburn valley", "1955", "henry v", "100\u20135,000 hp", "Sir William Henry Bragg and William Lawrence Bragg", "German", "`` The Secret of My Success '' ( performed by Night Ranger )", "Honey Nut Cheerios", "Thocmentony", "effective", "levels of economic inequality", "taekwondo", "Enrico Fermi", "Yulia Tym Ukraine", "Timmy Brown", "1982", "civil servants", "large areas in the Amazon forest, is now widely accepted as a product of indigenous soil management", "Q", "ulnar nerve", "forces", "james boswell", "Liao, Jin, and Song", "zh\u014dng ( \u4e2d ) meaning `` central '' or `` middle ''", "pigeons", "electromagnetic field", "Ant-Man", "Juliet"], "metric_results": {"EM": 0.6875, "QA-F1": 0.733047385620915}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5153", "before_prediction": "Dutch", "after_prediction": "German"}, {"id": "mrqa_hotpotqa-validation-4178", "before_prediction": "Angelina Jolie", "after_prediction": "Yulia Tym Ukraine"}, {"id": "mrqa_squad-validation-4233", "before_prediction": "large areas", "after_prediction": "large areas in the Amazon forest, is now widely accepted as a product of indigenous soil management"}, {"id": "mrqa_triviaqa-validation-4817", "before_prediction": "john donne", "after_prediction": "james boswell"}], "retained_ids": ["mrqa_squad-validation-5202", "mrqa_hotpotqa-validation-4035", "mrqa_squad-validation-7345", "mrqa_squad-validation-7880", "mrqa_squad-validation-8193"], "fixed_ids": ["mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_hotpotqa-validation-5735", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-5104", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-10351", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706", "mrqa_naturalquestions-validation-3470"], "unfixed_ids": ["mrqa_squad-validation-9173", "mrqa_triviaqa-validation-6185", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520"], "instant_fixing_rate": 0.7391304347826086, "instant_retention_rate": 0.5555555549382716}, {"timecode": 59, "before_eval": {"predictions": ["GE's four computer sales and service centers (Schenectady, Phoenix, Chicago, and Phoenix) to facilitate a computer time- sharing service", "skin", "Naturalization Act of 1790", "Matthew Vaughn", "2 %", "British Royal Family", "9 at the Century 16 multiplex ( operated by Cinemark ), located at the Town Center at Aurora shopping mall at 14300 E. Alameda Avenue", "John Christopher Lujack Jr. (pronounced Lu' jack", "Suicide Slums", "24\u201310", "kabuki and bunraku", "Of course [the price of oil] is going to rise", "5 mi east of Everest on highway K-20.", "a gestational age of approximately 7 weeks and 5 days", "Kelly Bundy", "Italy", "because they worked on the keels, boats that were used to transfer coal from the river banks to the waiting colliers", "Sir William Bruce", "pachytene stage of prophase I of meiosis during a process called synapsis", "Mario Addison", "321,520", "2017 Major League Baseball (MLB) First-Year Player Draft", "2005", "red deer", "kalapatthar crop.", "Helmuth von Moltke the Younger", "Baloo ( \u092d\u093e\u0932\u0942 Bh\u0101l\u016b, `` bear '' ; Himalayan brown bear )", "the ears of a hound dog", "2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )", "Selznick library", "david dickson", "samoan tala"], "metric_results": {"EM": 0.1875, "QA-F1": 0.23420852444021784}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.05714285714285714, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.08695652173913042, 0.0, 0.0, 1.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.0, 1.0, 0.0, 0.10526315789473684, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_triviaqa-validation-2965", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_squad-validation-825", "mrqa_hotpotqa-validation-1917", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-2525"], "after_eval": {"predictions": ["They lost money from the beginning, and Sinback, a high-level marketing manager, was given the job of turning the business around", "waxy cuticle", "restricted naturalization to `` free white persons '' of `` good moral character ''", "Matthew Vaughn", "4 percent cumulative effect", "the Queen", "Theater 9", "Jim Kelly", "Lex Luthor", "24\u201310", "kabuki and bunraku", "renewal of hostilities in the Arab\u2013 Israeli conflict released the underlying economic pressure on oil prices", "in the U.S. state of Kansas", "an anembryonic gestation", "Kelly Bundy", "vatican city", "keels", "the Queen's gaoler", "pachytene stage of prophase I of meiosis during a process called synapsis", "Norwood", "321,520", "June 12, 2017", "1996", "denisovans", "tajikistan", "Generalfeldmarschall\" (Field Marshal) Helmuth Karl Bernhard von Moltke and served as the Chief of the German General Staff", "Shere Khan", "no conclusive evidence seems to exist", "2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )", "Selznick library", "les dennis", "Western Samoan Tala"], "metric_results": {"EM": 0.75, "QA-F1": 0.8309057971014493}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6956521739130435, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1035", "mrqa_squad-validation-19", "mrqa_hotpotqa-validation-5577", "mrqa_naturalquestions-validation-7035", "mrqa_hotpotqa-validation-3606", "mrqa_squad-validation-5887"], "fixed_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_squad-validation-825", "mrqa_hotpotqa-validation-1917", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_triviaqa-validation-1933"], "unfixed_ids": ["mrqa_triviaqa-validation-2965", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-5649", "mrqa_triviaqa-validation-2525"], "instant_fixing_rate": 0.6923076923076923, "instant_retention_rate": 0.9999999983333333}, {"timecode": 60, "before_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "The Catcher in the Rye", "The nobility of England", "Merv (Turkmen: Merw, \"\u041c\u0435\u0440\u0432\" \u0645\u0631\u0648", "Bendigo and its environs", "Thomas Jefferson", "She became a naturalized American citizen in 1994 and also received Hungarian citizenship in June 2007.", "July 1872", "Boston and Maine Railroad's Southern Division", "James Lofton and Mark Malone as sideline reporters", "the left of the dinner plate", "summer months", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts returned for their respective ninth, eighth, seventh and second series on The Ice Panel", "Quatre \u00e9tudes de rythme (1949\u201350)", "Thailand, Burma, Cambodia, Indonesia and Sri Lanka", "segues", "Under Milk Wood", "tony", "During the reign of King Beorhtric of Wessex ( 786 -- 802 ) three ships of `` Northmen '' landed at Portland Bay in Dorset", "21 kilometres south-east of Adelaide", "Flag Day in 1954", "around 300,000", "1858", "Sexred", "Veronica Lodge", "neo-Nazi", "The New Statesman", "began to shrink", "frequency f", "the \"celebrity criminal\""], "metric_results": {"EM": 0.25, "QA-F1": 0.38024372792595296}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.4347826086956522, 0.25, 1.0, 0.0, 0.0, 0.4, 0.0, 0.23529411764705882, 0.6666666666666666, 1.0, 0.0, 0.888888888888889, 0.0, 0.17391304347826084, 0.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.1904761904761905, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333334, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_squad-validation-2842", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-9053", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_triviaqa-validation-1284", "mrqa_naturalquestions-validation-5798"], "after_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark", "positions 14 - 15, 146 - 147 and 148 - 149", "The Catcher in the Rye", "Anglo-Saxons", "Mary", "Bendigo", "John Locke", "in 1994", "1872", "Boston and Maine Railroad", "Boomer Esiason", "to the left of the dinner plate", "winter", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts returned for their respective ninth, eighth, seventh and second series on The Ice Panel", "third", "Sri Lanka", "extensive use of segues", "dylan thomas", "iron age", "786 -- 802", "Hills", "Flag Day in 1954", "50%", "In 1840", "S\u00e6ward", "Betty", "neo-Nazi", "flashheart", "began to shrink", "from 7023239999999999999 \u2660 2.4 \u00d7 10 Hz ( 1 GeV gamma rays ) down to the local plasma frequency of the ionized interstellar medium ( ~ 1 kHz )", "the \"celebrity criminal\""], "metric_results": {"EM": 0.90625, "QA-F1": 0.9304347826086956}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1124", "before_prediction": "Boston and Maine Railroad's Southern Division", "after_prediction": "Boston and Maine Railroad"}, {"id": "mrqa_squad-validation-8492", "before_prediction": "around 300,000", "after_prediction": "50%"}], "retained_ids": ["mrqa_hotpotqa-validation-425", "mrqa_hotpotqa-validation-949", "mrqa_naturalquestions-validation-6383", "mrqa_hotpotqa-validation-1971", "mrqa_squad-validation-4011", "mrqa_hotpotqa-validation-3681"], "fixed_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_squad-validation-2842", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_squad-validation-9053", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_triviaqa-validation-1284", "mrqa_naturalquestions-validation-5798"], "unfixed_ids": ["mrqa_naturalquestions-validation-1786"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.7499999990624999}, {"timecode": 61, "before_eval": {"predictions": ["The Two Noble Kinsmen", "john Hughes", "San Bernardino", "Judy Collins", "Out of Control", "the 2013 non-fiction book of the same name by David Finkel", "liza tarbuck", "The Frost Report", "fell from his horse", "incitement to terrorism", "Henry and Liza", "Grace O'Malley", "Tamaulipas", "iron", "Elk and Kanawha Rivers", "They circulate and are moved around within plant cells, and occasionally pinch in two to reproduce", "'Bucks Point'", "to `` help bring creative projects to life ''", "church of Christ", "Old World fossil representatives", "group 1 elements, excluding hydrogen ( H ), which is nominally a group 1 element but not normally considered to be an alkali metal as it rarely exhibits behaviour comparable to that of the alkali metals", "Rachel Dratch", "dave brubeck", "thicker consistency and a deeper flavour", "external genitalia", "new pomerania", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "VH1's \"100 Greatest Artists of Hard Rock\"", "after AD 70", "in 1985", "dance", "He was taken prisoner and eventually was convicted of crimes against peace"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2550024536866642}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.4, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.12121212121212122, 0.0, 0.0, 0.33333333333333337, 0.0, 0.4, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "after_eval": {"predictions": ["Edward III", "shermer high school", "Riverside", "Glynis Johns", "1984 to 1985", "Fort Riley, Kansas", "little arrows", "The Frost Report", "hunting", "incitement to terrorism", "two characters, called Henry and Liza", "first flume ride in Ireland", "Mexico City", "silicon", "Elk and Kanawha Rivers", "pinch in two", "'Bucks Point'", "global crowdfunding platform focused on creativity and merchandising", "mormon", "Old World fossil representatives", "group 1", "Jon Hamm", "sufjan stevens", "consistency", "reproductive", "papua new guinea", "L'Eglise du Saint-Esprit", "100 Greatest Artists of Hard Rock", "the empire fell", "1977", "kraftwerk", "report Hess's illegal May 1941 flight to Scotland"], "metric_results": {"EM": 0.9375, "QA-F1": 0.95}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4743", "before_prediction": "Tamaulipas", "after_prediction": "Mexico City"}], "retained_ids": ["mrqa_hotpotqa-validation-1715", "mrqa_squad-validation-9760", "mrqa_squad-validation-3115", "mrqa_hotpotqa-validation-2408"], "fixed_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_triviaqa-validation-2130", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "unfixed_ids": ["mrqa_naturalquestions-validation-7483"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 62, "before_eval": {"predictions": ["sleep", "whiteness", "from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "the Monarch", "United Kingdom, Australia, Canada and the United States", "Ballarat Bitter", "therefore", "in: Luzerne County, Pennsylvania", "pop gets, putting a spin on true love that any reprobate slacker can relate to", "magma", "margaret hancock", "a fee per unit of connection time", "coordinator", "In 1932", "winter of the 2017 -- 18 network television season", "cattle and citrus were major industries until farmlands were turned into suburbs", "Egypt", "Neil Armstrong, Michael Collins and Buzz Aldrin", "lorraine", "4145", "science", "during the production company vanity cards shown following the closing credits of most programs", "Kansas\u2013Nebraska Act of 1854", "44 Variable ( V ) gene segments", "1910\u20131940", "11:28", "Start Here", "Doctor Who", "Autobahn (expressway)", "endocrine", "Baron", "poodle"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4009398946360153}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.13333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.1, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0689655172413793, 0.5, 0.0]}}, "error_ids": ["mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-5396", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_triviaqa-validation-3507", "mrqa_naturalquestions-validation-7270", "mrqa_triviaqa-validation-1698", "mrqa_squad-validation-4750", "mrqa_hotpotqa-validation-1510", "mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_hotpotqa-validation-837", "mrqa_naturalquestions-validation-538", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_hotpotqa-validation-1692", "mrqa_triviaqa-validation-6254"], "after_eval": {"predictions": ["sleeps", "whiteness", "At the end", "the Monarch", "United Kingdom, Australia, Canada and the United States", "Ballarat Bitter is a 4.9% (abv) Australian beer", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "ricketts glen state park", "Can't Change Me", "magma", "hattie jacques", "fee per unit of information transmitted", "\"master builder\" of mid-20th century New York City, Long Island, Rockland County, and Westchester County", "2010", "2017", "richest", "Egypt", "Buzz Aldrin. Armstrong and Aldrin performed the first landing at the Sea of Tranquility at 20:17:40 UTC on July 20, 1969. They spent a total of 21 hours, 36 minutes on the surface", "lorraine", "4145 ft above mean sea level", "intelligent design", "ABC on Demand to the beginning of the ABC show", "Kansas\u2013Nebraska Act", "V", "1910\u20131940", "11:28 left in the second quarter", "Start Here", "Master", "Radio-Activity (German title: Radio-Aktivit\u00e4t) is the fifth studio album by German electronic band Kraftwerk", "endocrine ( hormonal ) systems and their physiological and behavioral effects, including gonadal differentiation, internal and external genital and breast differentiation, and differentiation of muscle mass, height, and hair distribution", "Baron of Holberg", "Labradoodle"], "metric_results": {"EM": 0.75, "QA-F1": 0.8478800034506556}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3961", "before_prediction": "Neil Armstrong, Michael Collins and Buzz Aldrin", "after_prediction": "Buzz Aldrin. Armstrong and Aldrin performed the first landing at the Sea of Tranquility at 20:17:40 UTC on July 20, 1969. They spent a total of 21 hours, 36 minutes on the surface"}, {"id": "mrqa_squad-validation-824", "before_prediction": "11:28", "after_prediction": "11:28 left in the second quarter"}], "retained_ids": ["mrqa_squad-validation-9843", "mrqa_squad-validation-9570", "mrqa_squad-validation-7766", "mrqa_squad-validation-4986", "mrqa_triviaqa-validation-4878", "mrqa_squad-validation-7440", "mrqa_squad-validation-6026"], "fixed_ids": ["mrqa_squad-validation-2339", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_triviaqa-validation-3507", "mrqa_triviaqa-validation-1698", "mrqa_squad-validation-4750", "mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_hotpotqa-validation-837", "mrqa_naturalquestions-validation-538", "mrqa_triviaqa-validation-4095", "mrqa_naturalquestions-validation-9064", "mrqa_hotpotqa-validation-1692", "mrqa_triviaqa-validation-6254"], "unfixed_ids": ["mrqa_naturalquestions-validation-5396", "mrqa_naturalquestions-validation-7270", "mrqa_hotpotqa-validation-1510", "mrqa_naturalquestions-validation-1555", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-5607"], "instant_fixing_rate": 0.7391304347826086, "instant_retention_rate": 0.7777777769135802}, {"timecode": 63, "before_eval": {"predictions": ["Bank of China Tower", "heat addition (in the boiler) and rejection ( in the condenser) are isobaric (constant pressure) processes in the Rankine cycle", "jenathan carson", "Operating System Principles", "Apr 23", "Kohlberg K Travis Roberts", "fylde coast", "probabilistic (or \"Monte Carlo\" and deterministic algorithms. Deterministic algorithms provide a way to tell for sure whether a given number is prime or not.", "the Who", "eight days after their initial broadcast", "Phoenix Hong Kong Channel", "a narcissistic ex-lover who did the protagonist wrong", "catawba", "optical microscopy", "michael mjackson", "james and the Black Jacobins", "Sondheim", "Strasbourg's metropolitan area had a population of 773,347 in 2013 (not counting the section across the border in Germany)", "3.762", "a system of recording important things", "1993", "Sunday", "ACL tears", "m Mayo county council", "diapsids", "German", "2001", "belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "Professor Kantorek", "31 - member Senate", "Cape Cod Evening", "orkney"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12029374758033295}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.2857142857142857, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.34146341463414637, 0.0, 0.5, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_hotpotqa-validation-97", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_triviaqa-validation-7598", "mrqa_squad-validation-5059", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "after_eval": {"predictions": ["Hong Kong", "constant pressure", "american family publishers", "suggested it for use in the ARPANET", "shakespeare", "KKR & Co", "wyre", "deterministic algorithms", "Jimi Hendrix", "eight", "Phoenix Television", "Rihanna", "american association for bank of America", "petrographic microscope", "mc hammer", "haitian revolution", "the cast members", "276,170 inhabitants", "2", "beads or shells", "Tian Tan Buddha", "guardian", "ACL tears", "castlebar", "jaw", "German", "1999", "their belief in the validity of the social contract", "Paul Baumer", "member", "edward hopper", "scottish history"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9627403846153846}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-306", "mrqa_hotpotqa-validation-4301"], "fixed_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_hotpotqa-validation-97", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_squad-validation-5059", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037"], "unfixed_ids": ["mrqa_triviaqa-validation-7598", "mrqa_triviaqa-validation-2254"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.999999995}, {"timecode": 64, "before_eval": {"predictions": ["failure rate", "Jim Justice", "cydippid adults", "Kyle Broflovski", "sukiyaki", "one of popular music's most poignant anthems of sorrow regarding the environment", "trial division", "consultant", "Preston", "Phineas and Ferb", "tuberculosis", "Saturn IB", "H. R. Haldeman", "daniel Baldwin", "Player of the Year", "american high Renaissance master Raphael", "brain stimulators for the treatment of Parkinson's disease, epilepsy and cerebellar tremor", "Swiss Alps", "charlie heen", "reform the lunisolar calendar to provide an accuracy of 365.2425 days of the year", "Charkhi Dadri mid-air collision occurred on 12 November 1996", "John Simm", "immediate judgement discrepancy, or cognitive bias, where a person making an initial assessment of another person, place, or thing will assume ambiguous information based upon concrete information", "New Orleans", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "macOS High Sierra", "George Foreman", "quadrilateral", "Diarmaid MacCulloch", "loire river is the longest one in France", "17th Century sources referring to Cardinal Richelieu after he was named to head the royal council in 1624", "provides funding at a rate or formula based on the previous year's funding"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23202395564683698}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.6666666666666666, 0.0, 0.05405405405405406, 0.0, 0.16949152542372883, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.19999999999999998]}}, "error_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_squad-validation-4567", "mrqa_hotpotqa-validation-2542", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_hotpotqa-validation-4702", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "after_eval": {"predictions": ["bathtub", "the governor of West Virginia", "more like true larvae, as they live among the plankton and thus occupy a different ecological niche from their parents and attain the adult form by a more radical metamorphosis, after dropping to the sea-floor", "Trey Parker and Matt Stone", "sashimi", "sorrow regarding the environment", "Miller\u2013Rabin primality test", "consultant at the Westinghouse Electric & Manufacturing Company's Pittsburgh labs", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "The Suite Life of Zack & Cody", "bladder cancer", "AS-205/208", "Rose Mary Woods", "bradley walsh", "Premier League club Crystal Palace and the Ivory Coast national team", "raffaello Santi", "skull", "saint moritz", "charlie", "granaries were ordered built throughout the empire", "On March 27, 1977, two Boeing 747 passenger jets, KLM Flight 4805 and Pan Am Flight 1736, collided on the runway at Los Rodeos Airport (now Tenerife North Airport)", "John Simm", "when an individual noticing that the person in the photograph is attractive, well groomed, and properly attired", "Speakeasies", "the final episode of the series", "macOS High Sierra, which was publicly released in September 2017", "Zaire", "trapezium", "Diarmaid MacCulloch", "c\u00e9vennes", "1624", "continues the pre-existing appropriations at the same levels as the previous fiscal year ( or with minor modifications ) for a set amount of time"], "metric_results": {"EM": 0.75, "QA-F1": 0.7825265522875817}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5833333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1312", "before_prediction": "consultant", "after_prediction": "consultant at the Westinghouse Electric & Manufacturing Company's Pittsburgh labs"}, {"id": "mrqa_hotpotqa-validation-548", "before_prediction": "Preston", "after_prediction": "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage"}, {"id": "mrqa_triviaqa-validation-2173", "before_prediction": "tuberculosis", "after_prediction": "bladder cancer"}, {"id": "mrqa_hotpotqa-validation-811", "before_prediction": "Player of the Year", "after_prediction": "Premier League club Crystal Palace and the Ivory Coast national team"}], "retained_ids": ["mrqa_squad-validation-2560"], "fixed_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_hotpotqa-validation-2542", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_hotpotqa-validation-4702", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "unfixed_ids": ["mrqa_squad-validation-4567", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_triviaqa-validation-4217"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.1999999996}, {"timecode": 65, "before_eval": {"predictions": ["California State Legislature and signed by the State governor John B. Weller", "L", "Diary of a Wimpy Kid : The Long Haul", "the recommended. html filename extension", "prayer", "heart", "Early Gothic", "american horse racing", "dancing sifaka", "Boz", "1991", "DuMont Television Network", "Birmingham, Alabama", "Euler", "2018", "wyre", "katherine", "gravitation", "nonconservative forces act to change the internal energies of the system", "tornros", "the applied force is opposed by static friction, generated between the object and the table surface", "sherrinford", "sazerac", "Shut Up", "Aztec language Nahuatl has lent many words to Spanish in Mexico and may have influenced the Mexican Spanish trait of pronouncing all consonants (as opposed to many Central American accents)", "Corbin Bleu and Karina Smirnoff became the runners - up, and Jack Osbourne and Cheryl Burke received third place", "Seattle Seahawks", "St. Augustine", "four", "Abrogation of the Private Mass, he condemned as idolatry the idea that the mass is a sacrifice, asserting instead that it is a gift, to be received with thanksgiving by the whole congregation", "kedah", "mycelium"], "metric_results": {"EM": 0.21875, "QA-F1": 0.26762519278966646}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6153846153846153, 0.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.06666666666666667, 0.21052631578947367, 0.0, 1.0, 0.33333333333333337, 0.07142857142857142, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-3048", "mrqa_triviaqa-validation-1923", "mrqa_squad-validation-5836", "mrqa_squad-validation-9021", "mrqa_naturalquestions-validation-1784", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_naturalquestions-validation-1783", "mrqa_squad-validation-239", "mrqa_hotpotqa-validation-4174", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "after_eval": {"predictions": ["Cow Counties", "LI", "Diary of a Wimpy Kid : The Long Haul", ". html", "haj", "heart", "Anglo-Saxon", "kentucky derby", "madagascar", "Boz", "1991", "ABC-DuMont", "primarily in the Southern part of the United States", "identity", "2020", "island of man", "mad", "Gravity", "nonconservative forces", "bullfight", "applied force", "ormond sacker", "rye", "Shut Up", "spanish", "Karina Smirnoff", "Arizona Cardinals", "St. Augustine", "four founding members", "a gift", "red", "fungi"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8255208333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-183", "before_prediction": "Birmingham, Alabama", "after_prediction": "primarily in the Southern part of the United States"}], "retained_ids": ["mrqa_naturalquestions-validation-714", "mrqa_triviaqa-validation-2752", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-5505", "mrqa_hotpotqa-validation-875", "mrqa_naturalquestions-validation-5468"], "fixed_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_triviaqa-validation-1499", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-3048", "mrqa_triviaqa-validation-1923", "mrqa_squad-validation-5836", "mrqa_squad-validation-9021", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_naturalquestions-validation-1783", "mrqa_squad-validation-239", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262"], "unfixed_ids": ["mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_triviaqa-validation-4199", "mrqa_hotpotqa-validation-4174", "mrqa_triviaqa-validation-3691"], "instant_fixing_rate": 0.76, "instant_retention_rate": 0.8571428559183674}, {"timecode": 66, "before_eval": {"predictions": ["cucumber", "to fund his Colorado Springs experiments", "eastern shore", "On the Computational Complexity of Algorithms", "from sea level", "Raja Dhilu", "energy loss", "La Nouba", "rabbit", "Duke Kent- Brown", "O2", "steak", "platypus", "better", "Vanessa Block", "insano", "2p \u2212 1", "swallow-tailed", "alaudine", "http://www.example.com/index.html", "w\u00fcrttemberg", "`` Abigail ''", "catechisms", "cheddar", "Concentrated O2 will allow combustion to proceed rapidly and energetically. Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel", "Saint-Domingue", "translated the New Testament from Greek into German and poured out doctrinal and polemical writings", "1963", "prokaryotic cell ( or organelle )", "Commissioners", "Great War for the Empire", "bread"], "metric_results": {"EM": 0.21875, "QA-F1": 0.29989622493734336}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.125, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.05263157894736842, 1.0, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_naturalquestions-validation-6843", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-6945", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-2469", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_squad-validation-2269", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "after_eval": {"predictions": ["steak tartare", "for Tesla to further develop and produce a new lighting system", "Firth of Clyde", "On the Computational Complexity of Algorithms", "from sea level", "the Pandavas", "Magnetically soft", "O", "cake", "South African Vice Consul Duke Kent-Brown", "pure O", "man v food", "winklevoss twins", "better academic results", "Mitchell Block and Michael Sarnoski", "slide", "2p + 1", "blue", "fox", "a protocol ( http ), a hostname ( www.example.com ), and a file name ( index. html )", "george iv", "`` Shawn Takes a Shot in the Dark ''", "two catechisms", "mendip hills", "special training to ensure that ignition sources are minimized", "Saint-Domingue", "disappearance", "1976", "prokaryotic", "Commissioners", "Fourth Intercolonial War and the Great War for the Empire", "oven"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9068993506493507}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.8, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-5927", "before_prediction": "energy loss", "after_prediction": "Magnetically soft"}, {"id": "mrqa_squad-validation-7130", "before_prediction": "better", "after_prediction": "better academic results"}, {"id": "mrqa_squad-validation-8980", "before_prediction": "2p \u2212 1", "after_prediction": "2p + 1"}], "retained_ids": ["mrqa_squad-validation-1853", "mrqa_squad-validation-10412", "mrqa_hotpotqa-validation-1482", "mrqa_squad-validation-4300"], "fixed_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_naturalquestions-validation-6843", "mrqa_hotpotqa-validation-5712", "mrqa_squad-validation-6945", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-2469", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_squad-validation-2269", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "unfixed_ids": ["mrqa_triviaqa-validation-7577", "mrqa_naturalquestions-validation-8229"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.571428570612245}, {"timecode": 67, "before_eval": {"predictions": ["high inequality", "commandaria wine", "funk", "Sweden, Norway and Denmark", "the island of Spitsbergen in Svalbard, Norway", "Deposition", "Norman origin", "Crossed: Family Values", "wonga", "Doctor of Philosophy", "1,388", "Otis Timson", "jack flash", "government representatives", "$150,000 and $250,000", "12 December 1964", "Ohio", "first freshman to finish as the runner-up", "The Crowned Prince of the Philadelphia Mob", "\u201c Resign.\u201d", "Homosexual", "a highly stable hierarchy", "Big Eight Conference", "In the 1920s", "American", "Cleopatra VII Philopator", "April Fool's Day", "mill stream", "quadrille", "chloroplasts", "Salta, Chaco, Santa Fe, C\u00f3rdoba, Catamarca and Tucum\u00e1n", "more than 265 million business records worldwide"], "metric_results": {"EM": 0.25, "QA-F1": 0.3734375}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.8, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.4444444444444445]}}, "error_ids": ["mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-4648", "mrqa_hotpotqa-validation-5297", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8526", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_naturalquestions-validation-1976", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_squad-validation-6327", "mrqa_hotpotqa-validation-3345", "mrqa_naturalquestions-validation-7089", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "after_eval": {"predictions": ["high inequality", "cyprus", "afghanistan", "Denmark\u2013 Norway\u2013Sweden", "island of Spitsbergen", "desublimation", "Norman origin", "Preacher", "Wonga", "Doctor", "1,388", "Sarah's brother, Brian", "jumping jack flash", "government officials and climate change experts", "US$100,000", "1963", "Toledo", "runner-up", "Crowned Prince of the Philadelphia Mob", "Resign", "bisexual", "the Meiji Restoration", "Pac-12 Conference", "the 1920s", "American", "Athenion", "Mean Girls", "constable", "paris", "chromoplasts", "Salta", "265 million"], "metric_results": {"EM": 0.75, "QA-F1": 0.8132440476190477}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-294", "before_prediction": "first freshman to finish as the runner-up", "after_prediction": "runner-up"}], "retained_ids": ["mrqa_squad-validation-7417", "mrqa_naturalquestions-validation-8643", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-1385", "mrqa_squad-validation-4721", "mrqa_hotpotqa-validation-242", "mrqa_hotpotqa-validation-3626"], "fixed_ids": ["mrqa_triviaqa-validation-6619", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-5297", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8526", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_naturalquestions-validation-1976", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-3345", "mrqa_naturalquestions-validation-7089", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "unfixed_ids": ["mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-4648", "mrqa_naturalquestions-validation-8911", "mrqa_squad-validation-6327", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395"], "instant_fixing_rate": 0.7083333333333334, "instant_retention_rate": 0.8749999989062499}, {"timecode": 68, "before_eval": {"predictions": ["Nuevo Reino de Le\u00f3n", "Delaware", "jus sanguinis", "last starring role was as Boston police detective Barry Frost", "The King of Chutzpah", "P $ C", "energy", "city and city railway", "Nepali", "john caird", "Monk's", "upper bound", "david green", "the dot", "dieppe", "1961", "Tyler Posey", "New South Wales", "hard-to-fill positions", "kung-fu", "brontosaurs", "qualifications", "Megyn Price", "the final episode of the series", "skylab", "1939", "automaticistas, or tolled ( quota ) highways", "redox", "eastern and interior Venezuela and the llanos of Colombia", "tsar", "the nation of Sokovia", "conservative"], "metric_results": {"EM": 0.375, "QA-F1": 0.4107142857142857}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_triviaqa-validation-4485", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8791", "mrqa_triviaqa-validation-2723", "mrqa_squad-validation-7076", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-339", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_triviaqa-validation-3089", "mrqa_naturalquestions-validation-2632"], "after_eval": {"predictions": ["1535", "Delaware", "Italian nationality law", "Lee Thompson Young", "King of Chutzpah", "Mike Jones featuring Nicole Wray, Trillville, Juvenile featuring Skip & Wacko, Nasty Nardo, 8Ball & MJG, Lil'Boosie & Webbie and other artists", "energy", "district line", "English", "london", "Monk's", "upper bound", "david green", "the dot", "Dieppe raid", "East Germany ), starting on", "Dylan O'Brien", "New South Wales", "teaching", "Shaolin", "dinosaur wars", "qualifications", "Megyn Price", "the final episode of the series", "curling", "1939", "autopistas", "Rust", "South America", "russia", "approximately one year after Ultron's defeat in the nation of Sokovia at the hands of the Avengers", "conservative American news and opinion website and online news aggregator"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8441157262277952}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.896551724137931, 0.18181818181818182]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5185", "before_prediction": "dieppe", "after_prediction": "Dieppe raid"}, {"id": "mrqa_squad-validation-2052", "before_prediction": "hard-to-fill positions", "after_prediction": "teaching"}, {"id": "mrqa_hotpotqa-validation-4275", "before_prediction": "conservative", "after_prediction": "conservative American news and opinion website and online news aggregator"}], "retained_ids": ["mrqa_hotpotqa-validation-1536", "mrqa_squad-validation-8626", "mrqa_squad-validation-1784", "mrqa_squad-validation-5777", "mrqa_squad-validation-2843", "mrqa_squad-validation-9493", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-2969"], "fixed_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_triviaqa-validation-2723", "mrqa_squad-validation-7076", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_triviaqa-validation-3089"], "unfixed_ids": ["mrqa_triviaqa-validation-4485", "mrqa_naturalquestions-validation-8791", "mrqa_naturalquestions-validation-339", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-2632"], "instant_fixing_rate": 0.7, "instant_retention_rate": 0.749999999375}, {"timecode": 69, "before_eval": {"predictions": ["Eisenhower Freeway", "Max Planck, Albert Einstein, Louis de Broglie, Arthur Compton, Niels Bohr and many others", "music became more expressive and emotional", "minerals that give the amount of time that has passed since a rock passed through its particular closure temperature, the point at which different radiometric isotopes stop diffusing into and out of the crystal lattice", "North Kest even", "Ming", "near major hotels and in the parking areas of major Chinese supermarkets", "Muhammad ibn Zakar\u012bya R\u0101zi", "Hellenion", "from the top of the leg to the foot on the posterior aspect", "German Shepherds", "unknown", "tea, horticultural produce, and coffee", "parliaments", "Joanna Cassidy", "Red : The blood spilled by the heroes who died in the name of their countrymen's Fatherland and Freedom", "island of sand and Fog", "break off the cathode", "Silver Gallery", "21.8 %", "euphoric", "Yuan dynasty is usually considered to be the legitimate dynasty between the Song dynasty and the Ming dynasty", "the group", "Paris", "american civil rights movement", "Martha Wainwright", "1,462", "island of butan", "the 10th or 11th century", "parliaments", "wind", "1698"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22616185897435898}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.08333333333333333, 0.0, 0.28571428571428575, 0.0, 0.15384615384615383, 0.0, 0.0, 0.5, 0.0, 0.09523809523809523, 1.0, 0.0, 1.0, 0.1, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8059", "mrqa_squad-validation-4929", "mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-6949", "mrqa_squad-validation-6464", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_naturalquestions-validation-3035", "mrqa_squad-validation-8185", "mrqa_naturalquestions-validation-2862", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_triviaqa-validation-5088", "mrqa_hotpotqa-validation-1381"], "after_eval": {"predictions": ["State Route 41", "Max Planck", "a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble", "Thermochemical techniques", "North Kest even, Lincolnshire, England", "Qing", "on a stretch of Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "Abu al-Qasim al-Zahrawi", "Hellenic polytheist", "on the posterior aspect", "The long - hair gene is recessive", "author of the tune is unknown and it may originate in plainchant, but a 1619 attribution to John Bull is sometimes made", "tea, horticultural produce, and coffee", "foreign exchange", "Dan Castellaneta ( voice ) as Animated Mrs. Sturak", "Yellow : The crops and the fertile soil.", "lost in translation", "physically strike him", "main silverware gallery", "approximately 21.8 % of the world's population", "pharmacological effect", "a period of foreign domination", "Tony Orlando and Dawn", "France", "pete seeger", "Gary Lightbody", "1,462 hypermarkets", "bhutan", "European colonization", "paul dukas", "Boreas", "since 1864"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8975970643939394}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.25, 1.0, 1.0, 0.6666666666666665, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-8645", "before_prediction": "Max Planck, Albert Einstein, Louis de Broglie, Arthur Compton, Niels Bohr and many others", "after_prediction": "Max Planck"}, {"id": "mrqa_naturalquestions-validation-849", "before_prediction": "Joanna Cassidy", "after_prediction": "Dan Castellaneta ( voice ) as Animated Mrs. Sturak"}, {"id": "mrqa_squad-validation-3610", "before_prediction": "euphoric", "after_prediction": "pharmacological effect"}, {"id": "mrqa_hotpotqa-validation-37", "before_prediction": "1,462", "after_prediction": "1,462 hypermarkets"}], "retained_ids": ["mrqa_squad-validation-8304"], "fixed_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8059", "mrqa_squad-validation-4929", "mrqa_naturalquestions-validation-7910", "mrqa_squad-validation-6464", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_squad-validation-8185", "mrqa_naturalquestions-validation-2862", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_triviaqa-validation-5088", "mrqa_hotpotqa-validation-1381"], "unfixed_ids": ["mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-3035"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.1999999996}, {"timecode": 70, "before_eval": {"predictions": ["kurt steiner", "The New York and New Jersey campaign", "February 28, 2018", "hotel room", "Ford's Victorian plants", "cordwainer", "Guthred", "1972", "2017", "a loanword of the Visigothic word guma `` man ''", "Major General Miles Francis Stapleton Fitzalan-Howard, 17th Duke of Norfolk", "kaph", "New Zealand", "chromium", "white", "Cape Cod", "the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "82.30'E", "a \"theo-democracy\" based on the principles of: tawhid (prophethood) and khilafa (caliphate)", "Salman Khan", "Skip Tyler", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything '", "WBMA-LD", "two Nobel Peace Prizes", "Tennessee whiskey", "Tesla said he could feel a sharp stinging pain where it entered his body, and again at the place where it passed out", "king james", "thirty articles affirming an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "a straight line", "Manning", "The Bad Hemingway Contest", "Kingsford, Michigan"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4058064180884905}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.2857142857142857, 0.7499999999999999, 0.0, 0.3076923076923077, 1.0, 0.0, 0.0, 0.2105263157894737, 0.0, 0.15384615384615383, 0.0, 1.0, 0.08, 1.0, 1.0, 0.0, 0.6875000000000001, 0.8, 0.2105263157894737, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_triviaqa-validation-672", "mrqa_hotpotqa-validation-4323", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_naturalquestions-validation-7938", "mrqa_squad-validation-361", "mrqa_naturalquestions-validation-2229"], "after_eval": {"predictions": ["jack higgins", "The New York and New Jersey campaign", "Ghost Island", "his hotel room", "a base for the global car industry", "shoes", "Guthred or Guthfrith", "1972", "2013", "man", "Miles Fitzalan-Howard, 17th Duke of Norfolk", "hebrew", "their June 2011 Milton Keynes performances, Australian and New Zealand tour", "chromium", "b Betsy Ross", "Los Angeles, California", "the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "82.30'E longitude, in Mirzapur, Uttar Pradesh, which is nearly on the corresponding longitude reference line", "unity of God", "Sajjad Delafrooz", "Skip Tyler", "Latin : liberalis, free and ars, art or principled practice", "WBMA-LD", "two Nobel Peace Prizes", "jack daniels", "he could feel a sharp stinging pain where it entered his body", "james i", "thirty articles affirming an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "a straight line (see world line) traveling through time, which normally increases up or to the right in the diagram", "Von Miller", "The Bad Hemingway Contest", "Oak Island"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8387844611528823}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2105263157894737, 0.4761904761904762, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2105263157894737, 0.21052631578947367, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10477", "before_prediction": "a straight line", "after_prediction": "a straight line (see world line) traveling through time, which normally increases up or to the right in the diagram"}], "retained_ids": ["mrqa_hotpotqa-validation-4939", "mrqa_squad-validation-1632", "mrqa_naturalquestions-validation-710", "mrqa_triviaqa-validation-6740", "mrqa_hotpotqa-validation-3270", "mrqa_squad-validation-5981", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4543"], "fixed_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_hotpotqa-validation-4323", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_squad-validation-361", "mrqa_naturalquestions-validation-2229"], "unfixed_ids": ["mrqa_squad-validation-2980", "mrqa_triviaqa-validation-672", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_naturalquestions-validation-4211", "mrqa_naturalquestions-validation-7938"], "instant_fixing_rate": 0.7391304347826086, "instant_retention_rate": 0.8888888879012344}, {"timecode": 71, "before_eval": {"predictions": ["John D. Rockefeller", "29", "electrical, water, sewage, phone, and cable facilities", "Saxon House of Wettin", "16,000", "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription", "Dwight David \"Ike\" Eisenhower", "football", "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "twelve", "shanley royals", "Randal Keith Orton", "Jane Fonda", "as a liquid", "Sunday", "October 16, 2012", "Czech Republic", "In 2012, during a preseason exhibition game held in Sassari, Italy, Olympiacos starter and former NBA player Joey Dorsey ended up breaking the glass of a backboard against Dinamo Sassari", "alpha efferent neurons", "antlers", "David Irving", "cabbage", "vincent viincent", "the Hongwu Emperor of the Ming Dynasty", "parliaments", "1565", "rapid expansion in telecommunication and financial activity", "parliaments", "Caroline Sterling, n\u00e9e Bone, formerly Pemberton ( born 3 April 1955 ; died 2017 ) ( Sara Coward )", "Libertarianism", "london", "R&B"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3655934343434343}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-862", "mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_naturalquestions-validation-2635", "mrqa_triviaqa-validation-6938", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-3689", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "after_eval": {"predictions": ["John D. Rockefeller", "29 days", "electrical, water, sewage, phone, and cable facilities", "Ernestine duchies", "1,100", "There is no known case", "34th", "FieldTurf", "Khitans, Jurchens, Mongols, and Tibetan Buddhists", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "henley royal regatta", "Randy Orton", "Sam Waterston", "special insulated tankers, since one liter of liquefied oxygen is equivalent to 840 liters of gaseous oxygen at atmospheric pressure and 20 \u00b0C (68 \u00b0F)", "Sunday evenings through the entirety of that night's primetime schedule", "October 16, 2012", "Czech Republic", "2012, during a preseason exhibition game held in Sassari, Italy", "Somatic motor neurons", "velvet", "David Irving", "mark twain", "Gene Vincent", "Zhu Di", "heptathlon", "never contained the element lead", "rapid expansion in telecommunication and financial activity", "walter scott", "Lilian Bellamy", "political", "john key", "American R&B vocal group"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8687227668845315}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.11764705882352942, 1.0, 1.0, 1.0, 1.0, 0.14814814814814814, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-253", "before_prediction": "29", "after_prediction": "29 days"}, {"id": "mrqa_squad-validation-8291", "before_prediction": "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "after_prediction": "Khitans, Jurchens, Mongols, and Tibetan Buddhists"}, {"id": "mrqa_hotpotqa-validation-4911", "before_prediction": "Sunday", "after_prediction": "Sunday evenings through the entirety of that night's primetime schedule"}], "retained_ids": ["mrqa_squad-validation-7849", "mrqa_squad-validation-7123", "mrqa_squad-validation-173", "mrqa_hotpotqa-validation-5203", "mrqa_hotpotqa-validation-5162", "mrqa_squad-validation-8401"], "fixed_ids": ["mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_naturalquestions-validation-2635", "mrqa_triviaqa-validation-6938", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "unfixed_ids": ["mrqa_hotpotqa-validation-862", "mrqa_squad-validation-3689", "mrqa_triviaqa-validation-237"], "instant_fixing_rate": 0.8695652173913043, "instant_retention_rate": 0.6666666659259258}, {"timecode": 72, "before_eval": {"predictions": ["Monk's Caf\u00e9", "a pagan custom, namely, the winter solstice which in Europe occurs in December", "fourth-level Republican leader in the House", "seven", "the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem", "Operation Neptune", "john f kenney", "Patrick Moore", "alpaca fiber and mohair from Angora goats", "Muskogean language", "Symbolic interactionism", "Long Island", "a gesture in which the head is tilted in alternating up and down arcs along the sagittal plane", "\"Field of Dreams\"; and Danny Concannon on the television series \"The West Wing\"", "snow and rain", "Parliament", "# 4 School of Public Health in the country", "shottery", "dolphin", "1883\u201384", "yellow", "`` A Pr\u00e9sent Tu Peux t'en Aller '", "fox", "Macau Peninsula, Macau", "produce \"de novo\"", "john marr", "john jumbo", "satirical erotic romantic comedy", "Greg (Shearsmith) Fran ( Sarah Hadland) and Duane (Javone Prince)\u2014celebrating the promotion of Roger (Pemberton)", "the late eighteenth century", "Puente Hills Mall, located in the City of Industry, California, United States", "james vi"], "metric_results": {"EM": 0.125, "QA-F1": 0.25113870504495506}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false], "QA-F1": [0.4, 0.09999999999999999, 0.8000000000000002, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.125, 0.42857142857142855, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.30769230769230765, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_squad-validation-1760", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_hotpotqa-validation-5478", "mrqa_squad-validation-3592", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "after_eval": {"predictions": ["Monk's Caf\u00e9", "in ancient Rome with gift - giving during the Saturnalia holiday", "the fourth-ranking Republican leader in the House", "Nobel Prize", "Boolean satisfiability problem", "the Battle of Iwo Jima", "runnymede", "xylophone", "feathers", "Apalachee", "effective conceptualizations", "the fictional town of West Egg on prosperous Long Island", "a gesture", "\"Field of Dreams\"", "temperatures", "the Channel 4 game show \" Fifteen to One\"", "# 4", "a mile west of Stratford-upon-Avon", "narwhals", "1884", "trees", "`` A Pr\u00e9sent Tu Peux t'en Aller '", "wisconsin", "Macau, China", "divide to form new pyrenoids, or be produced \"de novo\"", "smiths", "1969", "satirical erotic romantic comedy", "Melanie Owen", "who operated in Tennessee, Kentucky, Illinois, and Mississippi, in the late eighteenth century.", "Puente Hills Mall", "longchamp"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8696428571428572}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2192", "before_prediction": "Parliament", "after_prediction": "the Channel 4 game show \" Fifteen to One\""}, {"id": "mrqa_naturalquestions-validation-4018", "before_prediction": "Puente Hills Mall, located in the City of Industry, California, United States", "after_prediction": "Puente Hills Mall"}], "retained_ids": ["mrqa_naturalquestions-validation-3638", "mrqa_hotpotqa-validation-3252"], "fixed_ids": ["mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_squad-validation-1760", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_hotpotqa-validation-5478", "mrqa_squad-validation-3592", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "unfixed_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-1507", "mrqa_triviaqa-validation-417"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.49999999875}, {"timecode": 73, "before_eval": {"predictions": ["northwest", "Sarah", "energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+)", "Boston", "the \"Negro Cavalry\" by the Native American tribes they fought in the Indian Wars", "4 km", "The Future", "1969", "American composer for film", "Wahhabist", "buzzards", "drug management system development, deployment and optimization", "from that first set of endosymbiotic events", "Danish pronunciation : ( \u02c8\u0251n\u0250sn\u0329 )", "Edward Trowbridge Collins Sr.", "November 2014", "when a country's influence is felt in social and cultural circles", "increased productivity, trade, and secular economic trends", "Prince's band, Wendy Melvoin and Lisa", "the early 20th century", "1958", "political geographer", "around 200\u2013300)", "his mind", "rules and Newtonian mechanics in general were first developed to describe how forces affect idealized point particles rather than three-dimensional objects. However, in real life, matter has extended structure and forces that act on one part of an object", "kip", "\"Polovetskie plyaski\"", "royal charters", "government - owned Panama Canal Authority", "Vernier, Switzerland", "harmonica", "\"PM Magazine\""], "metric_results": {"EM": 0.1875, "QA-F1": 0.3501144688644689}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.42857142857142855, 0.5, 1.0, 0.0, 0.4, 0.0, 0.0, 0.8571428571428571, 0.8333333333333333, 0.5, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.1, 0.0, 0.0, 0.0, 0.3846153846153846, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9530", "mrqa_triviaqa-validation-7642", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_hotpotqa-validation-4284", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753", "mrqa_triviaqa-validation-7160"], "after_eval": {"predictions": ["northwest", "ishmael", "food in the form of sugars", "Boston", "Native American tribes", "8 km", "The Future", "july 20", "film", "Saudi", "wake", "medication management system development, deployment and optimization", "first set of endosymbiotic events", "Danish", "Edward Trowbridge Collins Sr.", "PlayStation 3 and Xbox 360 in November 2014", "soft power", "pharmaceuticals, aircraft, heavy machinery and other industries along with declines in low end, low skill industries such as clothing, toys, and other simple manufacturing have resulted in some U.S. jobs being more highly skilled and better paying", "purple rain", "After World War I", "1947", "Appointed Deputy F\u00fchrer", "a single MHC:antigen molecule", "all in his mind", "three-dimensional objects", "kilopond", "Polovtsian Dances", "british royal charters", "government - owned Panama Canal Authority", "Vernier, Switzerland", "accordion", "\"PM Magazine\""], "metric_results": {"EM": 0.90625, "QA-F1": 0.9318910256410257}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10256410256410257, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.3846153846153846, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-9043", "mrqa_squad-validation-139", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-1181", "mrqa_hotpotqa-validation-4383", "mrqa_hotpotqa-validation-3407"], "fixed_ids": ["mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_triviaqa-validation-7642", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_hotpotqa-validation-4284", "mrqa_triviaqa-validation-7160"], "unfixed_ids": ["mrqa_naturalquestions-validation-9530", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.9999999983333333}, {"timecode": 74, "before_eval": {"predictions": ["the Gulf of Mexico", "Friedrich Nietzsche", "Fern", "Anglo-Frisian languages", "Tower Hamlets", "july 6, 1937", "j. M. Coetzee", "DeWayne Warren", "20 ft", "hard Candy", "George Merrill and Shannon Rubicam of the band Boy Meets Girl", "Santa Fe, New Mexico", "1943", "translation", "wai Momi", "$125 per month", "student tuition, endowments, scholarship/voucher funds, and donations and grants from religious organizations or private individuals", "tolerance of civil disobedience", "smiths", "China", "film scripts written by ghost writers, nonfiction books on military subjects, and video games", "British and French Canadian fur traders from the mid-1830s, with its coastal areas north from the Columbia River frequented by ships from all nations engaged in the maritime fur trade", "Instagram's own account", "Karlheinz Stockhausen", "about 14", "her beautiful voice", "23 December 2014", "gluons", "simpler, more personal, Trinitarian language", "April 13, 2018", "\"Gosford Park\"", "business magnate, investor, and philanthropist"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2553756857366771}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.125, 1.0, 0.0, 0.0, 0.0, 0.13793103448275862, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_triviaqa-validation-6002", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_triviaqa-validation-4614", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_naturalquestions-validation-9487", "mrqa_squad-validation-801", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "after_eval": {"predictions": ["Atlantic ocean", "Richard Strauss", "henry", "Germanic", "bishopsgate", "new Jersey", "literature", "DeWayne Warren", "weir", "madonna", "written by George Merrill and Shannon Rubicam of the band Boy Meets Girl", "connected Independence, Missouri with Santa Fe, New Mexico", "1943", "German", "hawaii", "paying his rent", "endowments", "tolerance of civil disobedience", "ed miliband", "East India Company", "novel", "French Canadian", "Selena Gomez", "hardcore", "1990", "legend", "23 December 2014", "as gluons", "German", "March 23, 2018", "shrek", "business"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2371", "before_prediction": "translation", "after_prediction": "German"}], "retained_ids": ["mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-3188", "mrqa_squad-validation-6794", "mrqa_hotpotqa-validation-4964"], "fixed_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_triviaqa-validation-4614", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_naturalquestions-validation-9487", "mrqa_squad-validation-801", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "unfixed_ids": ["mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.7999999984}, {"timecode": 75, "before_eval": {"predictions": ["December 1974", "Inigo Jones, Sir Christopher Wren, Sir John Vanbrugh, Nicholas Hawksmoor, William Kent", "guitarist and founder of the rock band Led Zeppelin", "Gaahl", "darts", "heavy tank", "king james IV", "author of the New York Times bestseller Before I Fall Lauren Oliver", "Persian Gulf", "1902", "Statue of Freedom", "1963", "23 November 1963", "34 percent", "\"Limbo\"", "the state legislators of Assam", "350", "long eleventh century, for example in the roofs of the choir side - aisles at Durham Cathedral", "russia", "scrolls", "United States Senate", "523 km", "long", "musical director", "one person", "German \"Heer\"", "Al-Masjid an-Nabawi", "1556", "washing", "in mid-August and continues through mid-September", "manned lunar landing", "flyingair"], "metric_results": {"EM": 0.25, "QA-F1": 0.3262383540372671}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.17391304347826086, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.08, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8685", "mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-551", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_squad-validation-903", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4576", "mrqa_hotpotqa-validation-4413", "mrqa_naturalquestions-validation-6482", "mrqa_triviaqa-validation-1199", "mrqa_naturalquestions-validation-2006", "mrqa_hotpotqa-validation-2646"], "after_eval": {"predictions": ["around the time when ARPANET was interlinked with NSFNET in the late 1980s", "Sir Christopher Wren", "Eric Clapton", "Kristian Eivind Espedal", "7", "Atelier de Construction d'Issy - Les - Moulineaux", "county of northumberland", "Studs Terkel", "qatar", "1902", "Statue of Freedom", "1963", "17:16:20 GMT", "34", "Somerville", "state legislatures", "350 government officials and climate change experts", "two to three barrel vaults", "napoleon i", "scrolls dating back to the 12th century", "EPA", "325", "central line", "Goddess of Pop", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Luger P08", "Al-Masjid an-Nabaw\u012b", "Babur", "magdalene laundries", "at night, allowing them to find their direction from the stars and orient themselves by detecting the Earth's magnetic field", "manned CSM/LM flight", "SAS Group"], "metric_results": {"EM": 0.8125, "QA-F1": 0.866024330251304}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 0.3333333333333333, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7732", "before_prediction": "23 November 1963", "after_prediction": "17:16:20 GMT"}, {"id": "mrqa_hotpotqa-validation-1689", "before_prediction": "\"Limbo\"", "after_prediction": "Somerville"}, {"id": "mrqa_squad-validation-8525", "before_prediction": "350", "after_prediction": "350 government officials and climate change experts"}, {"id": "mrqa_naturalquestions-validation-4646", "before_prediction": "one person", "after_prediction": "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control"}, {"id": "mrqa_squad-validation-3775", "before_prediction": "manned lunar landing", "after_prediction": "manned CSM/LM flight"}], "retained_ids": ["mrqa_hotpotqa-validation-4407", "mrqa_naturalquestions-validation-4619", "mrqa_hotpotqa-validation-5643"], "fixed_ids": ["mrqa_naturalquestions-validation-8685", "mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-551", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_squad-validation-903", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4576", "mrqa_hotpotqa-validation-4413", "mrqa_naturalquestions-validation-6482", "mrqa_triviaqa-validation-1199", "mrqa_hotpotqa-validation-2646"], "unfixed_ids": ["mrqa_naturalquestions-validation-2006"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.37499999953124996}, {"timecode": 76, "before_eval": {"predictions": ["Raiders quarterback Rich Gannon", "2018", "many bands, including a 1990 single by Saint Etienne", "novelization", "May 27, 2016", "White Star Line", "congressional districts", "mulberry leaves", "The Miracle Maker", "Conrad Lewis", "December 10, 2017", "Hertz Corporation", "2007", "Medicaid, provides for the states to finance health care for individuals who were at or close to the public assistance level with federal matching funds", "Leonhard Euler", "Grease", "savannah", "California", "reborn", "Bhavageete", "Tachycardia, also called tachyarrhythmia", "\"Pluto\"", "Richard Burbage", "a type of \"blood poisoning\"", "Parliament of the United Kingdom", "achievement-oriented motivations", "discarded", "A Song of Ice and Fire", "You're the one for me", "Julia McKenzie", "15 February 1998", "Amazon.com"], "metric_results": {"EM": 0.25, "QA-F1": 0.3417410714285714}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 0.25, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_hotpotqa-validation-3337", "mrqa_hotpotqa-validation-5027", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-3678", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-2550", "mrqa_naturalquestions-validation-6027", "mrqa_squad-validation-1927", "mrqa_hotpotqa-validation-4510", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-956", "mrqa_naturalquestions-validation-2270", "mrqa_squad-validation-9547", "mrqa_triviaqa-validation-7099", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591"], "after_eval": {"predictions": ["Brad Johnson", "2018", "Neil Young", "film", "9 November 1967", "Colonization movement or Black Zionism", "Representatives", "mulberry", "Anomalisa", "2006", "fourteen", "Hertz", "2013", "Medicaid, provides for the states to finance health care for individuals who were at or close to the public assistance level with federal matching funds", "Leonhard Euler", "Grease", "buff-tipped skipper", "247.3 million", "be reborn", "Shukratara", "Tachycardia", "The Bomb Factory", "his fellow actor, Richard Burbage", "blood poisoning", "Parliament", "achievement-oriented motivations", "discarded", "A Song of Ice and Fire", "morrissey", "fresh fields", "1994", "Amazon.com"], "metric_results": {"EM": 0.875, "QA-F1": 0.9279057017543859}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5263157894736842, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-5031", "before_prediction": "a type of \"blood poisoning\"", "after_prediction": "blood poisoning"}], "retained_ids": ["mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-6258", "mrqa_squad-validation-9014", "mrqa_squad-validation-7323", "mrqa_squad-validation-3885", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-4791"], "fixed_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_hotpotqa-validation-3337", "mrqa_hotpotqa-validation-5027", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-3678", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-2550", "mrqa_naturalquestions-validation-6027", "mrqa_squad-validation-1927", "mrqa_hotpotqa-validation-4510", "mrqa_hotpotqa-validation-956", "mrqa_squad-validation-9547", "mrqa_triviaqa-validation-7099", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591"], "unfixed_ids": ["mrqa_hotpotqa-validation-3232", "mrqa_naturalquestions-validation-10131", "mrqa_naturalquestions-validation-2270"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.8749999989062499}, {"timecode": 77, "before_eval": {"predictions": ["New York Knickerbockers", "100-meter freestyle", "two previously unknown but related clades (genetic branches) of the Y. pestis genome associated with medieval mass graves", "east-west through the centre of Victoria", "four", "Reykjavik", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "lofsongur", "islay", "10 deg to -60 deg C", "Lesser Antilles", "The Fixx", "67,038", "The Swiss Express", "supporters", "handwriting", "is awarded the seat, which is then added to its constituency seats in allocating the second seat", "Matilda of Anjou", "After School", "Jack", "at any time after the auction", "north", "The show focuses on the original and founding ( `` mother '' ) charter, Sons of Anarchy Motorcycle Club, Redwood Original, referred to by the acronym SAMCRO or Sam Crow", "millais", "Great Yuan", "Song Il-gon", "1974", "Integra", "superoxide ion", "food and clothing", "Masahiko Takeshita", "The two amino acids are combined by the enzyme arginine : glycine amidinotransferase ( AGAT, EC : 2.1. 4.1 ) to form guanidinoacetate"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2907572751322751}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.21052631578947367, 0.33333333333333337, 1.0, 0.0, 0.07407407407407407, 0.0, 1.0, 0.0, 0.5, 0.33333333333333337, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.7894736842105263, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111]}}, "error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_squad-validation-4961", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_hotpotqa-validation-1237", "mrqa_naturalquestions-validation-686"], "after_eval": {"predictions": ["Toronto Huskies", "100-meter freestyle", "genetic branches", "east-west", "four", "Wellington", "Indo - Pacific", "iceland", "islay", "troposphere", "greater antilles", "new wave rock band The Fixx", "1,382", "Forrest Gump", "Islamism", "handwriting", "quotient", "William Adelin", "Seventeen", "Timmy Sanders", "at any time after the auction but for strategic reasons it is best to do so at the conclusion of play so as not to give the opponents information about the lay of the cards", "most northerly of the five major circles of latitude as shown on maps of Earth", "Sons of Anarchy Motorcycle Club, Redwood Original, referred to by the acronym SAMCRO or Sam Crow", "liverpool", "\u5143\u671d", "Song Il-gon", "1974", "honda", "dangerous by-products of oxygen use in organisms", "sugarcane", "Emperor of Japan", "arginine"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-70", "before_prediction": "New York Knickerbockers", "after_prediction": "Toronto Huskies"}], "retained_ids": ["mrqa_naturalquestions-validation-7390", "mrqa_triviaqa-validation-6883", "mrqa_triviaqa-validation-6204", "mrqa_hotpotqa-validation-2622", "mrqa_hotpotqa-validation-3732"], "fixed_ids": ["mrqa_squad-validation-4961", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_hotpotqa-validation-1237", "mrqa_naturalquestions-validation-686"], "unfixed_ids": ["mrqa_triviaqa-validation-6483"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.8333333319444445}, {"timecode": 78, "before_eval": {"predictions": ["21 June 2007", "healthcare professionals with specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "t Rupert Bear", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic Irish veterinary surgeon", "criminality", "Anne of Green Gables", "synovial joint", "london", "lager", "east end of london", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "chloroplasts", "1484", "A lymphocyte is one of the subtypes of white blood cell in a vertebrate's immune system", "electronic sound sources, live instrumental playing and digital signal processing", "1814", "1 atm ( 101.325 kPa ) unless otherwise specified", "Mongolian", "Gap", "The Washington Post", "Jurchen Aisin Gioro clan in Manchuria", "mortadella", "Fort Frontenac on the north shore of Lake Ontario and an expedition through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec", "friendship", "13.34%", "Tim Duncan", "DTIME(n2)", "British blockade of the French coastline limited French shipping", "loud and dirty as possible", "Billy Ray Cyrus", "chocolate confectionery"], "metric_results": {"EM": 0.125, "QA-F1": 0.2599167456951433}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.3448275862068966, 0.0, 0.35294117647058826, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92, 0.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.42857142857142855, 1.0, 1.0, 0.2666666666666667, 0.0, 0.14285714285714288, 0.9090909090909091, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_naturalquestions-validation-5838", "mrqa_hotpotqa-validation-1219", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_naturalquestions-validation-276", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-1465"], "after_eval": {"predictions": ["New Zealand Parliament as a private members bill by Green Party Member of Parliament Sue Bradford in 2005, after being drawn from the ballot", "healthcare professionals with specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "brown", "a virtual reality simulator", "neuro-orthopaedic", "footpad", "shirley", "ligaments", "foyles", "carlsberg", "whitechapel", "plays a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "suitable substances, such as water", "1484", "lymph", "drum and bass electronic musician", "1806", "The enthalpy of fusion of a substance, also known as ( latent ) heat of fusion", "the Commentaries on the Classic of Changes (I Ching)", "Chevron", "Cleveland Press", "Manchuria", "sausage", "capture Niagara, Crown Point and Duquesne", "friendship", "13.34%", "John Stockton leads the points - assists combination with 714", "computation time", "poor harvest", "as loud and dirty as possible", "Don Von Tress", "mars"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8727550287356322}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [0.08333333333333334, 0.3448275862068966, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3616", "before_prediction": "Billy Ray Cyrus", "after_prediction": "Don Von Tress"}], "retained_ids": ["mrqa_hotpotqa-validation-4280", "mrqa_squad-validation-6115", "mrqa_squad-validation-7476"], "fixed_ids": ["mrqa_naturalquestions-validation-5838", "mrqa_hotpotqa-validation-1219", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_naturalquestions-validation-276", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-1465"], "unfixed_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_squad-validation-10239"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.7499999981250001}, {"timecode": 79, "before_eval": {"predictions": ["Sir Hiram Stevens Maxim", "1993", "February 2011", "make direct representations to the Presiding Officer to nominate speakers", "Burnett \"Sully\" Sullenberger III", "October 12, 2017", "The United States Oath of Allegiance", "Detective Sergeant James Hathaway", "shirley", "clay animation or \"clay-mation\"", "Iowa", "1977", "\u20ac", "The stationary steam engine was a key component of the Industrial Revolution", "a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "The western North American species commonly known as the California king bolete", "wGN-TV", "rugged terrain such as the Arctic", "Mexico\u2013united States border", "The American Football Conference (AFC) champion Denver Broncos", "a ribosome in the cytosol", "the Town of Oyster Bay in southeastern Nassau County, New York", "Ringo Starr", "melton", "gas turbines", "provided majority of members present at that time approved the bill either by voting or voice vote", "Shoushi Li (\u6388\u6642\u66a6) or Calendar for Fixing the Seasons", "16 %", "july 3", "Secretary of Defense", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "thirteen American colonies, then at war with the Kingdom of Great Britain"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3451061122736314}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.4, 0.3636363636363636, 0.4, 1.0, 0.5882352941176471, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.18181818181818182, 0.3636363636363636, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.5, 0.6086956521739131, 0.4, 0.2222222222222222, 0.0, 1.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2846", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-4529", "mrqa_squad-validation-3256", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_hotpotqa-validation-3538", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "after_eval": {"predictions": ["Nathan Rothschild", "1996", "in April 2011, following the events of `` Lauren ''", "nominate speakers", "Sully", "October 12, 2017", "The United States Oath of Allegiance", "marx", "geoffrey rush", "clay animation or \"clay-mation\"", "new hampshire", "1977", "the sign precedes the value ( for instance, \u20ac 10, not 10 \u20ac )", "Industrial Revolution", "a radius 1.5 times the Schwarzschild radius", "Funki Porcini", "wGN-TV", "the Arctic", "the Mexico\u2013united States border", "Carolina Panthers", "ribosome", "Oyster Bay", "Ringo Starr", "national space centre", "steam turbines with reduction gearing", "majority of members present at that time approved the bill either by voting or voice vote", "Shoushi Li", "from 2 % naturally blond to 16 % in the US", "july 4", "Secretary of Defense", "arranged in grana", "the Second Continental Congress"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8591020499108735}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.5882352941176471, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-677", "mrqa_squad-validation-2692", "mrqa_hotpotqa-validation-701", "mrqa_hotpotqa-validation-5366"], "fixed_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-4529", "mrqa_squad-validation-3256", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_hotpotqa-validation-3538", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "unfixed_ids": ["mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_hotpotqa-validation-2846", "mrqa_triviaqa-validation-5983", "mrqa_naturalquestions-validation-3591", "mrqa_triviaqa-validation-1912"], "instant_fixing_rate": 0.7407407407407407, "instant_retention_rate": 0.9999999980000001}, {"timecode": 80, "before_eval": {"predictions": ["John Mills", "calliope kinema club", "Peya Mushelenga", "Sachin Tendulkar", "fREEWAY", "Charles Silverstein", "RAF Tangmere, West Sussex", "the oil shock", "the Louvre", "State Bar of Arizona", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "beer and soft drinks", "HgO", "red", "euthanasia", "1967", "Mondays at 21:30 (KST)", "22 miles (35 km)", "1598", "the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "fred buttons", "red", "Topeka, Kansas", "500", "red", "hijab", "1894", "since they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "the season ten episode `` Nelson's Sparrow ''", "coldplay", "siddhi", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2852392399267399}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 1.0, 0.4, 0.3571428571428571, 0.25, 0.0, 0.5, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-2148", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3056", "mrqa_hotpotqa-validation-3282", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_naturalquestions-validation-7848", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_hotpotqa-validation-2640", "mrqa_squad-validation-4818", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-2009", "mrqa_hotpotqa-validation-2840", "mrqa_squad-validation-10182", "mrqa_triviaqa-validation-5904", "mrqa_squad-validation-4975", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129", "mrqa_squad-validation-1930"], "after_eval": {"predictions": ["Sir Thomas Daniel Courtenay", "dalziel and Pascoe", "Erastus Utoni Nujoma", "Alastair Cook", "David Wagner", "Edmund Valentine White III", "RAF Tangmere, West Sussex", "the price had also remained fairly stable versus other currencies and commodities", "paris", "West Virginia American Water", "electric potential generated by muscle cells when these cells are electrically or neurologically activated", "beer and soft drinks", "HgO", "stars", "fish", "18 August 1967", "Mondays", "22 miles (35 km)", "1629", "Bauffet's Point", "george lichtenberg", "national front", "near Philip Billard Municipal Airport", "additional French forces under Claude-Pierre Pecaudy de Contrec\u0153ur", "cooperative", "hijab", "Hong Kong in 1894", "since they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "parachutes", "phowa and siddhi", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.625, "QA-F1": 0.753818913929208}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3571428571428571, 0.4, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3699", "before_prediction": "the oil shock", "after_prediction": "the price had also remained fairly stable versus other currencies and commodities"}, {"id": "mrqa_hotpotqa-validation-3406", "before_prediction": "1967", "after_prediction": "18 August 1967"}], "retained_ids": ["mrqa_hotpotqa-validation-3779", "mrqa_squad-validation-3570", "mrqa_naturalquestions-validation-870", "mrqa_squad-validation-4042"], "fixed_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-2148", "mrqa_hotpotqa-validation-3056", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_hotpotqa-validation-2640", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-2009", "mrqa_hotpotqa-validation-2840", "mrqa_triviaqa-validation-5904", "mrqa_squad-validation-4975", "mrqa_squad-validation-1930"], "unfixed_ids": ["mrqa_naturalquestions-validation-6474", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3282", "mrqa_naturalquestions-validation-7848", "mrqa_squad-validation-4818", "mrqa_triviaqa-validation-1100", "mrqa_squad-validation-10182", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129"], "instant_fixing_rate": 0.6153846153846154, "instant_retention_rate": 0.6666666655555555}, {"timecode": 81, "before_eval": {"predictions": ["one rotation of the crank and two piston strokes", "National Football Conference", "2009\u201310 Specials", "as an adviser to churches in new territories", "USD 3.1 billion dollars", "A rear - view mirror ( or rearview mirror ) is a mirror in automobiles and other vehicles, designed to allow the driver to see rearward through the vehicle's rear window ( rear windshield )", "The Birds", "identify rock samples in the laboratory", "French & Saunders", "the European Parliament and the Council of the European Union", "car crash", "on either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Thomas Edison", "trio", "M\u00fcntzer's execution", "South Africa", "a new entrance building", "florida", "karl Liebknecht", "a quarter", "heavy and civil engineering construction", "paraiso", "`` Feed Jake '' is a song written by Danny `` Bear '' Mayo", "30%", "radio", "Noel ( who had previously only sung lead on B-sides) instead of his brother, Liam", "Max West", "British Trains East Coast", "aluminium", "James C. Kennedy", "Lakshmibai", "moxibustion"], "metric_results": {"EM": 0.125, "QA-F1": 0.2351718956260665}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.2222222222222222, 0.6666666666666666, 0.0, 0.25, 0.47058823529411764, 0.20689655172413793, 0.0, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.0, 0.125, 0.3333333333333333, 0.0, 0.0, 0.0, 0.4, 0.2222222222222222]}}, "error_ids": ["mrqa_squad-validation-3267", "mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8591", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_triviaqa-validation-296", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-3695", "mrqa_squad-validation-5288", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664", "mrqa_squad-validation-8265"], "after_eval": {"predictions": ["one", "American Football Conference", "series 1", "adviser", "on average USD 5.2 billion and for the Winter Games USD 3.1 billion dollars", "rear - view mirror", "Cleopatra", "identifying rocks", "French & Saunders", "European Parliament and the Council of the European Union", "blackburn", "on either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Fred Ott", "heavy metal band", "defeat by the Swabian League at the Battle of Frankenhausen on 15 May 1525, followed by M\u00fcntzer's execution", "South Africa", "the Spiral", "president barack obama", "swiss army knife", "9", "service firms", "christ church", "American country music band Pirates of the Mississippi", "several hundred thousand, some 30% of the city", "photoelectric", "Noel Gallagher", "Walter Maxwell West Sr.", "Cross Country", "bauxite", "newspapers, television, radio, cable television, and other businesses", "Lakshmibai, the Rani of Jhansi", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8724601787101787}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2287", "before_prediction": "M\u00fcntzer's execution", "after_prediction": "defeat by the Swabian League at the Battle of Frankenhausen on 15 May 1525, followed by M\u00fcntzer's execution"}, {"id": "mrqa_squad-validation-914", "before_prediction": "30%", "after_prediction": "several hundred thousand, some 30% of the city"}], "retained_ids": ["mrqa_hotpotqa-validation-2973", "mrqa_squad-validation-4541"], "fixed_ids": ["mrqa_squad-validation-3267", "mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8591", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_triviaqa-validation-296", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-3695", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-1664", "mrqa_squad-validation-8265"], "unfixed_ids": ["mrqa_naturalquestions-validation-4809", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5288", "mrqa_hotpotqa-validation-4855"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.49999999875}, {"timecode": 82, "before_eval": {"predictions": ["north west coast of Scotland", "Pauli repulsion (due to fermionic nature of electrons) follows resulting in the force that acts in a direction normal to the surface interface between two objects", "the toe ( at the top of the cerebral hemisphere )", "24 hours later", "April 20, 1945", "dachshund", "helping farmers grow new pigeon pea varieties, instead of maize, in particularly dry areas", "geologic, topographic, and natural ecosystem landscapes", "129", "Bunkhouse", "Puma", "a growing sport in southern California, particularly at the high school level, with increasing numbers of schools adding rugby as an official school sport", "geese", "Jamukha", "tentacles and prey", "Gu\u00e9ck\u00e9dou", "Ramanaa", "Lawrence County State's Attorney John Fitzgerald, Chief Deputy Attorney General Charlie McGuigan, and attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "Infiltration", "9.9ft (3 m)", "film and short novels", "American-Canadian mystery-drama", "American animated television series \"Archer\"", "Gardnerville, Nevada", "Nucleotides", "25-minute episodes", "Julian Paul Julian", "Zapatista Army of National Liberation", "Vikram Bhatt, Bhushan Patel and Tinu Suresh Desai", "green with jealousy", "2003", "salt"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2716529052843708}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.33333333333333337, 0.16, 0.0, 0.8, 0.5, 0.0, 0.1, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 0.5517241379310345, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5454545454545454, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2133", "mrqa_squad-validation-10390", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-2791", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-2748", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_squad-validation-4616", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-678", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_hotpotqa-validation-164", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "after_eval": {"predictions": ["scotland", "normal force", "face", "24 hours", "1945", "Dachshunds", "drought resistant", "Peninsular Ranges", "73", "Bed and breakfast", "Rudolf Dassler", "official school sport", "september", "Jamukha, and his protector, Toghrul Khan of the Keraite tribe", "tentacles", "guinea", "Tagore", "Chief Deputy Attorney General Charlie McGuigan", "runoff", "11", "video game", "American-Canadian mystery-drama", "Arrested Development", "Gardnerville", "Nucleotides", "25-minute", "WikiLeaks", "mexico", "Tinu Suresh Desai", "othello", "at age 18 in 2003", "dead sea"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5592", "before_prediction": "Puma", "after_prediction": "Rudolf Dassler"}], "retained_ids": ["mrqa_hotpotqa-validation-2361", "mrqa_naturalquestions-validation-9324"], "fixed_ids": ["mrqa_triviaqa-validation-2133", "mrqa_squad-validation-10390", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-2748", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_squad-validation-4616", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-678", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_hotpotqa-validation-164", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "unfixed_ids": ["mrqa_squad-validation-2791"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 83, "before_eval": {"predictions": ["Ast\u00e9rix", "North Africa", "Maganlal Daiya", "architecture from the gothic, renaissance, baroque and neoclassical periods", "usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm", "the aboral organ ( at the opposite end from the mouth)", "piotr naskrecki", "christ church", "Los Angeles", "Piermont on the west, and runs to Plymouth, then to Conway, and east to the Maine border", "Kent, particularly Sandwich, Faversham and Maidstone", "kingdoms of Francia on the Lower Rhine, Burgundy on the Upper Rhine and Alemannia On the High Rhine", "Selim II", "3", "film director", "difficult and intricate topics", "email", "ABC Radio, with Clear Channel Communications and Westwood One ( which had earlier purchased NBC's radio division, as well as the distribution rights to CBS's, and the Mutual Broadcasting System during the 1990s)", "California", "detritus from the settlement of the sedimentation", "Rating R", "paris", "Steveston Outdoor pool in Richmond, BC", "electricity supply system", "Terry the Tomboy", "redbird", "South Australia", "Mach number (M or Ma) ( ; ] ) is a dimensionless quantity representing the ratio of flow velocity past a boundary to the local speed of sound", "circles the track at pit road speed during the warm - up laps", "North Atlantic Conference", "at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "british"], "metric_results": {"EM": 0.125, "QA-F1": 0.26625889138489944}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3636363636363636, 0.0, 0.14814814814814814, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12903225806451613, 0.0, 0.33333333333333337, 0.5, 0.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4615384615384615, 1.0, 0.8484848484848485, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_squad-validation-4490", "mrqa_triviaqa-validation-3113", "mrqa_triviaqa-validation-271", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_triviaqa-validation-5960", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_hotpotqa-validation-4966", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_squad-validation-1159", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-8518", "mrqa_triviaqa-validation-5793"], "after_eval": {"predictions": ["asterix", "Europe", "an illustration by Everest creative Maganlal Daiya back in the 1960s", "architectural", "bullets discharged into the air fall back down to the ground", "aboral organ", "bird", "christmas carol", "6", "Cushman", "Kent, particularly Sandwich, Faversham and Maidstone", "kingdoms", "Suleiman I", "7", "titanic", "Lego", "junk mail", "ABC Radio", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "detritus", "Rated R", "sea of galilee", "Richmond, BC", "alternating current", "Terry the Tomboy", "bird", "Australia", "2", "pit road speed", "North Atlantic Conference", "on location at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "victoria"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9348214285714286}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9142857142857143, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7486", "before_prediction": "Los Angeles", "after_prediction": "6"}], "retained_ids": ["mrqa_squad-validation-3107", "mrqa_hotpotqa-validation-1903", "mrqa_hotpotqa-validation-12"], "fixed_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_squad-validation-4490", "mrqa_triviaqa-validation-271", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_triviaqa-validation-5960", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_hotpotqa-validation-4966", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_squad-validation-1159", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_triviaqa-validation-5793"], "unfixed_ids": ["mrqa_triviaqa-validation-3113", "mrqa_naturalquestions-validation-8518"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 84, "before_eval": {"predictions": ["music", "26", "Nathan Bedford Forrest", "Theodosius I", "Ubiorum", "in front of only 700 fans", "brixton", "60", "Secretary for Administration and Management", "better fuel economy", "guitar", "evacuate the cylinder", "tree", "optic disc", "Carson City", "biologist", "Egyptians", "duke and duchis", "Poems : Series 1", "United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States", "NBA championship", "Alice Eve", "Chinese", "christ", "travel literature, cartography, geography, and scientific education", "Polish\u2013Lithuanian Commonwealth szlachcic, prince at Wi\u015bniowiec, magnate, grandfather", "royal residence", "mexican", "125 lb (57 kg)", "the trunk, which is a combination of the thoracic, mammary, abdominal, naval, and coxal regions", "car", "a prison"], "metric_results": {"EM": 0.28125, "QA-F1": 0.40392475579975573}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.25, 0.8571428571428571, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.24000000000000002, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.15384615384615385, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3830", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1628", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_naturalquestions-validation-10461", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1645", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_naturalquestions-validation-3173", "mrqa_triviaqa-validation-4696", "mrqa_naturalquestions-validation-6660"], "after_eval": {"predictions": ["music", "13 years and 48 days", "Major General Nathan Bedford Forrest", "Goths", "town of the Ubii", "Ottawa", "brixton riots", "third", "Secretary of Labor", "much better fuel economy", "Squeeze", "evacuate the cylinder", "cactus", "optic chiasma", "Carson City", "first suggested by the Russian biologist Konstantin Mereschkowski in 1905 after Andreas Schimper observed in 1883 that chloroplasts closely resemble cyanobacteria", "Egyptians against the British occupation in the 1919 Revolution", "marilyn monroe", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "Chief of Protocol", "2015", "Emma Thompson", "bird nests created by edible - nest swiftlets using solidified saliva", "Part I", "travel literature, cartography, geography, and scientific education", "grandfather", "Chaplain", "mao zedong", "125 lb (57 kg)", "trunk", "lexus", "as a royal residence"], "metric_results": {"EM": 0.84375, "QA-F1": 0.883608457918051}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 0.25, 1.0, 0.9302325581395349, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-370", "before_prediction": "26", "after_prediction": "13 years and 48 days"}, {"id": "mrqa_squad-validation-8486", "before_prediction": "biologist", "after_prediction": "first suggested by the Russian biologist Konstantin Mereschkowski in 1905 after Andreas Schimper observed in 1883 that chloroplasts closely resemble cyanobacteria"}, {"id": "mrqa_squad-validation-6728", "before_prediction": "Egyptians", "after_prediction": "Egyptians against the British occupation in the 1919 Revolution"}, {"id": "mrqa_naturalquestions-validation-732", "before_prediction": "Alice Eve", "after_prediction": "Emma Thompson"}], "retained_ids": ["mrqa_hotpotqa-validation-5850", "mrqa_squad-validation-3364", "mrqa_hotpotqa-validation-3359", "mrqa_squad-validation-8016", "mrqa_hotpotqa-validation-1810"], "fixed_ids": ["mrqa_hotpotqa-validation-3830", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1628", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1645", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_naturalquestions-validation-3173", "mrqa_triviaqa-validation-4696", "mrqa_naturalquestions-validation-6660"], "unfixed_ids": ["mrqa_naturalquestions-validation-10461"], "instant_fixing_rate": 0.9565217391304348, "instant_retention_rate": 0.5555555549382716}, {"timecode": 85, "before_eval": {"predictions": ["Europe, North America, East Asia and South Asia", "4.0", "Stevie Young", "one of the four temperate seasons", "3000 metres", "October 13, 1980", "1765", "discovery", "heart", "napkin", "september", "bilaterally symmetrical", "not consider the papacy part of the biblical Church", "1837", "No Game No Life, Please!, focusing on the character Izuna", "Bambi, a Life in the Woods", "point on the frontier indicates efficient use of the available inputs ( such as points B, D and C in the graph )", "12\u201318", "Retina", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "in school at a given time in the school day", "guinea", "marx", "lactobacilli", "other place of formal education", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "victor derby", "magazines and journals", "EE Kestrel", "In 1987", "Roland Ratzenberger", "200 to 500 mg up to 7 ml"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2586111111111111}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 1.0, 0.0, 0.2, 0.32, 0.0, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.2]}}, "error_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_hotpotqa-validation-4719", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-244", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-4854", "mrqa_triviaqa-validation-2508", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "after_eval": {"predictions": ["United States", "small", "Stephen Crawford Young", "fall", "south africa", "October 13, 1980", "1783", "henry hudson", "south africa", "at each place", "yeats", "a vertebral column ( spine )", "papacy was the Antichrist", "1889", "the sixth volume", "Bambi: Eine Lebensgeschichte aus dem Walde", "a point beneath the curve ( such as A ) indicates inefficiency", "Young adult fiction or young adult literature (YA) is fiction published for readers in their youth", "Retina Display", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "school", "sierra leone", "jane austen", "lactobacilli", "school", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "emily davison", "magazines and journals", "4G", "1987", "imola", "420 mg"], "metric_results": {"EM": 0.78125, "QA-F1": 0.7951388888888888}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6151", "before_prediction": "3000 metres", "after_prediction": "south africa"}, {"id": "mrqa_hotpotqa-validation-3220", "before_prediction": "1837", "after_prediction": "1889"}], "retained_ids": ["mrqa_hotpotqa-validation-5063", "mrqa_squad-validation-6608", "mrqa_squad-validation-1566"], "fixed_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_hotpotqa-validation-4719", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_squad-validation-1891", "mrqa_triviaqa-validation-4854", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "unfixed_ids": ["mrqa_hotpotqa-validation-244", "mrqa_squad-validation-8266", "mrqa_triviaqa-validation-4988", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-2508"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.5999999988}, {"timecode": 86, "before_eval": {"predictions": ["Native Americans", "thammasat", "Andaman and Nicobar Islands", "FCA", "Aaron Taylor-Johnson", "july 4", "mexican", "a gift", "Conservative", "Peter Davison, Colin Baker and Sylvester McCoy", "conservative Saudi-based Wahhabism", "1993", "maquiladora", "Bigger Than Both of Us", "in human and animals as a short - lived product in biochemical processes", "1989", "a problem", "13 May 1787", "WJRT-TV", "the Hudson River at Albany, N.Y.", "actual temperature rise was near the top end of the range given by IPCC's 2001 projection", "the Anabaptists, Zwinglianism, and the papacy", "film playback singer, director, writer and producer", "southern whites", "Marie", "not known if L ( the set of all problems that can be solved in logarithmic space) is strictly contained in P", "the Association of Indian Universities", "drawing letters", "standard model", "the Allstars", "he stood by their contents", "1980"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3148534549689441}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8750000000000001, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5217391304347826, 0.0, 0.25, 0.0, 1.0, 0.09523809523809523, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_squad-validation-2331", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_squad-validation-2113"], "after_eval": {"predictions": ["Spanish", "thailand", "Andaman Islands", "Fiat Chrysler Automobiles N.V.", "Aaron Taylor-Johnson", "blue ivy", "san francisco peace treaty", "a gift", "libertarian", "Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann", "hate them for their religion", "1993", "special economic zones", "\"Rich Girl\"", "nearly all living cells", "\"1989\" (2014)", "problem instance", "18 January 1788", "WTVG", "erie canal", "the actual sea level rise was above the top of the range", "Jews", "director", "the Confederacy", "Marie Butler", "L", "Bangalore University", "penciling", "self-consistent unification models", "the Allstars", "confirmed", "1980"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9791666666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1768", "before_prediction": "a problem", "after_prediction": "problem instance"}, {"id": "mrqa_hotpotqa-validation-1379", "before_prediction": "Marie", "after_prediction": "Marie Butler"}], "retained_ids": ["mrqa_hotpotqa-validation-5195", "mrqa_squad-validation-2295", "mrqa_squad-validation-782", "mrqa_triviaqa-validation-1431", "mrqa_naturalquestions-validation-6912"], "fixed_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_squad-validation-2331", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_squad-validation-2113"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7142857132653061}, {"timecode": 87, "before_eval": {"predictions": ["First Street in downtown Dayton, Ohio", "electronic gaming machines, table games, i Gaming and iLottery products, instant lottery games, lottery gaming systems, terminals and services, internet applications, server-based interactive gambling terminals, and gambling control systems", "August 21, 1995", "the last Shah of Iran", "digital streams", "Life Savers candy, drugstore chain Rexall and New York City radio station WMCA", "on a sound stage in front of a live audience in Burbank, California", "Chinese", "Due to the controversial and explicit nature of many of their songs, the band has frequently dealt with their videos being taken down off YouTube", "Meghan Trainor", "carbon cycle", "tenant management", "recite the 42 negative confessions of Maat", "Donna Noble (Catherine Tate) with Mickey Smith (noel Clarke) and Jack Harkness (Jo Barrowman) recurring as secondary companion figures", "salvaging a country usually seen as one of the most stable and prosperous in Africa", "The Kree, briefly known as the Ruul", "titanium", "\"Loud\" (2010)", "Kiinyaa", "henry kenzie", "domestic legislation", "an esoteric ( as opposed to exoteric, or actions-oriented, e.g. the Five Pillars of Islam)", "toothbrush", "two senators, regardless of its population", "sherry", "Thutmose III", "ten to fifteen", "Buck Owens", "Kansas", "political support", "marlin", "Wimbledon tennis championship"], "metric_results": {"EM": 0.25, "QA-F1": 0.40960423376910443}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false], "QA-F1": [0.5, 0.0, 1.0, 0.0, 1.0, 0.375, 1.0, 0.4, 0.06896551724137931, 0.0, 1.0, 0.5, 0.2, 0.5714285714285714, 0.0, 0.33333333333333337, 1.0, 0.6666666666666666, 0.4, 0.0, 0.5714285714285715, 0.15384615384615385, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2]}}, "error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_naturalquestions-validation-2196", "mrqa_squad-validation-5648", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_squad-validation-2122", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_squad-validation-8552", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-2814"], "after_eval": {"predictions": ["First Street", "paper-based", "2009", "Cyrus", "digital streams of the game via CBSSports.com, and the CBS Sports apps on tablets, Windows 10, Xbox One and other digital media players", "Life Savers", "on a sound stage in front of a live audience in Burbank, California", "Mongolian, Tibetan, and Chinese", "men who have sex with men", "Wiz Khalifa", "carbon cycle", "Property management", "against the feather of truth", "Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman)", "two political parties would share power equally", "Ruul", "titanium metal is not found as the free element", "Loud", "Kirinyaga, Kirenyaa and Kiinyaa", "emmy", "domestic legislation of the Scottish Parliament", "actions-oriented", "hitler", "Article One of the United States Constitution", "vodka", "Khonsu", "a somewhat larger number of \"contributing authors\"", "Buck Owens and the Buckaroos", "Kansas", "political support", "blue tang", "all england"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9065277777777778}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3885", "before_prediction": "August 21, 1995", "after_prediction": "2009"}, {"id": "mrqa_squad-validation-531", "before_prediction": "digital streams", "after_prediction": "digital streams of the game via CBSSports.com, and the CBS Sports apps on tablets, Windows 10, Xbox One and other digital media players"}, {"id": "mrqa_triviaqa-validation-7649", "before_prediction": "titanium", "after_prediction": "titanium metal is not found as the free element"}, {"id": "mrqa_hotpotqa-validation-5743", "before_prediction": "Buck Owens", "after_prediction": "Buck Owens and the Buckaroos"}], "retained_ids": ["mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-3620", "mrqa_naturalquestions-validation-7409", "mrqa_squad-validation-9565"], "fixed_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_naturalquestions-validation-2196", "mrqa_squad-validation-5648", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_squad-validation-2122", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_squad-validation-8552", "mrqa_triviaqa-validation-6757"], "unfixed_ids": ["mrqa_triviaqa-validation-2814"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.49999999937499995}, {"timecode": 88, "before_eval": {"predictions": ["Paolo Cannavaro, (] ; born 13 September 1973) is an Italian footballer", "Jackie Jackson", "Gold Coast", "to create a test case as to the constitutionality of a law", "Selena Gomez", "Hawaiian Airlines", "Forbes", "Tachycardia > 133 bpm", "small bowel", "Led Zeppelin", "\"public\" (state-controlled) and \"independent\" ( which includes traditional private schools and schools which are privately governed[clarification needed])", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "eAGLE", "real London nanny: cockney base notes overlaid with a strangled gentility", "the southwestern United States, Mexico, and Central America", "the high risk of a conflict of interest and/or the avoidance of absolute powers", "sacerdotalism by considering all baptized Christians to be a holy priesthood", "not being profitable", "2,000 km", "44", "the Gaulish name R\u0113nos, which was adapted in Roman-era geography (1st century BC) as Greek \u1fec\u1fc6\u03bd\u03bf\u03c2 ( Rh\u0113nos)", "cash from investors such as banks and shareholders, as well as the outflow of cash to shareholders as dividends as the company generates income", "duke of belgravia", "county council", "Solange Knowles & Destiny's Child", "Ward", "Amanda Leighton, Skylar Astin, Kari Wahlgren, Sam Lerner, David Kaye, David Fynn, Sean T. Krishnan, Kevin Michael Richardson, and Fryda Wolff", "Eddie Gottlieb Trophy", "Rihanna", "the Marmakhel Tribe", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18559541145353503}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.13333333333333333, 0.0, 0.0, 0.4, 0.5, 0.0, 0.0, 0.1, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3157894736842105, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.17391304347826084, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-4066", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_squad-validation-9246", "mrqa_naturalquestions-validation-5291", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_hotpotqa-validation-5498", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "after_eval": {"predictions": ["brother", "Motwon", "Gold Coast", "to create a test case as to the constitutionality of a law", "Instagram's own account", "8th", "Forbes Businessweek", "Tachycardia", "navel", "yardbirds", "South African Schools Act of 1996", "New Jersey", "venus", "fictional character", "arid lowland or mountainous shrubland, widely dispersed in dry open country with scattered brush", "because he or she can then sell more medications to the patient", "Pope", "the 90s", "half a million acres", "44", "the Gaulish name R\u0113nos, which was adapted in Roman-era geography (1st century BC) as Greek \u1fec\u1fc6\u03bd\u03bf\u03c2 ( Rh\u0113nos)", "the financing activities section", "national trust", "berkshire", "Destiny's Child", "Newton", "Amanda Leighton", "The National Basketball Association's Rookie of the Year Award", "The Beatles", "grand assembly", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8482383844225949}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.13333333333333333, 0.5714285714285715, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4843", "mrqa_squad-validation-1733", "mrqa_squad-validation-8594"], "fixed_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_hotpotqa-validation-4066", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_naturalquestions-validation-5291", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "unfixed_ids": ["mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-3343", "mrqa_squad-validation-6823", "mrqa_squad-validation-9246", "mrqa_naturalquestions-validation-2264", "mrqa_hotpotqa-validation-5498"], "instant_fixing_rate": 0.6896551724137931, "instant_retention_rate": 0.9999999966666667}, {"timecode": 89, "before_eval": {"predictions": ["13", "conscientious lawbreakers must be punished", "House of Fraser", "Buncle", "veal stock", "time complexity", "Deadman's Gun", "berksen", "Philippines", "filaments", "margaret", "1938", "the referendum in the Netherlands", "director", "William Allen White Book Award", "Louis XVIII", "January 30, 1930", "russia", "swissair", "all U.S. territories except American Samoa, but not on all Native American tribal lands", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "Janis Joplin with the poets Michael McClure and Bob Neuwirth", "Odinga", "homicides", "county town of shrewsbury", "Bergen County", "August 9, 2017", "xianbei", "sociological perspective which developed around the middle of the twentieth century and that continues to be influential in some areas of the discipline", "USC Trojans", "Ian Hart", "proteases"], "metric_results": {"EM": 0.1875, "QA-F1": 0.31077513495276654}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.23076923076923078, 0.9473684210526316, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.09523809523809523, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-3776", "mrqa_triviaqa-validation-3639", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_hotpotqa-validation-2774", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "after_eval": {"predictions": ["13", "neither conscientious nor of social benefit", "Army & Navy Stores", "Bonkyll Castle", "umami", "time complexity", "Far Away", "Costa del Sol", "Spanish", "proteins", "david laws", "1843", "the referendum in France", "rebecca", "middle America", "Napoleon", "January 30, 1930", "poland", "sabena", "American Samoa, but not on all Native American tribal lands", "Gaussian integers Z[i]", "singer Janis Joplin with the poets Michael McClure and Bob Neuwirth", "Odinga", "homicides", "river severn", "Bergen", "November 6, 2018", "liao", "sociological", "UCLA", "Ian Hart", "signal amplification"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-803", "mrqa_squad-validation-1700", "mrqa_hotpotqa-validation-5484", "mrqa_squad-validation-8423", "mrqa_squad-validation-7251", "mrqa_naturalquestions-validation-1445"], "fixed_ids": ["mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-3776", "mrqa_triviaqa-validation-3639", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_hotpotqa-validation-2774", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "unfixed_ids": ["mrqa_squad-validation-3985"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.9999999983333333}, {"timecode": 90, "before_eval": {"predictions": ["allotrope", "reactive allotrope of oxygen", "the Doctor battling a rogue Time Lord called The Master", "tragedy", "phylum", "fault", "magnetism", "bounding the time or space used by the algorithm", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "scrotchet", "four zonal offices at Chennai, Delhi, Kolkata and Mumbai", "black Bottom", "a self-referential time-related adage, coined by Douglas Hofstadter and named after him", "The Book of Roger", "time derivative", "photolysis", "1998\u20132002", "berks", "Grisha", "Type I", "rootlets", "violet", "Ken Howard", "red", "Pittsburgh Steelers", "epitopes", "A74", "baku", "september", "Morty", "Sarah Hurst", "Costiff collection of 178 Vivienne Westwood costumes"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23452380952380952}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.4444444444444445]}}, "error_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-1689", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_squad-validation-1070", "mrqa_squad-validation-10358", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-3988", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_squad-validation-6627", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "after_eval": {"predictions": ["a very reactive allotrope of oxygen that is damaging to lung tissue", "lung tissue", "Black Guardian Trilogy", "\"Carmen\" perhaps the most famous \"op\u00e9ra comique\" is a tragedy", "cnidarians", "younger than the fault", "maxwell", "complexity classes", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "stave", "20 regional offices and 11 sub-offices", "jelly roll morton", "professor of cognitive science", "Kitab Rudjdjar", "gravitational force", "one molecule of the pigment chlorophyll absorbs one photon and loses one electron", "2015", "gregory peck", "Grisha Alekandrovich Nikolaev", "Type II hypersensitivity", "SURFACE AREA OF ROOTS", "doll parton", "Ken Howard", "john virgo", "Broncos", "antigens", "heads north", "baku", "sydney", "XXXX", "Sarah Hurst in \"Easy Virtue\"", "Costiff"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9427083333333334}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3496", "before_prediction": "allotrope", "after_prediction": "a very reactive allotrope of oxygen that is damaging to lung tissue"}, {"id": "mrqa_naturalquestions-validation-3233", "before_prediction": "Grisha", "after_prediction": "Grisha Alekandrovich Nikolaev"}], "retained_ids": ["mrqa_squad-validation-6812", "mrqa_hotpotqa-validation-3250", "mrqa_triviaqa-validation-3575"], "fixed_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-1689", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_squad-validation-1070", "mrqa_squad-validation-10358", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_squad-validation-6627", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "unfixed_ids": ["mrqa_triviaqa-validation-3988"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.5999999988}, {"timecode": 91, "before_eval": {"predictions": ["40", "catherine", "Mongolian patrimonial feudalism", "drury lane", "The Taliban were spawned by the thousands of madrasahs the Deobandi movement established for impoverished Afghan refugees and supported by governmental and religious groups in neighboring Pakistan", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Australian-American", "100,000 writes", "paris", "surtiti", "tuscaloosa", "North Greenwich Arena", "the seed - producing plants that includes conifers, cycads, Ginkgo, and gnetophytes", "The 2015 Masters Tournament", "the table tennis sports film \"As One\"", "90%", "pig iron", "the machine gun had become an effective battlefield weapon", "1856", "Hepatocytes", "many deities and spirits, including the belief that spirits are found in non-human beings and objects such as animals, the waves, and the sky", "american national bank of new york", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "glastonbury", "magpies", "South Africa", "Four Weddings and a Funeral", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistan", "psilocybin, psilocin and baeocystin", "cuba and His Teddy Bear"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27879320855720285}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.07999999999999999, 0.47058823529411764, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.967741935483871, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4749", "mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-4471", "mrqa_hotpotqa-validation-2205", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-888", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_squad-validation-9812", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-1473", "mrqa_triviaqa-validation-6594"], "after_eval": {"predictions": ["40%", "Catherine Earnshaw", "autocratic-bureaucratic system", "muffin man", "Pakistan", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "American", "around 100,000 writes", "sardinia", "pacific ocean", "montgomery", "North Greenwich Arena", "either on the surface of scales or leaves", "2015 Masters Tournament", "Korea", "at least 90% certain", "steel", "communication", "1856", "liver", "belief in many deities and spirits", "manhattan", "in Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "blur", "birds", "South Africa", "Four Weddings and a Funeral", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistani", "psilocin", "cuba and His Teddy Bear"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8467991363211951}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.5, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-7551", "mrqa_hotpotqa-validation-1412", "mrqa_hotpotqa-validation-4256", "mrqa_naturalquestions-validation-6824", "mrqa_hotpotqa-validation-4229"], "fixed_ids": ["mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_hotpotqa-validation-2205", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-888", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_squad-validation-9812", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-1473"], "unfixed_ids": ["mrqa_triviaqa-validation-4749", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-1500", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_triviaqa-validation-6594"], "instant_fixing_rate": 0.7407407407407407, "instant_retention_rate": 0.9999999980000001}, {"timecode": 92, "before_eval": {"predictions": ["into a field in Somerset County, Pennsylvania", "socialism socialism", "the Gentle Don", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "Singapore", "1917", "BitInstant", "\"Stuck in the Suburbs\"", "santi", "steamboats", "Social Chapter", "Australia", "as few as 5 photoreceptor cells", "physics", "The Lone Ranger", "Robert Sargent Shriver Jr.", "Landry's, Inc.", "George Mifflin Dallas", "David Naughton, Jenny Agutter and Griffin Dunne", "national defence Volunteers", "1893 World's Columbian Exposition in Chicago with alternating current", "john alcock and Lieutenant Arthur Whitten-Brown", "1978", "member state size", "propeller", "the Irvine business centers of The Irvine Spectrum, West Irvine, and international corporations headquartered at the University of California, Irvine", "Marine Corps Base Hawaii (MCBH)", "Teen Titans Go!", "south african", "November 20, 1942", "Hugues Capet, king of France", "Morning Edition"], "metric_results": {"EM": 0.3125, "QA-F1": 0.45880907287157285}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.2857142857142857, 0.0, 0.5714285714285715, 0.25, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.4, 0.3333333333333333, 1.0, 0.6666666666666666, 0.19999999999999998, 0.4444444444444444, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_hotpotqa-validation-3514", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-6960", "mrqa_squad-validation-1400", "mrqa_triviaqa-validation-7185", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_hotpotqa-validation-2067", "mrqa_triviaqa-validation-1267", "mrqa_squad-validation-3189"], "after_eval": {"predictions": ["Pennsylvania", "karl marx", "\"the Gentle Don\" or \"the Docile Don\"", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "australia", "1898", "BitInstant", "\"Read It and Weep\" (2006)", "santi", "railway locomotives, ships, steamboats and road vehicles", "Social Chapter", "Australia", "photoreceptor cells", "quantized", "The Lone Ranger", "President John F. Kennedy", "Landry's, Inc.", "Vice President George Mifflin Dallas", "David Naughton, Jenny Agutter and Griffin Dunne", "local defence volunteers", "Chicago", "alcock and brown", "1978", "inversely", "kawasaki", "South Coast Metro", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "australia", "1942", "little Hugos, or those who want Hugo", "Morning Edition"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8789772727272727}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3276", "before_prediction": "steamboats", "after_prediction": "railway locomotives, ships, steamboats and road vehicles"}, {"id": "mrqa_hotpotqa-validation-3052", "before_prediction": "November 20, 1942", "after_prediction": "1942"}], "retained_ids": ["mrqa_hotpotqa-validation-5281", "mrqa_squad-validation-4106", "mrqa_squad-validation-3063", "mrqa_squad-validation-5811", "mrqa_hotpotqa-validation-1148", "mrqa_hotpotqa-validation-4387", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-2522"], "fixed_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_hotpotqa-validation-3514", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_triviaqa-validation-6960", "mrqa_squad-validation-1400", "mrqa_triviaqa-validation-7185", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_hotpotqa-validation-2067", "mrqa_squad-validation-3189"], "unfixed_ids": ["mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-1267"], "instant_fixing_rate": 0.7727272727272727, "instant_retention_rate": 0.7999999992}, {"timecode": 93, "before_eval": {"predictions": ["prairie region", "a method which pre-allocates dedicated network bandwidth specifically for each communication session, each having a constant bit rate and latency between nodes", "London Underground", "Utah", "manhattan", "France", "mid-size four - wheel drive luxury SUV", "Guyanese", "manhattan parlors", "we want to practice Christian love toward them and pray that they convert", "two populations of rodents: one resistant to the disease, which act as hosts, keeping the disease endemic, and a second that lack resistance", "around 1200", "T'Pau", "sherheitsdienst", "1815", "National Football Conference", "kimono (short sword) or a tant\u014d (knife)", "North America where it has a core population in Michigan and surrounding states and provinces", "antiforms", "2015", "man's disobedience to God", "as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "\"Winnie the Pooh\"", "Transpacific Yacht Race", "German", "\"Provisional Registration\"", "commercial explosives and blasting systems to the mining, quarrying, oil and gas and construction markets, a supplier of sodium cyanide for gold extraction, and a specialist provider of ground support services in mining and tunnelling", "either yes or no, or alternately either 1 or 0", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula", "In the Season 5 premiere, `` Weight Loss ''", "lie detector", "manhattan coast"], "metric_results": {"EM": 0.125, "QA-F1": 0.26126218371682086}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.06060606060606061, 0.0, 1.0, 0.0, 0.0, 0.0, 0.375, 0.33333333333333337, 0.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 0.1935483870967742, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.33333333333333337, 1.0, 0.06060606060606061, 0.4615384615384615, 0.16666666666666669, 0.9090909090909091, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-4204", "mrqa_squad-validation-9", "mrqa_triviaqa-validation-1548", "mrqa_naturalquestions-validation-2870", "mrqa_squad-validation-5111", "mrqa_hotpotqa-validation-421", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-3298", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "after_eval": {"predictions": ["alberta", "circuit switching", "green", "in nearly 100 locations across Utah, including : Mount Timpanogos, Ashley National Forest, Leeds, Snow Canyon State Park, St. George, Sundance Resort,", "golf", "Great Britain", "Mercedes - Benz", "barbadian", "chief wiggum", "convert", "two populations of rodents", "sometime between 124 and 800 CE, with some theories dating the earliest Polynesian settlements to the 10th or even 13th century", "British pop band T'Pau", "hemler", "1815", "American Football Conference", "seppuku", "north to the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts", "synforms", "2016", "alberta", "infinite sum of terms", "51st Disney animated feature film", "Transpac", "Operation Freshman and Operation Gunnerside", "\"Provisional Registration\"", "explosives", "yes or no", "Gibraltar", "the Season 5 premiere, `` Weight Loss ''", "lie detector", "king henry i"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8685141509433962}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.7924528301886793, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-919", "before_prediction": "France", "after_prediction": "Great Britain"}], "retained_ids": ["mrqa_squad-validation-831", "mrqa_squad-validation-2040", "mrqa_triviaqa-validation-2387"], "fixed_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-8161", "mrqa_squad-validation-9", "mrqa_triviaqa-validation-1548", "mrqa_naturalquestions-validation-2870", "mrqa_squad-validation-5111", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "unfixed_ids": ["mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-4204", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-3298"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.7499999981250001}, {"timecode": 94, "before_eval": {"predictions": ["the nucleus", "horror fiction", "tintagel", "alberta", "Southwest Florida International Airport ( R SW ), located southeast of the city", "the island of Puerto Rico", "the French island of Guadeloupe in the Lesser Antilles, mainly in the commune of Deshaies", "\"statute of Rageman\u201d (De Ragemannis)", "1938", "about 63% compared with an actual efficiency of 42% for a modern coal-fired power station", "American pharmaceutical company", "2016", "90% to 93% O2", "3 to 6 % of total solar radiation", "special sovereignty", "Goldbach's conjecture", "bremen", "short-tempered", "1987", "dastardly & Muttley", "to manage the pharmacy department and specialised areas in pharmacy practice allowing pharmacists the time to specialise in their expert field as medication consultants spending more time working with patients and in research", "sir walter", "1968", "chief petty officer", "led about 1,500 army troops and provincial militia on an expedition in June 1755 to take Fort Duquesne", "The Taliban", "2010", "Cork, Portarlington, Lisburn, Waterford and Youghal", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash in Hindi, Urdu and Punjabi", "Tom Coburn", "2016", "the ground water level fell significantly. Dead branches dried up and the amount of forests on the flood plains decreased sharply"], "metric_results": {"EM": 0.03125, "QA-F1": 0.17451431696640507}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.6666666666666666, 0.7368421052631579, 0.0, 0.0, 0.14285714285714288, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2105263157894737, 0.0, 0.0, 0.7499999999999999, 0.1, 1.0, 0.0, 0.923076923076923, 0.2857142857142857, 0.0, 0.0, 0.08695652173913045]}}, "error_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_squad-validation-3315", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-3677", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-9001", "mrqa_triviaqa-validation-6433", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_triviaqa-validation-3230", "mrqa_squad-validation-6322", "mrqa_triviaqa-validation-5584", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_hotpotqa-validation-848", "mrqa_squad-validation-3306", "mrqa_naturalquestions-validation-7496", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "after_eval": {"predictions": ["the nucleus", "carrie", "tamar", "chinese", "the Southwest Florida region", "Puerto Rico", "the French island of Guadeloupe in the Lesser Antilles", "rigmarole", "1933", "63%", "American", "2015", "90% to 93% O2", "45 %", "flags", "Chen's theorem", "kiel canal", "harsher", "mid-March", "Dastardly & Muttley", "governing body for pharmacy health care professionals", "Sir Walter Elliot", "1928", "E-1 through E-3 are known as Seamen", "a disaster", "The Taliban", "June 11, 1986", "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "Kirk Humphreys", "1988", "increased"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8420138888888888}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-9737"], "fixed_ids": ["mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_squad-validation-3315", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-9001", "mrqa_triviaqa-validation-6433", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_squad-validation-6322", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_hotpotqa-validation-848", "mrqa_squad-validation-3306", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "unfixed_ids": ["mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-8419", "mrqa_squad-validation-3677", "mrqa_triviaqa-validation-3230", "mrqa_triviaqa-validation-5584", "mrqa_naturalquestions-validation-7496"], "instant_fixing_rate": 0.8064516129032258, "instant_retention_rate": 0.9999999900000002}, {"timecode": 95, "before_eval": {"predictions": ["the \"richest 1 percent in the United States", "universal ruler", "red", "alain Giresse", "the Alps of northern Italy's Lombardy region", "ideal", "david duchovny", "amphibian", "the American newspaper magnate William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick", "parashah ( or parshah / p\u0251\u02d0r\u0283\u0259 / or parsha )", "in the s - block of the periodic table of elements", "World Music Awards", "six", "8\u20134\u20134 system", "exposed to scrutiny", "79", "banned the growing of coffee", "no French regular army troops", "a compromise between the two", "for exercise", "banshee", "Daniel Ken \"Daniel\" Inouye", "Jack Nicklaus", "Tom Brady", "honeycomb structures", "11 free suburban weekly newspapers together covering the Adelaide metropolitan area", "Dean Stanton", "Prince Henry", "a downward pressure on wages", "first adopted by the university's science club in 1886", "the Jurchen Aisin Gioro clan", "kronborg castle"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4120316772043746}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.375, 0.0, 0.9333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.0, 0.0, 1.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-717", "mrqa_squad-validation-9135", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8288", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_hotpotqa-validation-5033", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-4796"], "after_eval": {"predictions": ["the \"richest 1 percent in the United States now own more wealth than the bottom 90 percent\"", "universal ruler", "bra", "alain Giresse", "Lombardy", "Prime ideals", "\"The truth is out there\"", "cave bug", "the American newspaper magnate William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick, and aspects of Welles's own life", "a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week", "the s - block of the periodic table of elements as all alkali metals have their outermost electron in an s - orbital : this shared electron configuration results in their having very similar characteristic properties", "Best Selling Russian Artist", "28", "8\u20134\u20134 system", "exposed to scrutiny", "79 official PGA Tour events, second only to Sam Snead, and six ahead of Jack Nicklaus with 73 wins", "banned the growing of coffee, introduced a hut tax, and the landless were granted less and less land in exchange for their labour", "3,000 troupes de la marine, companies of colonial regulars (some of whom had significant woodland combat experience)", "Guilt implies wrong-doing. I feel I have done no wrong. I may have violated some specific laws, but I am guilty of doing no wrong", "stimulation his brain cells", "the bean chaointe (keening woman)", "Daniel Ken \"Daniel\" Inouye ( Japanese: \u4e95\u4e0a \u5efa, Hepburn: Inoue Ken ) was a United States Senator from Hawaii from 1963 to 2012.", "Sirest winner : Gene Sarazen in 1922 ( 20 years, 174 days )", "`` Mean Joe '' Greene : four as a defensive tackle, two as a special assistant for player personnel, all with the Pittsburgh Steelers", "caribbean", "11 free suburban weekly newspapers together covering the Adelaide metropolitan area", "Paul Edgecombe", "the Catholic Monarchs of Castile and Aragon funded Christopher Columbus's plan to sail west to reach the Indies by crossing the Atlantic", "a downward pressure on wages", "the university's science club in 1886", "the Kangxi Emperor ( r. 1661 -- 1722 )", "elsinore"], "metric_results": {"EM": 0.3125, "QA-F1": 0.47954328192331286}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2727272727272727, 1.0, 0.37837837837837834, 0.888888888888889, 1.0, 1.0, 1.0, 0.1, 1.0, 0.1, 0.7499999999999999, 0.0, 0.0, 0.24999999999999997, 0.10526315789473685, 0.2857142857142857, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.7272727272727272, 0.28571428571428575, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2178", "before_prediction": "red", "after_prediction": "bra"}, {"id": "mrqa_naturalquestions-validation-2159", "before_prediction": "79", "after_prediction": "79 official PGA Tour events, second only to Sam Snead, and six ahead of Jack Nicklaus with 73 wins"}, {"id": "mrqa_squad-validation-1445", "before_prediction": "for exercise", "after_prediction": "stimulation his brain cells"}, {"id": "mrqa_triviaqa-validation-2900", "before_prediction": "banshee", "after_prediction": "the bean chaointe (keening woman)"}, {"id": "mrqa_naturalquestions-validation-9985", "before_prediction": "Prince Henry", "after_prediction": "the Catholic Monarchs of Castile and Aragon funded Christopher Columbus's plan to sail west to reach the Indies by crossing the Atlantic"}], "retained_ids": ["mrqa_squad-validation-6130", "mrqa_squad-validation-8572", "mrqa_squad-validation-2293", "mrqa_squad-validation-7184"], "fixed_ids": ["mrqa_hotpotqa-validation-717", "mrqa_squad-validation-9135", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8288", "mrqa_triviaqa-validation-4796"], "unfixed_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_hotpotqa-validation-5033", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639"], "instant_fixing_rate": 0.2608695652173913, "instant_retention_rate": 0.4444444439506172}, {"timecode": 96, "before_eval": {"predictions": ["oxygen compounds, in particular various complex silicates (in silicate minerals)", "Xanthippus, a Spartan mercenary", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "Public-Private Partnering (PPPs) aka private finance initiatives (PFIs)", "the Greek word doxa ( \u03b4\u03cc\u03be\u03b1 )", "BASIC interpreters for the Altair 8800", "a particular nation, particularly with the aim of gaining and maintaining self- governance, or full sovereignty, over the group's homeland", "4,577 nautical miles (8,477 km)", "Army, Navy and other services", "carrie-Doo", "Renhe Sports Management Ltd, 100 % owned by Xiu Li Dai and Yongge Dai. 25 % Owned by Narin Niruttinanon", "Mike Schmidt", "faith in Jesus Christ as redeemer from sin", "hydrogen and helium", "where they were accepted and allowed to worship freely", "the radius R of the turntable in that animation, the rate of angular rotation \u03c9, and the speed of the cannonball ( assumed constant ) v", "2006", "74", "the Privy Council", "1162", "1928", "Porsche 968", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "1971", "the oldest street in the United States of America", "American Christian rock band Needtobreathe", "Americans to explain the Iranian Islamic Revolution and apolitical Islam was a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970\"", "September 1995", "cake or biscuit", "if the object is placed further away from the mirror / lens than the focal point and this real image is inverted", "gravitational", "kolinio Epeli Vanuacicila Rabuka and Salote Lomaloma Rabuka"], "metric_results": {"EM": 0.125, "QA-F1": 0.3026104957993503}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.5, 0.14285714285714288, 0.4, 0.0, 0.0, 0.0, 0.5714285714285715, 0.5714285714285715, 0.0, 0.2857142857142857, 0.0, 0.6666666666666666, 0.42857142857142855, 0.9411764705882353, 0.1904761904761905, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6363636363636364, 0.0, 1.0, 1.0, 0.07692307692307693, 0.0, 0.16666666666666666, 0.10526315789473684, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-7657", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_hotpotqa-validation-5490", "mrqa_squad-validation-3876", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_squad-validation-8189", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "after_eval": {"predictions": ["oxides of silicon", "Xanthippus", "Dome of the Rock", "Public-Private Partnering", "St. Augustine renders it as clara notitia cum laude, `` brilliant celebrity with praise ''", "microsoft", "Bulgaria", "13,900", "Army, Navy", "wild palms", "Xiu Li Dai", "phillies", "faith in Jesus Christ", "oxygen is the third-most abundant element in the universe, after hydrogen and helium", "they were accepted and allowed to worship freely", "angular rotation", "2006", "75", "Ministry of War", "1162", "bolivia", "924", "acts as a primer, by polymerizing the first few glucose molecules", "shaft", "New Paltz", "American Christian rock band Needtobreathe", "Americans", "on the shore of Lake Erie in downtown", "the Jaffa cake should be considered a cake for tax purposes", "inverted", "strong, electromagnetic, weak, and gravitational", "fiji"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9241071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3057", "before_prediction": "the oldest street in the United States of America", "after_prediction": "New Paltz"}], "retained_ids": ["mrqa_hotpotqa-validation-1088", "mrqa_squad-validation-6158", "mrqa_naturalquestions-validation-8272"], "fixed_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-7657", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_hotpotqa-validation-5490", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_squad-validation-8189", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_triviaqa-validation-3409"], "unfixed_ids": ["mrqa_squad-validation-3876", "mrqa_squad-validation-10311"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 97, "before_eval": {"predictions": ["third", "death", "suburb", "The National Era", "American Civil War", "blackberry", "July 1, 2005", "a few drops", "Addy Miller", "clangers", "President pro tempore of the Senate", "the optic chiasm, where there is a partial decussation ( crossing ) of fibres from the temporal visual fields ( the nasal hemi - retina ) of both eyes", "New York City:57\u201360", "nonviolence in protest and political action", "the Gararish", "Yuliya Snigir as Irina Komarova", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Galicia", "phillies", "science fiction", "26", "DC", "kolkata", "Nickelback", "Juliet", "as the \"father of the Mongols\"", "evidence that the ozone hole was indeed caused by chlorine and bromine from manmade organohalogens", "a combined concert/lecture by British progressive folk-rock band Gryphon", "island continent of Australia", "fomenting rebellion in many of Great Britain's far-flung colonies", "Psych", "the planned Nazi pre-emptive nuclear strike on Japan, `` Operation Dandelion, '' is apparently being prevented only by Hitler's personal refusal to authorise it"], "metric_results": {"EM": 0.09375, "QA-F1": 0.24622252747252749}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.20000000000000004, 0.0, 0.0, 0.8, 0.0, 0.5714285714285715, 0.14285714285714288, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.4, 0.0, 0.8571428571428571, 0.13333333333333333, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_hotpotqa-validation-3785", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-2504", "mrqa_naturalquestions-validation-1680", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_hotpotqa-validation-2802", "mrqa_squad-validation-1423", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_squad-validation-6228", "mrqa_naturalquestions-validation-654", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-1081", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "after_eval": {"predictions": ["6th season", "trust in Christ", "city centre", "in The National Era, an abolitionist periodical, starting with the June 5, 1851, issue", "the field of battle", "blackberries", "April 26, 2005", "a few drops", "Andrew Lincoln", "clangers", "Speaker of the House of Representatives", "lateral geniculate nucleus", "Continental Edison Company", "protest and political action", "Semitic people", "Yuliya Snigir", "pulmonary heart disease ( cor pulmonale ), which is usually caused by difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "the medieval city of Halych", "vanity fair", "science fiction drama", "26", "AC", "kolkata", "Canadian rock band Nickelback", "Tybalt", "father of the Mongols", "chlorine and bromine from manmade organohalogens", "a rock concert", "islands", "roger casement", "Psych is an American detective comedy-drama", "being tracked down by SS agents like Blake for dispatch to Hitler for an as - yet - unknown purpose"], "metric_results": {"EM": 0.75, "QA-F1": 0.8203125}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 0.38095238095238093]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7679", "before_prediction": "Addy Miller", "after_prediction": "Andrew Lincoln"}], "retained_ids": ["mrqa_squad-validation-3475", "mrqa_squad-validation-359"], "fixed_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-2504", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_hotpotqa-validation-2802", "mrqa_squad-validation-1423", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_squad-validation-6228", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271"], "unfixed_ids": ["mrqa_hotpotqa-validation-3785", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-1680", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-654", "mrqa_triviaqa-validation-1081", "mrqa_naturalquestions-validation-2729"], "instant_fixing_rate": 0.7586206896551724, "instant_retention_rate": 0.6666666644444444}, {"timecode": 98, "before_eval": {"predictions": ["Black Tuesday", "SKUM", "S7 series", "gazzetta Piemontese", "the eyespot allows the organism to move in response to light, often toward the light to assist in photosynthesis, and to predict day and night, the primary function of circadian rhythms", "phasimodo", "fossil sequences in which there was datable material, converting the old relative ages into new absolute ages", "heaviest album of all", "choral work", "San Francisco, California with offices in New York City and Atlanta", "economic recession", "ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "henry ivy", "sardinia", "\"citizenship\", so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for rights", "foot-oriented steps combined with fluid movements in the torso", "\"I'll Be There for You\"", "the Baltimore teenagers Ivan Ashford, Markel Steele, Cameron Brown, Tariq Al - Sabir and Avery Bargasse", "kent", "Sultans", "post-war communist control of the country", "clun", "much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast", "clangers", "north", "clangers", "Germ\u00e1n Efromovich", "a limited period of time", "kabuki", "Stritch", "between the three towns of Doncaster, Scunthorpe and Gainsborough", "in the United States was instituted by a New England cotton mill so that Jewish workers would not have to work on the Sabbath from sundown Friday to sundown Saturday"], "metric_results": {"EM": 0.1875, "QA-F1": 0.24394875957375958}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.10256410256410256, 0.0, 0.2222222222222222, 1.0, 0.0, 0.42857142857142855, 1.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 1.0, 0.30769230769230765, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_triviaqa-validation-6634", "mrqa_naturalquestions-validation-2213", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533", "mrqa_naturalquestions-validation-2713"], "after_eval": {"predictions": ["the most devastating stock market crash in the history of the United States", "SKUM", "S6", "Turin", "photoreceptor proteins that sense light, found even in unicellular organisms, called `` eyespots ''", "notre dame de paris", "fossil sequences", "heaviest album of all", "libretto", "San Francisco, California", "economic recession", "a former sexual or romantic partner, especially a former spouse", "jack", "sardinia", "\"citizenship\", so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for rights", "the jack", "friends", "the Baltimore teenagers Ivan Ashford, Markel Steele, Cameron Brown, Tariq Al - Sabir and Avery Bargasse", "kent", "a line of committed and effective Sultans", "World War II", "colne", "acquired a photosynthetic cyanobacterial endosymbiont more recently", "optical illusion", "Hannaford", "theatre", "Germ\u00e1n Efromovich", "time in exchange for detailed public disclosure of an invention", "tokyo", "American actor and drag queen Divine", "Isle of Axholme", "1908"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8703926282051282}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 0.0, 0.08333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2978", "before_prediction": "S7 series", "after_prediction": "S6"}], "retained_ids": ["mrqa_hotpotqa-validation-222", "mrqa_hotpotqa-validation-5011", "mrqa_naturalquestions-validation-9421", "mrqa_triviaqa-validation-1474", "mrqa_hotpotqa-validation-4093"], "fixed_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_triviaqa-validation-6634", "mrqa_naturalquestions-validation-2213", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_triviaqa-validation-2787", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533", "mrqa_naturalquestions-validation-2713"], "unfixed_ids": ["mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_naturalquestions-validation-10557"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8333333319444445}, {"timecode": 99, "before_eval": {"predictions": ["Doctor Who", "venstead", "elstow", "to force the Huguenots to convert", "a Gender pay gap in favor of males in the labor market", "Woody's Roundup", "December 19, 1967", "economic growth by collecting resources from colonies", "in 1997 by Bloomsbury", "October 1, 2017 on CBS for the 2017 -- 18 television season", "Washington, D.C.", "wicked", "Toronto, Ontario, Canada", "an Anglo-Saxon saint, of unknown date or origin, whose relics were held by Exeter Cathedral", "France's claim to the region was superior to that of the British", "a balance sensor consisting of a statolith, a solid particle supported on four bundles of cilia", "alberta", "extracurricular activities", "Roman Jakobson", "saloon-keeper", "the studies and developments department of the French firm R2E Micral in 1980 at the request of the company CCMC specializing in payroll and accounting", "Europe toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "Pope Gregory I the Great", "the author recounts how his own opinions changed about that line when he talks to the different people about their beliefs", "Twink", "Trinidadian and Tobagonian", "derry", "infinitely many primes", "porto", "Bhaktivedanta Manor", "giant jellyfish or the hair jelly", "detect heat (i.e. temperatures above body temperature)"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2744722119614854}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 0.21052631578947364, 0.2105263157894737, 0.0, 0.0, 0.4444444444444445, 0.4, 0.4615384615384615, 1.0, 0.6666666666666666, 0.5, 0.13333333333333333, 0.14814814814814817, 0.5555555555555556, 0.0, 0.0, 0.0, 1.0, 0.25, 0.9545454545454545, 1.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_squad-validation-9926", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-5630", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_hotpotqa-validation-1086", "mrqa_squad-validation-10231", "mrqa_squad-validation-4494", "mrqa_triviaqa-validation-4000", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-5590", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794", "mrqa_hotpotqa-validation-2779"], "after_eval": {"predictions": ["Seventh", "prohibition", "grace abounding", "At first he sent missionaries, backed by a fund to financially reward converts to Catholicism", "Gender", "horse", "May 5, 1939", "economic growth", "1997", "October 1, 2017", "Washington, D.C.", "wicked witch", "Toronto", "saint", "As to the Summons you send me to retire, I don't think myself obliged to obey it", "a balance sensor consisting of a statolith", "yosemite national park", "study halls", "Nikolai Trubetzkoy", "saloon-keeper", "the studies and developments department of the French firm R2E Micral in 1980 at the request of the company CCMC specializing in payroll and accounting", "originated in Europe toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "Pope Gregory I the Great", "his own opinions changed", "Chlo\u00eb Alexandra Adele Emily Agnew", "calypso", "Bloody Sunday", "at most one prime number", "portugal", "in the village of Aldenham", "capillata", "Mammals"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9737215909090909}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3347", "mrqa_hotpotqa-validation-4961", "mrqa_naturalquestions-validation-251"], "fixed_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_squad-validation-9926", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-5630", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_hotpotqa-validation-1086", "mrqa_squad-validation-4494", "mrqa_triviaqa-validation-4000", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-5590", "mrqa_naturalquestions-validation-3505", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794", "mrqa_hotpotqa-validation-2779"], "unfixed_ids": ["mrqa_squad-validation-10231", "mrqa_naturalquestions-validation-2732"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.9999999966666667}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.161875, "QA-F1": 0.27373623698678645}, "overall_error_number": 2682, "overall_instant_fixing_rate": 0.8542419183818444, "final_instream_test": {"EM": 0.6978125, "QA-F1": 0.7709093826485985}, "final_upstream_test": {"EM": 0.716, "QA-F1": 0.8274827393517067}}}