{"model_update_steps": 0, "method_class": "online_ewc", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ewc_gamma=1.0, ewc_lambda=500.0, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/cl_simple/nq_dev_0723_dynamic_ewc_l500_50_ckpts/', save_all_ckpts=1, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=10, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', predict_batch_size=16, sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', task_name='mrqa_naturalquestions', train_batch_size=1)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Merry Clayton", "Quantitative psychological research", "October 22, 2017", "Descriptive research", "Mike Myers", "CBS", "Landry's, Inc.", "Juan Francisco Ochoa", "RMS Titanic", "Gary Player", "Ryan Seacrest", "Mitch Murray", "every two to six years ( depending on the positions being filled with most positions good for four years )", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "each team is given a position in the drafting order in reverse order relative to its record in the previous year, which means that the last place team is positioned first", "in all cases affecting ambassadors, other public ministers and consuls, and those in which a state shall be party", "James Halliday", "Western Australia", "Ali Daei", "204,408 in 2013", "symbolises the freedom of the recipient to enter and leave the city at will, as a trusted friend of city residents", "10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "Georgia Groome", "18", "The Mandate of Heaven", "Chicago", "Michael English", "Massachusetts", "Ali", "an Abstergo agent", "Ming dynasty"], "metric_results": {"EM": 0.75, "QA-F1": 0.784691360870367}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45454545454545453, 0.11764705882352942, 0.0, 0.13793103448275862, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "after_eval": {"predictions": ["Merry Clayton", "statistical estimation or statistical inference", "October 22, 2017", "Descriptive research", "Mike Myers", "CBS", "Landry's, Inc.", "Juan Francisco Ochoa", "RMS Titanic", "Gary Player", "Giuliana Rancic", "Mitch Murray", "every two to six years", "a metaphor for a burden to be carried as penance", "backflow prevention", "each team", "in all cases affecting ambassadors, other public ministers and consuls, and those in which a state shall be party", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "South Korea", "Ali Daei", "204,408 in 2013", "symbolises the freedom of the recipient to enter and leave the city at will, as a trusted friend of city residents", "greater than 14", "Georgia Groome", "18", "The Mandate of Heaven", "Chicago", "Michael English", "Massachusetts", "Ali", "an Abstergo agent", "imperial rule"], "metric_results": {"EM": 0.90625, "QA-F1": 0.91875}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-6592", "mrqa_naturalquestions-validation-8279"], "retained_ids": ["mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-6568", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-6268", "mrqa_naturalquestions-validation-7392", "mrqa_naturalquestions-validation-7115", "mrqa_naturalquestions-validation-8546", "mrqa_naturalquestions-validation-2053", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-8092", "mrqa_naturalquestions-validation-1819", "mrqa_naturalquestions-validation-7837", "mrqa_naturalquestions-validation-7197", "mrqa_naturalquestions-validation-4821", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-1789", "mrqa_naturalquestions-validation-10550", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-9660", "mrqa_naturalquestions-validation-3922"], "fixed_ids": ["mrqa_naturalquestions-validation-7707", "mrqa_naturalquestions-validation-7017", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-816"], "unfixed_ids": ["mrqa_naturalquestions-validation-10080"], "error_ids": ["mrqa_naturalquestions-validation-10080", "mrqa_naturalquestions-validation-7707", "mrqa_naturalquestions-validation-7017", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-816"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.9166666666666666, "doing-nothing_instant_EM": 0.75, "doing-nothing_accmulative_EM": 0.75}, {"timecode": 1, "before_eval": {"predictions": ["Atlanta, Georgia", "Pat McCormick", "the Gentiles", "Felicity Huffman", "1976", "Piet van der Walt", "Ohio", "Thomas Jefferson", "any data that can be used to identify a living individual", "overharvesting, pollution, habitat destruction, introduction of invasive species ( such as new predators and food competitors ), overhunting, and other influences", "October 1941", "a loop", "mid November", "testes", "Pluto", "1974", "Domhnall Gleeson", "360", "Presley Smith", "Taron Egerton", "Woody Paige", "The Main Ingredient", "the Battle of Antietam", "Mad - Eye Moody and Hedwig", "Matthew Broderick", "Leo Howard", "Wales and Yorkshire", "seven", "needle - like", "2005", "enforcing racially separated educational facilities", "China"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7198660714285714}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["Atlanta, Georgia", "Pat McCormick", "to Jewish audiences", "Felicity Huffman", "1976", "Erastus Utoni Nujoma", "Toledo", "Thomas Jefferson", "to data which is held, or intended to be held, on computers ('equipment operating automatically in response to instructions given for that purpose'), or held in a'relevant filing system '", "Explosive, unsustainable human population growth", "October 1941", "a loop", "late November or early December", "Reproductive system", "Dis Pater", "1889", "Domhnall Gleeson", "360", "Presley Smith", "Taron Egerton", "Woody Paige", "Ronnie Dyson", "Battle of Antietam", "Mad - Eye Moody", "Matthew Broderick", "Leo Howard", "Wales and Yorkshire", "seven", "needle - like", "2005", "enforcing racially separated educational facilities", "China"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9689102564102564}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.20512820512820515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-3927"], "retained_ids": ["mrqa_naturalquestions-validation-7649", "mrqa_naturalquestions-validation-412", "mrqa_naturalquestions-validation-1920", "mrqa_naturalquestions-validation-5596", "mrqa_naturalquestions-validation-6786", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-160", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-4459", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-10091", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-5281", "mrqa_naturalquestions-validation-7352", "mrqa_naturalquestions-validation-6641", "mrqa_naturalquestions-validation-5119", "mrqa_naturalquestions-validation-6040", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-9004"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-8529", "mrqa_naturalquestions-validation-8884", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-10326", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-922"], "unfixed_ids": ["mrqa_naturalquestions-validation-6474"], "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-8529", "mrqa_naturalquestions-validation-8884", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-10326", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-922"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.9545454545454546, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.71875}, {"timecode": 2, "before_eval": {"predictions": ["Ethiopia", "Hendersonville, North Carolina", "Bunkhouse", "Woodrow Wilson", "Gary Grimes", "1773", "Stephen Lang", "2016", "1999", "Lauren Tom", "Robert Koch", "Mission : Impossible -- Fallout", "Ozzie Smith", "members of the gay ( LGBT ) community", "Amitabh Bachchan", "Miami Heat", "Mahatma Gandhi", "1995", "First Lieutenant Israel Greene", "judges", "Lord's", "1979", "New York Yankees'third baseman Alex Rodriguez", "the Speaker", "a combination of genetics and the male hormone dihydrotestosterone", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "September 1993", "political ideology", "Dilwale Dulhania Le Jayenge", "New England", "Dollree Mapp", "the President"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8072916666666666}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["Ethiopia", "across western North Carolina including Asheville, Cashiers and Saluda", "Bed and breakfast", "Woodrow Wilson", "Gary Grimes", "1773", "Stephen Lang", "2016", "1999", "Lauren Tom", "Robert Koch", "Mission : Impossible -- Fallout", "Ozzie Smith", "members of the gay ( LGBT ) community", "Amitabh Bachchan", "Miami Heat", "Mahatma Gandhi", "1995", "First Lieutenant Israel Greene", "The courts", "Lord's", "1979", "Alex Rodriguez", "President", "a combination of genetics and the male hormone dihydrotestosterone", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "September 1993", "political ideology", "Dilwale Dulhania Le Jayenge", "1958", "Dollree Mapp", "President"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-1950", "mrqa_naturalquestions-validation-3043", "mrqa_naturalquestions-validation-2540", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-1605", "mrqa_naturalquestions-validation-5751", "mrqa_naturalquestions-validation-2025", "mrqa_naturalquestions-validation-1475", "mrqa_naturalquestions-validation-8726", "mrqa_naturalquestions-validation-9872", "mrqa_naturalquestions-validation-5063", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-5883", "mrqa_naturalquestions-validation-4454", "mrqa_naturalquestions-validation-8423", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-2418", "mrqa_naturalquestions-validation-4532", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-684", "mrqa_naturalquestions-validation-9578", "mrqa_naturalquestions-validation-3000", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-9716"], "fixed_ids": ["mrqa_naturalquestions-validation-4974", "mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-4999", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3893"], "unfixed_ids": ["mrqa_naturalquestions-validation-2100"], "error_ids": ["mrqa_naturalquestions-validation-4974", "mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-2100", "mrqa_naturalquestions-validation-4999", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3893"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.8125, "doing-nothing_accmulative_EM": 0.75}, {"timecode": 3, "before_eval": {"predictions": ["Bill Russell", "Johnson", "1837", "Broken Hill and Sydney", "Justin Timberlake", "alternation of generations", "China", "June Gable", "seawater pearls", "Donald Trump", "February 25, 2004", "Havana Harbor", "about 3.5 mya", "The Internet protocol suite ( TCP / IP )", "Clement Attlee's Labour Party", "The Han", "extends 2,000 kilometres ( 1,200 mi ) down the Australian northeast coast", "Database - Protocol driver", "May 2010", "reserved for cars of the royal family", "Benzodiazepines", "1983", "The federal government", "Paul Hogan", "Tori Kelly", "Christianity", "886 AD", "rear leg of the cow", "Cedric Alexander", "October 2012", "Henry and Liza", "sepoys of the Company's army"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7585227272727273}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.27272727272727276]}}, "after_eval": {"predictions": ["Bill Russell", "Johnson", "1837", "Broken Hill and Sydney", "Justin Timberlake", "alternation of generations", "East India Company", "June Gable", "the Indian Ocean", "Donald Trump", "February 25, 2004", "Havana Harbor", "about 3.5 mya", "the French CYCLADES project directed by Louis Pouzin", "Labour Party", "Qing", "South Pacific", "Database - Protocol driver ( Pure Java driver )", "May 2010", "reserved for cars of the royal family", "Benzodiazepines", "1983", "states", "Paul Hogan, AM", "Tori Kelly", "Christianity", "the 1960s.", "the `` round '', the rear leg of the cow", "Cedric Alexander", "October 2012", "two characters, called Henry and Liza", "sepoys of the Company's army in the garrison town of Meerut, 40 miles northeast of Delhi ( now Old Delhi )"], "metric_results": {"EM": 0.875, "QA-F1": 0.9563492063492063}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.9142857142857143]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-1171", "mrqa_naturalquestions-validation-7001", "mrqa_naturalquestions-validation-6821"], "retained_ids": ["mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-4370", "mrqa_naturalquestions-validation-397", "mrqa_naturalquestions-validation-6358", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-1535", "mrqa_naturalquestions-validation-10476", "mrqa_naturalquestions-validation-2234", "mrqa_naturalquestions-validation-7922", "mrqa_naturalquestions-validation-8318", "mrqa_naturalquestions-validation-7027", "mrqa_naturalquestions-validation-9972", "mrqa_naturalquestions-validation-6110", "mrqa_naturalquestions-validation-4442", "mrqa_naturalquestions-validation-9685", "mrqa_naturalquestions-validation-9786", "mrqa_naturalquestions-validation-3222", "mrqa_naturalquestions-validation-744", "mrqa_naturalquestions-validation-3431"], "fixed_ids": ["mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-3732", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-8368"], "unfixed_ids": ["mrqa_naturalquestions-validation-4098"], "error_ids": ["mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-3732", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-8368", "mrqa_naturalquestions-validation-4098"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.8636363636363636, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7421875}, {"timecode": 4, "before_eval": {"predictions": ["Henry Selick", "honey bees", "2010", "Michael Rosen", "interpreter", "June 1991", "converting glucose to glycogen", "the subcutis, the layer of skin directly below the dermis and epidermis, collectively referred to as the cutis", "18 - season", "a young girl", "two senior enlisted sailor ( `` E-9 '' )", "July 1, 1890", "preaching, evangelism, and ministry, especially to the poor", "Skat", "Karen Gillan", "Iowa", "Kim Basinger", "Roxette", "George II", "1939", "Kyla Pratt", "Keegan - Michael Key", "1 mile ( 1.6 km )", "Gatiman express", "Alton, Elora, King Township, Toronto, Uxbridge, and Whitevale", "Ewan McGregor", "nomads from Inner Asia", "126 PYG to 1 USD", "Sanchez Navarro", "Frank Langella", "a desire to be reckoned with as an openly wounded and unabashedly portentous rock balladeer", "the United States"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7411301560758082}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "after_eval": {"predictions": ["Henry Selick", "pineapple", "2010", "Michael Rosen", "source code", "June 1991", "acts as a primer, by polymerizing the first few glucose molecules", "the subcutis, the layer of skin directly below the dermis and epidermis, collectively referred to as the cutis", "2001", "an illustration by Everest creative Maganlal Daiya back in the 1960s", "E-7s are called chief petty officer", "July 1, 1890", "preaching, evangelism, and ministry, especially to the poor", "Skat", "Karen Gillan", "Iowa", "Kim Basinger", "Roxette", "George II", "1939", "Kyla Pratt", "Keegan", "1 mile", "160km / hour", "Alton, Elora, King Township, Toronto, Uxbridge, and Whitevale, all located in the Canadian province of Ontario", "Ewan McGregor", "nomads from Inner Asia", "126 PYG", "Morelos Battalion", "Frank Langella", "Can't Change Me", "Taft"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9159226190476191}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.5714285714285715, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-10492", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-4450", "mrqa_naturalquestions-validation-8883"], "retained_ids": ["mrqa_naturalquestions-validation-3612", "mrqa_naturalquestions-validation-5072", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-5744", "mrqa_naturalquestions-validation-2435", "mrqa_naturalquestions-validation-8795", "mrqa_naturalquestions-validation-1578", "mrqa_naturalquestions-validation-8531", "mrqa_naturalquestions-validation-4691", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-2955", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-10284", "mrqa_naturalquestions-validation-9248", "mrqa_naturalquestions-validation-576", "mrqa_naturalquestions-validation-7816", "mrqa_naturalquestions-validation-793"], "fixed_ids": ["mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-9885", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-824", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-3395", "mrqa_naturalquestions-validation-8488", "mrqa_naturalquestions-validation-8990"], "unfixed_ids": ["mrqa_naturalquestions-validation-7270"], "error_ids": ["mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-9885", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-824", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-3395", "mrqa_naturalquestions-validation-8488", "mrqa_naturalquestions-validation-7270", "mrqa_naturalquestions-validation-8990"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.8181818181818182, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.73125}, {"timecode": 5, "before_eval": {"predictions": ["Wisconsin", "local authorities, specifically London boroughs, Metropolitan Boroughs, unitary authorities, and district councils", "Menelaus", "Vincenzo Peruggia", "the 9th century", "Kostas", "Wylie Draper", "2003", "Hans Raffert", "The Lykan Hypersport", "Meri", "Arthur Chung", "1984", "two alkyl halides are reacted with sodium metal in dry ether solution to form a higher alkane", "1940s", "self - closing flood barrier", "February 27, 2007", "Billie `` The Blue Bear ''", "159 beats per minute ( bpm )", "Nuevo Reino de Le\u00f3n", "February 3, 2017", "October 6, 2017", "used obscure languages as a means of secret communication during wartime", "Pete Maravich", "Walter Brennan", "precipitation rate exceeds the infiltration rate", "the town Anguillara Sabazia outside of Rome", "October 14, 2017", "the 2nd century", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "Coton", "Baaghi"], "metric_results": {"EM": 0.5, "QA-F1": 0.656954398258746}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.8, 0.30434782608695654, 0.5, 0.5]}}, "after_eval": {"predictions": ["Wisconsin", "local authorities", "Aegisthus", "Vincenzo Peruggia", "the 9th century", "Kostas", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "Cristeta Comerford", "The Lykan Hypersport", "Meri", "Arthur Chung", "1984", "to form a higher alkane", "in the 1940s", "The self - closing flood barrier ( SCFB )", "February 27, 2007", "Billie `` The Blue Bear ''", "Tachycardia", "1535", "February 3, 2017", "October 6, 2017", "Native Americans in the United States Marine Corps whose primary job was the transmission of secret tactical messages", "Pete Maravich", "Walter Brennan", "runoff", "in the town Anguillara Sabazia outside of Rome", "October 14, 2017", "in the 2nd century", "enforce the best practice in ethics ( such as authorship, research ethics, and disclosure )", "Coton in the Elms", "Baaghi ( English : Rebel )"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9797619047619047}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6857142857142856, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7087"], "retained_ids": ["mrqa_naturalquestions-validation-10712", "mrqa_naturalquestions-validation-3507", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2637", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-5230", "mrqa_naturalquestions-validation-6877", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-6347", "mrqa_naturalquestions-validation-1930", "mrqa_naturalquestions-validation-2565", "mrqa_naturalquestions-validation-557"], "fixed_ids": ["mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-1531", "mrqa_naturalquestions-validation-10619", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-1657", "mrqa_naturalquestions-validation-5558", "mrqa_naturalquestions-validation-10162", "mrqa_naturalquestions-validation-6352", "mrqa_naturalquestions-validation-4496", "mrqa_naturalquestions-validation-746", "mrqa_naturalquestions-validation-9912", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-3623"], "unfixed_ids": ["mrqa_naturalquestions-validation-4050"], "error_ids": ["mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-1531", "mrqa_naturalquestions-validation-10619", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-1657", "mrqa_naturalquestions-validation-5558", "mrqa_naturalquestions-validation-10162", "mrqa_naturalquestions-validation-6352", "mrqa_naturalquestions-validation-4496", "mrqa_naturalquestions-validation-746", "mrqa_naturalquestions-validation-9912", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-4050", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-3623"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.9375, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.7239583333333334}, {"timecode": 6, "before_eval": {"predictions": ["Content", "1932 and 1980", "Dido", "Jonathan Goldstein", "Americans who served in the armed forces and as civilians", "Rugrats in Paris : The Movie", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "UTC \u2212 09 : 00", "1955", "1876", "just after the Super Bowl", "Crepuscular", "to be controlled via pulse - width modulation of the pump voltage", "The distance covered by a vehicle ( for example as recorded by an odometer ), person, animal, or object along a curved path from a point A to a point B", "Disha Vakani", "103", "The balance sheet", "Vienna", "July 1, 2005", "Zoroastrian", "`` There is one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and in all ''", "Jack Nicklaus", "Steven `` Steve '' Hale", "December 20, 1951", "The Crescent City Live - Stock Landing and Slaughter - House Company", "Dr. Jesse Bennett", "southwestern United States", "Bob Dylan", "Hold On", "1800 to 1850", "B.J. Thomas", "Cadillac"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7286539032862562}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.1111111111111111, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.23076923076923078, 1.0, 1.0]}}, "after_eval": {"predictions": ["information", "twice", "Dido", "Jonathan Goldstein", "Americans who served in the armed forces and as civilians during World War II", "Rugrats in Paris : The Movie", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "eight hours ( UTC \u2212 08 : 00 )", "1955", "1876", "the tradition of announcing winners of its $10 million prize just after the Super Bowl", "Crepuscular", "via pulse - width modulation of the pump voltage", "displacement", "Disha Vakani", "103", "The balance sheet", "Vienna", "April 26, 2005", "Zoroastrian", "the oneness of the body, the church, through what Christians have in common, what they have communion in", "Greatest winning margin in the stroke play era : 8 strokes, Rory McIlroy", "Steven `` Steve '' Hale ( originally introduced as Steve Peters ; portrayed by Scott Weinger )", "December 20, 1951", "New Orleans", "Dr. Jesse Bennett", "arid lowland or mountainous shrubland, widely dispersed in dry open country with scattered brush", "Bob Dylan", "Hold On", "originated in Europe toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "B.J. Thomas", "Cadillac"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9522058823529411}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-571", "mrqa_naturalquestions-validation-5043"], "retained_ids": ["mrqa_naturalquestions-validation-8182", "mrqa_naturalquestions-validation-1557", "mrqa_naturalquestions-validation-9646", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-2682", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-9848", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-1028", "mrqa_naturalquestions-validation-6466", "mrqa_naturalquestions-validation-159", "mrqa_naturalquestions-validation-4151", "mrqa_naturalquestions-validation-7362", "mrqa_naturalquestions-validation-135", "mrqa_naturalquestions-validation-1067", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-8181"], "fixed_ids": ["mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-1385", "mrqa_naturalquestions-validation-735", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-8319", "mrqa_naturalquestions-validation-3505"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-1385", "mrqa_naturalquestions-validation-735", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-8319", "mrqa_naturalquestions-validation-3505"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8571428571428571, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7232142857142857}, {"timecode": 7, "before_eval": {"predictions": ["rises in two branches in the Texas Panhandle and flows east, where it acts as the border between the states of Texas and Oklahoma", "Kate Warne", "May 2017", "to prevent organizations from abusing their tax - exempt status", "English law", "Max Martin", "`` Robber baron ''", "P $ C", "before the first year begins", "Andy", "Freddie Highmore", "2008", "in the kidneys", "Keith Thibodeaux", "a chute beneath his or her feet", "President pro tempore of the Senate", "c. 1000 AD", "Charlene Holt", "Pittsburgh", "electron pairs", "Authority ( derived from the Latin word auctoritas )", "gonadotropin - releasing hormone ( GnRH )", "Frank Zappa", "Gabourey Sidibe as older Regina, Nya Auzenne as young Regina )", "1989", "Daenerys Targaryen ( season 1 -- present ) portrayed by Emilia Clarke", "the public", "Reverend J. Long", "late summer", "1", "Shepperton Studios in Surrey, United Kingdom", "unknown origin"], "metric_results": {"EM": 0.625, "QA-F1": 0.679298418972332}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, true], "QA-F1": [0.17391304347826084, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.20000000000000004, 1.0, 1.0, 1.0, 0.28571428571428575, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["the Texas Panhandle", "Kate Warne", "May 2017", "provides the public with financial information about a nonprofit organization", "English law", "Max Martin", "`` Robber baron ''", "P $ C featuring T.I. & Lil Scrappy, Mike Jones featuring Nicole Wray, Trillville, Juvenile featuring Skip & Wacko, Nasty Nardo, 8Ball & MJG, Lil", "the student's transition from the study of preclinical to clinical health sciences", "Andy", "Freddie Highmore", "2002", "heart", "Keith Thibodeaux", "a chute", "Speaker of the House of Representatives", "c. 1000 AD", "Charlene Holt", "Pittsburgh", "shared pairs or bonding pairs", "Authority", "estrogen", "Frank Zappa", "Bonnie Lipton ( portrayed by Skyler Samuels )", "1989", "Emilia Clarke", "the public", "Reverend J. Long", "late - September through early January", "1", "Shepperton Studios in Surrey, United Kingdom", "unknown origin"], "metric_results": {"EM": 0.875, "QA-F1": 0.9386398176291794}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8936170212765957, 0.8571428571428572, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-10015", "mrqa_naturalquestions-validation-4996"], "retained_ids": ["mrqa_naturalquestions-validation-4273", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-1462", "mrqa_naturalquestions-validation-6924", "mrqa_naturalquestions-validation-4751", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-1886", "mrqa_naturalquestions-validation-6432", "mrqa_naturalquestions-validation-467", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-2863", "mrqa_naturalquestions-validation-7991", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-8054", "mrqa_naturalquestions-validation-8426", "mrqa_naturalquestions-validation-6950", "mrqa_naturalquestions-validation-9071"], "fixed_ids": ["mrqa_naturalquestions-validation-8064", "mrqa_naturalquestions-validation-925", "mrqa_naturalquestions-validation-1179", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-8180", "mrqa_naturalquestions-validation-4309", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-226"], "unfixed_ids": ["mrqa_naturalquestions-validation-8791", "mrqa_naturalquestions-validation-5465"], "error_ids": ["mrqa_naturalquestions-validation-8064", "mrqa_naturalquestions-validation-925", "mrqa_naturalquestions-validation-8791", "mrqa_naturalquestions-validation-5465", "mrqa_naturalquestions-validation-1179", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-8180", "mrqa_naturalquestions-validation-4309", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-226"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.7109375}, {"timecode": 8, "before_eval": {"predictions": ["A simple majority vote", "Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson in supporting roles", "Luke 6 : 12 -- 16", "Muhammad", "Total Drama World Tour", "personnel directors", "Jack Barry", "around 4 P.M. on Monday, July 10, 2017", "the UK Singles Chart for four weeks during the summer of 1979", "1939", "Rocky Dzidzornu", "Blake Lively", "Greek", "Dustin Johnson", "Michael Buffer", "1947", "Christopher Allen Lloyd", "Dorothy Kilgallen", "1959", "the Ramones", "Ephesus", "Charles Lebrun", "complex structured and unstructured information used by a computer system", "meta - ideology", "A.O Hume, a retired British officer", "the Mediterranean coastal region of southern Turkey from the central Anatolian Plateau", "Joan Baez", "Selena Gomez", "fertilization", "1996", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root mlk `` king ''", "Cheryl Lynn"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6974547773654917}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true], "QA-F1": [0.8, 0.6938775510204082, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8333333333333333, 0.0, 0.0, 1.0, 0.0, 0.14285714285714288, 1.0]}}, "after_eval": {"predictions": ["A simple majority", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma", "Luke 6 : 12 -- 16", "Muhammad", "Total Drama World Tour", "NFL coaches, general managers, and scouts", "Jack Barry", "Monday, July 10, 2017", "1979", "1940", "Rocky Dzidzornu", "Blake Lively", "Greek", "Dustin Johnson", "Michael Buffer", "1947", "Christopher Allen Lloyd", "John Daly", "1959", "the Ramones", "Ephesus", "Louis XIV", "complex structured and unstructured information", "ideology", "A.O Hume, a retired British officer", "in southern Turkey, dividing the Mediterranean coastal region of southern Turkey from the central Anatolian Plateau", "President Lyndon Johnson", "Instagram's own account", "fertilization", "2010", "king", "Cheryl Lynn"], "metric_results": {"EM": 0.875, "QA-F1": 0.9651785714285714}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-1807", "mrqa_naturalquestions-validation-1037"], "retained_ids": ["mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-6650", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-8341", "mrqa_naturalquestions-validation-9165", "mrqa_naturalquestions-validation-2920", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-52", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-115", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-6517", "mrqa_naturalquestions-validation-3693", "mrqa_naturalquestions-validation-2350", "mrqa_naturalquestions-validation-10187"], "fixed_ids": ["mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-8599", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-407", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-9581", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-2085"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-5785"], "error_ids": ["mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-8599", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-407", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-9581", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-5785", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-2085"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8947368421052632, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7118055555555556}, {"timecode": 9, "before_eval": {"predictions": ["constitutional right", "Aristotle", "March 23, 2013", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "2017", "Richard Crispin Armitage", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "December 24, 1836", "to Napoleon's planned invasion of the United Kingdom", "Thomas Hobbes in his Leviathan", "status line", "1608", "at the foot of biblical Mount Sinai", "a prison", "3D modeling ( or three - dimensional modeling )", "Donna Mills", "energy loss", "to denote the groups of the periodic table", "A error does not count as a hit", "Amanda Leighton", "Manley", "free floating", "Ella Mitchell", "1938", "St. Albans, Vermont", "reinforce the front and sides of the trachea to protect and maintain the airway", "Elizabeth Lail", "displacement", "instructions", "frequency f, wavelength \u03bb, or photon energy E", "Wyoming", "Zeebo"], "metric_results": {"EM": 0.625, "QA-F1": 0.6755608974358974}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.06666666666666667, 0.0, 1.0]}}, "after_eval": {"predictions": ["constitutional right", "Aristotle", "March 23, 2013", "stress", "2018", "Richard Crispin Armitage", "the final episode of the series", "December 24, 1836", "Napoleon's planned invasion of the United Kingdom", "Thomas Hobbes in his Leviathan", "the status line", "1608", "the foot of biblical Mount Sinai", "as a royal residence", "3D modeling ( or three - dimensional modeling )", "Donna Mills", "energy loss", "to denote the groups of the periodic table", "counts as an at bat for the batter unless, in the scorer's judgment, the batter would have reached first base safely but one or more of the additional base ( s ) reached was the result of the fielder's mistake", "Amanda Leighton", "Manley", "fiat money", "Ella Mitchell", "1933", "St. Albans, Vermont", "to protect and maintain the airway", "Elizabeth Mitchell", "displacement", "A computer program", "from 702399999999999999999 \u2660 2.4 \u00d7 10 Hz ( 1 GeV gamma rays ) down to the local plasma frequency of the ionized interstellar medium ( ~ 1 kHz )", "Idaho", "Zeebo"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9738786604020979}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.9545454545454546, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-4801"], "retained_ids": ["mrqa_naturalquestions-validation-2242", "mrqa_naturalquestions-validation-7033", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-7996", "mrqa_naturalquestions-validation-1453", "mrqa_naturalquestions-validation-4879", "mrqa_naturalquestions-validation-10683", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-4323", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-971", "mrqa_naturalquestions-validation-5368", "mrqa_naturalquestions-validation-469"], "fixed_ids": ["mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2657", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-6660", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-2624", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-4506"], "unfixed_ids": ["mrqa_naturalquestions-validation-8700", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-5798"], "error_ids": ["mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2657", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-8700", "mrqa_naturalquestions-validation-6660", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-2624", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-4506"], "instant_fixing_rate": 0.75, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.703125}, {"timecode": 10, "before_eval": {"predictions": ["the transition from summer to winter, in September ( Northern Hemisphere ) or March ( Southern Hemisphere )", "the major contributor and the associated free software philosophy", "Professor Kantorek", "2002", "Barbara Windsor", "The head contains the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "Alice", "Colman", "six 50 minute ( one - hour with advertisements )", "ancient cult activity as far back as 7th century BCE", "Husrev Pasha", "New York University", "after the 2015 model year", "Ledger", "23", "the body responsible for the encouragement, regulation and enforcement of workplace health, safety and welfare, and for research into occupational risks in Great Britain", "Kenneth Cook ( 2018 )", "Napoleon Bonaparte", "Charles Sherrington", "arthropods, molluscs, roundworms, ringed worms, flatworms, and other phyla in Ecdysozoa and Spiralia", "Bill Pullman", "sex hormones", "Kaley Christine Cuoco", "Theodore Roosevelt, Robert M. La Follette, Sr., and Charles Evans Hughes on the Republican side, and William Jennings Bryan, Woodrow Wilson and Al Smith on the Democratic side", "to foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "Kyla Pratt", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "1998", "Eagles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "inequality of opportunity", "Katherine Kiernan Maria `` Kate '' Mulgrew"], "metric_results": {"EM": 0.53125, "QA-F1": 0.631751888292586}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.06666666666666667, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9767441860465117, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4666666666666667, 1.0, 0.4444444444444445, 0.0, 1.0, 0.4615384615384615, 1.0, 1.0]}}, "after_eval": {"predictions": ["fall", "Richard Stallman", "Paul Baumer", "2002", "Barbara Windsor", "midpiece", "a card from a pack of playing cards by Alice, yet somehow she is able to talk and is the ruler of the lands in the story, alongside her tiny husband, the King of Hearts", "Colman", "16", "Vesta", "Husrev Pasha", "Columbia University", "after the 2015 model year", "Ledger", "23", "responsible for the encouragement, regulation and enforcement of workplace health, safety and welfare, and for research into occupational risks in Great Britain", "Kenneth Cook", "Napoleon Bonaparte", "Charles Sherrington", "a vertebral column ( spine )", "Bill Pullman", "reproductive", "Kaley Christine Cuoco", "Robert M. La Follette, Sr.", "promote high employment and sustainable economic growth", "Kyla Pratt", "Gina Tognoni", "1997", "Eagles", "toasted wheat bun", "inequality of opportunity", "Katherine Kiernan Maria `` Kate '' Mulgrew"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9788306451612903}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32258064516129037, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2176"], "retained_ids": ["mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-3145", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-287", "mrqa_naturalquestions-validation-10361", "mrqa_naturalquestions-validation-6093", "mrqa_naturalquestions-validation-1", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-9613", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-5790", "mrqa_naturalquestions-validation-3969", "mrqa_naturalquestions-validation-3163"], "fixed_ids": ["mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-4006", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-8841", "mrqa_naturalquestions-validation-6483", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4021", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-390"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-4006", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-8841", "mrqa_naturalquestions-validation-6483", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4021", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-390"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9411764705882353, "doing-nothing_instant_EM": 0.59375, "doing-nothing_accmulative_EM": 0.6931818181818182}, {"timecode": 11, "before_eval": {"predictions": ["to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "The Man", "July 2014", "2017", "James Rodr\u00edguez", "September 27, 2017", "Lori Rom", "Buffalo Bill", "art of the Persian Safavid dynasty from 1501 to 1722", "John Hurt", "2017", "1919", "The Maginot Line", "2015", "Anna Faris and Allison Janney in lead roles as dysfunctional daughter / mother duo Christy and Bonnie Plunkett", "Rock Island, Illinois", "Wynonna Judd", "a million - dollar question without using any lifelines", "Hermann Ebbinghaus", "in England and Wales", "2013", "North American Plate", "to permit the immediate consideration of a legislative measure, notwithstanding the usual order of business, and to prescribe conditions for its debate and amendment", "Andy Warhol", "Camping World Stadium in Orlando, Florida", "Frankie Valli", "Texas A&M Aggies", "Jason Marsden", "43", "Eleanor Parker as Ruth Hartley", "Dr. Lexie Grey", "Bachendri Pal"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7812316310225279}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.35294117647058826, 0.06451612903225806, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "after_eval": {"predictions": ["London", "The Man", "second season", "2017", "Thomas M\u00fcller", "September 27, 2017", "Lori Rom", "Levine", "ceramics", "John Hurt", "2017", "1919", "The Maginot Line", "2015", "Allison Janney", "Rock Island, Illinois", "Wynonna Judd", "Carpenter", "Hermann Ebbinghaus", "arose separately in England and Wales", "2013", "Subduction of the Nazca Plate beneath the South American Plate to form the Andes", "determining under what rule other bills will come to the floor", "Andy Warhol", "Camping World Stadium in Orlando, Florida", "Frankie Valli", "Texas A&M Aggies", "Jason Marsden", "43", "Anthony Caruso", "Dr. Lexie Grey", "Prem Lata Agarwal"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7339", "mrqa_naturalquestions-validation-4090", "mrqa_naturalquestions-validation-10268"], "retained_ids": ["mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-9917", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-1853", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-5864", "mrqa_naturalquestions-validation-5082", "mrqa_naturalquestions-validation-340", "mrqa_naturalquestions-validation-1502", "mrqa_naturalquestions-validation-1625", "mrqa_naturalquestions-validation-651", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-10682", "mrqa_naturalquestions-validation-5346", "mrqa_naturalquestions-validation-1389", "mrqa_naturalquestions-validation-4443", "mrqa_naturalquestions-validation-13", "mrqa_naturalquestions-validation-10176", "mrqa_naturalquestions-validation-2232"], "fixed_ids": ["mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9346", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-1910", "mrqa_naturalquestions-validation-2646", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-9681", "mrqa_naturalquestions-validation-3882"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9346", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-1910", "mrqa_naturalquestions-validation-2646", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-9681", "mrqa_naturalquestions-validation-3882"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8695652173913043, "doing-nothing_instant_EM": 0.84375, "doing-nothing_accmulative_EM": 0.7057291666666666}, {"timecode": 12, "before_eval": {"predictions": ["biochemistry", "a rotationally symmetric saltire", "Saint Etienne", "Matt Flinders", "sinoatrial node", "1997", "ITV", "along the length of peninsular Italy", "mocks the differences between what liberals say and what they do", "John B. Watson", "2015", "weight - loss amphetamines", "1 US dollar", "25 December 2010", "of Norman origin, deriving from the Norman given name Robert", "Lionel Richie", "62", "Macon Blair", "Fa Ze Rug", "Solomon", "Kiss", "Simon Callow", "a combined 115 home runs in 1961", "Garwin Sanford", "Todd Bridges", "Sally Field", "Wilhelm Conrad R\u00f6ntgen", "Paul", "from the leaves of the plant species Stevia rebaudiana", "arose as patronymics, via a shortening of `` ap Harry '' ( son of Harry )", "on the southeastern coast of the Commonwealth of Virginia in the United States", "Fennel seeds"], "metric_results": {"EM": 0.625, "QA-F1": 0.7010052447552447}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["Human anatomy", "the symbol \u00d7", "Neil Young", "Matt Flinders", "the sinoatrial node", "1997", "the BBC", "along the length of peninsular Italy", "the differences between what liberals say and what they do", "John B. Watson", "2015", "weight - loss amphetamines", "1 US dollar worth close to 5,770 guaranies", "25 December 2010", "Norman origin", "Lionel Richie", "62", "Macon Blair", "FaZe Rug", "Solomon, king of the United Kingdom of Israel and Judah", "Kiss", "Simon Callow", "Mickey Mantle", "Garwin Sanford", "Todd Bridges", "Sally Field", "Wilhelm Conrad R\u00f6ntgen", "Philippians", "the leaves of the plant species Stevia rebaudiana", "Old English pyrige ( pear tree )", "on the southeastern coast of the Commonwealth of Virginia in the United States", "Fennel seeds ( xiao huixiang \u5c0f \u8334\u9999 )"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9827302631578947}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9473684210526316, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-917", "mrqa_naturalquestions-validation-4336"], "retained_ids": ["mrqa_naturalquestions-validation-8466", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-7600", "mrqa_naturalquestions-validation-10344", "mrqa_naturalquestions-validation-438", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-4420", "mrqa_naturalquestions-validation-5679", "mrqa_naturalquestions-validation-8553", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-9322", "mrqa_naturalquestions-validation-10060", "mrqa_naturalquestions-validation-8128", "mrqa_naturalquestions-validation-10062", "mrqa_naturalquestions-validation-5200", "mrqa_naturalquestions-validation-5971", "mrqa_naturalquestions-validation-2162", "mrqa_naturalquestions-validation-5912"], "fixed_ids": ["mrqa_naturalquestions-validation-9088", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-8381", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-4274", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-9172", "mrqa_naturalquestions-validation-6881"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-9088", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-8381", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-4274", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-9172", "mrqa_naturalquestions-validation-6881"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.75, "doing-nothing_accmulative_EM": 0.7091346153846154}, {"timecode": 13, "before_eval": {"predictions": ["a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form", "authority", "Miami Heat", "center core", "Warren Zevon", "Manoir de la Fi\u00e8re and Chef - du - Pont", "James `` Jamie '' Dornan", "an unknown recipient", "2019", "Database - Protocol driver ( Pure Java driver )", "reproductive role", "$2.18 billion", "three", "Humpty Alexander Dumpty", "administrative supervision over all courts and the personnel thereof", "1665 to 1666", "1951 -- 52", "neutral rights, which included allowing private corporations and banks to sell or loan money to either side", "the digestive systems of many organisms", "Anglican", "Jonathan Breck", "17 December 1968", "August 5, 1937", "The British Indian Association", "business network", "digestion of proteins", "1890", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "an `` allosteric site ''", "Utah", "1939 to 1945", "Yuzuru Hanyu"], "metric_results": {"EM": 0.625, "QA-F1": 0.7155844155844155}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.19999999999999998, 0.4, 1.0, 0.5, 0.06060606060606061, 0.5, 1.0]}}, "after_eval": {"predictions": ["Dragon Ball GT", "authority", "Miami Heat", "center core", "Warren Zevon", "over the Merderet in the fictional town of Ramelle", "James `` Jamie '' Dornan", "an unknown recipient", "in 2019", "Database - Protocol driver ( Pure Java driver )", "endocrine ( hormonal ) systems and their physiological and behavioral effects, including gonadal differentiation, internal and external genital and breast differentiation, and differentiation of muscle mass, height, and hair distribution", "$2.18 billion", "three", "Humpty Alexander Dumpty", "has `` administrative supervision over all courts and the personnel thereof ''", "1665 to 1666", "1951 -- 52", "neutrality", "digestive systems", "The Church of England", "Jonathan Breck", "17 December 1968", "August 5, 1937", "The British Indian Association", "a form of business network", "plays a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "first published in 1890", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "regulatory site", "in nearly 100 locations across Utah, including : Mount Timpanogos, Ashley National Forest, Leeds, Snow Canyon State Park, St. George, Sundance Resort, Uinta National Forest", "1945", "Yuzuru Hanyu"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9832808123249299}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2575", "mrqa_naturalquestions-validation-5512"], "retained_ids": ["mrqa_naturalquestions-validation-1290", "mrqa_naturalquestions-validation-4110", "mrqa_naturalquestions-validation-5218", "mrqa_naturalquestions-validation-7402", "mrqa_naturalquestions-validation-5378", "mrqa_naturalquestions-validation-7056", "mrqa_naturalquestions-validation-3710", "mrqa_naturalquestions-validation-4519", "mrqa_naturalquestions-validation-8372", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-1915", "mrqa_naturalquestions-validation-6655", "mrqa_naturalquestions-validation-10014", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3469", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-6414", "mrqa_naturalquestions-validation-4074"], "fixed_ids": ["mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-5651", "mrqa_naturalquestions-validation-9064", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-7581", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2996"], "unfixed_ids": ["mrqa_naturalquestions-validation-126"], "error_ids": ["mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-5651", "mrqa_naturalquestions-validation-9064", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-7581", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-126", "mrqa_naturalquestions-validation-2996"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7098214285714286}, {"timecode": 14, "before_eval": {"predictions": ["Aman Gandotra and Natasha Bharadwaj", "Characters 1 -- 3 ( the category of disease )", "1960", "between $10,000 and $30,000", "1945", "Cylinder", "season two", "Canada", "1930s", "higher the volatility and the lower the normal boiling point of the liquid", "July 2012", "Tokyo", "Ramanaa", "first five", "ummat al - Islamiyah", "Amanda Leighton", "allows Parliament or provincial legislatures to override certain portions of the Charter", "November 2, 2016", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "pancreas", "Jericho in the Levant region", "London, United Kingdom", "Gibraltar", "Gabrielle - Suzanne Barbot de Villeneuve", "in the Roman Empire", "late Classical and Hellenistic Greece", "Lee County", "Celtic", "Covington, Kentucky", "the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "serves as the physical link between the mRNA and the amino acid sequence of proteins", "the Supreme Court of Canada"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6734644766997708}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, true], "QA-F1": [0.5714285714285715, 0.0, 1.0, 0.32, 1.0, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.47619047619047616, 0.36363636363636365, 1.0]}}, "after_eval": {"predictions": ["Natasha Bharadwaj", "7", "1960", "believed to cost between $10,000 and $30,000 or annual dues were estimated in 2009 to be less than $10.000 per year", "1945", "Cyrus", "season two", "Canada", "1940", "The higher the vapor pressure of a liquid at a given temperature", "July 2012", "Tokyo", "Tagore", "five", "ummah", "Amanda Leighton", "allows Parliament or provincial legislatures to override certain portions of the Charter", "November 2, 2016", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "positions 14 - 15, 146 - 147 and 148 - 149", "Mesopotamia", "London, United Kingdom", "Gibraltar", "French novelist Gabrielle - Suzanne Barbot de Villeneuve", "the Roman Empire", "the Roman Empire", "Lee County", "Celtic", "Covington, Kentucky", "the most recent Super Bowl champions", "carrying an amino acid to the protein synthetic machinery of a cell ( ribosome ) as directed by a three - nucleotide sequence ( codon ) in a messenger RNA ( mRNA", "the Supreme Court of Canada"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9620535714285714}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5458"], "retained_ids": ["mrqa_naturalquestions-validation-4236", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-4855", "mrqa_naturalquestions-validation-1629", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-8575", "mrqa_naturalquestions-validation-5213", "mrqa_naturalquestions-validation-4989", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8409", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-6754", "mrqa_naturalquestions-validation-6076"], "fixed_ids": ["mrqa_naturalquestions-validation-2606", "mrqa_naturalquestions-validation-5214", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-8028", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-7003"], "unfixed_ids": ["mrqa_naturalquestions-validation-4768"], "error_ids": ["mrqa_naturalquestions-validation-2606", "mrqa_naturalquestions-validation-5214", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-8028", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-7003"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.8888888888888888, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7104166666666667}, {"timecode": 15, "before_eval": {"predictions": ["the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Elena Anaya", "South Carolina", "Jacob Packer", "228 minutes", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "water", "Warren Hastings", "mitochondrial membrane", "2014", "typically a `` drive - through '' or `` stop and go '' penalty", "the famous T\u014dsh\u014d - g\u016b shrine in Nikk\u014d, Japan", "March 31, 2017", "present - day southeastern Texas", "1979", "Susan's boyfriend, Edmund Crumb ( Adam Caine )", "2011", "Mainland Greece", "Manchuria", "Dyrham Park", "Edd Kimber", "1926", "the optic disc", "Judi Dench", "cut off close by the hip, and under the left shoulder, he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird", "Martin Lawrence", "creating a so called minimum viable product that addresses and solves a problem or need that exists", "Sheev Palpatine", "an expression of at least a moderate amount of manual dexterity", "a number of small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "Bill Henderson", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5553098141502746}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.375, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 0.0, 0.7000000000000001, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.07407407407407407, 1.0, 0.0, 0.4444444444444445, 0.13333333333333333, 0.3157894736842105, 0.0, 0.3636363636363636]}}, "after_eval": {"predictions": ["one - mile - wide", "Elena Anaya", "South Carolina", "Jacob Packer", "228", "8 bytes", "solids", "Warren Hastings", "mitochondrial membrane", "never made", "pit road speed", "a 17th - century carving over a door of the famous T\u014dsh\u014d - g\u016b shrine in Nikk\u014d, Japan", "March 31, 2017", "near Arenosa Creek and Matagorda Bay", "near the end of 2015 and the beginning of 2016", "Adam Caine", "2011", "peninsula", "in Manchuria", "Weston - super-Mare", "Edd Kimber", "1926", "optic chiasma", "Judi Dench", "under `` the immortal Hawke ''", "Martin Lawrence", "Mark Andreessen", "Sheev Palpatine, ( colloquial : Darth Sidious and The Emperor )", "an example of a useless, time - wasting activity", "southern marsupial mole", "Chilliwack", "Emmanuelle Chriqui"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9791666666666666}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7998", "mrqa_naturalquestions-validation-7311"], "retained_ids": ["mrqa_naturalquestions-validation-2495", "mrqa_naturalquestions-validation-6836", "mrqa_naturalquestions-validation-4870", "mrqa_naturalquestions-validation-5236", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-9438", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-10493", "mrqa_naturalquestions-validation-4853", "mrqa_naturalquestions-validation-3763", "mrqa_naturalquestions-validation-8043"], "fixed_ids": ["mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-9110", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-8940", "mrqa_naturalquestions-validation-95", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-1698", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-3482"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-9110", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-8940", "mrqa_naturalquestions-validation-95", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-1698", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-3482"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8571428571428571, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.705078125}, {"timecode": 16, "before_eval": {"predictions": ["under Solomon, during the united monarchy of Israel and Judah", "Michael Clarke Duncan", "Rachel Sarah Bilson", "Barry Bonds", "the American newspaper magnate William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick, and aspects of Welles's own life", "Audrey II", "Jason Paige", "the British Isles of French and Latin origin", "standing on a tilted floor", "Luther Ingram", "Bhupendranath Dutt", "The genome", "February 7, 2018", "backbones", "Max Thieriot", "John Young", "1992", "ancient Mesopotamia", "an NCIS Special Agent in Charge", "Tokyo", "Steve Hale", "Steve Kazee", "John Cooper Clarke", "April 1917", "Claims adjuster", "Scheria", "A rear - view mirror", "red - billed hornbill", "Derek Hough", "the ground", "James Brown", "Robert Remak"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7029671717171717}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["the mid-10th century BCE", "Michael Clarke Duncan", "Rachel Sarah Bilson", "Barry Bonds", "William Randolph Hearst", "Audrey II", "Jason Paige", "Old French", "gravity hill, tilt - induced visual illusion", "Luther Ingram", "Bhupendranath Dutt", "The genome", "February 7, 2018", "backbones", "Norma's brother, Caleb", "John Young", "1992", "Iran", "Grisha", "Tokyo", "Steve Hale", "Christina Perri", "John Cooper Clarke", "April 1917", "Claims adjuster ( claim adjuster )", "Scheria", "A rear - view mirror", "red - billed hornbill", "Karina Smirnoff", "a hole", "James Brown", "Robert Remak"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9761904761904762}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7309"], "retained_ids": ["mrqa_naturalquestions-validation-9511", "mrqa_naturalquestions-validation-10019", "mrqa_naturalquestions-validation-10513", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4155", "mrqa_naturalquestions-validation-4796", "mrqa_naturalquestions-validation-9733", "mrqa_naturalquestions-validation-9332", "mrqa_naturalquestions-validation-9367", "mrqa_naturalquestions-validation-7766", "mrqa_naturalquestions-validation-4239", "mrqa_naturalquestions-validation-3376", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-5048", "mrqa_naturalquestions-validation-9199", "mrqa_naturalquestions-validation-7958", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-8591", "mrqa_naturalquestions-validation-8708", "mrqa_naturalquestions-validation-10180", "mrqa_naturalquestions-validation-3678"], "fixed_ids": ["mrqa_naturalquestions-validation-650", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-4946", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-3233", "mrqa_naturalquestions-validation-3502", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6524"], "unfixed_ids": ["mrqa_naturalquestions-validation-1904"], "error_ids": ["mrqa_naturalquestions-validation-650", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-4946", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-3233", "mrqa_naturalquestions-validation-3502", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6524"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.9545454545454546, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7058823529411765}, {"timecode": 17, "before_eval": {"predictions": ["Bobby Beathard", "16", "Amartya Sen", "Golan Heights", "New Orleans", "William Strauss", "AM 5778", "England", "One unknown", "Jason Lee", "1987", "Jefferson Davis", "Dadra", "Detroit Tigers", "the season four episode `` Run ''", "Sedimentary rock", "the 1962 novel of the same name", "mitochondrial membrane", "2002", "Lulu", "he cheated on Miley", "Mendel", "Megan Park", "Julie Gonzalo", "April 9, 2018", "at the center of the Northern Hemisphere", "2014", "February 6, 2005", "President pro tempore of the United States Senate", "Anglican", "May 3, 2005", "more than 1,000"], "metric_results": {"EM": 0.5, "QA-F1": 0.6107282763532763}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.7692307692307693, 0.6666666666666666, 1.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.07407407407407408, 1.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["Bobby Beathard, Robert Brazile, Brian Dawkins, Jerry Kramer, Ray Lewis, Randy Moss, Terrell Owens, and Brian Urlacher", "16 or older", "Amartya Sen", "Golan Heights", "Speakeasies", "The Washington Post", "AM 5778", "England", "unknown", "Dashiell Robert Parr / Dash, the Parrs'second child", "mid-March", "The Confederate States Army ( C.S.A. )", "Meghalaya", "White Sox", "the season four episode `` Run ''", "metamorphic rock", "the 1962 novel of the same name by Madeleine L'Engle", "mitochondrial membrane in eukaryotes", "2002 -- 03", "Lulu", "Miley finally ends it with him", "Mendel", "Megan Park", "Felicity Huffman", "April 9, 2018", "latitude 90 \u00b0 North", "2014 -- 15", "February 6, 2005", "the duty of presiding officer is rotated among junior U.S. Senators of the majority party to give them experience in parliamentary procedure", "Anglican services in Jamestown 1607", "May 3, 2005", "more than 1,000"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9212424089068826}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-4915", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-5926", "mrqa_naturalquestions-validation-7579"], "retained_ids": ["mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-9940", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-3666", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10342", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-6169"], "fixed_ids": ["mrqa_naturalquestions-validation-322", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8582", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-1213", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-1639", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2953", "mrqa_naturalquestions-validation-10631"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135"], "error_ids": ["mrqa_naturalquestions-validation-322", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8582", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-1213", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-1639", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2953", "mrqa_naturalquestions-validation-10631"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.75, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.703125}, {"timecode": 18, "before_eval": {"predictions": ["active absorption of water from the soil by the root", "Foofa", "sovereign states", "16 seasons", "Moctezuma II", "Nala", "31 December 1960", "on the edge or underside of a fertile frond", "random - access memory ( RAM )", "the U.S. Electoral College", "two stems", "Proposition 103", "September 2017", "about 1500 BC", "Kimberlin Brown", "Melanie Walters", "March 2, 2016", "October 27, 2017", "unknown", "Darren McGavin", "in France, shipped overseas in crates, and assembled on the completed pedestal on what was then called Bedloe's Island", "a bank", "Hank Williams", "Coppolas", "Missouri", "Road / Track", "Fifty Shades Darker", "near Grande Comore, Comoros Islands", "Mercedes - Benz Stadium in Atlanta, Georgia", "2009", "U + 002A * Asterisk", "Muhammad Yunus"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7558061053368715}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, false, true], "QA-F1": [0.16666666666666666, 1.0, 0.08333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["SURFACE AREA OF ROOTS", "Foofa", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "16 seasons", "Moctezuma II", "Nala", "1957", "a yellowish or brownish mass on the edge or underside of a fertile frond", "random - access memory ( RAM )", "electors", "a Germanic name deriving from two stems : Rod or Hr\u014d\u00f0, meaning `` fame '', and olf meaning `` wolf ''", "Proposition 103", "September 2017", "about 1500 BC", "Kimberlin Brown", "Melanie Walters", "March 2, 2016", "October 27, 2017", "author of the tune is unknown and it may originate in plainchant, but a 1619 attribution to John Bull is sometimes made", "Darren McGavin", "France", "a bank", "Hank Williams", "Coppolas", "Jackson County, Missouri", "the performance marker used on Dodge automobiles since the 1960s ( much like Chevrolet Super Sport )", "erotic novels by E.L. James", "23 November 1996", "Mercedes - Benz Stadium in Atlanta, Georgia", "1994", "*", "Muhammad Yunus"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8346253229974161}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.9302325581395349, 1.0, 1.0, 1.0, 0.0, 0.7777777777777778, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-6507", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-4039", "mrqa_naturalquestions-validation-7780"], "retained_ids": ["mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-777", "mrqa_naturalquestions-validation-5933", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-6984", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-2734", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-7885", "mrqa_naturalquestions-validation-8251", "mrqa_naturalquestions-validation-3296", "mrqa_naturalquestions-validation-1133", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8105", "mrqa_naturalquestions-validation-730"], "fixed_ids": ["mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-980", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-3396", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-4804", "mrqa_naturalquestions-validation-10364"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559"], "error_ids": ["mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-980", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-3396", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-4804", "mrqa_naturalquestions-validation-10364"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.782608695652174, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.7039473684210527}, {"timecode": 19, "before_eval": {"predictions": ["a page before the start of a written work", "Deposition", "norm in Chief of the United States Armed Forces", "naos", "47 cents", "star", "white blood cell", "Steve Russell", "Christopher Lloyd", "ESPN", "the present day some `` Nestorian '' churches such as the Church of the East reject it", "the Reverse - Flash", "supply and demand", "Philip Seymour Hoffman", "the New Croton Reservoir in Westchester and Putnam counties", "Armored Vehicles produced by GIAT Industries of France ( from Atelier de Construction d'Issy - Les - Moulineaux )", "22", "Richard Parker", "1981", "hydrogen ions ( low pH )", "the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east )", "Josh McDaniels", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s", "a diversity of ecosystem services including converting carbon dioxide into oxygen and biomass, acting as a carbon sink, aiding in regulating climate, purifying water, mitigating natural hazards such as floods, and serving as a genetic reserve", "consistency", "Neuropsychology", "September 13, 2012", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "the south western escarpment of the Jos Plateau", "1840", "1904", "President Friedrich Ebert"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5867338004865978}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, false, true, true], "QA-F1": [0.8, 1.0, 0.875, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.36363636363636365, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0606060606060606, 0.0, 0.25, 0.35, 1.0, 1.0, 1.0, 0.4347826086956522, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "after_eval": {"predictions": ["usually found on a page before the start of a written work", "Deposition", "Commander in Chief of the United States Armed Forces", "naos", "47 cents", "a star ( representing either the Star of Bethlehem or the Star Of David ), finials, angels ( `` Christmas angel '' ), or fairies", "B cells", "Steve Russell", "Christopher Lloyd", "ESPN", "last book", "Professor Eobard Thawne", "capital and financial markets", "Clifton Collins, Jr.", "The New Croton Aqueduct", "Atelier de Construction d'Issy - Les - Les -- Les - Moulineaux", "232", "Richard Parker", "1981", "Acid rain", "224.7 Earth days", "Tom Brady", "French Canadian", "providing a diversity of ecosystem services including converting carbon dioxide into oxygen and biomass, acting as a carbon sink, aiding in regulating climate, purifying water, mitigating natural hazards such as floods, and serving as a genetic reserve", "consistency", "Neuropsychology", "September 13, 2012", "the illegitimate son of Ned Stark", "arrives in central Nigeria in July", "In 1840", "1904", "President Friedrich Ebert"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9437064459930313}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34146341463414637, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-4681"], "retained_ids": ["mrqa_naturalquestions-validation-8643", "mrqa_naturalquestions-validation-4922", "mrqa_naturalquestions-validation-929", "mrqa_naturalquestions-validation-4005", "mrqa_naturalquestions-validation-5345", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-2701", "mrqa_naturalquestions-validation-4124", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9962", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-1504", "mrqa_naturalquestions-validation-1622"], "fixed_ids": ["mrqa_naturalquestions-validation-9209", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-1838", "mrqa_naturalquestions-validation-4278", "mrqa_naturalquestions-validation-3148", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-6337"], "unfixed_ids": ["mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-10201"], "error_ids": ["mrqa_naturalquestions-validation-9209", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-1838", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-4278", "mrqa_naturalquestions-validation-3148", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-10201", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-6337"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.9285714285714286, "doing-nothing_instant_EM": 0.5, "doing-nothing_accmulative_EM": 0.69375}, {"timecode": 20, "before_eval": {"predictions": ["North Atlantic Ocean", "M\u00e1xima Zorreguieta Cerruti", "Elvis Presley", "Alex Skuby", "the Battle of Antietam", "Matt Monro", "September 1959", "the lungs", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash in Hindi, Urdu and Punjabi", "A footling breech", "July 21, 1861", "March 10, 2017", "New Mexico", "November 2, 2016", "Giorgio Vasari", "Nick Sager", "16 August 1975", "`` His / Her Majesty's Ship '' in the British Royal Navy, abbreviated `` H.M.S. '' and then `` HMS ''", "Julius Caesar", "Lead and lead dioxide", "Simon Callow", "Noel Harrison", "Aristotle", "The Sun", "Ashoka", "In 1943", "North America", "December 18, 2017", "2010", "a tradeable entity used to avoid the inconveniences of a pure barter system", "Tom Lowes", "thylakoid membranes"], "metric_results": {"EM": 0.625, "QA-F1": 0.7062558356676004}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.8]}}, "after_eval": {"predictions": ["the North Atlantic Ocean", "King Willem - Alexander", "Hugo Peretti", "Doug Pruzan", "the Battle of Antietam", "Matt Monro", "September 1959", "the right side of the heart", "Tanvi Shah", "A footling breech", "July 21, 1861", "March 10, 2017", "New Mexico", "November 2, 2016", "Giorgio Vasari", "Nick Sager", "1975", "`` United States Ship '' ( USS )", "emperors", "sulfuric acid in the electrolyte", "Simon Callow", "Noel Harrison", "Bacon", "The Sun", "Ashoka", "1943", "physiographically a part of the continent of North America", "December 18, 2017", "2010", "a tradeable entity used to avoid the inconveniences of a pure barter system", "Stefanie Scott", "on the thylakoid membranes"], "metric_results": {"EM": 0.9375, "QA-F1": 0.953125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-8994"], "retained_ids": ["mrqa_naturalquestions-validation-670", "mrqa_naturalquestions-validation-5387", "mrqa_naturalquestions-validation-9560", "mrqa_naturalquestions-validation-121", "mrqa_naturalquestions-validation-10350", "mrqa_naturalquestions-validation-10574", "mrqa_naturalquestions-validation-9579", "mrqa_naturalquestions-validation-7564", "mrqa_naturalquestions-validation-4988", "mrqa_naturalquestions-validation-2800", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-8120", "mrqa_naturalquestions-validation-4264", "mrqa_naturalquestions-validation-5608", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-559", "mrqa_naturalquestions-validation-10704", "mrqa_naturalquestions-validation-10265"], "fixed_ids": ["mrqa_naturalquestions-validation-4053", "mrqa_naturalquestions-validation-9763", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-783"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-4053", "mrqa_naturalquestions-validation-9763", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-783"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.6919642857142857}, {"timecode": 21, "before_eval": {"predictions": ["1921", "Charles Oscar Waters", "Timmy Smith", "Lori McKenna", "eventually discontinued", "1599", "Daniel A. Dailey", "Mowgli", "Isabela Moner", "The Yankees", "Lake Wales, Florida", "Marcus Atilius Regulus", "2018", "Parthenogenesis", "Friedman Billings Ramsey", "his frustration with the atmosphere in the group at that time", "gastrocnemius muscle", "Space is the Place", "Joanne Wheatley", "Chandan Shetty", "the President of the United States", "a cylinder of glass or plastic that runs along the fiber's length", "A Turtle's Tale : Sammy's Adventures", "1985", "Leonardo da Vinci", "the Canadian rock band Nickelback", "the roofs of the choir side - aisles at Durham Cathedral", "a simple ketonic monosaccharide found in many plants", "Jean Antonin Merci\u00e9", "in Dunedin, Port Chalmers and on the Otago Peninsula, Saint Bathans in Central Otago and at the Cape Campbell Lighthouse in Marlborough", "Cozonac", "the federal government's nearly 700 million acres ( 2,800,000 km ) of subsurface mineral estate located beneath federal, state and private lands severed from their surface rights by the Homestead Act of 1862"], "metric_results": {"EM": 0.5, "QA-F1": 0.5789068853347791}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.8571428571428572, 0.4, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.2857142857142857, 0.06451612903225806]}}, "after_eval": {"predictions": ["Guwahati", "the physician George Huntington", "Timmy Smith", "Lori McKenna", "the 90s", "1603", "Daniel A. Dailey", "Shere Khan", "Isabela Moner", "The Yankees", "Lake Wales, Florida", "Xanthippus", "2018", "Parthenogenesis", "the investment bank Friedman Billings Ramsey", "his frustration with the atmosphere in the group at that time", "gastrocnemius muscle", "cat in the hat", "Joanne Wheatley", "rapper Chandan Shetty", "the Attorney General", "cylinder of glass or plastic that runs along the fiber's length", "A Turtle's Tale : Sammy's Adventures", "1985", "Leonardo da Vinci", "the Canadian rock band Nickelback", "an armature of piped masonry often carved in decorative patterns", "Fructose", "Ren\u00e9 Georges Hermann - Paul", "Australia", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "247.3 million"], "metric_results": {"EM": 0.875, "QA-F1": 0.9377232142857144}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428572, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-5631"], "retained_ids": ["mrqa_naturalquestions-validation-9192", "mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4259", "mrqa_naturalquestions-validation-509", "mrqa_naturalquestions-validation-5605", "mrqa_naturalquestions-validation-10386", "mrqa_naturalquestions-validation-2650", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-8215", "mrqa_naturalquestions-validation-4068", "mrqa_naturalquestions-validation-1157", "mrqa_naturalquestions-validation-7095"], "fixed_ids": ["mrqa_naturalquestions-validation-3688", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-4185", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-1304", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-6027"], "unfixed_ids": ["mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-714"], "error_ids": ["mrqa_naturalquestions-validation-3688", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-4185", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-1304", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-6027"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.875, "doing-nothing_instant_EM": 0.53125, "doing-nothing_accmulative_EM": 0.6846590909090909}, {"timecode": 22, "before_eval": {"predictions": ["Moton Field, the Tuskegee Army Air Field", "Help!", "The Stanley Hotel", "the last Ice Age", "northernmost point at which the noon sun is just visible on the December solstice", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "5 : 25 p.m. UTC", "Andy", "Thomas Middleditch", "6 - 6", "Michael Sata", "on average USD 5.2 billion", "the Kansas City Chiefs", "Hanna Alstr\u00f6m", "Hellenism", "Edward V, King of England", "the Italian / Venetian John Cabot", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "James Rodr\u00edguez", "the inferior thoracic border", "1960", "Mandy", "Russia", "R&B singer Lou Rawls", "Gorakhpur Junction", "Kitty Softpaws", "Jyotirindra Basu", "Executive Chef Danny Veltri", "the Miracles", "16 December 1908", "George Merrill", "Joseph Heller"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7360347985347986}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.8571428571428571, 0.07692307692307691, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.6666666666666665, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.2857142857142857, 1.0]}}, "after_eval": {"predictions": ["Moton Field, the Tuskegee Army Air Field", "Help!", "The Stanley Hotel", "During the last Ice Age", "most northerly of the five major circles of latitude as shown on maps of Earth", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "6 : 44 p.m. UTC ( 2 :44 p. m. UTC )", "Andy", "Thomas Middleditch", "5", "Edgar Lungu", "on average USD 5.2 billion and for the Winter Games USD 3.1 billion dollars", "the Kansas City Chiefs", "Hanna Alstr\u00f6m", "Hellenism", "Edward IV of England", "the English", "technological advances in printing", "James Rodr\u00edguez", "the inferior thoracic border", "1960", "Mandy", "Russia", "Lou Rawls", "Gorakhpur Junction", "a European fairy tale in 1697", "Jyotirindra Basu", "Danny Veltri", "the Miracles", "31 March 1909", "written by George Merrill and Shannon Rubicam of the band Boy Meets Girl", "Joseph Heller"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9595588235294118}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7346"], "retained_ids": ["mrqa_naturalquestions-validation-2209", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-7801", "mrqa_naturalquestions-validation-4766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-4382", "mrqa_naturalquestions-validation-4895", "mrqa_naturalquestions-validation-7321", "mrqa_naturalquestions-validation-6447", "mrqa_naturalquestions-validation-5684", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-7594", "mrqa_naturalquestions-validation-1851", "mrqa_naturalquestions-validation-1562", "mrqa_naturalquestions-validation-10549", "mrqa_naturalquestions-validation-9505"], "fixed_ids": ["mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8744", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-5775", "mrqa_naturalquestions-validation-1186", "mrqa_naturalquestions-validation-8008"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020"], "error_ids": ["mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-2020", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8744", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-5775", "mrqa_naturalquestions-validation-1186", "mrqa_naturalquestions-validation-8008"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.9473684210526315, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.6834239130434783}, {"timecode": 23, "before_eval": {"predictions": ["Icarus", "John F. Kennedy", "85 %", "Renishaw Hall, Derbyshire, England, UK", "a jazz funeral without a body", "Laura Jane Haddock", "Roger Federer", "The Enchantress", "Nicole Gale Anderson", "Chlorofluorocarbons ( CFCs )", "September 19, 2017", "Great Britain", "AD 95 -- 110", "both plasma membranes", "1960", "parthenogenesis", "Peking", "twelve", "the pigeons", "near the city of Cairo, Illinois", "subduction zone", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "Jonathan Larson", "1999", "the people of Britain", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "total cost ( TC )", "$2 million in 2011", "the Canadian Rockies continental divide", "Symbolic interactionism", "twice in the Hebrew Bible, in the books of Exodus and Deuteronomy", "reared in South Africa"], "metric_results": {"EM": 0.5, "QA-F1": 0.5831867784992785}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 0.7499999999999999, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.1111111111111111, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.6666666666666666]}}, "after_eval": {"predictions": ["Icarus", "U.S. President John F. Kennedy", "33 % in 2013", "Renishaw Hall, Derbyshire, England, UK", "Those who follow the band just to enjoy the music", "Laura Jane Haddock", "Roger Federer", "The Magician", "Nicole Gale Anderson", "Chlorofluorocarbons", "September 19, 2017", "Great Britain", "AD 95 -- 110", "the cytoskeletons of adjacent cells", "1948", "parthenogenesis", "Peking", "twelve", "kiss", "near the city of Cairo, Illinois", "subduction zone", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "script", "14 November 2001", "the city of Oslo, Norway", "the presence of correctly oriented P waves", "total cost ( TC )", "$2 million in 2011", "central Saskatchewan", "role theory", "Exodus", "South Africa"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-4531", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-2355", "mrqa_naturalquestions-validation-5087", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-7031", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-1222", "mrqa_naturalquestions-validation-2304", "mrqa_naturalquestions-validation-3982", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-1519", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-9684", "mrqa_naturalquestions-validation-10537"], "fixed_ids": ["mrqa_naturalquestions-validation-1121", "mrqa_naturalquestions-validation-9214", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-7166", "mrqa_naturalquestions-validation-3782", "mrqa_naturalquestions-validation-5659", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-10352", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-9635", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-4744"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-1121", "mrqa_naturalquestions-validation-9214", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-7166", "mrqa_naturalquestions-validation-3782", "mrqa_naturalquestions-validation-5659", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-10352", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-9635", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-4744"], "instant_fixing_rate": 1.0, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.53125, "doing-nothing_accmulative_EM": 0.6770833333333334}, {"timecode": 24, "before_eval": {"predictions": ["the biomechanics of human or animal movement", "Japanese", "Owen Vaccaro", "John Donne", "Three Billboards Outside Ebbing, Missouri", "thirteen independent sovereign states", "Donna", "the Washington metropolitan area", "one person", "January 2004", "Brazil", "1,350 at the 2010 census", "the President of the United States", "Elizabeth Dean Lail", "the Anglo - Norman French waleis", "Andrew Lloyd Webber", "membrane lipids", "USS Chesapeake", "Bart Howard", "Kimberly Marie `` Kim '' Matula", "the Bee Gees", "the Finance Minister of India in Parliament", "1978", "September 29, 2017", "31 - member Senate", "1908", "the chief lawyer of the United States government", "Dr. Hartwell Carver", "2004", "they believed that it violated their rights as Englishmen to `` No taxation without representation ''", "a loanword of the Visigothic word guma `` man ''", "Butter Island"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6339208447308542}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.5, 0.0, 0.3870967741935484, 1.0, 0.0, 0.5490196078431372, 0.2857142857142857, 0.3636363636363636]}}, "after_eval": {"predictions": ["electric potential generated", "Japanese", "Owen Vaccaro", "John Donne", "Three Billboards Outside Ebbing, Missouri", "the Second Continental Congress", "Donna", "FedExField in Landover, Maryland", "one person", "January 2004", "Brazil", "1,350", "the President of the United States", "Elizabeth Dean Lail", "a Scottish surname", "Andrew Lloyd Webber", "nearly all living cells", "USS Chesapeake", "Bart Howard", "Kimberly Marie `` Kim '' Matula", "the Bee Gees", "the Finance Minister of India", "1977", "September 29, 2017", "member", "1920", "the head of the United States Department of Justice per 28 U.S.C. \u00a7 503, concerned with all legal affairs, and is the chief lawyer of the U States government", "Dr. Hartwell Carver", "2009", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "man", "Butter Island off North Haven, Maine in the Penobscot Bay"], "metric_results": {"EM": 0.96875, "QA-F1": 0.99875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-6351", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-5406", "mrqa_naturalquestions-validation-5392", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-5620", "mrqa_naturalquestions-validation-7696", "mrqa_naturalquestions-validation-5331", "mrqa_naturalquestions-validation-926", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-2084", "mrqa_naturalquestions-validation-4672", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-2052", "mrqa_naturalquestions-validation-9850"], "fixed_ids": ["mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-360", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-3704", "mrqa_naturalquestions-validation-1861", "mrqa_naturalquestions-validation-4042", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-10382"], "unfixed_ids": ["mrqa_naturalquestions-validation-5903"], "error_ids": ["mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-360", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-3704", "mrqa_naturalquestions-validation-1861", "mrqa_naturalquestions-validation-4042", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-5903", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-10382"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.6775}, {"timecode": 25, "before_eval": {"predictions": ["other locations in Cambridgeshire and across the United Kingdom", "1994", "Saturday evenings", "Spike", "eleven", "Norman Greenbaum", "Phosphorus pentoxide", "23 hours, 56 minutes, and 4 seconds", "orogenic belt", "annuity", "Mike Czerwien", "Matt Monro", "2 %", "crossbar", "The New Croton Aqueduct", "a house edge of between 0.5 % and 1 %", "Brittany Paige Bouck", "4 September 1936", "the Speaker of the House", "Annette Strean", "Timothy B. Schmit", "empire", "Jason Weaver", "Elvis Presley", "Night Ranger", "Matthew `` Matt '' Camden", "September 19, 2017", "Thomas Chisholm", "1983", "The management team", "Matt Monro", "Jurriaen Aernoutsz"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6455492424242424}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.0, 0.36363636363636365, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "after_eval": {"predictions": ["Cambridge University, and at other locations in Cambridgeshire and across the United Kingdom", "1994", "Sunday night", "Butch or Killer", "eleven", "Norman Greenbaum", "Phosphorus pentoxide", "about 24 hours", "orogenic belt", "whether they wish to collect a jackpot prize in cash or annuity", "Mike Czerwien", "Matt Monro", "4 percent cumulative effect", "arm", "two reservoirs in the eastern Catskill Mountains", "between 0.5 % and 1 %", "Brittany Paige Bouck", "4 September 1936", "the Speaker of the House", "Annette Strean", "Timothy B. Schmit", "the Mandate of Heaven", "Wylie Draper", "Hugo Peretti", "`` Sometimes the Good Guys Finish First '' ( performed by Pat Benatar )", "Barry Watson", "September 19, 2017", "Thomas Chisholm", "1984", "The management team", "Matt Monro", "England"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2269", "mrqa_naturalquestions-validation-42"], "retained_ids": ["mrqa_naturalquestions-validation-1339", "mrqa_naturalquestions-validation-6951", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-3632", "mrqa_naturalquestions-validation-1139", "mrqa_naturalquestions-validation-3466", "mrqa_naturalquestions-validation-9563", "mrqa_naturalquestions-validation-6636", "mrqa_naturalquestions-validation-6770", "mrqa_naturalquestions-validation-2097", "mrqa_naturalquestions-validation-747", "mrqa_naturalquestions-validation-3", "mrqa_naturalquestions-validation-2455", "mrqa_naturalquestions-validation-8761", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-8725"], "fixed_ids": ["mrqa_naturalquestions-validation-3524", "mrqa_naturalquestions-validation-8287", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-1514", "mrqa_naturalquestions-validation-10626", "mrqa_naturalquestions-validation-1258", "mrqa_naturalquestions-validation-9135", "mrqa_naturalquestions-validation-504"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-3524", "mrqa_naturalquestions-validation-8287", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-1514", "mrqa_naturalquestions-validation-10626", "mrqa_naturalquestions-validation-1258", "mrqa_naturalquestions-validation-9135", "mrqa_naturalquestions-validation-504"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8888888888888888, "doing-nothing_instant_EM": 0.75, "doing-nothing_accmulative_EM": 0.6802884615384616}, {"timecode": 26, "before_eval": {"predictions": ["Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Isaiah Amir Mustafa", "1970", "a flash music video featuring an animated dancing banana", "`` Audrey II '', from a Chinese flower shop during a solar eclipse ( `` Da - Doo '' )", "Woodward, Oklahoma", "from states with economies dependent upon slavery, to states in which former slaves were citizens with civil rights", "two classes of organic compounds", "Mummy Zebra", "South America", "the tax on trade in and out of the empire, along with all the gold Mansa Musa had", "2017", "England's Steve Waugh", "`` The Chump ''", "1960", "a constitutional monarchy in which the power of the Emperor is limited and is relegated primarily to ceremonial duties", "two", "2026", "1773", "the common use of performing dogs and ponies as the main attractions of the events", "a small number of muscle fibers in a larger muscle or muscle bundle", "all productive processes", "1989", "1999", "Vasoepididymostomy", "Niveditha", "201", "Kelly Reno", "1 August 1965", "Eydie Gorm\u00e9", "matiasma", "Daya"], "metric_results": {"EM": 0.5, "QA-F1": 0.6179640061998933}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 1.0, 0.72, 0.0, 0.5714285714285715, 0.8, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0909090909090909, 0.0, 0.19354838709677416, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "after_eval": {"predictions": ["Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Isaiah Amir Mustafa", "1970", "Buckwheat Boyz", "Audrey II", "Woodward, Oklahoma", "the attempted transformation of the Southern United States from 1863 to 1877, as directed by Congress, from states with economies dependent upon slavery, to states in which former slaves were citizens with civil rights", "peptide bond", "Zoe Zebra", "in South America", "a place of trade, entertainment, and education", "1947", "Alastair Cook", "`` Goodbye Toby ''", "1960", "constitutional monarchy", "two", "September 23, 2017", "1773", "in the United States in the late - 19th and early - 20th centuries", "muscles", "in all productive processes, adding more of one factor of production, while holding all others constant ( `` ceteris paribus '' ), will at some point yield lower incremental per - unit returns", "1991", "1999", "Vasoepididymostomy", "Niveditha, Diwakar, Shruti", "As of January 17, 2018, 201 episodes", "Kelly Reno", "1 August 1965", "Eydie Gorm\u00e9", "matiasma", "vocals of American singer Daya"], "metric_results": {"EM": 0.9375, "QA-F1": 0.953125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-10396"], "retained_ids": ["mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-425", "mrqa_naturalquestions-validation-8236", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-8103", "mrqa_naturalquestions-validation-8290", "mrqa_naturalquestions-validation-5152", "mrqa_naturalquestions-validation-3836", "mrqa_naturalquestions-validation-9890", "mrqa_naturalquestions-validation-8421", "mrqa_naturalquestions-validation-5578"], "fixed_ids": ["mrqa_naturalquestions-validation-10249", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-10671", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-1298", "mrqa_naturalquestions-validation-6635", "mrqa_naturalquestions-validation-7013", "mrqa_naturalquestions-validation-10246", "mrqa_naturalquestions-validation-934", "mrqa_naturalquestions-validation-4280", "mrqa_naturalquestions-validation-124"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-10249", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-10671", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-1298", "mrqa_naturalquestions-validation-6635", "mrqa_naturalquestions-validation-7013", "mrqa_naturalquestions-validation-10246", "mrqa_naturalquestions-validation-934", "mrqa_naturalquestions-validation-4280", "mrqa_naturalquestions-validation-124"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.875, "doing-nothing_instant_EM": 0.75, "doing-nothing_accmulative_EM": 0.6828703703703703}, {"timecode": 27, "before_eval": {"predictions": ["1978", "2018", "the plane crash in 1959 which killed early rock and roll performers Buddy Holly, The Big Bopper, and Ritchie Valens", "the British", "Dr. Sachchidananda Sinha", "Lesley Gore", "prokaryotic cell ( or organelle )", "at Cairo, Illinois", "Lewis", "`` Mirror Image ''", "Randy VanWarmer", "Emma Thompson", "the efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization", "water ice", "2002 season", "Terrell Suggs", "Michael Moriarty", "experimental psychology", "Arizona ( except for the Navajo, who do observe daylight saving time on tribal lands ), Hawaii, and the overseas territories of American Samoa, Guam, the Northern Mariana Islands, Puerto Rico, and, the United States Virgin Islands", "The Osmonds", "American actor and drag queen Divine, who was best known for his frequent appearances in several films directed by filmmaker John Waters", "1952", "April 12, 2017", "September 28, 2017", "Jerry Ekandjo", "the tenderness of meat", "an apprentice named Jean - Paul Valley ( a.k.a. Azrael )", "2010", "all the states under the Supremacy Clause", "Francisco Pizarro", "Bob Dylan", "on kickoffs at the 25 - yards line instead of the previous 20 - yard line"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6770670995670995}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 0.8, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5909090909090909, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8799999999999999]}}, "after_eval": {"predictions": ["1978", "15 December 2017", "the plane crash in 1959", "the French", "Dr. Rajendra Prasad", "Lesley Gore", "prokaryotic", "Cairo, Illinois", "waiter turned emerging young actor Smith Jerrod", "`` Mirror Image ''", "Randy VanWarmer", "Alice Eve", "accomplish the objectives of the organization", "water ice", "the most recent Super Bowl champion", "Mike Czerwien, Waynesburg University, 2002 -- 04", "Michael Moriarty", "philosophy of mind", "Arizona ( except for the Navajo, who do observe daylight saving time on tribal lands )", "The Osmonds", "American actor and drag queen Divine", "1952", "April 12, 2017", "September 28, 2017", "Erastus Utoni", "the tenderness of meat", "Jean - Paul Valley ( a.k.a. Azrael )", "2010", "the President", "Francisco Pizarro", "Bob Dylan", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard lines"], "metric_results": {"EM": 0.875, "QA-F1": 0.9152097902097902}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-3341", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-4112"], "retained_ids": ["mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-255", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-3308", "mrqa_naturalquestions-validation-8391", "mrqa_naturalquestions-validation-7976", "mrqa_naturalquestions-validation-5696", "mrqa_naturalquestions-validation-6484", "mrqa_naturalquestions-validation-2906", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-6252", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-1248"], "fixed_ids": ["mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-10357", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-5439", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3209", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-7335", "mrqa_naturalquestions-validation-886", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-2311", "mrqa_naturalquestions-validation-3241"], "unfixed_ids": ["mrqa_naturalquestions-validation-9105"], "error_ids": ["mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-10357", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-5439", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3209", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-7335", "mrqa_naturalquestions-validation-886", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-2311", "mrqa_naturalquestions-validation-3241", "mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.8235294117647058, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.6808035714285714}, {"timecode": 28, "before_eval": {"predictions": ["1987", "Roman Reigns", "Middle Eastern alchemy", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "during surgical procedures and in intensive care and emergency medicine to cause temporary paralysis", "Sylvester Stallone", "1979", "from the northern California coast north to the southern Oregon Coast", "Andy Serkis", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "the fictional town of West Egg on prosperous Long Island", "July 4, 1898", "Havana Harbor", "Chernobyl", "part of the present Indian constitutive state of Meghalaya ( formerly Assam )", "Patrick Swayze", "Catherine Tramell", "three", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "the Coercive Acts", "West Norse", "Kerris Lilla Dorsey", "part husky or other Nordic breed, and possibly part terrier", "the Missouri River", "14", "Sean O'Neal", "San Antonio", "temporal lobes", "because the ozone hole was indeed caused by chlorine and bromine from manmade organohalogens", "Heather Stebbins", "17 % of the GDP", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6740706196271612}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.2758620689655172, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.38095238095238093]}}, "after_eval": {"predictions": ["1996", "Roman Reigns", "Middle Eastern alchemy", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "to alleviate musculoskeletal pain and spasms and to reduce spasticity in a variety of neurological conditions", "Sylvester Stallone", "1979", "from the northern California coast north to the southern Oregon Coast", "Andy Serkis", "a biocidal effect of metals", "the fictional town of West Egg on prosperous Long Island", "July 4, 1898", "Havana Harbor", "Chernobyl Nuclear Power Plant", "part of the present Indian constitutive state of Meghalaya ( formerly Assam )", "Patrick Swayze", "Catherine Tramell", "three", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "The Intolerable Acts", "European colonization", "Kerris Lilla Dorsey", "mongrel female", "the Missouri River", "14", "Sean O'Neal", "the Alamodome", "temporal lobes", "bromine", "Panic! at the Disco", "23 %", "storage of minerals"], "metric_results": {"EM": 0.96875, "QA-F1": 0.98125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-851", "mrqa_naturalquestions-validation-2396", "mrqa_naturalquestions-validation-961", "mrqa_naturalquestions-validation-5950", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-6574", "mrqa_naturalquestions-validation-5713", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-8340", "mrqa_naturalquestions-validation-4559", "mrqa_naturalquestions-validation-5440", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-5040", "mrqa_naturalquestions-validation-8857", "mrqa_naturalquestions-validation-2273", "mrqa_naturalquestions-validation-7549", "mrqa_naturalquestions-validation-2226"], "fixed_ids": ["mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-2563", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-2739", "mrqa_naturalquestions-validation-5826"], "unfixed_ids": ["mrqa_naturalquestions-validation-3598"], "error_ids": ["mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-2563", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-2739", "mrqa_naturalquestions-validation-5826"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.6821120689655172}, {"timecode": 29, "before_eval": {"predictions": ["the semi-fluid mass of partly digested food that is expelled by the stomach, through the pyloric valve, into the duodenum ( the beginning of the small intestine )", "the Slesinger family", "William Wyler", "17 August 1945", "eukaryotic", "nine", "22 -- 21 ( last appearance after beating New England Patriots in Super Bowl LII )", "`` Feed Jake ''", "Staci Keanan", "Julius Caesar", "Real Madrid", "September 6, 2019", "126 by Wilt Chamberlain from October 19, 1961 -- January 19, 1963", "Selena Gomez", "Noel Kahn", "35 to 40 hours per week", "multiple origins", "640 \u00d7 360 Himax HX7309 LCoS display", "March 11, 2018", "March 9, 2018", "December 9, 2016", "the 1982 championship team", "George Strait", "a mixture of phencyclidine and cocaine", "the primal rib", "two years", "Rob Reiner", "a chain of hypermarkets", "G. Hannelius", "Himadri Station", "maquiladora ( Spanish pronunciation : ( makila\u02c8\u00f0o\u027ea ) ) or maquila ( IPA : ( ma\u02c8kila ) )", "Mariah Carey"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6322103507905138}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, false, true], "QA-F1": [0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.17391304347826084, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["the pyloric valve", "all trademark and copyright rights to Disney", "William Wyler", "17 August 1945", "the scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment", "nine", "Super Bowl LII", "American country music band Pirates of the Mississippi", "Staci Keanan", "a haruspex named Spurinna", "Real Madrid", "September 6, 2019", "126", "American singer Selena Gomez", "Noel Kahn", "35 to 40 hours per week", "up to 100,000 present in a single human cell", "640 \u00d7 360 Himax HX7309 LCoS display", "March 11, 2018", "March 9, 2018", "30 days after the original air date", "2003", "George Strait", "phencyclidine", "the primal rib", "two years and eight months for men ( with some roles requiring an additional four months of service ), and two years for women", "Rob Reiner", "multinational retail corporation", "G. Hannelius", "Himadri Station", "special economic zones", "Zara Larsson"], "metric_results": {"EM": 0.875, "QA-F1": 0.9402515723270439}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.7547169811320755, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2545", "mrqa_naturalquestions-validation-2740", "mrqa_naturalquestions-validation-3682"], "retained_ids": ["mrqa_naturalquestions-validation-5219", "mrqa_naturalquestions-validation-6816", "mrqa_naturalquestions-validation-10166", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5597", "mrqa_naturalquestions-validation-5709", "mrqa_naturalquestions-validation-6769", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-756", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-7936", "mrqa_naturalquestions-validation-6074", "mrqa_naturalquestions-validation-8080", "mrqa_naturalquestions-validation-400", "mrqa_naturalquestions-validation-1127"], "fixed_ids": ["mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-2479", "mrqa_naturalquestions-validation-7838", "mrqa_naturalquestions-validation-7234", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-5146", "mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-1070", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-3004"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355"], "error_ids": ["mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-2479", "mrqa_naturalquestions-validation-7838", "mrqa_naturalquestions-validation-7234", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-5146", "mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-1070", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-3004"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.8421052631578947, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.6822916666666666}, {"timecode": 30, "before_eval": {"predictions": ["Escherichia coli", "Ben Fransham", "in the retina of mammalian eyes", "American figure skater Gillis Grafstr\u00f6m", "Joseph Sherrard Kearns", "an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "William Alan `` Will '' Friedle", "1", "its absolute temperature", "a region within the federal states of Saxony, Thuringia and Saxony - Anhalt, or a smaller part of this region, such as the metropolitan area of Leipzig and Halle", "elsewhere on the North Shore, at locations in Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "the author of V\u1e5bksayurveda ( the science of life of trees )", "drawing letters in the air ( `` penciling '' )", "a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud", "8.7 -- 9.2", "the president", "the 1979 -- 80 season", "October 17, 2017", "Prince James, Duke of York and of Albany ( later King James II & VII )", "August 1, 2016", "The Miracles", "Shirley Mae Jones", "points - rebounds", "lacteal", "2018", "1960", "2 Constant ( C\u03bc and C\u03b4 ) gene segments", "American Horror Story : Roanoke", "tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "the University of Michigan campus at Ann Arbor, Michigan", "the Hebrew name Immanu'el", "October 15, 1997"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4823451976944624}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.25, 0.0, 1.0, 0.05714285714285714, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, 0.07692307692307693, 1.0, 0.0, 0.3333333333333333]}}, "after_eval": {"predictions": ["Escherichia coli", "Ben Fransham", "the fovea centralis", "Canadian ice dancers Tessa Virtue and Scott Moir", "Joseph Sherrard Kearns", "consists of thirty articles affirming an individual's rights", "William Alan `` Will '' Friedle", "1", "volume", "Central Germany", "Essex", "Parashara", "penciling", "a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud", "The 1700 Cascadia earthquake", "Chief Election Commissioner", "the 1979 -- 80 season", "October 17, 2017", "English", "1980", "The Miracles", "Shirley Mae Jones", "Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840", "lacteal", "2018", "Super Bowl LII", "V", "American Horror Story : Roanoke", "Indo - Pacific", "the University of Michigan campus at Ann Arbor, Michigan", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "July 8, 1997"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9875}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 0.7999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-7142", "mrqa_naturalquestions-validation-6612", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-2592", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-5102", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-4880", "mrqa_naturalquestions-validation-9104", "mrqa_naturalquestions-validation-375", "mrqa_naturalquestions-validation-3122"], "fixed_ids": ["mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-3323", "mrqa_naturalquestions-validation-2884", "mrqa_naturalquestions-validation-7153", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-6912", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-10612", "mrqa_naturalquestions-validation-6365"], "unfixed_ids": ["mrqa_naturalquestions-validation-7358", "mrqa_naturalquestions-validation-7938"], "error_ids": ["mrqa_naturalquestions-validation-7358", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-7938", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-3323", "mrqa_naturalquestions-validation-2884", "mrqa_naturalquestions-validation-7153", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-6912", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-10612", "mrqa_naturalquestions-validation-6365"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.53125, "doing-nothing_accmulative_EM": 0.6774193548387096}, {"timecode": 31, "before_eval": {"predictions": ["Deuteronomy 5 : 4 -- 25", "a Japanese light novel series", "Buffalo Lookout", "203", "Kevin Kline", "September 19, 2017", "Joaquin Phoenix", "Turner Layton", "March 1, 2018", "Jewel Akens", "Las Vegas, Nevada", "the last million years since the Late Miocene", "on the Cap - Vert peninsula on the Atlantic coast and is the westernmost city in the Old World as well as on the African mainland", "Justice Harlan", "when they enter the army during initial entry training", "Spanish / Basque", "all Americans", "the head of the arrow or cockerel ( or equivalent depending on the chosen design )", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "March 6, 2018", "Hormones", "London, England and British Columbia, Canada", "a race of extraterrestrials called Saiyans", "4 January 2011", "the root respiration", "1988", "Sarah Silverman", "mashed potato", "between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west", "Justin Timberlake", "15 February 1998", "Samantha Jo `` Mandy '' Moore"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7051959614459614}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.5185185185185185, 1.0, 0.6666666666666666, 0.8, 1.0, 0.0, 0.14285714285714288, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["Deuteronomy 5 : 4 -- 25", "Isekai wa Sum\u0101tofon to Tomo ni", "Buffalo Lookout", "203", "Kevin Kline", "September 19, 2017", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "Turner Layton", "September 21, 2017", "Jewel Akens", "Las Vegas, Nevada", "In the last million years since the Late Miocene", "on the Cap - Vert peninsula on the Atlantic coast", "Justice Harlan", "during initial entry training", "Spanish / Basque origin", "all Americans", "the direction from which the wind is blowing", "Dome of the Rock", "March 6, 2018", "Plant hormones", "British Columbia, Canada", "During his epic battle with Frieza", "4 January 2011", "ATP", "1988", "Sarah Silverman", "mashed potato", "between the front ranges of the Rocky Mountains on the east and the Cascade Range and Sierra Nevada on the west", "Justin Timberlake", "1994", "Samantha Jo `` Mandy '' Moore"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9975961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-1309", "mrqa_naturalquestions-validation-7794", "mrqa_naturalquestions-validation-8485", "mrqa_naturalquestions-validation-5446", "mrqa_naturalquestions-validation-9094", "mrqa_naturalquestions-validation-8668", "mrqa_naturalquestions-validation-4800", "mrqa_naturalquestions-validation-4597", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-10389", "mrqa_naturalquestions-validation-8528", "mrqa_naturalquestions-validation-10204", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-7404", "mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-10039"], "fixed_ids": ["mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2076", "mrqa_naturalquestions-validation-4360", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-9688", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5542", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9591"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227"], "error_ids": ["mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-9227", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2076", "mrqa_naturalquestions-validation-4360", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-9688", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5542", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9591"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.6787109375}, {"timecode": 32, "before_eval": {"predictions": ["30.4 % in 2016", "one of a number of friends ( who provide their phone numbers in advance )", "after a scuffle with the Beast Folk", "at least 18 or 21 years old ( or have a legal guardian present ), and must sign a waiver prior to shooting", "Anglo - Saxon origin", "Michael Christopher McDowell", "Tandi, in Lahaul", "Andrea Brooks", "Washington Redskins", "San Crist\u00f3bal, Pinar del R\u00edo Province ( now in Artemisa Province ), in western Cuba", "Richard Burbage", "Gravity, or gravitation", "Alan Shearer ( Blackburn Rovers, 1994 -- 95 )", "Garbi\u00f1e Muguruza", "13 May 1787", "Elijah, Rebekah, Klaus and Davina surrounding Kol", "Bohrium", "cycads", "the judiciary", "Sloane Stephens", "Ed Sheeran", "Canadian singer Justin Bieber", "Tyrann Devine Mathieu", "Jay Baruchel", "to `` help bring creative projects to life ''", "up to three terms until 2015", "Joe Turano", "10 May 1940", "London", "St. Mary's County", "Geoffrey Zakarian", "first adopted by the university's science club in 1886"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5636199874686716}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false], "QA-F1": [0.0, 0.5714285714285715, 0.5263157894736842, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.5, 0.5, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715]}}, "after_eval": {"predictions": ["16.5 quadrillion BTUs", "the contestant makes a thirty - second call to one of a number of friends ( who provide their phone numbers in advance ) and reads them the question and answer choices, after which the friend provides input", "Montgomery, his servant M'ling, and the Sayer of the Law die after a scuffle with the Beast Folk", "Typically, no", "mainly of Anglo - Saxon origin", "Michael Christopher McDowell", "Tandi, in Lahaul", "Andrea Brooks", "currently a free agent", "San Crist\u00f3bal, Pinar del R\u00edo Province ( now in Artemisa Province ), in western Cuba", "almost certainly wrote his version of the title role for his fellow actor, Richard Burbage", "Gravity", "Alan Shearer", "Garbi\u00f1e Muguruza", "18 January 1788", "Kol", "Bohrium", "either on the surface of scales or leaves", "judges", "Sloane Stephens", "Ed Sheeran", "Singh H Spot", "Tyrann Devine Mathieu", "Jay Baruchel", "global crowdfunding platform focused on creativity and merchandising", "two four - year terms", "Frederick in a duet with Teresa James", "10 May 1940", "Wimbledon, London", "Washington metropolitan area", "Geoffrey Zakarian", "the university's science club in 1886"], "metric_results": {"EM": 0.90625, "QA-F1": 0.973248106060606}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7272727272727272]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-965", "mrqa_naturalquestions-validation-8147"], "retained_ids": ["mrqa_naturalquestions-validation-3862", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-3562", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-5268", "mrqa_naturalquestions-validation-7937", "mrqa_naturalquestions-validation-6947", "mrqa_naturalquestions-validation-4611", "mrqa_naturalquestions-validation-8263", "mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7097"], "fixed_ids": ["mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-894", "mrqa_naturalquestions-validation-8617", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-2270", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-10032", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-2439", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-6814", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-787", "mrqa_naturalquestions-validation-6167", "mrqa_naturalquestions-validation-5961"], "unfixed_ids": ["mrqa_naturalquestions-validation-8707"], "error_ids": ["mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-894", "mrqa_naturalquestions-validation-8617", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-2270", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-10032", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-2439", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-6814", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-787", "mrqa_naturalquestions-validation-6167", "mrqa_naturalquestions-validation-5961", "mrqa_naturalquestions-validation-8707"], "instant_fixing_rate": 0.9444444444444444, "instant_retention_rate": 0.8571428571428571, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.6770833333333334}, {"timecode": 33, "before_eval": {"predictions": ["Cody Fern", "Tara / Ghost of Christmas Past", "PPG Paints Arena, Pittsburgh, Pennsylvania", "Akbar the Great", "a movement within the Church of England in the 18th century", "Mercedes - Benz Stadium in Atlanta, Georgia", "pigs", "Harlem River", "2016", "seven", "the Kansas City Chiefs", "Beijing, China", "Portuguese and Spanish - French origins", "the praises of Whig candidates William Henry Harrison ( the `` hero of Tippecanoe '' ) and John Tyler, while denigrating incumbent Democrat Martin Van Buren", "Veronica Lodge", "the original 13 colonies", "April 2011", "White won gold in the half - pipe", "Marty Robbins", "Exodus 20 : 1 -- 21", "in London's West End in 1986", "in a wide surrounding area, in the Georgia counties of Newton ( where Covington is located ), Rockdale, Walton, Morgan, and Jasper", "Neutron sources", "1956", "Ganesh Chaturthi", "between the left atrium and the left ventricle", "four", "Hon July Moyo", "Pakhangba", "such famous figures as Judy Garland, Carole Landis, Dean Martin, and Ethel Merman", "the western coast of Italy", "between the lungs, in the middle compartment of the chest"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6614823348694316}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.09090909090909091, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7096774193548387, 0.0, 0.0, 0.0, 0.9090909090909091, 1.0, 1.0, 0.2857142857142857, 0.8387096774193548, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0]}}, "after_eval": {"predictions": ["Cody Fern", "Tara / Ghost of Christmas Past", "Duquesne University", "Babur", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Mercedes - Benz Stadium in Atlanta, Georgia", "pigs", "Harlem River", "2007", "seven", "the Kansas City Chiefs", "Beijing, China", "Portuguese and Spanish - French origins", "Whig candidates William Henry Harrison ( the `` hero of Tippecanoe '' ) and John Tyler", "Betty", "the May Revolution of 1810", "2014", "won gold in the half - pipe", "Marty Robbins", "Exodus 20 : 1 -- 21", "1986", "Decatur in Dekalb County", "startup neutron source", "1956", "Ganesh", "between the left atrium and the left ventricle", "four", "Hon July Moyo", "Pakhangba", "Ethel Merman", "Sicily", "between the lungs, in the middle compartment of the chest"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-2338", "mrqa_naturalquestions-validation-3494", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-9813", "mrqa_naturalquestions-validation-3205", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-3275", "mrqa_naturalquestions-validation-3273", "mrqa_naturalquestions-validation-9277", "mrqa_naturalquestions-validation-9971", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-4029", "mrqa_naturalquestions-validation-4798", "mrqa_naturalquestions-validation-5081"], "fixed_ids": ["mrqa_naturalquestions-validation-3058", "mrqa_naturalquestions-validation-6482", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6765", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-8343", "mrqa_naturalquestions-validation-6968", "mrqa_naturalquestions-validation-150"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-3058", "mrqa_naturalquestions-validation-6482", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6765", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-8343", "mrqa_naturalquestions-validation-6968", "mrqa_naturalquestions-validation-150"], "instant_fixing_rate": 1.0, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.6764705882352942}, {"timecode": 34, "before_eval": {"predictions": ["Madhya Pradesh", "an expression of Priestley's socialist political principles", "muscles", "EVR Race", "Jessica Simpson", "Jules Shear", "bilingual German author B. Traven", "Phalaborwa, Limpopo", "Cetshwayo", "2018", "non-magnetic property or resistance to corrosion ( e.g. zinc )", "both natural and man - made features", "agrees to certain conditions before the completion of the maximum sentence period", "Geraldine Margaret Agnew - Somerville", "`` state '' or `` states ''", "Erika Mitchell Leonard", "the adrenal medulla", "Teri Hatcher", "Walter Egan", "September 2014", "1546", "as a reflex response to food that is in the mouth, and also as a response to the sensation of food within the esophagus itself", "Brianna", "R.H. Thomson", "Grand Inquisitor", "I Write Sins Not Tragedies", "the enzyme RuBisCO", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film", "Kimberlin Brown", "Latin liberalia studia", "1984", "northern Europe's seasonal less solar radiation"], "metric_results": {"EM": 0.5, "QA-F1": 0.5975562757997936}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 0.125, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.2857142857142857, 0.35294117647058826, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.16666666666666669, 0.0, 1.0, 1.0, 1.0, 0.0, 0.21052631578947367, 1.0, 0.0, 0.0, 0.0]}}, "after_eval": {"predictions": ["Madhya Pradesh", "a scathing critique of the hypocrisies of Victorian / Edwardian English society", "the brain, muscles, and liver", "EVR Race", "Jessica Simpson", "Jules Shear", "bilingual German author B. Traven, whose identity remains unknown", "in the north - east of South Africa, in the eastern parts of Limpopo and Mpumalanga provinces", "Cetshwayo", "2018", "non-ferrous", "relief", "a temporary release of a prisoner who agrees to certain conditions before the completion of the maximum sentence period", "Geraldine Margaret Agnew - Somerville", "zh\u014dng ( \u4e2d ) meaning `` central '' or `` middle '', and gu\u00f3 ( \u570b / \u56fd ), representing `` state'or `` states '' ; in contemporary usage, `` nation ''", "Erika Mitchell Leonard ( born 7 March 1963 ), known by her pen name E.L. James", "the adrenal medulla", "Teri Hatcher", "Walter Egan", "PlayStation 3 and Xbox 360 in November 2014", "1546", "push the food down the esophagus", "Rick", "R.H. Thomson", "Grand Inquisitor", "I Write Sins Not Tragedies", "3 - phosphoglycerate", "Michael Edwards", "Kimberlin Brown", "artes liberales", "1998", "a low concentration in pigmentation"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9785714285714286}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7704"], "retained_ids": ["mrqa_naturalquestions-validation-7317", "mrqa_naturalquestions-validation-2613", "mrqa_naturalquestions-validation-2602", "mrqa_naturalquestions-validation-6041", "mrqa_naturalquestions-validation-6212", "mrqa_naturalquestions-validation-3765", "mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-1611", "mrqa_naturalquestions-validation-2866", "mrqa_naturalquestions-validation-9328", "mrqa_naturalquestions-validation-1436", "mrqa_naturalquestions-validation-2500", "mrqa_naturalquestions-validation-3157", "mrqa_naturalquestions-validation-2857", "mrqa_naturalquestions-validation-2745"], "fixed_ids": ["mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-5272", "mrqa_naturalquestions-validation-2626", "mrqa_naturalquestions-validation-6388", "mrqa_naturalquestions-validation-7200", "mrqa_naturalquestions-validation-6723", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-6810", "mrqa_naturalquestions-validation-1452", "mrqa_naturalquestions-validation-6699", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-6214"], "unfixed_ids": ["mrqa_naturalquestions-validation-5624"], "error_ids": ["mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-5272", "mrqa_naturalquestions-validation-2626", "mrqa_naturalquestions-validation-6388", "mrqa_naturalquestions-validation-7200", "mrqa_naturalquestions-validation-6723", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-6810", "mrqa_naturalquestions-validation-1452", "mrqa_naturalquestions-validation-6699", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-6214"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.9375, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.675}, {"timecode": 35, "before_eval": {"predictions": ["J. Presper Eckert", "along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "maestro Walter Damrosch and great Russian composer Pyotr Ilyich Tchaikovsky", "Janie Crawford", "a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "the President of the United States", "around 1600 BC", "Shaunette Ren\u00e9e Wilson as Dr. Mina Okafor", "Robert James Anderson", "five", "Texas A&M University", "1908", "a subdivision, or sub domain of the domain to the right", "the class Cephalopoda with squids, cuttlefish and nautiloids", "Meg Tilly", "an integral membrane protein that builds up a proton gradient across a biological membrane", "Tristan Rogers", "Todd Griffin", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "Ricky Nelson", "Montreal Canadiens", "Richard Masur", "an orange vermilion called international orange", "Cincinnati", "spherical boundary of zero thickness", "the 1950s", "Jacques Cartier", "tabby", "H CO ( equivalently OC ( OH ) )", "Arun Jaitley", "a nitrogenous base, a five - carbon sugar ( ribose or deoxyribose ), and at least one phosphate group", "a list of actions or event steps typically defining the interactions between a role ( known in the Unified Modeling Language as an actor ) and a system to achieve a goal"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7186091686091687}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.30769230769230765, 0.6, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["John von Neumann", "along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "Walter Damrosch", "Janie Crawford", "Everywhere", "the President", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Shaunette Ren\u00e9e Wilson", "Robert James Anderson", "five", "Texas A&M University", "1940", "hostname", "class Cephalopoda", "Meg Tilly", "an integral membrane protein that builds up a proton gradient across a biological membrane", "Tristan Rogers", "Todd Griffin", "Kelly Osbourne", "Ricky Nelson", "Montreal Canadiens", "Richard Masur", "an orange vermilion called international orange", "Cincinnati", "a radius 1.5 times the Schwarzschild radius", "1969", "Jacques Cartier", "tabby", "H CO ( equivalently OC ( OH ) )", "Indian government", "Nucleotides", "a list of actions or event steps typically defining the interactions between a role ( known in the Unified Modeling Language as an actor ) and a system to achieve a goal"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9291666666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-3115", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-2713"], "retained_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-6919", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-2992", "mrqa_naturalquestions-validation-5207", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-8654", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-5738", "mrqa_naturalquestions-validation-1299", "mrqa_naturalquestions-validation-1577", "mrqa_naturalquestions-validation-2895", "mrqa_naturalquestions-validation-9338", "mrqa_naturalquestions-validation-9594", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-1749"], "fixed_ids": ["mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5445", "mrqa_naturalquestions-validation-2663", "mrqa_naturalquestions-validation-5710", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-9324"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5445", "mrqa_naturalquestions-validation-2663", "mrqa_naturalquestions-validation-5710", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-9324"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8571428571428571, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.6736111111111112}, {"timecode": 36, "before_eval": {"predictions": ["Bonnie Hunt", "Welsh poet Dylan Thomas", "Computer simulation", "the court from its members for a three - year term", "Philippe Petit ( French pronunciation : \u200b ( filip p\u0259ti ) ; born 13 August 1949 )", "a chimera ( a mixture of several animals )", "Bette Midler", "20", "display compressed video content on the web", "April 1917", "India", "Atlanta Falcons", "Q'eqchi", "September 1972", "Terry Reid", "336", "Automobile drivetrains", "the United Kingdom", "a warrior, mage, or rogue coming from an elven, human, or dwarven background", "a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble", "Joseph M. Scriven", "Ireland", "the Hindu sage Valmiki", "Lucknow", "September 8, 2017", "21.8 %", "the Jurchen Aisin Gioro clan in Manchuria", "hostname ( www.example.com )", "October 2008", "one of Jesus'disciples", "a convergent plate boundary", "subdural hematoma ( SDH )"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6886294261294261}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.2222222222222222, 0.3076923076923077, 0.33333333333333337, 1.0, 1.0, 0.4, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["John Goodman", "Welsh poet Dylan Thomas", "Computer simulation", "the court", "Philippe Petit", "a chimera", "Bette Midler", "20", "to display interactive web pages, online games, and to playback video and audio content", "April 1917", "India", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "K'iche '", "September 1972", "The Spencer Davis Group", "336", "in the transmission", "the United Kingdom", "a warrior, mage, or rogue coming from an elven, human, or dwarven background", "a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble", "Joseph M. Scriven", "Ireland", "traditionally ascribed to the Hindu sage Valmiki", "Lucknow", "September 8, 2017", "approximately 21.8 % of the world's population", "the Qianlong Emperor", "a hostname", "October 2008", "twin", "a convergent plate boundary", "subdural hematoma"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9539772727272727}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-7369"], "retained_ids": ["mrqa_naturalquestions-validation-8825", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-4037", "mrqa_naturalquestions-validation-5854", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-8126", "mrqa_naturalquestions-validation-6186", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-8059", "mrqa_naturalquestions-validation-2512", "mrqa_naturalquestions-validation-1962", "mrqa_naturalquestions-validation-2887", "mrqa_naturalquestions-validation-8754", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-8699"], "fixed_ids": ["mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-8853", "mrqa_naturalquestions-validation-4544", "mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-9639", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-5164"], "unfixed_ids": ["mrqa_naturalquestions-validation-3035"], "error_ids": ["mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-8853", "mrqa_naturalquestions-validation-4544", "mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-3035", "mrqa_naturalquestions-validation-9639", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-5164"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.8947368421052632, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.6739864864864865}, {"timecode": 37, "before_eval": {"predictions": ["April 1948", "Walter Pauk", "May 18, 2018", "a charbagh", "Texas", "Tachycardia", "habitat", "a tropical desert climate", "New England", "Tiffany Adams Coyne", "1961", "16 % in the US", "`` If These Dolls Could Talk ''", "two - third of the total members present", "minced meat", "the 1840s", "Medicaid", "ecological regions", "Triple threat", "the pilot", "England - James I, King of England", "Kevin Spacey", "George Strait", "substitute good", "$66.5 million in 2014", "Joseph Stalin", "Hasmukh Adhia", "Annette", "a head - up display", "De Wayne Warren", "enable direct, regulated, symplastic transport of substances between cells", "Ewan McGregor"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7297436938061939}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5454545454545454, 1.0, 0.4615384615384615, 1.0, 1.0, 0.08333333333333333, 1.0, 1.0, 0.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.2857142857142857, 0.0]}}, "after_eval": {"predictions": ["in the 1980s", "Walter Pauk, an education professor at Cornell University", "May 18, 2018", "a charbagh", "Oklahoma", "tachycardia in adults", "species", "a tropical desert climate", "New York", "Tiffany Adams Coyne", "1961", "from 2 % naturally blond to 16 % in the US", "`` If These Dolls Could Talk ''", "majority of members present at that time", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "the 1840s", "Medicaid, provides for the states to finance health care for individuals who were at or close to the public assistance level with federal matching funds", "ecological regions", "Triple threat", "Waylon Jennings", "James I, King of England", "Kevin Spacey", "George Strait", "substitute good", "$66.5 million", "Joseph Stalin", "Hasmukh Adhia", "Annette", "a head - up display", "DeWayne Warren", "microscopic channels which traverse the cell walls of plant cells and some algal cells, enabling transport and communication between them", "Count Dooku / Darth Tyranus"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9547672672672673}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1081081081081081, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2980", "mrqa_naturalquestions-validation-10625"], "retained_ids": ["mrqa_naturalquestions-validation-2165", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-9216", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-9991", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-3192", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-750"], "fixed_ids": ["mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-10131", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-8509", "mrqa_naturalquestions-validation-3591", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-6168", "mrqa_naturalquestions-validation-5753", "mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-4061", "mrqa_naturalquestions-validation-5550"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-10131", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-8509", "mrqa_naturalquestions-validation-3591", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-6168", "mrqa_naturalquestions-validation-5753", "mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-4061", "mrqa_naturalquestions-validation-5550"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8947368421052632, "doing-nothing_instant_EM": 0.59375, "doing-nothing_accmulative_EM": 0.671875}, {"timecode": 38, "before_eval": {"predictions": ["Duisburg", "Ravi Shastri", "1823", "last one - quarter of a synodic month, or 7.38 days, on average", "Lana Del Rey", "six", "Chicago metropolitan area", "mohair from Angora goats", "Eric Clapton", "a means of restarting play after a minor infringement", "NFL owners", "Nathan Hale", "August 5, 1937", "Jason Ravnsborg", "Queenstown ( now Cobh ) in Ireland", "a scythe", "Dan Stevens", "eight", "A 30 - something man ( XXXX ), is a London underworld criminal who has established himself as one of the biggest cocaine suppliers in the city, with effective legitimate cover", "9", "Doreen Mantle", "Kristy Swanson", "Lana Del Rey", "American country music artist Mary Chapin Carpenter", "StubHub Center in Carson, California", "Jessica Simpson", "Germany", "1951 -- 52", "the central canal of the spinal cord or into the subarachnoid cisterns via three small foramina : the central median aperture and the two lateral apertures", "terrestrial biosphere", "the American girl group No Secrets", "to represent'a voyage of adventure'on which the programme would set out"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6788392857142858}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333333, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 0.6, 0.7142857142857143, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809525]}}, "after_eval": {"predictions": ["Duisburg", "Ravi Shastri", "1783", "when the Moon's ecliptic longitude and the Sun's Eclipti longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "Lana Del Rey", "six", "Chicago Tylenol murders", "silk", "George Harrison", "restarting play after a minor infringement", "NFL owners", "Nathan Hale", "1937", "Lawrence County State's Attorney John Fitzgerald", "about 375 miles ( 600 km ) south of Newfoundland", "scythe", "Dan Stevens", "eight", "XXXX", "9", "Doreen Mantle", "Kristy Swanson", "Lana Del Rey", "Mary Chapin Carpenter", "National Training Center at StubHub Center in Carson, California", "Jessica Simpson", "Germany", "1951 -- 52", "the fourth ventricle", "terrestrial biosphere", "Lana Del Rey", "a maritime signal, indicating that the vessel flying it is about to leave"], "metric_results": {"EM": 0.875, "QA-F1": 0.9503777472527473}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.8095238095238095, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-3476"], "retained_ids": ["mrqa_naturalquestions-validation-2703", "mrqa_naturalquestions-validation-7015", "mrqa_naturalquestions-validation-2989", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-3226", "mrqa_naturalquestions-validation-4245", "mrqa_naturalquestions-validation-7319", "mrqa_naturalquestions-validation-3423", "mrqa_naturalquestions-validation-1610", "mrqa_naturalquestions-validation-9113", "mrqa_naturalquestions-validation-7123", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-7669", "mrqa_naturalquestions-validation-2599", "mrqa_naturalquestions-validation-3146", "mrqa_naturalquestions-validation-2087", "mrqa_naturalquestions-validation-8502"], "fixed_ids": ["mrqa_naturalquestions-validation-9620", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-3310", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-1829", "mrqa_naturalquestions-validation-8061", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-1301"], "unfixed_ids": ["mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-8544"], "error_ids": ["mrqa_naturalquestions-validation-9620", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-3310", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-1829", "mrqa_naturalquestions-validation-8061", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-1301"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8947368421052632, "doing-nothing_instant_EM": 0.78125, "doing-nothing_accmulative_EM": 0.6746794871794872}, {"timecode": 39, "before_eval": {"predictions": ["Bumblebee", "15 March every year", "vanishing point", "copper", "Ki Toy Johnson", "18", "first published on November 12, 1976 by Ballantine Books", "2002", "Jack Gleeson", "As of December 10, 2017 ( 2017 - 12 - 10 ), 205 original episodes", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane, resulting in an electrical potential or ion concentration difference across the membrane", "Eastern Division Champion, 2017 Georgia Bulldogs football team against the Western Division Co-Champion, the 2017 Auburn Tigers football team", "when a population temporarily exceeds the long term carrying capacity of its environment", "Robert Newman", "Hathi Jr", "in the early 1980s", "163", "2.26 GHz quad - core Snapdragon 800", "Wabanaki Confederacy members Abenaki and Mi'kmaq", "All Souls'Day", "Bactrian", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "1 October 2006", "the central plains", "proscribes conduct perceived as threatening, harmful, or otherwise endangering to the property, health, safety, and moral welfare of people", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Akshay Kumar", "2018", "1945", "2014", "Kyla Coleman", "1995"], "metric_results": {"EM": 0.5625, "QA-F1": 0.69458139630837}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.21052631578947367, 1.0, 0.4, 1.0, 0.5714285714285715, 1.0, 0.923076923076923, 0.0, 0.28571428571428575, 0.25, 0.5555555555555556, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "after_eval": {"predictions": ["Ravage and the Decepticon Rampage", "15 March every year", "vanishing point", "gold ( Au )", "Fonzworth Bentley", "18", "film", "2002", "Jack Gleeson", "fourteen", "ATP synthesis from ADP and inorganic phosphate", "Georgia Bulldogs", "when a population temporarily exceeds the long term carrying capacity of its environment", "the church sexton Robert Newman and Captain John Pulling", "Hathi Jr", "in the very late 1980s", "163", "a 2.26 GHz quad - core Snapdragon 800 processor", "Iroquois", "All Saints ( or All Hallows )", "Bactrian, or two - humped camel ( C. bactrianus )", "during the 1890s Klondike Gold Rush", "1 October 2006", "in the central plains", "proscribes conduct perceived as threatening, harmful, or otherwise endangering to the property, health, safety, and moral welfare of people", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Akshay Kumar", "2018", "1945", "2014", "Kyla Coleman", "1995"], "metric_results": {"EM": 0.96875, "QA-F1": 0.99375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7661"], "retained_ids": ["mrqa_naturalquestions-validation-722", "mrqa_naturalquestions-validation-2569", "mrqa_naturalquestions-validation-7138", "mrqa_naturalquestions-validation-5516", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-6359", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-99", "mrqa_naturalquestions-validation-1069", "mrqa_naturalquestions-validation-2629", "mrqa_naturalquestions-validation-7894", "mrqa_naturalquestions-validation-1537", "mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5571", "mrqa_naturalquestions-validation-2491"], "fixed_ids": ["mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-243", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6341", "mrqa_naturalquestions-validation-3491", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-1364"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-243", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6341", "mrqa_naturalquestions-validation-3491", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-1364"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9444444444444444, "doing-nothing_instant_EM": 0.625, "doing-nothing_accmulative_EM": 0.6734375}, {"timecode": 40, "before_eval": {"predictions": ["Carol Worthington", "2008", "Kit Harington", "Narendra Modi", "Pangaea", "Bobby Darin", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "31", "Nicole DuPort", "Spain", "presidential representative democratic republic", "Joe Pizzulo and Leeza Miller", "Alfred Thomas `` Freddie '' Highmore", "Twisty the Clown ( portrayed by John Carroll Lynch )", "Olivia O'Brien", "23 September 1889", "BC Jean", "in March 2016", "Tulsa, Oklahoma", "Brian Johnson", "in the 1820s", "two", "Baltimore, Maryland", "September 2017", "Ben Faulks", "supporting the natural rights of self - defense and resistance to oppression", "the President of the United States", "Ole Einar Bj\u00f8rndalen", "the virtual band the Archies", "Werner Heisenberg", "in May 2002", "funicular railways with two connected railway cars on inclined tracks"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7870993589743589}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222218, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.8, 0.15384615384615383]}}, "after_eval": {"predictions": ["Carol Worthington", "2008", "Kit Harington", "Narendra Modi", "Pangaea", "Kevin Spacey", "the director's own approved edit", "31", "Nicole DuPort", "Spain", "presidential representative democratic republic", "Joe Pizzulo and Leeza Miller", "Alfred Thomas `` Freddie '' Highmore", "Bonnie Lipton", "Angel Benitez", "23 September 1889", "BC Jean", "March 2016", "Tulsa, Oklahoma", "Brian Johnson", "1820s", "two parallel planes", "Baltimore, Maryland", "BETA game was released in September 2017", "Ben Faulks", "the natural rights of self - defense and resistance to oppression, and the civic duty to act in concert in defense of the state", "the President of the United States", "Ole Einar Bj\u00f8rndalen", "the Archies", "Werner Heisenberg", "May 2002", "An elevator with a counterbalance"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9739583333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-8151"], "retained_ids": ["mrqa_naturalquestions-validation-9545", "mrqa_naturalquestions-validation-6590", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-9870", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-4814", "mrqa_naturalquestions-validation-6768", "mrqa_naturalquestions-validation-283", "mrqa_naturalquestions-validation-2930", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5635", "mrqa_naturalquestions-validation-6278", "mrqa_naturalquestions-validation-5334", "mrqa_naturalquestions-validation-2241", "mrqa_naturalquestions-validation-8118", "mrqa_naturalquestions-validation-6849", "mrqa_naturalquestions-validation-5548", "mrqa_naturalquestions-validation-7889", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-2112"], "fixed_ids": ["mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4246", "mrqa_naturalquestions-validation-4263", "mrqa_naturalquestions-validation-9895", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-896", "mrqa_naturalquestions-validation-9677", "mrqa_naturalquestions-validation-6777", "mrqa_naturalquestions-validation-2730"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "error_ids": ["mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-4246", "mrqa_naturalquestions-validation-4263", "mrqa_naturalquestions-validation-9895", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-896", "mrqa_naturalquestions-validation-9677", "mrqa_naturalquestions-validation-6777", "mrqa_naturalquestions-validation-2730"], "instant_fixing_rate": 0.9090909090909091, "instant_retention_rate": 0.9523809523809523, "doing-nothing_instant_EM": 0.875, "doing-nothing_accmulative_EM": 0.6783536585365854}, {"timecode": 41, "before_eval": {"predictions": ["Zeus", "in Florida, where new arrival Roy makes two oddball friends and a bad enemy, and joins an effort to stop construction of a pancake house which would destroy a colony of burrowing owls who live on the site", "Gibraltar", "16,801 students in 12 separate colleges / schools", "the civil, political, economic, social, health and cultural rights of children", "~ 3.5 million years old from Idaho, USA", "The Bellamy Brothers", "Texhoma", "transfers power from the transmission to the front and rear axles by means of drive shafts", "Chung", "Abid Ali Neemuchwala", "James I, King of England", "the New York Yankees", "2001", "Glynis Johns", "Tu'i Malila", "as a preparation for the Feast of the Divine Mercy, celebrated each year on first Sunday after Easter", "Judi Dench", "Thomas Edison", "Epithelium", "the central plate", "1999", "18", "the London Symphony Orchestra and London Philharmonic", "No. 1 seed Virginia", "1973", "Interphase", "R.E.M.", "1923", "at the hour of death or in the presence of the dying", "starch", "Roman Reigns"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6276430615065525}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.05882352941176471, 1.0, 0.4444444444444445, 0.0, 0.7272727272727273, 0.5, 1.0, 0.782608695652174, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["Zeus", "Florida", "Gibraltar", "16,801 students", "The United Nations", "~ 3.5 million years old", "American country music duo The Bellamy Brothers", "Texhoma", "transfers power from the transmission to the front and rear axles", "Forbes Burnham", "Abid Ali Neemuchwala", "James I", "the New York Yankees", "2001", "Glynis Johns", "tortoise", "Good Friday", "Judi Dench", "Thomas Edison", "Epithelium", "at each place", "October 2000", "18", "the cast", "UMBC", "1973", "Interphase", "R.E.M.", "1923", "at the hour of death or in the presence of the dying", "glucose", "Roman Reigns"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-10562", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-8931", "mrqa_naturalquestions-validation-10343", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-8328", "mrqa_naturalquestions-validation-6118", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-5371", "mrqa_naturalquestions-validation-7459", "mrqa_naturalquestions-validation-1556", "mrqa_naturalquestions-validation-143", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10546", "mrqa_naturalquestions-validation-1990", "mrqa_naturalquestions-validation-8568"], "fixed_ids": ["mrqa_naturalquestions-validation-1312", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-592", "mrqa_naturalquestions-validation-7050", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-2719", "mrqa_naturalquestions-validation-5256", "mrqa_naturalquestions-validation-6189", "mrqa_naturalquestions-validation-3309", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-10469", "mrqa_naturalquestions-validation-9773", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-9726"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-1312", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-592", "mrqa_naturalquestions-validation-7050", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-2719", "mrqa_naturalquestions-validation-5256", "mrqa_naturalquestions-validation-6189", "mrqa_naturalquestions-validation-3309", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-10469", "mrqa_naturalquestions-validation-9773", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-9726"], "instant_fixing_rate": 1.0, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.8125, "doing-nothing_accmulative_EM": 0.6815476190476191}, {"timecode": 42, "before_eval": {"predictions": ["Carl Belew", "Treme ( 2011 )", "the end zone ( 10 yards )", "Wilt Chamberlain", "red lead primer", "Kenny Rogers", "T.J. Miller", "near the city of Alessandria, in Piedmont, Italy", "Primary storage ( also known as main memory or internal memory )", "Kathy Najimy", "at the Dolby Theatre in Hollywood, Los Angeles, California", "Crohn's disease or ulcerative colitis", "sport utility vehicles", "Numbers 22 : 28", "The Fifth Amendment and Fourteenth Amendment", "The Noahic Covenant", "Sir Hugh Beaver", "Alan Shearer", "21 February", "The planner Raymond Unwin and the architect Barry Parker", "Mary Elizabeth Patterson", "1858", "Parietal cells ( also known as oxyntic or delomorphous cells )", "Johannes Gutenberg", "Ann Gillespie", "Chesapeake Bay, south of Annapolis in Maryland", "the narrator reflects on his life as a troubadour", "South Africa", "Justice A.K Mathur", "Lizzy Greene", "Naomi", "February 14, 2015"], "metric_results": {"EM": 0.625, "QA-F1": 0.7730711996336996}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.09523809523809523, 1.0, 0.5, 0.5714285714285715, 1.0, 1.0, 0.7692307692307693, 1.0, 0.9333333333333333, 0.5714285714285715, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5833333333333334, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "after_eval": {"predictions": ["Carl Belew", "The Man", "17 yards ( 7 yards in Canadian football ) longer than the distance of the line of scrimmage to the goal line", "Wilt Chamberlain", "red", "Kenny Rogers and the First Edition", "T.J. Miller", "near the city of Alessandria, in Piedmont, Italy", "Primary storage ( also known as main memory or internal memory ), often referred to simply as memory", "Kathy Najimy", "the Dolby Theatre in Hollywood, Los Angeles, California", "short bowel syndrome", "sport utility vehicles and off - road vehicles", "Numbers 22 : 28", "Chapter III, Article 13 of the 1947 Constitution of Japan", "Exodus", "Sir Hugh Beaver", "Alan Shearer", "21 February", "The planner Raymond Unwin and the architect Barry Parker", "Mary Elizabeth Patterson", "1757", "gastric glands found in the lining of the fundus and in the body of the stomach", "Johannes Gutenberg", "Ann Gillespie", "Chesapeake Bay, south of Annapolis in Maryland", "the narrator reflects on his life as a troubadour, feeling that he is content with what he has accomplished", "South Africa", "Justice A.K Mathur", "Lizzy Greene", "Michelle", "February 14, 2015"], "metric_results": {"EM": 0.9375, "QA-F1": 0.95625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-8393"], "retained_ids": ["mrqa_naturalquestions-validation-840", "mrqa_naturalquestions-validation-6668", "mrqa_naturalquestions-validation-6683", "mrqa_naturalquestions-validation-10520", "mrqa_naturalquestions-validation-3858", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-4720", "mrqa_naturalquestions-validation-2524", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-2214", "mrqa_naturalquestions-validation-7268", "mrqa_naturalquestions-validation-2005", "mrqa_naturalquestions-validation-1231", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-10372", "mrqa_naturalquestions-validation-5499", "mrqa_naturalquestions-validation-3440"], "fixed_ids": ["mrqa_naturalquestions-validation-7567", "mrqa_naturalquestions-validation-10270", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-10037", "mrqa_naturalquestions-validation-8002", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-7043", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-4513", "mrqa_naturalquestions-validation-7778", "mrqa_naturalquestions-validation-9675"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-7567", "mrqa_naturalquestions-validation-10270", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-10037", "mrqa_naturalquestions-validation-8002", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-7043", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-4513", "mrqa_naturalquestions-validation-7778", "mrqa_naturalquestions-validation-9675"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9, "doing-nothing_instant_EM": 0.78125, "doing-nothing_accmulative_EM": 0.6838662790697675}, {"timecode": 43, "before_eval": {"predictions": ["$72", "0 \u00b0", "Spanish", "the left ring finger", "Aaron Rodgers", "January 1, 1976", "2 September 1990", "Ford", "About 2.5 million years before writing was developed", "later in the 1970s", "the frontal lobe", "1957", "Brooke Wexler", "1834", "February 28, 2018", "Kate Walsh", "neuronal cell bodies", "the opisthodomus ( the back room of the cella )", "Patrick Walshe", "South American country", "Massillon Jackson High School", "the Spanish Empire", "October 27, 1904", "August 18, 1998", "1671", "The enthalpy of fusion of a substance", "monocot related to lilies and grasses", "1875", "cake or biscuit", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything", "1813", "Austria - Hungary"], "metric_results": {"EM": 0.5, "QA-F1": 0.5750490196078432}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.4, 0.5882352941176471, 0.0, 0.0, 0.16666666666666666, 0.08, 1.0, 1.0]}}, "after_eval": {"predictions": ["72 ounce ( 4.5 pounds or 2.04 kg ) steak", "antimeridian", "Spanish", "the left ring finger", "Aaron Rodgers", "January 1, 1976", "20 November 1989", "Ford", "bury their dead", "1970s", "frontal lobe", "1957", "Brooke Wexler", "1834", "Ghost Island", "Kate Walsh", "Grey matter ( or gray matter )", "cella", "Patrick Walshe", "The Republic of Tecala", "Massillon, Ohio", "Ta\u00edno", "October 27, 1904", "August 18, 1998", "As early as 1671", "The enthalpy of fusion of a substance, also known as ( latent ) heat of fusion", "an edible tuber", "around 1872", "the Jaffa cake should be considered a cake for tax purposes", "Latin : liberalis, `` worthy of a free person ''", "1813", "Austria - Hungary"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9756944444444444}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-7509"], "retained_ids": ["mrqa_naturalquestions-validation-8854", "mrqa_naturalquestions-validation-8476", "mrqa_naturalquestions-validation-4789", "mrqa_naturalquestions-validation-4816", "mrqa_naturalquestions-validation-2741", "mrqa_naturalquestions-validation-6750", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-8308", "mrqa_naturalquestions-validation-3891", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-5905", "mrqa_naturalquestions-validation-1515", "mrqa_naturalquestions-validation-7516", "mrqa_naturalquestions-validation-1917", "mrqa_naturalquestions-validation-3214"], "fixed_ids": ["mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-2083", "mrqa_naturalquestions-validation-3060", "mrqa_naturalquestions-validation-4930", "mrqa_naturalquestions-validation-6633", "mrqa_naturalquestions-validation-2012", "mrqa_naturalquestions-validation-272", "mrqa_naturalquestions-validation-2968", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-4211"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-2083", "mrqa_naturalquestions-validation-3060", "mrqa_naturalquestions-validation-4930", "mrqa_naturalquestions-validation-6633", "mrqa_naturalquestions-validation-2012", "mrqa_naturalquestions-validation-272", "mrqa_naturalquestions-validation-2968", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-4211"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9375, "doing-nothing_instant_EM": 0.71875, "doing-nothing_accmulative_EM": 0.6846590909090909}, {"timecode": 44, "before_eval": {"predictions": ["Rockwell", "a passing train", "Rugrats in Paris : The Movie", "Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru", "The Parlement de Bretagne ( Administrative and judicial centre of Brittany, Breton : Breujo\u00f9 Breizh )", "Peter Greene", "President Theodore Roosevelt", "a Remington 870 Police Magnum 12 \u2010 gauge shotgun", "2010", "innermost in the eye", "1994", "James Intveld", "1992", "Erica Rivera", "Betty", "DNA", "Thomas Edison", "Morgan Woodward", "Abraham", "the government - owned Panama Canal Authority", "six", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "October 14, 2017", "Keeley Clare Julia Hawes", "Deadman's Gun", "The vascular cambium", "Terry Kath", "the Swedish astronomer Anders Celsius ( 1701 -- 1744 ), who developed a similar temperature scale", "the colonists of Jamestown", "the thirteen British colonies that declared independence from the Kingdom of Great Britain", "1990", "Ptolemy"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6740897444585775}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.3870967741935484, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4705882352941177, 0.0, 0.7857142857142858, 1.0, 1.0]}}, "after_eval": {"predictions": ["former Jackson 5 members Michael Jackson ( vocals in the chorus ) and Jermaine Jackson ( additional backing vocals )", "Manhattan", "Rugrats in Paris : The Movie", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "The Parlement de Bretagne ( Administrative and judicial centre of Brittany, Breton : Breujo\u00f9 Breizh )", "Peter Greene", "Roosevelt Corollary", "a Remington 870 Police Magnum 12 \u2010 gauge shotgun", "2010", "The optic nerve", "UNESCO", "James Intveld", "1992", "Erica Rivera", "neither issue made it clear whether Archie was married to Betty or Veronica", "The results of the Avery -- MacLeod -- McCarty experiment", "Fred Ott", "Morgan Woodward", "The patriarch, then a hundred years old, named the child `` Isaac '' ( Hebrew yitschaq, `` laughter '' ) and circumcised him when he was eight days old", "in 1999 the canal was taken over by the Panamanian government and is now managed and operated by the government - owned Panama Canal Authority", "six", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "October 14, 2017", "Keeley Clare Julia Hawes", "Far Away", "The vascular cambium", "Terry Kath", "named after the Swedish astronomer Anders Celsius", "John Smith", "the thirteen British colonies that declared independence from the Kingdom of Great Britain, and became the first states in the U.S.", "1990", "Ptolemy"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9340277777777778}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-4013", "mrqa_naturalquestions-validation-5721"], "retained_ids": ["mrqa_naturalquestions-validation-9626", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-2767", "mrqa_naturalquestions-validation-8449", "mrqa_naturalquestions-validation-8710", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-6486", "mrqa_naturalquestions-validation-8035", "mrqa_naturalquestions-validation-7244", "mrqa_naturalquestions-validation-6121", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-3756", "mrqa_naturalquestions-validation-8220", "mrqa_naturalquestions-validation-1295", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-6149"], "fixed_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-2501", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-1641", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-5818", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-3918"], "unfixed_ids": ["mrqa_naturalquestions-validation-9087"], "error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-9087", "mrqa_naturalquestions-validation-2501", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-1641", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-5818", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-3918"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.8947368421052632, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.6847222222222222}, {"timecode": 45, "before_eval": {"predictions": ["to help batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship", "May 20, 2018", "The ecliptic", "U.S. population exceeds 75 million", "Hero Beauregard Fiennes - Tiffin", "India", "Hugo von Mohl", "Currington", "Georges Auguste Escoffier", "The UN General Assembly", "Stephen A. Davis", "four", "George Strait", "1918", "Left Behind", "The Gupta Empire", "Buddhism", "Harry Dean Stanton", "butane", "Gustav Bauer", "James W. Marshall", "February 2017", "6 - 7 % average GDP growth annually", "Jason Flemyng", "Paspahegh", "Langdon", "September 19, 1977", "no more than 38 inches ( 965 mm )", "Brooke Wexler", "the U.S. Fund for UNICEF", "Ace", "in the summer months"], "metric_results": {"EM": 0.75, "QA-F1": 0.7801339285714286}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7142857142857143, 1.0, 0.25, 1.0, 0.0]}}, "after_eval": {"predictions": ["re-education", "October 1, 2017", "ecliptic", "U.S. population exceeds 75 million", "Hero Beauregard Fiennes - Tiffin", "Pakistan", "Hugo von Mohl", "Currington", "Georges Auguste Escoffier", "The UN General Assembly", "Stephen A. Davis", "four", "George Strait", "1918", "Left Behind", "The Gupta Empire", "Buddhism", "Harry Dean Stanton", "butane", "Gustav Bauer", "James W. Marshall", "March 2018", "6 - 7 % average GDP growth annually", "Jason Flemyng", "uninhabited", "Langdon", "September 19, 1977", "no more than 4.25 inches ( 108 mm )", "Brooke Wexler", "UNICEF's global programing", "Ace", "winter"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9866071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_ids": [], "retained_ids": ["mrqa_naturalquestions-validation-8271", "mrqa_naturalquestions-validation-8608", "mrqa_naturalquestions-validation-1764", "mrqa_naturalquestions-validation-9397", "mrqa_naturalquestions-validation-858", "mrqa_naturalquestions-validation-2665", "mrqa_naturalquestions-validation-629", "mrqa_naturalquestions-validation-6616", "mrqa_naturalquestions-validation-6122", "mrqa_naturalquestions-validation-7911", "mrqa_naturalquestions-validation-6323", "mrqa_naturalquestions-validation-1103", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-6680", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-6804", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-8289", "mrqa_naturalquestions-validation-4850"], "fixed_ids": ["mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-5630", "mrqa_naturalquestions-validation-7012", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-8027"], "unfixed_ids": ["mrqa_naturalquestions-validation-4641"], "error_ids": ["mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-5630", "mrqa_naturalquestions-validation-7012", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-4641", "mrqa_naturalquestions-validation-8027"], "instant_fixing_rate": 0.875, "instant_retention_rate": 1.0, "doing-nothing_instant_EM": 0.84375, "doing-nothing_accmulative_EM": 0.6881793478260869}, {"timecode": 46, "before_eval": {"predictions": ["White House Executive Chef", "Janis Joplin", "a pagan custom, namely, the winter solstice which in Europe occurs in December", "an epithelial surface", "The Elk River", "Bulgaria", "September 2000", "French Union", "International Border ( IB )", "John Stephenson", "Thomas Jefferson", "Shenzi", "Ali", "at the bottom of every page", "Yahya Khan", "Thunder Road", "for creative reasons and `` not a reflection '' of the actress'performance", "Scottish singer - songwriter Dougie MacLean", "Aaron Lewis", "English occupational name for one who obtained his living by fishing or living by a fishing weir", "Stromal", "Albert Einstein", "the epidermis", "Ed Roland", "in an explosion", "left", "unknown date in the 1520s", "a number of Early Christian communities in Galatia", "the nerves and ganglia outside the brain and spinal cord", "James Chadwick", "Mark Jackson", "Alex Wong"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6356456043956045}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.33333333333333337, 0.09999999999999999, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 0.4, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "after_eval": {"predictions": ["White House Executive Chef", "singer Janis Joplin with the poets Michael McClure and Bob Neuwirth", "in ancient Rome with gift - giving during the Saturnalia holiday", "bloodstream", "Kanawha River", "Bulgaria", "2001", "France", "International Border ( IB )", "Paul Lynde", "Thomas Jefferson", "Shenzi ( voiced by Whoopi Goldberg in the films and Tress MacNeille in Timon & Pumbaa and Kingdom Hearts II )", "Ali", "at the bottom of every page ( above the copyright notice )", "Yahya Khan", "Thunder Road", "creative reasons", "Dougie MacLean", "Aaron Lewis", "an English occupational name for one who obtained his living by fishing or living by a fishing weir", "Stromal cells", "Albert Einstein", "the uppermost layer of the dermis", "Ed Roland", "in an explosion", "the right", "the Americas", "a number of Early Christian communities in Galatia", "the nerves and ganglia outside the brain and spinal cord", "James Chadwick", "Mark Jackson", "Adam Shankman"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9722222222222222}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-3018"], "retained_ids": ["mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-7521", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-4737", "mrqa_naturalquestions-validation-9707", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-6604", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-6480", "mrqa_naturalquestions-validation-1369", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-3003", "mrqa_naturalquestions-validation-6506", "mrqa_naturalquestions-validation-4335", "mrqa_naturalquestions-validation-1123"], "fixed_ids": ["mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-4815", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-7480", "mrqa_naturalquestions-validation-5897", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-811", "mrqa_naturalquestions-validation-5175", "mrqa_naturalquestions-validation-1592", "mrqa_naturalquestions-validation-6918", "mrqa_naturalquestions-validation-3971", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7852"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-4815", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-7480", "mrqa_naturalquestions-validation-5897", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-811", "mrqa_naturalquestions-validation-5175", "mrqa_naturalquestions-validation-1592", "mrqa_naturalquestions-validation-6918", "mrqa_naturalquestions-validation-3971", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7852"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9411764705882353, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.6875}, {"timecode": 47, "before_eval": {"predictions": ["Hercules", "New Jersey", "Tommy James and the Shondells", "Paul Rudd", "Argentine composer Lalo Schifrin", "Louis Hynes", "1957", "Alta Wind Energy Center in California", "To capitalize on her publicity", "1923", "Amanda Fuller", "1940s", "Cyndi Grecco", "14 and 15 August 1945", "Plank", "James Intveld", "Crist\u00f3bal Baca ( Vaca )", "24 November 1949", "Master Christopher Jones", "after the Spanish -- American War in the 1898 Treaty of Paris", "3.2 million", "DeWayne Warren", "in the 18th century in the United Kingdom when members of parliament disparagingly used the title in reference to Sir Robert Walpole", "the states or the people", "Twenty - seven", "1912", "the French Caribbean island of Guadeloupe", "a kiss - off to a narcissistic ex-lover who did the protagonist wrong", "Beijing for the 2022 Winter Olympics", "MacFarlane", "Games played", "160 km / h"], "metric_results": {"EM": 0.625, "QA-F1": 0.6949652777777777}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4000000000000001, 1.0, 1.0, 0.7499999999999999]}}, "after_eval": {"predictions": ["Hercules", "Pittsburgh", "Tommy James and the Shondells", "Rashida Jones", "Lalo Schifrin", "Malina Weissman", "1957", "Iowa", "gets relocated to Miami", "1923", "Amanda Fuller", "1940s", "Cyndi Grecco", "14 and 15 August 1945", "Plank", "James Intveld", "New Mexico", "24 November 1949", "Master Christopher Jones", "1898", "3.2 million", "DeWayne Warren", "in the 18th century in the United Kingdom", "the states or the people", "Thirty - three", "1912", "the French Caribbean island of Guadeloupe", "Rihanna", "Tokyo for the 2020 Summer Olympics", "MacFarlane", "Games played", "12951 / 52 Mumbai Rajdhani Express"], "metric_results": {"EM": 0.96875, "QA-F1": 0.98375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4799999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-4569"], "retained_ids": ["mrqa_naturalquestions-validation-5868", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-289", "mrqa_naturalquestions-validation-7088", "mrqa_naturalquestions-validation-370", "mrqa_naturalquestions-validation-1634", "mrqa_naturalquestions-validation-5896", "mrqa_naturalquestions-validation-8709", "mrqa_naturalquestions-validation-6489", "mrqa_naturalquestions-validation-2827", "mrqa_naturalquestions-validation-7973", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-7114", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-7788", "mrqa_naturalquestions-validation-10523", "mrqa_naturalquestions-validation-716"], "fixed_ids": ["mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-7853", "mrqa_naturalquestions-validation-156", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-8623", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-2156", "mrqa_naturalquestions-validation-6326", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-3416"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-7853", "mrqa_naturalquestions-validation-156", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-8623", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-2156", "mrqa_naturalquestions-validation-6326", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-3416"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.95, "doing-nothing_instant_EM": 0.75, "doing-nothing_accmulative_EM": 0.6888020833333334}, {"timecode": 48, "before_eval": {"predictions": ["Sam Waterston", "Agrippa I", "Peter Dinklage", "Nepal", "Italy", "Iden Versio", "the heat produced can make combustion self - sustaining", "April 7, 2016", "translocation Down syndrome", "Ethel `` Edy '' Proctor", "Daren Maxwell Kagasoff", "Rodney Crowell", "Giancarlo Stanton", "Kristy Swanson", "in northern China", "Ernest Hemingway", "December 1, 2009", "one of popular music's most poignant anthems of sorrow regarding the environment", "September 19 - 22, 2017", "1912", "the King's Chamber from the possibility of a roof collapsing under the weight of stone above the Chamber", "Pepperdine University", "Abraham Gottlob Werner", "Villa de Bejar", "Buddhism", "Pac - 12 Conference Champions Stanford Cardinal", "four", "the company generates income", "Phil Simms", "Etienne de Mestre", "William Jennings Bryan", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5467365355233003}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "after_eval": {"predictions": ["Sam Waterston", "Herod", "Tyrion Lannister ( season 1 -- present ) portrayed by Peter Dinklage", "Nepal", "Italian Campaign", "Iden Versio, leader of an Imperial Special Forces group known as Inferno Squad", "an oxidant, usually atmospheric oxygen", "April 7, 2016", "a rearrangement of chromosomal material between chromosome 21 and another chromosome", "Ethel `` Edy '' Proctor", "Daren Maxwell Kagasoff", "Rodney Crowell", "Giancarlo Stanton", "Kristy Swanson", "northern China", "Ernest Hemingway", "May 18, 2010", "sorrow regarding the environment", "September 19 - 22, 2017", "1912", "the name of a work gang", "Staples Center, Los Angeles, California", "James Hutton", "Spanish explorers", "Buddhism", "Stanford Cardinal", "20 regional offices and 11 sub-offices", "the financing activities section", "Phil Simms", "Bart Cummings", "William Jennings Bryan", "deal with local administrative applications in common law jurisdictions"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-734"], "retained_ids": ["mrqa_naturalquestions-validation-8109", "mrqa_naturalquestions-validation-9880", "mrqa_naturalquestions-validation-5363", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-2672", "mrqa_naturalquestions-validation-5135", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-8207", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-9876", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3593", "mrqa_naturalquestions-validation-930"], "fixed_ids": ["mrqa_naturalquestions-validation-4294", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-4200", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-7857", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-2938", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-379", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-7034", "mrqa_naturalquestions-validation-5291", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-2476"], "unfixed_ids": [], "error_ids": ["mrqa_naturalquestions-validation-4294", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-4200", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-7857", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-2938", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-379", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-7034", "mrqa_naturalquestions-validation-5291", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-2476"], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9333333333333333, "doing-nothing_instant_EM": 0.6875, "doing-nothing_accmulative_EM": 0.6887755102040817}, {"timecode": 49, "accumulative_EM": 0.8762755102040817, "accumulative_forgotten_ids": ["mrqa_naturalquestions-validation-6592", "mrqa_naturalquestions-validation-8279", "mrqa_naturalquestions-validation-7837", "mrqa_naturalquestions-validation-7197", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-7352", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-9578", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-1535", "mrqa_naturalquestions-validation-6110", "mrqa_naturalquestions-validation-7001", "mrqa_naturalquestions-validation-2435", "mrqa_naturalquestions-validation-1578", "mrqa_naturalquestions-validation-7816", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-9848", "mrqa_naturalquestions-validation-5043", "mrqa_naturalquestions-validation-10015", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-6517", "mrqa_naturalquestions-validation-2242", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-10683", "mrqa_naturalquestions-validation-10361", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-917", "mrqa_naturalquestions-validation-8128", "mrqa_naturalquestions-validation-4519", "mrqa_naturalquestions-validation-6414", "mrqa_naturalquestions-validation-4236", "mrqa_naturalquestions-validation-1629", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-8708", "mrqa_naturalquestions-validation-9940", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6169", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-8994", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-10537", "mrqa_naturalquestions-validation-1139", "mrqa_naturalquestions-validation-3466", "mrqa_naturalquestions-validation-2097", "mrqa_naturalquestions-validation-10671", "mrqa_naturalquestions-validation-5578", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-6574", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-756", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-6612", "mrqa_naturalquestions-validation-375", "mrqa_naturalquestions-validation-8528", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-894", "mrqa_naturalquestions-validation-3562", "mrqa_naturalquestions-validation-3273", "mrqa_naturalquestions-validation-3157", "mrqa_naturalquestions-validation-1749", "mrqa_naturalquestions-validation-8825", "mrqa_naturalquestions-validation-5854", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-7319", "mrqa_naturalquestions-validation-2569", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-2629", "mrqa_naturalquestions-validation-7894", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-8151", "mrqa_naturalquestions-validation-10520", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-3440", "mrqa_naturalquestions-validation-8476", "mrqa_naturalquestions-validation-4013", "mrqa_naturalquestions-validation-2767", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-3018", "mrqa_naturalquestions-validation-7973", "mrqa_naturalquestions-validation-4569", "mrqa_naturalquestions-validation-734"], "accumulative_fixed_ids": ["mrqa_naturalquestions-validation-7707", "mrqa_naturalquestions-validation-7017", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-816", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-3927", "mrqa_naturalquestions-validation-8529", "mrqa_naturalquestions-validation-8884", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-10326", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-4974", "mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-6358", "mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-1171", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-8368", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-9885", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-824", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-3395", "mrqa_naturalquestions-validation-4450", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-1531", "mrqa_naturalquestions-validation-10619", "mrqa_naturalquestions-validation-10162", "mrqa_naturalquestions-validation-6352", "mrqa_naturalquestions-validation-4496", "mrqa_naturalquestions-validation-746", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-8319", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-1179", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-8180", "mrqa_naturalquestions-validation-4309", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8599", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-407", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-6660", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-2624", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-4021", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-9346", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-9681", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6881", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-5218", "mrqa_naturalquestions-validation-5651", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-7581", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-5214", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-7003", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-4946", "mrqa_naturalquestions-validation-3233", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8582", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-3396", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-8643", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-10201", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-9763", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-559", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-4185", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8744", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1186", "mrqa_naturalquestions-validation-9214", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-7166", "mrqa_naturalquestions-validation-3782", "mrqa_naturalquestions-validation-5659", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-10352", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-9635", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-360", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-3704", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-8287", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-1298", "mrqa_naturalquestions-validation-6635", "mrqa_naturalquestions-validation-7013", "mrqa_naturalquestions-validation-10246", "mrqa_naturalquestions-validation-4280", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-10357", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3209", "mrqa_naturalquestions-validation-7335", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-7838", "mrqa_naturalquestions-validation-7234", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-5146", "mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-3004", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3323", "mrqa_naturalquestions-validation-2884", "mrqa_naturalquestions-validation-6912", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-10612", "mrqa_naturalquestions-validation-6365", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9688", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-8617", "mrqa_naturalquestions-validation-2270", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-2439", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-787", "mrqa_naturalquestions-validation-6167", "mrqa_naturalquestions-validation-5961", "mrqa_naturalquestions-validation-3058", "mrqa_naturalquestions-validation-6482", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6765", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-6968", "mrqa_naturalquestions-validation-150", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-5272", "mrqa_naturalquestions-validation-6212", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-1452", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-6214", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-2713", "mrqa_naturalquestions-validation-2663", "mrqa_naturalquestions-validation-5710", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-4544", "mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-8059", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-9639", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-10131", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-8509", "mrqa_naturalquestions-validation-3591", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-3310", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-8061", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6341", "mrqa_naturalquestions-validation-3491", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-1364", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-6118", "mrqa_naturalquestions-validation-3309", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-7567", "mrqa_naturalquestions-validation-10270", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-10037", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-4513", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-2083", "mrqa_naturalquestions-validation-272", "mrqa_naturalquestions-validation-2968", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-4211", "mrqa_naturalquestions-validation-2501", "mrqa_naturalquestions-validation-1641", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-5818", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-5630", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-4815", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-5897", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5175", "mrqa_naturalquestions-validation-6480", "mrqa_naturalquestions-validation-6918", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-2156", "mrqa_naturalquestions-validation-6326", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-7857", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-7034", "mrqa_naturalquestions-validation-5291", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-2476"], "accumulative_forgotten_rate": 0.0625, "accumulative_fixed_rate": 0.25, "before_eval": {"predictions": ["Support for and the elevation of leaves, flowers and fruits", "1967", "Caparra", "Sets heart in mediastinum and limits its motion", "1840s", "edible - nest swiftlets using solidified saliva", "James Madison", "euro", "4 January 2011", "Werner Ruchti", "the people of the United States", "medieval realism", "a crown cutting of the fruit", "Carol Ann Susi", "Ray Charles", "1986", "P.V. Sindhu", "September 14, 2008", "2004", "Independence Creek located near Atchison, Kansas", "14300 E. Alameda Avenue", "1913", "Missi Hale", "The Beatles", "Johnny Cash", "Lake Powell", "2001", "northwestern Highlands County", "Upstate New York", "Alex Drake", "Holly Sorensen", "the close quarters and poor hygiene exhibited at that time"], "metric_results": {"EM": 0.625, "QA-F1": 0.7202520212630507}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5, 0.0, 0.7142857142857143]}}, "after_eval": {"predictions": ["Support for and the elevation of leaves, flowers and fruits", "1967", "Puerto Rico", "Sets heart in mediastinum and limits its motion", "1840s", "bird nests created by edible - nest swiftlets using solidified saliva", "John Adams, Benjamin Franklin, Alexander Hamilton, John Jay, Thomas Jefferson, James Madison, and George Washington", "euro", "4 January 2011", "Werner Ruchti", "the people of the United States", "medieval", "Brazil", "Carol Ann Susi", "Ray Charles", "1990", "P.V. Sindhu", "September 14, 2008", "2004", "the Missouri River", "Theater 9", "1913", "Missi Hale", "The Beatles", "Johnny Cash", "Kanab, Utah", "2001", "in northwestern Highlands County at 27 \u00b0 35 \u2032 40 '' N 81 \u00b0 30 \u2032 12 '' W \ufeff / \ufffdTY 27.59444 \u00b0 N 81.50333 \u00b0 W \ufffd\u1eff", "Upstate New York", "CeCe Drake", "former elite, Olympian or NCAA champion gymnasts", "close quarters and poor hygiene"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9642857142857143}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_ids": ["mrqa_naturalquestions-validation-8526"], "retained_ids": ["mrqa_naturalquestions-validation-3097", "mrqa_naturalquestions-validation-3433", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-3625", "mrqa_naturalquestions-validation-1162", "mrqa_naturalquestions-validation-10383", "mrqa_naturalquestions-validation-2137", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-3594", "mrqa_naturalquestions-validation-6586", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-5002", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-8299", "mrqa_naturalquestions-validation-1901"], "fixed_ids": ["mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-9477", "mrqa_naturalquestions-validation-7134", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-7974", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-7588", "mrqa_naturalquestions-validation-10156"], "unfixed_ids": ["mrqa_naturalquestions-validation-10130"], "error_ids": ["mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-9477", "mrqa_naturalquestions-validation-7134", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-7974", "mrqa_naturalquestions-validation-10130", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-7588", "mrqa_naturalquestions-validation-10156"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.95, "doing-nothing_instant_EM": 0.65625, "doing-nothing_accmulative_EM": 0.688125}]}