{"model_update_steps": 2595, "method_class": "index_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='exp_results/data_streams/init_memory.pkl', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/index_based/ckpt_dir/0929_MixedAllErrors_T=100_index_M=U+I_rs=32_rq=3_seed=456_rank=most_similar_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/index_based/ckpt_dir/0929_MixedAllErrors_T=100_index_M=U+I_rs=32_rq=3_seed=456_rank=most_similar_ckpts/', replay_candidate_size=8, replay_frequency=3, replay_size=32, save_all_ckpts=0, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=100, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='exp_results/data_streams/mrqa.nq_train.memory.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "French 18th-century art and furnishings", "impulse turbine", "adaptive", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "50 fund", "ned sherrin", "the Mandate of Heaven", "Uncle Remus", "buddha", "Poseidon", "Oregon", "2009", "the direction from which the wind is blowing", "john Mortimer", "oxygen", "gees seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "john Stratford", "Julie Andrews", "omen of good or bad luck", "power blackouts"], "metric_results": {"EM": 0.875, "QA-F1": 0.9226190476190477}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-5937", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-7369"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "The Iroquois", "philanthropy", "john Leslie", "Virginia Wade", "Gary Morris", "to the anterolateral corner of the spinal cord", "1966", "for scientific observation", "product or policy that is open and honest", "Stock Market crash in New York", "Rotherham, South Yorkshire, England", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "koran,kuran reader", "Vigor", "mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "Charlie", "acmthompson", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "DC Comics", "May and June 2010"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24436141880994822}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.23529411764705885, 0.0, 0.14285714285714288, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.5, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["the Italian pignatta", "originally designated HU - 1", "philanthropy", "mariette", "Virginia Wade", "Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York", "Rotherham United", "norman Tebbit", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years before", "is the religious text of Islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "Charlie", "gallantry", "Danny DeVito", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "Superman", "2010"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8460648148148149}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.07407407407407407, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10410", "before_prediction": "Galileo", "after_prediction": "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object"}], "retained_ids": ["mrqa_squad-validation-10015", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-4684", "mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-2210", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 2, "before_eval": {"predictions": ["Kronprins Harald", "sports, among them cricket, rallying, football, rugby union and boxing", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "rumbley and District Choral Society", "acetate", "John II Casimir Vasa", "rizzio Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "technological advances", "an undergraduate who is not yet a senior", "Bothtec", "Terry Reid", "non- peer- reviewed sources", "Elgar", "North America", "Andr\u00e9 3000", "Lovell, Jack Swigert, and Fred Haise", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "Georges Bizet", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.0625, "QA-F1": 0.25250817401552694}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.8235294117647058, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.4444444444444445, 0.4, 0.9090909090909091, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.0, 0.6666666666666666, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "never", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "catherine de\u2019 Medici", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "bakusou Buggy Ippatsu Yarou", "Spencer Davis Group", "non-peer-reviewed sources", "Enigma\u2019 Variations", "physiographically a part of the continent of North America", "is a song written and produced by Andr\u00e9 3000", "two rookies", "the Aten, a representation of the Egyptian god, Ra", "Roosevelt Corollary", "2010 to 2012", "four", "the United States, its NATO allies and others", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "Pacific"], "metric_results": {"EM": 0.90625, "QA-F1": 0.8888888888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "bakusou Buggy Ippatsu Yarou"}], "retained_ids": ["mrqa_squad-validation-194"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "unfixed_ids": ["mrqa_triviaqa-validation-1935", "mrqa_naturalquestions-validation-5180"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.4999999975}, {"timecode": 3, "before_eval": {"predictions": ["why do Americans call it period and the British a full stop", "four-year-plan", "c + angle d = 180 degrees", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006 British Academy Television Award for Best Drama Series", "is the leading nation of the Uniting for Consensus", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "crescent Mints", "baze", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "It has trouble distinguishing between carbon dioxide and oxygen", "bambi", "cement City, Texas", "The Renewable Heat Incentive scandal", "23 July 1989", "many educational institutions especially within the US", "often exercising a great deal of control over the lives of their disciples", "for control purposes", "bamboula", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor with 2 GB of RAM, either 16 or 32 GB of internal storage, and a 2300 mAh battery", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins", "laparoscopic cholecystectomy", "berenice Abbott"], "metric_results": {"EM": 0.0625, "QA-F1": 0.13281555474095796}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.09523809523809525, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.45161290322580644, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-6341", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "Staten Island", "splash", "2005\u20132010", "G20", "efferent nerves", "max bygraves", "polar bear", "lester piggott", "don't disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1929", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo", "Callability", "a 2.26 GHz quad - core Snapdragon 800 processor", "over 10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museum"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9241071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2385", "before_prediction": "callable bonds", "after_prediction": "Callability"}], "retained_ids": ["mrqa_hotpotqa-validation-5662"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-6341", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "unfixed_ids": ["mrqa_squad-validation-1539", "mrqa_triviaqa-validation-6683"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.4999999975}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Nijmegen, over the Waal distributary of the Rhine", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "month of Juno, the king of gods", "a shepherd", "museum", "is a rare but often fatal disease that affects the central nervous system by causing painful muscular contractions", "bounding the time or space used by the algorithm", "museum", "Australian actor", "Eddie Leonski", "Jack", "a mixture of phencyclidine and cocaine", "a chain or screw stoking mechanism and its drive engine or motor", "a bygone age when men's home grooming was little more than primitive", "Reverse - Flash", "All Souls'Day", "museum", "Azerbaijan", "Catholics", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "8 April 1912", "the English colonies of North America, and Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "A steam turbine", "Splodgenessabounds"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2891369047619048}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_squad-validation-3126", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_squad-validation-3021", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "unmanned Saturn V flights", "Gryphon", "16 April 1898", "june", "a son of Amram and Jochebed, of the tribe of Levi", "New York", "tetanus", "bounding", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine", "bunker", "Fleet Street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "Azerbaijan", "new converts", "CeCe Drake", "cricket", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Malcolm K. Hughes", "rotating discs", "Jonathon Dutton"], "metric_results": {"EM": 0.84375, "QA-F1": 0.898798076923077}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1277", "before_prediction": "1898", "after_prediction": "16 April 1898"}, {"id": "mrqa_squad-validation-8700", "before_prediction": "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "after_prediction": "Malcolm K. Hughes"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Jonathon Dutton"}], "retained_ids": ["mrqa_triviaqa-validation-5654", "mrqa_triviaqa-validation-5168", "mrqa_hotpotqa-validation-3978", "mrqa_naturalquestions-validation-3840"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_squad-validation-3126", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_squad-validation-3021", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.571428570612245}, {"timecode": 5, "before_eval": {"predictions": ["museum", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "Renfrew", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "2 : 44 p.m. EDT", "swanee or swannee whistle", "rapeseed plant", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "India", "parietal cells", "placental", "September 13, 1994", "g. j. Guiteau", "imperial rule", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "kinks", "A study by the World Institute for Development Economics Research at United Nations University", "entropy", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "People's Republic of China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 19408 December 1980", "Selden", "structural collapses", "nymph, Pareia"], "metric_results": {"EM": 0.0625, "QA-F1": 0.16922299621603026}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 0.4, 0.3333333333333333, 0.0, 0.3333333333333333, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace Walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "cardiac", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "bury their dead", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotreme", "Ready to Die", "President Garfield", "imperial rule", "1787", "defiant speech", "Mark Twain", "sunny afternoon", "on the basis of the methodology used", "nonconservative forces", "death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9548611111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-484", "before_prediction": "September 13, 1994", "after_prediction": "Ready to Die"}], "retained_ids": ["mrqa_naturalquestions-validation-816"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020", "mrqa_squad-validation-7554"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.4999999975}, {"timecode": 6, "before_eval": {"predictions": ["Zinnemann", "to prevent the flame from being blown out", "Barack Hussein Obama II", "2010", "n Carolina", "island of Menorca", "90-60's", "unaided school", "dolph Camilli", "the times sign or the dimension sign", "Best Supporting Actress", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "Wichita", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "dads", "moths", "blood", "widow - maker infarction", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "near Grande Comore, Comoros Islands", "rupees", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17898065476190475}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.28571428571428575, 1.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film directors", "capillary action", "2008", "1996", "north carolina", "menorca", "70", "independent schools", "boston braves", "the symbol \u00d7", "Best Supporting Actress nomination for her work as Missy", "Juice Newton", "Super Bowl LII,", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "chisholm trail", "simplest", "beaches", "japan", "true", "red admiral", "o", "the left coronary artery", "10 % of the carbon stores in ecosystems", "boston", "concentrated in the leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide"], "metric_results": {"EM": 0.84375, "QA-F1": 0.884375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1679", "before_prediction": "2010", "after_prediction": "1996"}, {"id": "mrqa_squad-validation-7819", "before_prediction": "Best Supporting Actress", "after_prediction": "Best Supporting Actress nomination for her work as Missy"}, {"id": "mrqa_triviaqa-validation-5795", "before_prediction": "Wichita", "after_prediction": "chisholm trail"}], "retained_ids": [], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "unfixed_ids": ["mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.0}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules, such as squalene and the carotenes", "The U.S. Army Chaplain insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who want more services and more control over the central city", "film", "near the Black Sea", "the last book accepted into the Christian biblical canon", "Bruno Mars", "% IACS conductivity values", "for \u201cacts of the greatest heroism or of the most conspicuous courage in circumstances of extreme danger.\u201d", "16 million", "1950s", "cattle are slaughtered for meat before the age of three years, except where they are needed ( castrated ) as work oxen for haulage", "1998", "a priest", "third most abundant chemical element in the universe", "18 - season career", "family member", "long-term environmental changes", "Learjet", "the unbalanced centripetal force felt by any object", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "marlborough", "present-day Charleston, South Carolina", "a \"quiescent\" stance towards Israel, focusing on preaching, education and social services, and benefiting from Israel's \"indulgence\" to build up a network of mosques and charitable organizations", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Heinz Guderian"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2679909143144437}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.19999999999999998, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.25, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.07692307692307693, 0.23529411764705882, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "a few", "the right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "lost weekend", "near the Black Sea", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george", "the most popular show at the time", "post\u2013World War II", "as work oxen for haulage", "2011", "a priest", "most", "2001", "a family member, or by anyone with knowledge or skills in the wider community setting", "over-fishing and long-term environmental changes", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george I, great-grandson of James I", "the Charleston Orange district", "quiescent", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.875, "QA-F1": 0.9432291666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1863", "before_prediction": "family member", "after_prediction": "a family member, or by anyone with knowledge or skills in the wider community setting"}], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_squad-validation-6297", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-4318"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "unfixed_ids": ["mrqa_triviaqa-validation-1293", "mrqa_naturalquestions-validation-98", "mrqa_triviaqa-validation-781"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.7999999984}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "nino' Farina (59 ) Italian racing driver died", "37.7", "6.4 nanometers apart", "the eighth and eleventh episodes of the season", "Carl Edwards", "over 400 games", "adrenal glands", "artes liberales", "the Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "Eureka", "1918", "three times, losing in their first two appearances but winning the third, in 2018", "boston braves", "law firm", "Pottawatomie County", "The tuatara, a lizard - like reptile native to New Zealand, can live well above 100 years", "theory of general relativity", "The church tower", "but only today will Tube users be told that \u201c there is a good service running on all London Underground Lines\u2026Bang On\u2026Proper\u2026\u201d", "Toronto, Ontario, Canada", "but the further into Wales you go - ie further into the strongholds of the still surviving (and flourishing) Welsh language the Welsh word takes precedence", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "one of the largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychotherapeutic theories and associated techniques", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York", "acidic bogs"], "metric_results": {"EM": 0.125, "QA-F1": 0.2767282196969697}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.375, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.3636363636363636, 0.4, 0.0, 0.0, 0.25, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_naturalquestions-validation-6991", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "after_eval": {"predictions": ["computability theory", "formula One World Championship", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidneys", "liberal pursuits", "Swiss of England", "Edward IV of England", "St. Louis County, Missouri, United States", "1828", "2018", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "theory of general relativity", "The church tower", "walford East Station", "Montreal", "slow", "110 miles", "Kona coast", "liberal conservative", "gold rushes", "six", "no contest", "freudian psychoanalysis", "New York", "acidic"], "metric_results": {"EM": 0.8125, "QA-F1": 0.9063405797101449}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1360", "before_prediction": "artes liberales", "after_prediction": "liberal pursuits"}, {"id": "mrqa_hotpotqa-validation-4212", "before_prediction": "Eureka", "after_prediction": "St. Louis County, Missouri, United States"}], "retained_ids": ["mrqa_squad-validation-10369", "mrqa_squad-validation-5313"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_naturalquestions-validation-6991", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "unfixed_ids": ["mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-3161", "mrqa_triviaqa-validation-316", "mrqa_triviaqa-validation-7767"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.49999999875}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian professional tennis player", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "sweetened sheeps\u2019 milk ricotta cream", "photosynthesis", "images of different animals and humans perform various actions", "lost liberal agenda and the lapdogs in the media", "The Daily Stormer", "triplet", "water", "The president", "the citizens", "George, Margrave of Brandenburg-Ansbach", "Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co. fire", "acting career", "C. W. Grafton", "LED illuminated display", "Americans acting under orders", "iPod Classic", "My Sassy Girl", "prevent damage to the body", "The Edge of Night", "non-combustible substances that corrode, such as iron", "pedagogy", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "the root respiration", "soils", "Dennis Allen", "medium and heavy- Duty diesel trucks", "penis"], "metric_results": {"EM": 0.28125, "QA-F1": 0.41498536186036183}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.4, 0.1, 0.0, 0.0, 0.8888888888888888, 0.0, 1.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.3333333333333333, 0.15384615384615383, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_hotpotqa-validation-832", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentinian", "a report", "cake", "consumes ATP and oxygen, releases CO2, and produces no sugar", "images of different animals and humans performimg various actions", "White House", "\" Total Fascism\"", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "citizens", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "a meat cold storage facility", "acting career", "C. W. Grafton", "a liquid crystal on silicon ( LCoS ) ( based on an L CoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "ATP", "plants", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.875, "QA-F1": 0.9150798525798526}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3428", "before_prediction": "The Daily Stormer", "after_prediction": "\" Total Fascism\""}, {"id": "mrqa_hotpotqa-validation-4834", "before_prediction": "Worcester Cold Storage and Warehouse Co. fire", "after_prediction": "a meat cold storage facility"}, {"id": "mrqa_naturalquestions-validation-5579", "before_prediction": "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "after_prediction": "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd"}], "retained_ids": ["mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-133", "mrqa_naturalquestions-validation-1327", "mrqa_squad-validation-5940"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_hotpotqa-validation-832", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_naturalquestions-validation-754"], "instant_fixing_rate": 0.9565217391304348, "instant_retention_rate": 0.6666666659259258}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander Pope", "yellow fever", "three legal systems", "Las Vegas, Nevada", "status code and reason message", "globetrotters", "cruiserweight title", "a bridge over the Merderet in the fictional town of Ramelle", "assassination attempt", "to be brother and sister", "menhirs", "Queen Victoria", "base 10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "1947 Kon-Tiki expedition", "a special Las Vegas concert", "digital fashion gallery", "Ronnie Hillman", "formulation of a single all-encompassing definition of the term is extremely difficult, if not impossible", "\" When Body Snatchers Targeted Mormons and the Miraculous\"", "more than 60 percent of the state's total land surface", "Eagle Ridge Mall", "Pel\u00e9", "reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "a portion of air is consumed during combustion and respiration", "James Thurston Nabors", "must be at least 18 or 21 years old ( or have a legal guardian present ), and must sign a waiver prior to shooting", "Ward", "novelist and poet", "Jamestown", "Rouen Cathedral", "biomass and subsequent carbon related emissions"], "metric_results": {"EM": 0.0625, "QA-F1": 0.24221230158730156}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 0.8, 0.28571428571428575, 0.5, 0.6666666666666666, 0.9333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.14285714285714288, 0.0, 0.19999999999999998, 0.3333333333333333, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_squad-validation-3525", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["Alexander Pope", "Hampton's hump and Hampton's line", "Northern Ireland law", "Las Vegas", "A status line", "a striker", "cruiserweight", "over the Merderet in the fictional town of Ramelle", "Benito Mussolini", "victor Hugo quotes", "menhirs", "British Royal Family", "7", "Thor Heyerdahl", "the MGM Grand Garden Special Events Center", "Valentino", "C. J. Anderson", "a maze of semantical problems and grammatical niceties", "joseph Smith", "60", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "Monastir / Tunisia / Africa", "the classical element fire", "Barney Fife", "at least 18 or 21 years old ( or have a legal guardian present )", "Ann", "writer", "Virginia", "Claude Monet", "carbon related emissions"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8711174242424242}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-1553"], "fixed_ids": ["mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_hotpotqa-validation-3419", "mrqa_triviaqa-validation-3515", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_squad-validation-3525", "mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "unfixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-4162", "mrqa_triviaqa-validation-6389", "mrqa_naturalquestions-validation-10205", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-1451", "mrqa_naturalquestions-validation-8617"], "instant_fixing_rate": 0.7666666666666667, "instant_retention_rate": 0.999999995}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "Arthur Schnitzler's 1926 novella \" Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "The TEU", "thermodynamic temperature", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "Dan Dares", "a longer span than another", "Luas", "cricket bat", "King Crimson", "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "died in battle", "Volkswagen Beetle", "joseph Cash", "North American Technate", "Queen Elizabeth I", "infection, irritation, or allergies", "ascend the tower every day", "the world's only certified 7 star hotel Town House Galleria", "catfish aquaculture", "atomic number 53", "James and D.J. Looney as Young Sparrow and DJ Dragon Nutz", "Iraq", "a co-op of grape growers", "victor willsmeron", "Verdi", "1952", "Los Angeles Lakers", "a yellow background instead of a white one, the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "the back of the head"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23584358367573377}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true], "QA-F1": [0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.15384615384615383, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.06896551724137931, 0.22222222222222224, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_hotpotqa-validation-2852", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "Dan Dares", "span", "Dublin", "duke of Edinburgh", "poseidon", "the Byzantines", "alamo", "Adolf Hitler", "arkansas", "Canada", "britten", "allergies", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "heaviest of the stable halogens", "Evermoist", "alastair Finlan", "An agricultural cooperative", "norway", "verdi", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean F kernel", "the chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8015625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.25]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5248", "before_prediction": "King Crimson", "after_prediction": "poseidon"}, {"id": "mrqa_squad-validation-1003", "before_prediction": "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "after_prediction": "the Byzantines"}, {"id": "mrqa_naturalquestions-validation-6442", "before_prediction": "the back of the head", "after_prediction": "the chest, back, shoulders, torso and / or legs"}], "retained_ids": ["mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_hotpotqa-validation-2852", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271"], "unfixed_ids": ["mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7703", "mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.3999999992}, {"timecode": 12, "before_eval": {"predictions": ["Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade", "Minos and Kokalos", "1860", "cienfuegos in the Las Villas province of Cuba", "Byker", "New South Wales", "the French", "Dandy", "caccavella", "Orwell", "Czech Kingdom", "Gregg Popovich", "that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "immunological memory", "uncle", "a musician", "tunis", "December 1, 1969", "american", "jK Rowling", "California State Automobile Association", "\"alone\"", "Cinderella", "The astronauts were asphyxiated before the hatch could be opened", "due to a fear of seeming rude"], "metric_results": {"EM": 0.1875, "QA-F1": 0.31450797008451137}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4615384615384615, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.23529411764705882, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, 0.631578947368421]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "sport fencing", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cigars", "maryland", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \"regnum Bohemiae\", sometimes Latin", "Bob Hill", "secularism and secular nationalism", "creative reasons", "immunological memory", "under the tutelage of his uncle", "Originally a musician", "thumbelina", "1973", "maryland", "john buchan", "regional tourism groups", "\"alone\"", "Cinderella", "communications problems", "lack of understanding of the legal ramifications, or due to a fear of seeming rude."], "metric_results": {"EM": 0.90625, "QA-F1": 0.925}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4904", "before_prediction": "Czech Kingdom", "after_prediction": "Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \"regnum Bohemiae\", sometimes Latin"}, {"id": "mrqa_hotpotqa-validation-4241", "before_prediction": "uncle", "after_prediction": "under the tutelage of his uncle"}], "retained_ids": ["mrqa_hotpotqa-validation-4826", "mrqa_squad-validation-6678", "mrqa_squad-validation-2372", "mrqa_hotpotqa-validation-4165"], "fixed_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "unfixed_ids": ["mrqa_triviaqa-validation-6902"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.6666666655555555}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Jason Lee as Buddy Pine / Incredi - Boy / Syndrome", "Napoleon's army", "maryland", "3.7% of the entire student population", "a negative effect on subsequent long-run economic growth", "matt Willis and Charlie Quirke", "Little Golden Lion award and the Ecumenical Award", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "9", "paddington", "amyotrophic lateral sclerosis", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "mid 1970s", "Torah or Bible", "the western coast of Italy", "first and only U.S. born world grand prix champion", "brass band parades", "mid November", "Facebook", "mohnbeugel", "Rock Star", "Seattle", "King George's War", "cheated on Miley", "Punk", "Fort Snelling, Minnesota", "daguerreotypes", "infrequent rain and many sunny days"], "metric_results": {"EM": 0.0625, "QA-F1": 0.20731083152958155}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.4444444444444445, 0.0, 0.4444444444444445, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.3333333333333333, 0.0, 0.5]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "bread went stale", "3.7", "negative", "Garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "9", "Michael Hordern", "Lou Gehrig's Disease", "\"Odorama\"", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "quintessential New Orleans art form -- a jazz funeral without a body", "late November or early December", "Facebook", "bread product", "Tim \"Ripper\" Owens", "Issaquah", "primarily focused on resolving issues in Europe", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "pinhole camera", "infrequent rain"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8386217948717949}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10168", "before_prediction": "King George's War", "after_prediction": "primarily focused on resolving issues in Europe"}], "retained_ids": ["mrqa_triviaqa-validation-2779"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_squad-validation-2656"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4301", "mrqa_naturalquestions-validation-9897", "mrqa_triviaqa-validation-2896", "mrqa_triviaqa-validation-6913"], "instant_fixing_rate": 0.8, "instant_retention_rate": 0.4999999975}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "geoff keegan", "geoff keegan", "FX option or currency option", "electromagnetic waves", "Wahhabi/ Salafi", "good luck, protection and auspiciousness for over", "Dimensions in Time", "Surveyor 3 unmanned lunar probe", "January 1981", "gonadotropin - releasing hormone ( GnRH )", "the structure and substance of his questions and answers concerning baptism in the Small Catechism", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "\u00a31,150,000", "slowing the vehicle", "Cheyenne rivers", "appearance of fossils in sedimentary rocks", "Hanna- Barbera, The Jetsons", "Cortina d'Ampezzo", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "geoff keegan", "maryland", "Timo Hildebrand", "The public sector ( also called the state sector )", "October 1999", "weak government institutions", "a god of the Ammonites", "cornea", "Uncle Fester", "Charles Whitman"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20195888670153375}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.5882352941176471, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/ Salafi extremist militant group", "to be good", "Children in Need", "Apollo 12", "1981", "estrogen", "baptism", "that priest whose name was Martin Luther", "brian clough", "slowing the vehicle", "Belle Fourche and Cheyenne", "organisms", "Hanna- Barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome, in the Alban Hills", "binky", "1788", "Kur\u00e1nyi", "the economy", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8552884615384615}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7692307692307693, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6019", "before_prediction": "The public sector ( also called the state sector )", "after_prediction": "the economy"}], "retained_ids": ["mrqa_hotpotqa-validation-970", "mrqa_naturalquestions-validation-727"], "fixed_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_triviaqa-validation-6385", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": ["mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-3945"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.6666666644444444}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "San Antonio", "Royce da 5'9\" ( Bad) and Eminem ( Evil)", "jupiter (now known as the Galilean moons)", "a friend and publicist", "l\u00e1szl\u00f3 de Alm\u00e1sy", "masons'marks", "Theodore Haynes (1988) and Julia Rose (1989)", "the Old Town Hall, Gateshead", "Motown, Philly soul, and Earth, Wind & Fire ( particularly `` That's the Way of the World '' )", "uterus", "1898", "Heavyweight", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "The Bells of St. Mary's", "a Curtiss JN-4 airplane", "brian keener eyes and more subtle feeling and with a hand more cunning  than the majority of their \"fellow countrymen", "chimpanzees", "March 15, 1945", "absolute temperature", "The organization has a user base of over 1,800,000", "Julius Robert Oppenheimer", "bicuspid", "his brother, Menelaus", "25 November 2015", "tallahassee", "prefabricated housing projects", "London", "WOTV"], "metric_results": {"EM": 0.125, "QA-F1": 0.14285714285714285}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "galileo", "the editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "roof", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "after the Spanish -- American War in the 1898 Treaty of Paris", "martial artist", "Spanish", "stunt performances", "fred astaire", "postage stamp", "belgium", "chimpanzee", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolars", "Aegisthus", "3 December", "florida", "an Eastern Bloc city", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9272058823529412}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-335", "before_prediction": "Royce da 5'9\" ( Bad) and Eminem ( Evil)", "after_prediction": "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz"}, {"id": "mrqa_naturalquestions-validation-3808", "before_prediction": "1898", "after_prediction": "after the Spanish -- American War in the 1898 Treaty of Paris"}, {"id": "mrqa_hotpotqa-validation-5188", "before_prediction": "chimpanzees", "after_prediction": "chimpanzee"}], "retained_ids": ["mrqa_hotpotqa-validation-3456"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.249999999375}, {"timecode": 16, "before_eval": {"predictions": ["galileo", "galileo", "benedict", "the lateral side of the tibia", "ferguside royal clan", "the North Sea", "the Kalahari Desert", "Colin Montgomerie", "October 29", "Amway", "secondary school", "Thomas Sowell", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in the absence, the Deputy - Chairman of the Rajya Sabha", "the Royal Albert Hall", "Tanzania", "Chad", "galileo", "an open work crown", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a vampire", "London", "French", "galileo", "The Fugitive", "What's Up (TV series)", "supply chain", "galileo", "galileo", "polynomial algebra", "florida", "The three wise monkeys", "sheepskin and Merino Wool", "Honolulu"], "metric_results": {"EM": 0.09375, "QA-F1": 0.15044642857142856}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "after_eval": {"predictions": ["florida", "belgian", "benedict", "leg", "d\u00f9n Chailleann", "the North Sea", "Botswana", "Colin Montgomerie", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "the President", "BBC Radio's \"The Show Band Show\"", "Tanzania", "niger", "60-mile-wide river", "top row", "Sam's soul is not with him", "London", "French, English and Spanish", "dave Lamb", "Beyond the Clouds", "\"The Heirs\"", "blood, platelets, and plasma", "Mars rover", "poland", "matrices", "Michael J. Fox", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru", "sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7472527472527472}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8095238095238095, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-9319", "mrqa_triviaqa-validation-3238", "mrqa_hotpotqa-validation-4164"], "fixed_ids": ["mrqa_triviaqa-validation-2551", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-5997", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-6125", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "unfixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2324", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-4681", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-2382", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.6206896551724138, "instant_retention_rate": 0.9999999966666667}, {"timecode": 17, "before_eval": {"predictions": ["dymock", "X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "stable, non-radioactive rubidium - 85", "James Zeebo", "sovereign states", "president of the United States", "the Discovery Institute's \"Teach the Controversy\" campaign", "Bumblebee", "Australian", "30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "opportunities will vary by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Frank Wentz", "\"antiforms\"", "June 9, 2015", "Veyyil", "Grace Nail Johnson", "Keith Richards", "at least one prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "knowledgeable in that one area", "180th meridian in a 360 \u00b0 - system", "Cartoon Network", "the Presiding Officer", "Miami Heat", "33", "vitifolia", "Annual Conference Cabinet", "Olympic bronze medal", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3635366532976827}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.5454545454545454, 1.0, 0.6666666666666666, 1.0, 0.08333333333333334, 0.0, 0.7499999999999999, 0.0, 0.0, 0.40909090909090906, 0.19999999999999998, 0.16, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.23529411764705882, 0.25, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845", "rubidium - 85", "James Zeebo", "an emerging norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "Dick Cheney", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Colgate University", "Roy Spencer", "\"antiforms\"", "the second half of the third season", "\"Veyyil\" (2006)", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "prime number p with n < p < 2n \u2212 2", "Bangor Air National Guard Base", "knowledgeable", "antimeridian ( the 180th meridian in a 360 \u00b0 - system )", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "the Phoenix Suns", "33-member", "vitis", "Annual Conference Cabinet", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.75, "QA-F1": 0.8452890512265512}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.16, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.25, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3637", "before_prediction": "Veyyil", "after_prediction": "\"Veyyil\" (2006)"}, {"id": "mrqa_squad-validation-9405", "before_prediction": "the Presiding Officer", "after_prediction": "the Presiding Officer on the advice of the parliamentary bureau"}], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_naturalquestions-validation-430", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-3573", "mrqa_squad-validation-10074"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_hotpotqa-validation-3440", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_squad-validation-8966", "mrqa_naturalquestions-validation-10347"], "instant_fixing_rate": 0.76, "instant_retention_rate": 0.7142857132653061}, {"timecode": 18, "before_eval": {"predictions": ["The Rwanda genocide, also known as the genocide against the Tutsi", "social networking support", "400 metres", "Vili Fualaau and Mary Kay Letourneau, a student and teacher who made news for their sexual relationship", "ABC News", "straight - line distance from A to B", "12", "the Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "dave Garcia", "dundee", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "1587", "\"Grindhouse\" fake trailer", "davenport", "digital transmission", "Swiss- Austrian border", "lithium-ion battery", "821", "Video On Demand content", "gas", "Kim Hyun-ah", "the races of highest'social efficiency'", "transposition", "the \" King of Cool\"", "President Woodrow Wilson", "davis", "the fifth season", "dave dors", "Hockey Club Davos", "Michael Crawford", "Aibak's successor and son - in - law Iltutmish"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31302083333333336}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.2, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666665, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.25]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_triviaqa-validation-5996", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "in sync", "500 metres", "Piper", "the entertainment division", "displacement", "five", "the Museum of Manufactures", "Edward Longshanks", "Diego Garc\u00eda", "dundee", "the person compelled to pay for reformist programs", "fotheringhay", "Spy Kids", "venus Williams", "Olivia", "Baden-W\u00fcrttemberg", "Gigafactory 1", "821", "the basic channels", "pressure", "Hyuna", "races of highest'social efficiency", "transposed", "the \" King of Cool\"", "the American delegation from the Paris Peace Conference", "Socrates", "thirteenth", "violet", "HC Davos", "Michael Patrick Smith", "Firoz Shah Tughlaq"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8958333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6029", "before_prediction": "ABC News", "after_prediction": "the entertainment division"}, {"id": "mrqa_hotpotqa-validation-2993", "before_prediction": "Edward Longshanks and the Hammer of the Scots", "after_prediction": "Edward Longshanks"}, {"id": "mrqa_hotpotqa-validation-4415", "before_prediction": "lithium-ion battery", "after_prediction": "Gigafactory 1"}], "retained_ids": ["mrqa_squad-validation-5257", "mrqa_triviaqa-validation-5036", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-4068"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "unfixed_ids": ["mrqa_triviaqa-validation-5996", "mrqa_squad-validation-9841"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.571428570612245}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "Norman Macdonnell", "aragon", "percent of pupils", "trans-Pacific", "Sharman Joshi", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "a divisor of p \u2212 1", "Ana", "White Castle in New Brunswick", "the end of `` Goodbye Toby ''", "f. O. Matthiessen", "fredge madeleine Sopie Blanchard", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "blackstar", "India", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1889", "Nicki Minaj", "violet", "Huguenot", "belle Epoque", "friedrich Engels", "Tara Lyn Charendoff", "William the Conqueror", "Tel Aviv", "two degrees of freedom", "Mainland Greece", "phlebotomists Duties", "Guinness World Records", "the Sunset Publishing Corporation"], "metric_results": {"EM": 0.125, "QA-F1": 0.21938795853269538}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.10526315789473684, 1.0, 0.3333333333333333, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 0.08333333333333334, 0.0, 0.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-3049", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-2627"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q", "Ana", "Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia Earhart", "Six Degrees of Separation", "david bowie", "Indian", "fortitude", "1889", "Sir Mix - a-Lot", "slave of duty", "surnames", "portier", "friedrich", "Teen Titans Go!", "Norman invaders", "Ben Gurion International Airport", "two", "peninsula", "taking blood", "youngest TV director ever", "Southern Progress Corporation"], "metric_results": {"EM": 0.90625, "QA-F1": 0.93125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5061", "before_prediction": "Tel Aviv", "after_prediction": "Ben Gurion International Airport"}], "retained_ids": ["mrqa_squad-validation-5538", "mrqa_hotpotqa-validation-5710", "mrqa_naturalquestions-validation-4951"], "fixed_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-3049", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-2627"], "unfixed_ids": ["mrqa_naturalquestions-validation-3951", "mrqa_triviaqa-validation-4068"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 20, "before_eval": {"predictions": ["reciprocating", "Robert Smigel", "the Sackler Centre for arts education", "dante Terrell Smith", "David Brewster", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "Apollo", "ribosomes", "kookaburra", "six", "CCH Pounder as Loretta Wade, medical examiner", "I Swear", "Kozunak ( Bulgarian : \u043a\u043e\u0437\u0443\u043d\u0430\u043a, Bulgarian pronunciation : ( kozu\u02c8nak ) )", "Belfast West", "a lunar radiation environment experiment", "Lucius Cornelius Sulla Felix", "Super Bowl LII, following the 2017 season", "Golden Globe", "Kenyan English", "the primacy of core Christian values such as love, patience, charity, and freedom", "faulkner", "Pantone Matching System", "Firoz Shah Tughlaq", "\" My Love from the Star\"", "San Jose", "sea wasp", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "giving Super Bowl ever", "29.7 percent", "b.J. Hunnicutt"], "metric_results": {"EM": 0.125, "QA-F1": 0.2818240174857822}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.48484848484848486, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.3333333333333333, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.888888888888889, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "prints and architectural drawings", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Mercury astronaut", "ribosomal RNA (rRNA) molecules", "Laughing Kookaburra / Jackass / Kingfisher 1080p (NA)", "six-time", "Vanessa Ferlito", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "Gains Dunmurry ward and part of Derriaghy ward", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "mother tongues within their own communities", "personal presence and living word", "Turkey", "CMYKOG process", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "lower chamber", "a \"teleforce\" weapon", "Native American", "giving Super Bowl", "29.7%", "4077th MASH"], "metric_results": {"EM": 0.875, "QA-F1": 0.9036654135338346}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.631578947368421, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2434", "before_prediction": "ribosomes", "after_prediction": "ribosomal RNA (rRNA) molecules"}, {"id": "mrqa_triviaqa-validation-3486", "before_prediction": "kookaburra", "after_prediction": "Laughing Kookaburra / Jackass / Kingfisher 1080p (NA)"}], "retained_ids": ["mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-1521"], "fixed_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "unfixed_ids": ["mrqa_triviaqa-validation-4852", "mrqa_squad-validation-8464"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.49999999875}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "dust jacket", "standardized breeds", "blood", "Yazoo", "1894", "black hole", "dreams", "cede the former, but was able to negotiate the retention of Saint Pierre and Miquelon, two small islands in the Gulf of St. Lawrence, along with fishing rights in the area", "Willie Nelson and Kris Kristofferson", "ill. (some col.)", "private", "a French pirate", "Smith Jerrod", "Charles Dickens and Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "fats, fatty acids, amino acids, and proteins", "2001", "is closely related to prime numbers", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "Tallemaja \"pine tree Mary\"", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "James Bond", "4 in ( 10 cm )", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "backup", "Larry Gatlin & the Gatlin Brothers Band"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3241117055298073}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.1818181818181818, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 0.4210526315789474, 0.25, 1.0, 0.0, 0.0, 0.23529411764705882, 1.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.19999999999999998, 0.15384615384615385]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-3627", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "transfused", "alison moyet", "1926", "stars exceeding about eight times the mass of the sun", "dreams", "value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auction", "private institutions such as the California Institute of Technology, Chapman University, the Claremont Colleges (Claremont McKenna College, Harvey Mudd College, Pitzer College, Pomona College, and Scripps College) Loma Linda", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "Organizations could come together to address global issues", "proteins", "2001", "exceeds any given number", "alastair burnet", "by padlocking the gates", "1969", "R\u00e5", "Great Lakes", "Protestant", "casino royale", "4 in", "oh so sharp", "the Western Atlantic ctenophore Mnemiopsis leidyi was accidentally introduced", "Menace II Society", "backup to Dan Marino as a member of the Miami Dolphins, and a starting quarterback for the Eagles and Cleveland Browns", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9301167582417582}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6923076923076924, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-192", "before_prediction": "black hole", "after_prediction": "stars exceeding about eight times the mass of the sun"}, {"id": "mrqa_squad-validation-2709", "before_prediction": "private", "after_prediction": "private institutions such as the California Institute of Technology, Chapman University, the Claremont Colleges (Claremont McKenna College, Harvey Mudd College, Pitzer College, Pomona College, and Scripps College) Loma Linda"}], "retained_ids": ["mrqa_squad-validation-2412", "mrqa_naturalquestions-validation-5897", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-3627", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_naturalquestions-validation-2758"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.6666666655555555}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "Crociere S. p.A.", "casino royale", "a European fairy tale in 1697", "Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres", "Parliamentarians \" Roundheads\" and Royalists \"Cavaliers\"", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "are ceremonially placed on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "al\u00e9a seydoux", "20,000 leagues under the sea and Around the world in 80 days", "Augustus Waters", "1619", "Tony Blair", "\u2018expensive damaging\"", "June 11, 1973", "Kenya", "a chronological collection of critical quotations about William Shakespeare and his works", "alred", "an active supporter of the League of Nations", "Cargill", "AMC Entertainment Holdings, Inc.", "\"The Gang\"", "3 October 1990", "March 1, 2018", "The weak force is due to the exchange of the heavy W and Z bosons", "fred royale", "oldest son", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28626916486291487}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.1111111111111111, 0.16, 0.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.5, 0.0, 0.0, 0.625, 0.0, 0.1818181818181818, 0.0, 0.3333333333333333, 0.0, 0.2, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Kitty Softpaws", "Nationals", "Parliamentarians", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "smersh", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1619", "Tony Blair", "often damaging", "July 26, 1959", "national parks", "chronological collection of critical quotations", "edward I", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "p.G. Wodehouse", "Dexter", "Manhattan Project", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.875, "QA-F1": 0.9010416666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2959", "before_prediction": "Parliamentarians \" Roundheads\" and Royalists \"Cavaliers\"", "after_prediction": "Parliamentarians"}, {"id": "mrqa_naturalquestions-validation-1328", "before_prediction": "Development of Substitute Materials", "after_prediction": "Manhattan Project"}], "retained_ids": ["mrqa_hotpotqa-validation-3944", "mrqa_triviaqa-validation-4731", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_hotpotqa-validation-1929"], "unfixed_ids": ["mrqa_triviaqa-validation-6872", "mrqa_triviaqa-validation-2179"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.6666666655555555}, {"timecode": 23, "before_eval": {"predictions": ["an additional $105 billion in growth to the country's economy over five years", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "reigo Luna", "zinc silicate primer and vinyl topcoats", "Luna Park", "Animated Feature", "European Union institutions", "381.6 days", "nine", "NASA's CAL IPSO satellite", "celandine", "Ulbricht", "Ronnie Schell", "artemisinin", "Tata Consultancy Services in Kochi", "east", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "southern part of Nigeria", "Solitaire", "Incudomalleolar joint", "billie Jean Moffitt", "Democritus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth by certain groups", "log-space reductions", "Corey Brown"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3271355380730381}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.3076923076923077, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5, 0.5, 0.25, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.3636363636363636, 1.0, 0.0, 0.2, 0.0, 0.33333333333333337, 0.5, 0.0, 1.0, 0.0, 0.7692307692307693, 0.4, 0.0]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-7481", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "after_eval": {"predictions": ["$105 billion", "kissing disease", "17 nm vs 25 nm", "a 1934 Austin seven box saloon", "Dirty Dancing", "red", "Steeplechase Park", "Academy Award for Best Animated Feature", "European Convention on Human Rights", "flew on one Space Shuttle mission, STS-134 as a Mission Specialist", "nine", "NASA's CAL IPSO satellite", "yellow", "Khrushchev", "Jack Cassidy", "artemisinin-based therapy", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "begins in central Nigerian while the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall which can be daily occurrence lasting till September", "Dr. Kananga", "Incudomalleolar joint", "moffitt", "Leucippus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth", "bound on the complexity of reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.71875, "QA-F1": 0.786527293844367}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2926829268292683, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2741", "before_prediction": "381.6 days", "after_prediction": "flew on one Space Shuttle mission, STS-134 as a Mission Specialist"}], "retained_ids": ["mrqa_squad-validation-542", "mrqa_naturalquestions-validation-4048", "mrqa_squad-validation-2420", "mrqa_squad-validation-327"], "fixed_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-7481", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-3595", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-6781"], "instant_fixing_rate": 0.7037037037037037, "instant_retention_rate": 0.7999999984}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "British failures in North America, combined with other failures in the European theater, led to the fall from power of Newcastle and his principal military advisor, the Duke of Cumberland", "alchemy", "WBO lightweight title", "moluccas", "the first Saturday in May", "Cordelia", "multilateral", "1971", "J.R. R. Tolkien", "Peyton Manning", "Selena Gomez", "joins a polytechnic or other technical college and study for four years", "Bingo", "Eugene", "an unofficial title sometimes given to new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze Rug", "benjamin franklin", "the Muslim", "from Nova Scotia and Newfoundland in the north, to Georgia in the south", "the Friars Minor Conventual (O.F.M. Conv)", "CD Castell\u00f3n", "1789, or 1798", "finished the regular season with a 12\u20134 record", "by having colloblasts", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "the Space Shuttle \"Discovery\" on STS-51-C.", "it will retreat to its den and winter will persist for six more weeks", "edith Cresson"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2929282516504198}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 0.19999999999999998, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.2608695652173913, 0.0, 0.0, 0.41379310344827586, 0.7692307692307693, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.5957446808510638, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-67", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Edgar", "multilateral negotiations", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic", "31", "Eugene", "comparable to the seven Wonders of the World", "2p + 1 with p prime", "coupe", "FaZe Rug", "dante", "Muslim", "along the coast", "order of poor ladies", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "by having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.875, "QA-F1": 0.9239495136011528}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4444", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_squad-validation-6204", "mrqa_squad-validation-4417"], "fixed_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-67", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_squad-validation-8876", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3080", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.9999999980000001}, {"timecode": 25, "before_eval": {"predictions": ["synchronized skating", "france", "over 50 million singles", "states'rights to expand slavery", "between 1923 and 1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "determined to become the finest actor he possibly could", "d'Hondt method", "yellow", "decrease", "france france", "Sylvester McCoy", "August 14, 1848", "lower rates of health and social problems", "young live as cydippid-like plankton until they reach near- Adult size, but then sink to the bottom and rapidly metamorphose into the adult form", "breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "James Kirkwood, Jr.", "2,664", "weak point on the inside of the chassis right beneath the volume buttons", "chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning, support services, property services, catering services, security services and facility management services", "Violin Sonata No. 5 in F major, Opus 24", "dordogne", "1603", "above the two personal physicians of the Emperor", "dance of the sugar Plum Fairy", "Admitted to God, to ourselves, and to another human being the exact nature of our wrongs", "Cubs"], "metric_results": {"EM": 0.09375, "QA-F1": 0.27906328116757684}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.25, 0.1111111111111111, 0.6, 0.923076923076923, 0.0, 1.0, 0.0, 0.2857142857142857, 0.3636363636363636, 0.47058823529411764, 0.16666666666666666, 0.0, 1.0, 0.10526315789473684, 0.7499999999999999, 0.14285714285714288, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastics", "abram", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "crimson Tide", "iteratively", "geese", "effect", "Brisbane", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "lower rates of economic utility in society from resources devoted on high-end consumption", "juveniles are capable of reproduction before reaching the adult size and shape", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "bendgate", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde", "1603", "Ranked positions", "Nutcracker", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "Cubs"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8538873626373626}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.7200000000000001, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-6545"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481"], "unfixed_ids": ["mrqa_hotpotqa-validation-5762", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.7931034482758621, "instant_retention_rate": 0.9999999966666667}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "abridged story", "Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz improvisation", "tennis", "4,000", "Khagan", "Catherine Earnshaw", "canal", "spice products", "The Simpsons Spin-Off Showcase", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "Eldon Square Shopping Centre", "Albany High School for Educating People of Color", "Government House at New Delhi", "Sergeant First Class", "Anakin Skywalker", "A technical defense", "Cee - Lo", "The Church of England was legally established in the colony in 1619, and authorities in England sent in 22 Anglican clergyman by 1624", "mammy two Shoes", "duke of York", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "January 11, 1755 or 1757"], "metric_results": {"EM": 0.25, "QA-F1": 0.40370410839160836}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, true, false], "QA-F1": [0.8, 0.19999999999999998, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8000000000000002]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "Joel Greenblatt", "kelly", "County of Honolulu", "1910\u20131940", "those who refuse vetting", "Catch Me Who Can", "jazz", "Margaret Smith Court", "3,677 seated", "Khagan", "catherine and heathcliff", "abbot of a monastery", "cassia", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "a portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre", "Albany High School", "charbagh", "Sergeant First Class", "Anakin Skywalker", "jury nullification", "Cee - Lo", "The Church of England", "pacific region", "scharnhorst", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.75, "QA-F1": 0.8067708333333333}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-5184", "before_prediction": "Eldon Square Shopping Centre", "after_prediction": "a portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre"}], "retained_ids": ["mrqa_squad-validation-7435", "mrqa_squad-validation-3176", "mrqa_squad-validation-6148", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-7801", "mrqa_squad-validation-7319"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5050", "mrqa_hotpotqa-validation-945"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_hotpotqa-validation-4553", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_naturalquestions-validation-5476", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-3393"], "instant_fixing_rate": 0.7083333333333334, "instant_retention_rate": 0.8749999989062499}, {"timecode": 27, "before_eval": {"predictions": ["l.A. producer Bones Howe", "geldof", "youngberry", "astrolights Nebula", "\" Big Mamie\"", "ocelots", "the \"eternal outsider, the sardonic drifter\" someone who rebels against the social structure", "a light sky-blue color", "the peasants had to work for free on church land", "2009", "2005\u201306 NBA season", "the internal thylakoid system", "charigot", "sports tourism", "BSkyB has no veto", "the third season", "a more fundamental electroweak interaction", "availability of skilled tradespeople", "abrasion", "A simple iron boar crest", "the University of Northumbria at Newcastle", "japan", "James", "25 - yard line", "the Latin centum", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "the righteousness of Christ", "ludwig", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "collective noun"], "metric_results": {"EM": 0.21875, "QA-F1": 0.312503382034632}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.0, 0.375, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "\" Big Mamie\"", "orinoco", "Teamsters leader", "clear substances with a light sky-blue color", "wat tyler", "1963", "Zaza Pachulia", "inner chloroplast membrane", "Renoir", "sports tourism", "no", "third", "electro weak interaction", "Cost of construction", "gypsum", "A simple iron boar crest adorns the top of this helmet", "polytechnics became new universities", "australian", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yards line", "named after the Swedish astronomer Anders Celsius", "7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "lives by faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "rubens", "badgers"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9147435897435897}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7711", "before_prediction": "2009", "after_prediction": "1963"}, {"id": "mrqa_squad-validation-10312", "before_prediction": "a more fundamental electroweak interaction", "after_prediction": "electro weak interaction"}, {"id": "mrqa_hotpotqa-validation-1226", "before_prediction": "A simple iron boar crest", "after_prediction": "A simple iron boar crest adorns the top of this helmet"}, {"id": "mrqa_squad-validation-5125", "before_prediction": "7,000", "after_prediction": "7,000 out of 20,000 inhabitants"}], "retained_ids": ["mrqa_hotpotqa-validation-994", "mrqa_squad-validation-2966", "mrqa_squad-validation-8279"], "fixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.4285714279591837}, {"timecode": 28, "before_eval": {"predictions": ["the Muslim faith as a tool of the devil", "Chris Weidman", "nullification", "Harishchandra", "Arabic grammar", "Professor Eobard Thawne", "slivovitz", "US+10 a week raise over Tesla's US+18 per week salary", "October 25, 1825 - June 3, 1899", "member states", "because of all the instruments", "McKinsey's offices in Silicon Valley and India", "gypsophobia", "2000", "Crohn's disease", "Ondemar Dias", "Raya Yarbrough", "UniversityVA entered as the No. 1 overall seed, placed in the South regional, but suffered a historic upset in the first round to UMBC", "gypset", "Charles L. Hutchinson", "Old Testament", "gypsetzel", "local talent", "the Football League for Doncaster Rovers, Mansfield Town, Preston North End and Stockport County", "tristan Farnon", "Pliocene-to- Holocene", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "John Surratt", "1332", "extinct", "people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "2000s television sitcom On the Buses"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24101807389622515}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.2857142857142857, 0.4444444444444445, 0.0, 0.4444444444444445, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.09523809523809523, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3529411764705882, 0.0, 0.0, 0.1, 0.0, 1.0, 0.0, 0.2040816326530612, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-2953", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "inform the jury and the public of the political circumstances", "Kusha", "poet, and writer", "Professor Eobard Thawne", "plum", "US$10 a week raise", "1825", "contributed by member states on a voluntary basis", "oboe", "McKinsey's offices", "hyprophobia", "lionel b", "ulcerative colitis", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "John D. Rockefeller", "Song of Songs", "ups", "local talent", "the Football League for Doncaster Rovers, Mansfield Town, Preston North End and Stockport County", "peter davison", "pemberton", "contemporary accounts were exaggerations", "Lincoln", "1332", "dodo", "based on the idea that people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "stan butler"], "metric_results": {"EM": 0.8125, "QA-F1": 0.846229883462819}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3529411764705882, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22641509433962262, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8031", "before_prediction": "Charles L. Hutchinson", "after_prediction": "John D. Rockefeller"}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-4309", "mrqa_squad-validation-5086", "mrqa_squad-validation-8190"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-4584", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-2953", "mrqa_triviaqa-validation-4308"], "unfixed_ids": ["mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-6881", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 29, "before_eval": {"predictions": ["poisonous", "1,100 years ago", "to finance his own projects with varying degrees of success", "24 Hours of Le Mans", "Kinect", "Tokyo", "safety Darian Stewart", "parallelogram rule of vector addition", "japan", "364", "startup neutron source", "starry starry night", "the bore, and often the stroke", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "Doctorin' the Tardis", "National Basketball Development League (NBDL)", "gillingham", "St. Mary's County", "Ted Ginn Jr.", "2,615 at the 2010 census", "Pyeongchang", "athlete", "a password recovery tool for Microsoft Windows", "Captain John Guidry", "husband and wife American designers who made significant historical contributions to the development of modern architecture and furniture", "Brazil", "austin Szymkowiak", "the smallest subfield", "gan", "53%", "photosynthesis"], "metric_results": {"EM": 0.1875, "QA-F1": 0.27336601307189545}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 0.38095238095238093, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.058823529411764705, 0.0, 0.3, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "His patents", "Formula One", "Kinect", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "evolution", "blackbirds", "a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors, when they are loaded with fresh nuclear fuel, whose neutron flux from spontaneous fission is insufficient for a reliable startup, or after prolonged shutdown periods", "Van Gogh", "cylinder volume", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "The Justified Ancients of Mu Mu (later known as The KLF)", "National Basketball Development League", "kent", "Washington metropolitan area", "Emmanuel Sanders", "The population was 2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods like as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "south korea", "arthur", "the smallest subfield of a field F containing both 0 and 1", "heartburn", "53% in Botswana to -40% in Bahrain", "chloroplasts are specialized for the light reactions, so they lack rubisco, and have normal grana and thylakoids, which they use to make ATP and NADPH, as well as oxygen"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7940957633053222}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.25, 0.25]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3103", "before_prediction": "364", "after_prediction": "blackbirds"}, {"id": "mrqa_naturalquestions-validation-8653", "before_prediction": "startup neutron source", "after_prediction": "a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors, when they are loaded with fresh nuclear fuel, whose neutron flux from spontaneous fission is insufficient for a reliable startup, or after prolonged shutdown periods"}, {"id": "mrqa_squad-validation-7914", "before_prediction": "Doctorin' the Tardis", "after_prediction": "The Justified Ancients of Mu Mu (later known as The KLF)"}, {"id": "mrqa_squad-validation-9036", "before_prediction": "the smallest subfield", "after_prediction": "the smallest subfield of a field F containing both 0 and 1"}, {"id": "mrqa_squad-validation-7445", "before_prediction": "53%", "after_prediction": "53% in Botswana to -40% in Bahrain"}], "retained_ids": ["mrqa_squad-validation-8075"], "fixed_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-814"], "unfixed_ids": ["mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-4572", "mrqa_squad-validation-8873"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.16666666638888888}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "He has 96 daughters, 1 son named JoJo and a wife named Sally", "abraham lincoln", "Basil Fawlty", "Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "BBC UKTV", "arthur", "demographics and economic ties", "three or more separate periods", "The Kickoff Game", "narcolepsy", "arctic monkeys", "monza", "arthur", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "instructions", "Nationals are strongest in Victoria's North Western and Eastern rural regional areas", "marduk", "arthur", "$474 million, representing Kenya's largest source of foreign direct investment, and... bilateral trade", "nash", "South Pacific off the northeast coast of Australia", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "John-a-kite", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "k. Kamaraj", "National Lottery", "Apollo", "katherine swynford", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.03125, "QA-F1": 0.11407917283739652}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.2105263157894737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.0, 0.4444444444444445, 0.4, 0.12121212121212122, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "jurassic park", "all transmissions", "A computer program", "Greens", "babylon", "surtsey", "Kenya's largest source of foreign direct investment", "national network", "South Pacific", "7", "New Jersey", "John-a-kite", "Shalita Grant", "indira gandhi", "state-franchised", "skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9615384615384616}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2750"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608", "mrqa_hotpotqa-validation-3333"], "instant_fixing_rate": 0.9354838709677419, "instant_retention_rate": 0.9999999900000002}, {"timecode": 31, "before_eval": {"predictions": ["Yolanda Sald\u00edvar", "Peter", "jayne Torvill and Christopher Dean", "sport commentator", "crossroads of the Newell Highway between Melbourne and Brisbane", "androids", "15 hands", "a suburb of the Twin Cities", "Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions", "DreamWorks Animation", "Johann Strauss", "his own men", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "arthur", "the RAF", "reduce growth in relatively poor countries but encourage growth", "Ibrium", "surt Daly", "Polish-Jewish", "General Francisco Franco", "piano-Sheets", "jockeys", "an estimated 390 billion individual trees divided into 16,000 species", "Washington Street", "May 10, 1976", "five", "l Lindsay Lohan", "his frustration with the atmosphere in the group at that time", "surtsey", "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23688973063973062}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.7272727272727273, 0.0, 0.0, 0.0, 0.37037037037037035, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "make a defiant speech, or a speech explaining their actions", "Andrew Adamson", "waltz king", "Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage growth", "Ibrium", "Strictly Come Dancing", "Polish", "the Falange", "1936", "1967", "16,000", "Washington Street", "8 November 1978", "five", "\"Fudge\"", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "1978", "John Smith", "1915", "economic separation"], "metric_results": {"EM": 0.875, "QA-F1": 0.8890625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45000000000000007, 0.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4148", "before_prediction": "his frustration with the atmosphere in the group at that time", "after_prediction": "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter"}, {"id": "mrqa_triviaqa-validation-4524", "before_prediction": "lusitania", "after_prediction": "1915"}], "retained_ids": ["mrqa_hotpotqa-validation-1444", "mrqa_hotpotqa-validation-3233", "mrqa_squad-validation-932"], "fixed_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4500", "mrqa_squad-validation-3106"], "unfixed_ids": ["mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-743"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "Oktoberfest", "gender test", "Matt Jones", "potassium", "In extreme circumstances, a driver may attempt to jackknife the vehicle deliberately in order to halt it following brake failure", "T cell", "relatively low salaries", "non-GMO", "Heading Out to the Highway", "Moonraker", "Wii U", "Michael Oppenheimer", "England national team", "rich and well socially standing Chinese", "No Night Today", "Convention", "5,922", "December 5, 1991", "psychological horror", "Philadelphia 76ers", "the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "Potsdam", "Joe Frazier", "23 March 1991", "Sunday", "Dealey Plaza", "Nairobi", "the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3362265904385469}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.08695652173913045, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.1818181818181818, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.13333333333333333, 0.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5510", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "after_eval": {"predictions": ["orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "september", "south africa", "Thomas Middleditch", "kalium", "If a vehicle towing a trailer skids", "T cell receptor", "relatively low salaries", "non-GMO", "Point of Entry", "bridge", "u", "Science Magazine", "Premier League club Manchester United and the England national team", "poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "the Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "Stern-Plaza", "Jimmy Ellis", "1991", "Sunday, May 1", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8831845238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7394", "before_prediction": "potassium", "after_prediction": "kalium"}, {"id": "mrqa_squad-validation-6602", "before_prediction": "T cell", "after_prediction": "T cell receptor"}], "retained_ids": ["mrqa_squad-validation-6744", "mrqa_squad-validation-2234", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-5557"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5510", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "unfixed_ids": ["mrqa_triviaqa-validation-7156", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-7049", "mrqa_triviaqa-validation-1079"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.6666666655555555}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\"Boston Herald\" Rumor Clinic", "1967", "\"bookie\" for taking a bet from a gambler", "the twelfth most populous city in the United States", "50", "bridge", "is involved in oncogenesis, either by gene mutation, or chromosome translocation, or simply by over-expression", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Chava with Fyedka", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country", "japan", "bridge", "Yunnan- Fu", "Mumbai", "Sydney", "2005", "all punishments and granted them salvation", "\"The Doctor's Daughter\"", "a person who made or repaired wagons", "cole peyre", "The project must adhere to zoning and building code requirements. Constructing a project that fails to adhere to codes does not benefit the owner", "1877", "daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system", "\"motivational embellishment\"", "korea", "luxury divisions", "Bill Clinton", "Telemark"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17953700014488552}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.2857142857142857, 0.0, 0.06896551724137931, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "after_eval": {"predictions": ["defeat of Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "largest", "Mickey Mantle", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher rates", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "St. Lawrence River valley", "emperor", "oakum", "Spring city", "London", "Broken Hill and Sydney", "2005", "all punishments", "Smith and Jones", "wagon", "ilich ramirez sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "power windows", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1573", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-1903"], "fixed_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9999999966666667}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "jasmine", "expressing defiance toward the government and unwillingness to stand for its policies", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "red or pimento peppers", "0.2 inhabitants per square kilometre", "spileas fogg", "France", "Ian Paisley", "bataan", "euro", "suggs", "the United States", "1974", "1890", "2008 NFL season", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "juba", "a circular movement of an object around a center ( or point ) of rotation", "Johnny Darrell", "carotid artery disease", "vegetable fat", "Euler's totient function", "ear wax", "binary strings", "Busiest", "red, yellow, purple and orange", "Honda Accord", "Kurt Vonnegut", "september"], "metric_results": {"EM": 0.125, "QA-F1": 0.18546245421245422}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.2222222222222222, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman and a Deputy Chairman", "norman hartnell", "expressing defiance toward the government and unwillingness to stand for its policies", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52/ sq mi", "the Phantom", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "World War II", "lTL", "Madness", "Taft -- Katsura Agreement", "late 1970s", "first published in 1890", "24\u201324 tie", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "relationship of the number to its corresponding value of Euler's totient function", "ear wax blockage", "how graphs are encoded as binary strings", "third", "succulent orange", "large", "Lauren Oliver", "ill with what would surely result in her death"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7875}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3408", "before_prediction": "ear wax", "after_prediction": "ear wax blockage"}], "retained_ids": ["mrqa_hotpotqa-validation-3982", "mrqa_naturalquestions-validation-951", "mrqa_hotpotqa-validation-1139"], "fixed_ids": ["mrqa_triviaqa-validation-7248", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034"], "unfixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_squad-validation-6673", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_naturalquestions-validation-8990", "mrqa_hotpotqa-validation-3002", "mrqa_triviaqa-validation-7184", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.7142857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "supply and demand", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "an interesting-shaped pasta from Puglia", "Washington Redskins", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "Howard Ashton", "national security, big oil companies and bribery and corruption", "high and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Broward County", "Song Kang-ho, Lee Byung-hun", "changing display or audio settings quickly", "fought 1642-1651", "the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "the benefits don't trickle down", "Beautyy and the Beast", "South Africa", "Tyler \" Ty\" Mendoza", "the Alamo", "a seal illegally is broken", "the UMC", "Brian Liesegang", "Roger Allers and Rob Minkoff", "Papua New Guinea", "witch Doctor", "National Association for the Advancement of Colored People", "1963\u20131989", "an unusual amount of icebergs were reported in the area by other ships", "sudden death of incumbent leader John Smith", "a witch and a mortal fall in love and get married", "6500 - 1500 BC"], "metric_results": {"EM": 0.125, "QA-F1": 0.28727766106442576}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.5, 0.28571428571428575, 0.14285714285714288, 0.4, 0.0, 0.0, 0.25, 0.8, 0.0, 0.11764705882352941, 0.0, 0.0, 0.4, 0.0, 0.4799999999999999, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_hotpotqa-validation-2971", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["2%", "capital and financial markets", "Dan Stevens", "liver", "butterfly", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard adjoining the Assembly Hall", "William Howard Ashton, (born 19 August 1943) better known by his stage name Billy J. Kramer", "national security, big oil companies and bribery and corruption", "Unemployment", "Miami", "Song Kang-ho, Lee Byung-hun, and Jung Woo-sung", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "king charles i", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "South Africa", "Tyler \" Ty\" Mendoza", "texas", "a seal", "United Methodist", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "National Association for the Advancement of Colored People", "1963\u20131989", "Titanic", "margaret beckett", "elizabeth montgomery", "6500 - 1500 BC"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8223684210526316}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10036", "before_prediction": "the UMC", "after_prediction": "United Methodist"}], "retained_ids": ["mrqa_triviaqa-validation-6450", "mrqa_hotpotqa-validation-1475", "mrqa_squad-validation-7610"], "fixed_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969"], "unfixed_ids": ["mrqa_hotpotqa-validation-2971", "mrqa_triviaqa-validation-6423", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-1812"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.7499999981250001}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Amber Laura Heard", "Uranus", "family history", "Cobham\u2013Edmonds thesis", "human, or humanoid aliens", "the prefix given to the end of the name to avoid confusion for the winner of the 1996 Record of the Year", "March 2012", "jazz club", "Muhammad Ali", "Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Menorca", "submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen", "Julius Caesar", "2", "1979", "a virtual reality simulator", "decision problem", "Hexham, Northumberland, England", "heart", "Miasma theory", "a form of drinkware made to hold either a British ( `` imperial '' ) pint of 20 imperial fluid ounces ( 568 ml ) or an American pint of 16 US fluid ounces", "mountain ranges", "red", "significant production of peaches as early as 1571, with exports to other states occurring around 1858", "nettle", "$12", "flat", "Love Is All Around - Top Of The Pops", "to build a nationwide network in the UK", "roughly west through the Netherlands and extended to the southwest, through the English Channel and finally, to the Atlantic Ocean", "Sudan"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31253236142942026}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.1, 0.0, 1.0, 1.0, 0.35294117647058826, 0.4444444444444445, 0.0, 0.4, 0.0, 0.21428571428571425, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.7272727272727273, 0.2222222222222222, 0.11764705882352941, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-110", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "north pole", "rudolph", "Cobham\u2013 edmonds thesis", "to remind the Doctor of his \"moral duty\"", "II", "April", "the great curve of the Mississippi River", "Raymond Patterson", "Coldplay", "Menorca", "receive no jail time", "emperors", "2", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "The formal language associated with this decision problem", "Hexham, Northumberland, England", "the right side of the heart", "bad air", "imperial fluid ounces", "mountain ranges", "white", "South Carolina", "nettle", "US $3 per barrel", "20 %", "love is all around", "use in the ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8631944444444444}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1758", "before_prediction": "Cobham\u2013Edmonds thesis", "after_prediction": "Cobham\u2013 edmonds thesis"}, {"id": "mrqa_squad-validation-3635", "before_prediction": "$12", "after_prediction": "US $3 per barrel"}], "retained_ids": ["mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-3060", "mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-4069"], "fixed_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-110", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "unfixed_ids": ["mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-3803", "mrqa_triviaqa-validation-5936"], "instant_fixing_rate": 0.88, "instant_retention_rate": 0.7142857132653061}, {"timecode": 37, "before_eval": {"predictions": ["South Joaquin Valley Railroad", "three of his ribs were broken", "7 December 2000", "Post Alley under Pike Place Market", "mother-of-pearl", "February 20, 1978", "india", "Ronald Reagan", "96", "De Inventione by Marcus Tullius Cicero", "india", "black", "the alluvial plain", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Carlos Tevez", "many types of lizard including the vulnerable great desert skink ( Egernia kintorei ) and a number of small marsupials including the endangered sandhill dunnart", "events and festivals", "rudscher tafelwein", "1991", "india", "7 January 1936", "ten years", "twenty-four", "Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Nlend Wom\u00e9", "lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "india", "Oxford, UK"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23843491200828157}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.75, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2608695652173913, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.39999999999999997, 0.13333333333333333, 0.8, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_naturalquestions-validation-969", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524", "mrqa_hotpotqa-validation-5371"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "the Roman Empire", "Great Britain", "gold", "Mesopotamia", "37\u00b0 9' 58.23\"", "woodentops", "Henry", "shared", "sandhill dunnart", "Festival of Old Music", "kabinett", "2010", "avatar", "7 January 1936", "lifetime protection", "It contains twenty-four episodes", "Carl Sagan", "tax base dissipated", "Nationalists", "Pierre Nlend Wom\u00e9", "mistreatment from government officials", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9296875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-677", "before_prediction": "events and festivals", "after_prediction": "Festival of Old Music"}], "retained_ids": ["mrqa_squad-validation-5451", "mrqa_hotpotqa-validation-513", "mrqa_hotpotqa-validation-4154", "mrqa_hotpotqa-validation-85"], "fixed_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_naturalquestions-validation-969", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524", "mrqa_hotpotqa-validation-5371"], "unfixed_ids": ["mrqa_triviaqa-validation-3479", "mrqa_hotpotqa-validation-2377"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.7999999984}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "Great Britain and France", "a children's story published by John Newbery in London in 1765", "243 days", "gathering money from the public", "Thorgan Hazard", "commissioned officers are given a one - time stipend when commissioned to purchase their required uniform items", "Jeff Meldrum", "1973", "Phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "suez Canal", "57", "journalist", "the fact that there is no revising chamber", "1960s", "when lifted to an extension field", "most of the items in the collection, unless those were newly accessioned into the collection", "receive floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "glycine", "Alta Wind Energy Center in California", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation", "Lord's", "Eddy Shah", "flunkey - King Louie's monkey servant and right hand - man", "first heart sound"], "metric_results": {"EM": 0.15625, "QA-F1": 0.279325370036352}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.09523809523809523, 0.0, 0.0, 0.4, 0.47058823529411764, 0.6666666666666666, 0.23529411764705882, 0.25, 0.0, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 0.6, 0.0, 0.0, 0.5, 0.06451612903225806, 0.0, 0.0, 0.3846153846153846, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-3320", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "after_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson", "1958", "Bart Cummings", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "military units from their parent countries of Great Britain and France, as well as by American Indian allies", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \"Jeff\" Meldrum", "It topped the Billboard Top LPs & Tapes chart for a week and remained in the chart for 741 weeks from 1973 to 1988", "Painting with Ysanne Churchman", "French and English", "The Chipettes", "emigrant ship Australis", "60 by West All - Stars ( 2017 )", "journalist", "no revising chamber", "beehive", "ramification", "newly accessioned into the collection", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.75, "QA-F1": 0.8006994203114892}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.896551724137931, 1.0, 1.0, 1.0, 0.09523809523809523, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.09523809523809523, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4762", "before_prediction": "Phil Archer", "after_prediction": "Painting with Ysanne Churchman"}, {"id": "mrqa_triviaqa-validation-3118", "before_prediction": "suez Canal", "after_prediction": "emigrant ship Australis"}], "retained_ids": ["mrqa_squad-validation-1862", "mrqa_triviaqa-validation-4677", "mrqa_squad-validation-1660"], "fixed_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-3320", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.5999999988}, {"timecode": 39, "before_eval": {"predictions": ["capital city of Taiwan", "Dan Conner", "Checkpoint Charlie", "President John F. Kennedy", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "kuskusi", "the 1980s", "John M. Grunsfeld", "New York City", "a man who makes potions in a traveling show", "2003", "pedicels", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "the relative units of force and mass", "lady and woman", "two", "August 10, 1933", "The Golden Gate Bridge", "Sochi, Russia", "those who already hold wealth have the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "B. Traven", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "oil prices", "wooded forest", "264,152", "Princeton, New Jersey", "the United States", "high pressure or an electric current"], "metric_results": {"EM": 0.3125, "QA-F1": 0.41589989531166005}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.8571428571428571, 1.0, 0.0, 0.0, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.37037037037037035, 0.3636363636363636, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["taipei", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "the 1980s", "John M. Grunsfeld", "detroit", "yours", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the second Sunday of March, and standard time restarts on the first Sunday in November", "fixed", "agatha christie", "porto", "August 10, 1933", "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "vancouver", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "Fortean", "inflation", "squirrel", "247,597", "The Institute for Advanced Study", "German service cartridge", "DC"], "metric_results": {"EM": 0.875, "QA-F1": 0.9274806076276665}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6839", "before_prediction": "the second Sunday of March", "after_prediction": "the second Sunday of March, and standard time restarts on the first Sunday in November"}, {"id": "mrqa_naturalquestions-validation-3108", "before_prediction": "The Golden Gate Bridge", "after_prediction": "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean"}], "retained_ids": ["mrqa_hotpotqa-validation-2243", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_naturalquestions-validation-3698", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-489"], "fixed_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-7195"], "instant_fixing_rate": 0.9090909090909091, "instant_retention_rate": 0.7999999992}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "on the road back to Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "spaniels", "the 14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "The antichrist of 2 Thessalonians 2", "Bacon", "Charlton Heston", "anti-inflammatory molecules, such as cortisol and catecholamines", "war", "detroit McNabb", "one of the uses of money", "statute or the Constitution itself", "spaines", "when the Mongols placed the Uighurs of the Kingdom of Qocho over the Koreans at the court the Korean King objected", "Sochi, Russia", "left", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "At the insistence of NASA Administrator Webb", "new Zealand", "detroit", "30", "the Secret Intelligence Service", "100 billion", "tai su, teknon", "photosynthesis", "4.7 / 5.5 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.28125, "QA-F1": 0.34744635572760574}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 1.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.13333333333333333, 0.4, 0.0, 0.09523809523809522, 1.0, 0.0, 0.18181818181818182, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-4123", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_squad-validation-3617", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "Samarkand", "ice dancing", "Isabella (Belle) Baumfree", "corgi", "every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "prophetic faith", "Bacon", "Yul Brynner as Rameses, Anne Baxter as Dathan, Yvonne De Carlo as Sephora, Debra Paget as Lilia, and John Derek as Joshua", "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "United States Presidents", "achedrales en lumi\u00e8re", "surrendered peacefully without violently resisting", "Sochi, Russia", "detroit", "central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "immediately", "australia", "shorthand typist", "30 Major League Baseball teams and their 160 minor league baseball affiliates", "MI6", "neurons", "tai su, teknon", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.625, "QA-F1": 0.6806219362745098}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.375, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 0.5882352941176471, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6248", "before_prediction": "on the road back to Samarkand", "after_prediction": "Samarkand"}, {"id": "mrqa_triviaqa-validation-1571", "before_prediction": "sarajevo", "after_prediction": "ice dancing"}, {"id": "mrqa_squad-validation-4953", "before_prediction": "the 14th to 17th centuries", "after_prediction": "every year between 1346 and 1671"}, {"id": "mrqa_triviaqa-validation-3280", "before_prediction": "new Zealand", "after_prediction": "australia"}], "retained_ids": ["mrqa_squad-validation-395", "mrqa_hotpotqa-validation-1453", "mrqa_naturalquestions-validation-4330", "mrqa_hotpotqa-validation-4076", "mrqa_hotpotqa-validation-178"], "fixed_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-2249", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_squad-validation-8247", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-4123", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_squad-validation-3617", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "unfixed_ids": ["mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_hotpotqa-validation-3151", "mrqa_triviaqa-validation-579"], "instant_fixing_rate": 0.6521739130434783, "instant_retention_rate": 0.5555555549382716}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Raj Kishore and Keshto Mukherjee", "Gaels", "Brag", "d\u00edsabl\u00f3t", "lion", "Russian film industry", "sediment load", "Washington metropolitan area", "newly formed vesicles from the membrane of one cellular compartment", "User State Migration Tool ( USMT )", "Ordos City China Science Flying Universe Science and Technology Co.", "pie tins", "PPG Paints Arena, Pittsburgh, Pennsylvania ( Host : Duquesne University )", "l Leicester", "Section 30 of the Teaching Council Act 2001", "Ron Messick as Jeffrey, a young, undersized gosling whom Wilbur befriends shortly after his birth", "mid-1988", "quasars", "Monsoon or Retreating Monsoon", "Romansh", "Tudor queen", "MIX 94.5", "James Bond films and film novelisations", "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "the division of labour, productivity, and free markets", "Gerard Marenghi (born January 24, 1920) known as Jerry Maren", "Pat Houston", "Nebula Award", "Conservative Party", "Saul", "Hugo Peretti, Luigi Creatore"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2544439935064935}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.19999999999999998, 0.0, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 0.0, 0.33333333333333337, 0.0, 0.4, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.3636363636363636, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag, but rather players aim to reach a total of 11 points, gained over successive deals", "Idisi", "P. spelaea", "The cinema of Russia", "increasing land clearance (Bronze Age agriculture)", "FedExField in Landover, Maryland", "scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment, both at the cell surface", "Windows Easy Transfer", "Ordos City", "frisbee", "Duquesne University", "leicester", "Section 30", "Paul Lynde", "October 1986", "huge-LQG", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george III", "5AA", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret Thatcher", "jonathan", "Hugo Peretti, Luigi Creatore, and George David Weiss"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8600465118762817}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5625, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8421052631578948, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2053", "before_prediction": "lion", "after_prediction": "P. spelaea"}, {"id": "mrqa_squad-validation-9355", "before_prediction": "sediment load", "after_prediction": "increasing land clearance (Bronze Age agriculture)"}], "retained_ids": ["mrqa_squad-validation-1592"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320"], "unfixed_ids": ["mrqa_hotpotqa-validation-1391", "mrqa_naturalquestions-validation-10355", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-8338", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.3333333322222222}, {"timecode": 42, "before_eval": {"predictions": ["Paul Madsen", "cavatelli, acini di pepe, pastina, orzo, etc. ), lentils, or grated parmesan cheese", "julette de Valois", "independence from the Duke of Savoy through an alliance between the city-state of Geneva and the Swiss Confederation", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "Abraham Lincoln's war goals", "paid professionals", "mistreatment from government officials", "a large Danish shipping company that operates passenger and freight services across northern Europe", "Giorgio Chiellini", "japan", "the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position )", "glucose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity F.C.", "Paul Laxalt of Nevada", "an abbreviation used in the publications of the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types", "Thursday", "yellow", "medication choice, dose, route, frequency, and duration of therapy", "Mars", "aviator, polar explorer, and organizer of polar logistics", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "jules", "The Private Education Student Financial Assistance", "bow hair", "The benefits of good works could be obtained by donating money to the church", "colonies", "two forces, one pointing north, and one pointing east", "Bills", "Qualcomm Stadium", "the time and space hierarchy theorems"], "metric_results": {"EM": 0.125, "QA-F1": 0.2884323142135642}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.7000000000000001, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.7222222222222222, 0.0, 0.375, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0, 0.8888888888888888, 1.0, 0.18181818181818182, 0.13333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.19999999999999998, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "the ozone generated in contact with the skin", "the American Civil War", "Chartered", "lack of remorse", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "Introverted Sensing ( Si )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "egyptus Mons", "feats of exploration", "piston", "rob lowe", "The Private Education Student Financial Assistance", "bow", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9501488095238095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7133", "before_prediction": "Mars", "after_prediction": "egyptus Mons"}], "retained_ids": ["mrqa_squad-validation-1429", "mrqa_squad-validation-7034", "mrqa_squad-validation-9452"], "fixed_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-4842"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 43, "before_eval": {"predictions": ["fall", "letters", "egypt", "temple Square", "French", "a \"homeward bounder\"", "e.example.com", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "Py", "natural-ing Ingredients- only personal care products", "fly", "Sparafucile", "Russia", "the most abundant element by mass in the Earth's crust as part of oxide compounds such as silicon dioxide, making up almost half of the crust's mass", "furniture", "169 national organisations governed by the World Organization of the Scout Movement", "egypt", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Algernod Lanier Washington", "the Outfield", "Croatia", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong", "railway locomotives", "eddie", "first quarter, full moon, and third quarter ( also known as last quarter )", "egypt", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "technology incidental to rocketry and manned spaceflight", "eve", "615 square kilometers", "egypt"], "metric_results": {"EM": 0.0625, "QA-F1": 0.18126461709085548}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21052631578947367, 0.0, 0.6, 0.0, 1.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.4, 0.0, 0.2666666666666667, 0.0, 0.0, 0.11764705882352942, 0.0, 0.8571428571428571, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "after_eval": {"predictions": ["Niagara Falls", "Scrabble", "indiana", "salt lake city", "Italian", "sailor", "sub domain", "recurring and life-threatening infections", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third-most", "IKEA", "169", "mexico", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Plies", "English rock band the Outfield", "tennis", "Michael Edwards", "road engines", "richard burton", "third quarter ( also known as last quarter )", "sergeant-major bullimore", "Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "mitochondrial Eve", "237", "matthew"], "metric_results": {"EM": 0.84375, "QA-F1": 0.85625}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-4624"], "fixed_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "unfixed_ids": ["mrqa_triviaqa-validation-4314", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.999999995}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda met Captain America in early 1941 and gave him a second sample of vibranium, an alien metal with unique vibration absorption properties and found only in Wakanda and the Savage Land", "graduated scales", "2003", "cricket", "soccer", "campaign setting", "fourth Revised Edition", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\"\u00f7\"", "Christopher Lee as Count Dooku / Darth Tyranus : A former Jedi Master who now leads a Separatist movement and is Darth Sidious'new Sith apprentice", "8th", "picture book", "all health care settings", "increased patient health outcomes and decreased costs to the health care system", "treble clef", "Gabriel Alberto Azucena (born September 23, 1988) who goes by the stage name Gawvi, formerly G-Styles", "160 km / h", "Piazza Trinit\u00e0 dei Monti", "December 1, 2009", "Estelle Sylvia Pankhurst", "egypt", "Lord Chancellor of England", "sweden", "The Ministry of Corporate Affairs ( MCA )", "Irish", "ancient cult activity", "boston bronte", "energy-storage molecules", "Hubble Space Telescope", "a genuine love of our neighbors as ourselves", "chorale cantatas"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3292489801864802}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, true], "QA-F1": [0.3, 0.0, 0.19999999999999998, 0.0, 0.0, 0.4, 0.5454545454545454, 0.6666666666666666, 1.0, 0.15384615384615385, 0.32, 0.0, 0.0, 1.0, 0.39999999999999997, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_squad-validation-9951"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "English and Wales Cricket Board ( ECB ) in 2003 for the inter-county competition in England and Wales", "gymnastics", "sweden", "published campaign settings available for purchase", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Padm\u00e9 Amidala", "second", "picture book", "all health care settings", "more integral within the health care system", "music", "Lecrae Devaughn Moore", "average speed 112 km / h", "Rome", "May 18, 2010", "Estelle Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "British", "Vesta", "branwell", "energy", "sp Hubble", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.75, "QA-F1": 0.8651041666666667}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5696", "before_prediction": "Irish", "after_prediction": "British"}, {"id": "mrqa_triviaqa-validation-1504", "before_prediction": "Hubble Space Telescope", "after_prediction": "sp Hubble"}], "retained_ids": ["mrqa_naturalquestions-validation-10612", "mrqa_squad-validation-6319", "mrqa_hotpotqa-validation-389", "mrqa_squad-validation-2419"], "fixed_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_triviaqa-validation-6579", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_squad-validation-9951"], "unfixed_ids": ["mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_hotpotqa-validation-4794"], "instant_fixing_rate": 0.7692307692307693, "instant_retention_rate": 0.6666666655555555}, {"timecode": 45, "before_eval": {"predictions": ["maxis spillane", "Detroit Lions", "perique", "under `` the immortal Hawke ''", "death penalty", "a stout man with a \" Double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "bran", "rich Fisher king", "Mangal Pandey of the 34th BNI", "Pannonian troops", "richard", "four of the 50 states", "curling", "the eighth series", "the gated community of Pebble Beach", "Canadian Football League (CFL) team", "Korean", "Gareth", "\"LOVE Radio\"", "Boston Red Sox", "the five appellate judicial districts of the state", "white", "Sven Davison and David Dobkin", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "Cashin' In", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "San Francisco Bay Area at Santa Clara, California", "fortified complex", "Operation Neptune", "Isthmus of Corinth"], "metric_results": {"EM": 0.21875, "QA-F1": 0.29618246336996334}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.15384615384615385, 0.0, 1.0, 0.4166666666666667, 0.16666666666666669, 0.4, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-2067"], "after_eval": {"predictions": ["mike hammer", "the 2009 St. Louis Rams", "smoke it", "His left leg was cut off close by the hip, and under the left shoulder, he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird", "death penalty", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "Ubiorum", "Lorne Greene", "Kentucky", "1998", "they signed with Simon Cowell's record label Syco Music and released a cover of Damien Rice's `` Cannonball '' as their winner's single", "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove", "St. Louis", "Canadian", "Gareth", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "radicalize the Islamist movement", "People! and The Carnabeats", "\" Cashin' In\"", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8876772171389984}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.06451612903225806, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1907", "before_prediction": "Detroit Lions", "after_prediction": "the 2009 St. Louis Rams"}, {"id": "mrqa_naturalquestions-validation-4123", "before_prediction": "under `` the immortal Hawke ''", "after_prediction": "His left leg was cut off close by the hip, and under the left shoulder, he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird"}], "retained_ids": ["mrqa_triviaqa-validation-3989", "mrqa_hotpotqa-validation-1433", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-3509", "mrqa_hotpotqa-validation-712"], "fixed_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-2067"], "unfixed_ids": ["mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.88, "instant_retention_rate": 0.7142857132653061}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "take that \u201cborrows\u201d from Rick Astley", "youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Einstein", "electromagnetic theory", "Premier League club Swansea City", "millais", "Elizabeth Weber", "an earlier Funcom game, \"The Secret World\"", "hundreds", "\"Waiting for Guffman\"", "June 22, 1978", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "The Five Doctors", "5% abv draught beer", "they can not be produced using currently available resources", "Chu'Tsai", "Liz", "least onerous", "como", "Grissom, White, and Chaffee", "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores", "passion fruit", "Bharata Muni", "the sand grains cause a scrubbing noise as they rub against each other when walked on", "english businessman Samuel Ryder", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "vienna"], "metric_results": {"EM": 0.375, "QA-F1": 0.46945558033920104}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.5384615384615384, 1.0, 0.06666666666666667, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0689655172413793, 0.3333333333333333, 0.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_hotpotqa-validation-1831", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523"], "after_eval": {"predictions": ["bat-and-ball", "that continents `` ploughed '' through the sea.", "take that", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Sir Isaac Newton", "the unexistence of the ultraviolet catastrophe", "Swansea City", "lily", "Joel", "massively multiplayer online role-playing video game", "hundreds", "\"Waiting for Guffman\"", "2003", "The Watermark business park", "apple", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "lago di como", "Grissom, White, and Chaffee", "multinational retail corporation", "yellow", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "incorrectly", "vienna"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8125}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10341", "before_prediction": "Einstein", "after_prediction": "Sir Isaac Newton"}, {"id": "mrqa_squad-validation-10489", "before_prediction": "electromagnetic theory", "after_prediction": "the unexistence of the ultraviolet catastrophe"}, {"id": "mrqa_triviaqa-validation-4081", "before_prediction": "millais", "after_prediction": "lily"}, {"id": "mrqa_triviaqa-validation-1128", "before_prediction": "passion fruit", "after_prediction": "yellow"}], "retained_ids": ["mrqa_squad-validation-5157", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-5221", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913", "mrqa_triviaqa-validation-4430"], "fixed_ids": ["mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_hotpotqa-validation-1831", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523"], "unfixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-2914"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.666666666111111}, {"timecode": 47, "before_eval": {"predictions": ["gerry ltd", "horse racing", "Burnley and the New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "CGI computer animation", "when they enter the army during initial entry training", "moral tale", "they announced a hiatus and re-united two years later for the release of their fourth and final studio album, Destiny Fulfilled ( 2004 )", "leeds", "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form", "74 per cent", "heathrow", "often social communities with considerable face-to-face interaction among members.", "Landon Jones", "cnidarians and bilaterians are more closely related to each other than either is to ctenophores.", "study insects and their relationship to humans, other organisms, and the environment", "candidates on specific catechism questions", "a pH indicator, a color marker, and a dye. It can be prepared by slowly adding excess bromine to a hot solution of phenolsulfonphthalein in glacial acetic acid", "about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa.", "63,182,000", "John and Charles Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Campbellsville", "loner", "appearing as Jude in the musical romance drama film \" Across the Universe\" (2007)", "overweight", "work in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "downward pressure on wages"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3488915598290598}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.5, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.7499999999999999, 0.15384615384615385, 0.5384615384615384, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666669, 0.0, 0.5555555555555556, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "horse racing", "New Zealand national team", "Kumbum Monastery or Ta'er Shi near Xining", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "l Leeds", "a star ( representing either the Star of Bethlehem or the Star Of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "paddington", "Neighbourhood", "The Washington Post", "tentacles", "insects", "specific catechism questions", "a pH indicator", "50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa.", "2011", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "Campbellsville University", "Paul Newman", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "less workers are required in proportion to capital inputs, increasing unemployment ( the \"reserve army of labour\")"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7984758771929825}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.56, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7368421052631579, 1.0, 0.4210526315789474]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1256", "before_prediction": "leeds", "after_prediction": "l Leeds"}], "retained_ids": ["mrqa_hotpotqa-validation-5788", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-2143", "mrqa_squad-validation-1609", "mrqa_naturalquestions-validation-2092"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477"], "unfixed_ids": ["mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_triviaqa-validation-1516", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-1799", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.6538461538461539, "instant_retention_rate": 0.8333333319444445}, {"timecode": 48, "before_eval": {"predictions": ["Anthony John Herrera", "Good Kid, M.A.D City", "el Capitan", "Interventive treatment", "3", "Bishop Reuben H. Mueller", "ry Charles", "During his epic battle with Frieza", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "2001", "Emmanuel Mudiay", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "not given at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "every good work designed to attract God's favor is a sin. All humans are sinners by nature", "annuity ticket", "Darth Vader", "Buffalo Bill", "justice resides", "France", "It insisted on neutral rights, which included allowing private corporations and banks to sell or loan money to either side", "cappuccino", "cubhound", "Hecuba", "pastors and teachers", "Wylie Draper", "political role for Islam", "the university's off- Campus rental policies", "hockey greats Bobby Hull and Dennis Hull", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.25, "QA-F1": 0.3649077740070387}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.22222222222222218, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.11764705882352941, 0.15384615384615385, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2666666666666667, 0.4, 0.6666666666666665, 0.26666666666666666, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "yosemite national park", "interventive", "3", "Bishop Reuben H. Mueller", "georgia", "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan", "the director's own approved edit", "shirley williams", "unesco", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "part of a pre-recorded television program, Rendezvous with Destiny", "a sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France fashioned a semi-independent State of Vietnam, within the French Union, with B\u1ea3o \u0110\u1ea1i as Head of State", "neutrality", "coffee", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies.", "Dennis Hull, as well as painter Manley MacDonald.", "the defending Super Bowl XLIX champion New England Patriots in the AFC Championship Game, 20\u201318, by intercepting a pass on New England's 2-point conversion attempt with 17 seconds left on the clock.", "war, famine, and weather"], "metric_results": {"EM": 0.875, "QA-F1": 0.8995098039215685}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1834", "before_prediction": "During his epic battle with Frieza", "after_prediction": "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan"}, {"id": "mrqa_naturalquestions-validation-3614", "before_prediction": "France", "after_prediction": "France fashioned a semi-independent State of Vietnam, within the French Union, with B\u1ea3o \u0110\u1ea1i as Head of State"}, {"id": "mrqa_squad-validation-264", "before_prediction": "Pittsburgh Steelers", "after_prediction": "the defending Super Bowl XLIX champion New England Patriots in the AFC Championship Game, 20\u201318, by intercepting a pass on New England's 2-point conversion attempt with 17 seconds left on the clock."}], "retained_ids": ["mrqa_naturalquestions-validation-49", "mrqa_squad-validation-9860", "mrqa_squad-validation-8248", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-4774"], "fixed_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.6249999992187499}, {"timecode": 49, "before_eval": {"predictions": ["vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL", "Genghis Khan and particularly Timur", "R.E.M.", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna", "12", "yosemite", "1937", "improved", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane.", "work at various electrical repair jobs and even as a ditch digger for $2 per day", "Marxist and a Leninist", "Hansomouc ( Friedrich Franz and Johann Karl Nestler ), and his colleagues at the monastery ( such as Franz Diebl ) to study variation in plants", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers) These include abortion, broadcasting policy, civil service, common markets for UK goods and services, constitution, electricity, coal,", "Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades.", "3,600", "Albany Schenectady Road", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "georgia", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Wisconsin v. Yoder", "uneven trade agreements", "kiamsha kinywa", "adenosine triphosphate", "georgia", "Ruth Elizabeth \"Bette\" Davis", "uranium", "7 December 2004"], "metric_results": {"EM": 0.09375, "QA-F1": 0.19207984997458682}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.33333333333333337, 0.0, 1.0, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.0, 0.0, 0.0, 0.05714285714285715, 0.10526315789473685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "the state of Odisha and stretches to the south of the Mahanadi Delta", "Ravenna", "12", "meat", "1895", "improved markedly", "tiltrotor/tilt-wing concept as well as the earliest proposal for the use of turbine engines in rotor aircraft", "assigned them to the company in lieu of stock", "communist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers) These include abortion, broadcasting policy, civil service, common markets for UK goods and services, constitution, electricity, coal,", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "imperialism", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8575714644832292}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.32, 0.15384615384615385, 0.2222222222222222, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.05714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2275", "before_prediction": "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "after_prediction": "the state of Odisha and stretches to the south of the Mahanadi Delta"}], "retained_ids": ["mrqa_squad-validation-8906", "mrqa_hotpotqa-validation-1772"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "unfixed_ids": ["mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_squad-validation-1459", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.6666666644444444}, {"timecode": 50, "before_eval": {"predictions": ["basketball", "Igor Stravinsky, Carl Orff, Paul Hindemith, Richard Strauss, Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman express its ranges 160km / hour between Delhi to Agra In 100 min its cross 180km", "Murder in...T.S. Eliot", "Big Machine Records", "conflicting territorial claims between British and French colonies in North America were turned over to a commission to resolve", "the Hindu sage Valmiki", "Ramsay", "every two to six years ( depending on the positions being filled with most positions good for four years )", "China was torn by dissension and unrest", "association football", "2016", "Dan Castellaneta", "2007", "Wicked Twister", "multiplication", "rocket designer and creator of the Atlas ICBM.", "shoe", "unclear as to how or whether this connection is relevant on microscales", "supernatural psychological horror", "originate", "The Revenant", "the evening of the same day", "Blue (Da Ba Dee)", "Constitution", "Faurot Field", "Annette Charles as Charlene `` Cha - Cha '' DiGregorio", "crossing the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return.", "5", "konya", "the footbrake pedal being in use when the car comes to a halt"], "metric_results": {"EM": 0.125, "QA-F1": 0.32478118246307097}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.4210526315789474, 0.1081081081081081, 0.2222222222222222, 0.3333333333333333, 1.0, 0.3243243243243243, 0.6666666666666666, 0.0, 0.45454545454545453, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.4, 0.4, 0.6666666666666666, 1.0, 0.0, 0.8627450980392156, 0.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_naturalquestions-validation-7707", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-290", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239", "mrqa_naturalquestions-validation-3022"], "after_eval": {"predictions": ["basketball", "Igor Stravinsky, Carl Orff, Paul Hindemith, Richard Strauss, Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman express its ranges 160km / hour between Delhi to Agra In 100 min its cross 180km", "sweeney agonistes", "Taylor Swift", "claimed by both sides", "traditionally ascribed to the Hindu sage Valmiki", "Scots in origin", "every two to six years", "Outlaws ravaged the country without interference", "YouTube", "2007", "Daniel Louis Castellaneta", "1994", "Wicked Twister", "arithmetic", "rocket", "khrushchev", "General relativity offers an equivalence between space-time and mass, but lacking a coherent theory of quantum gravity", "American supernatural psychological horror film", "raising revenue", "dicaprio", "evening", "Blue (Da Ba Dee) is a song by the Italian music group Eiffel 65.", "Constitution", "Faurot Field", "Lorenzo Lamas", "an extended metaphor to compare death with crossing the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return", "5\u00bd", "konya", "upon braking to a full stop"], "metric_results": {"EM": 0.625, "QA-F1": 0.7438859975866554}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.4210526315789474, 0.1081081081081081, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.6666666666666666, 1.0, 1.0, 0.9824561403508771, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5623", "before_prediction": "Big Machine Records", "after_prediction": "Taylor Swift"}], "retained_ids": ["mrqa_triviaqa-validation-7291", "mrqa_hotpotqa-validation-4497", "mrqa_hotpotqa-validation-3545"], "fixed_ids": ["mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_naturalquestions-validation-7707", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_triviaqa-validation-290", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_naturalquestions-validation-1008", "mrqa_squad-validation-290", "mrqa_naturalquestions-validation-3022"], "unfixed_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-118", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-71", "mrqa_triviaqa-validation-239"], "instant_fixing_rate": 0.6071428571428571, "instant_retention_rate": 0.7499999981250001}, {"timecode": 51, "before_eval": {"predictions": ["third", "The main pulmonary artery begins at the base of the right ventricle", "a card from a pack of playing cards by Alice", "Orange, San Diego, San Bernardino, and Riverside", "Alex Breckenridge as Monique Valentine, Sebastian's superficial girlfriend", "seven", "Schr\u00f6dinger equation", "dick", "Ashland is home to Scribner-Fellows State Forest", "in some public schools in Alabama, Arkansas, Georgia, Louisiana, Mississippi, Oklahoma, Tennessee and Texas", "Ghostface mask", "Roger Staubach", "AC induction motor and transformer", "Eric Morecambe", "Punk's Blood", "the port of Veracruz", "Robert John Day", "1775\u20131795", "Empiricism", "The Moon and Sixpence", "Miller Brewing", "redistributive", "Tyrion Lannister", "dic piedi\u2019s overhead kick vs Sunderland in the League Cup", "expressed through some medium, as speech, writing or any of various arts ''", "Those not fit to enter heaven are denied entrance at the gates", "``An Act to provide for the better government of Ireland\"", "t\u00e3t Ni\u00ean", "Gebhard v Consiglio dell\u2019 Ordine degli Avvocati e Procuratori di Milano", "Ukraine", "1835", "The Virgin Queen, Gloriana or Good Queen Bess"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27629534973284975}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.3636363636363636, 0.4324324324324324, 0.25, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.33333333333333337, 0.2666666666666667, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 0.0, 0.14285714285714288, 0.0, 0.4, 0.4444444444444445]}}, "error_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3033", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "after_eval": {"predictions": ["three", "the right ventricle", "a card from a pack of playing cards by Alice, yet somehow she is able to talk and is the ruler of the lands in the story, alongside her tiny husband, the King of Hearts", "Riverside", "Emily Perkins", "seven", "Newtonian equations", "caviar", "Ashland", "the South", "edvard munch", "Roger Thomas Staubach (born February 5, 1942)", "transformer", "Bring Me Sunshine ( 1994) was originally a three-part retrospective in tribute to Eric Morecambe and was hosted by the comedian and author Ben Elton", "rock band", "the Americas", "Bob Day", "1775\u20131795", "epistemology", "paul Gauguin", "Miller Brewing Company", "positive", "Tyrion Lannister ( season 1 -- present ) portrayed by Peter Dinklage", "owls", "information", "Saint Peter ( the keeper of the `` keys to the kingdom '' )", "An Act to provide for the better government of Ireland", "t\u1ebft", "Commission v Italy the Court of Justice", "Belarus", "[O.S. 6 January] 1835", "The Virgin Queen"], "metric_results": {"EM": 0.875, "QA-F1": 0.9449156746031746}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.7428571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5740", "before_prediction": "Ashland is home to Scribner-Fellows State Forest", "after_prediction": "Ashland"}, {"id": "mrqa_hotpotqa-validation-596", "before_prediction": "Miller Brewing", "after_prediction": "Miller Brewing Company"}], "retained_ids": ["mrqa_hotpotqa-validation-120", "mrqa_squad-validation-971", "mrqa_hotpotqa-validation-2549"], "fixed_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3033", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "unfixed_ids": ["mrqa_hotpotqa-validation-3521", "mrqa_naturalquestions-validation-91"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 52, "before_eval": {"predictions": ["the Myllokunmingia", "Edd Kimber, Joanne Wheatley, John Whaite, Frances Quinn, Nancy Birtwhistle, Nadiya Hussain, Candice Brown and Sophie Faldo", "b Brenda", "the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers.", "asphyxia", "SG", "Carey Mulligan, Matthias Schoenaerts, Michael Sheen, Tom Sturridge and Juno Temple", "The Worm", "16 December 1908", "the seven cards of the five community cards and their own two hole cards", "German hymns", "Bury Football Club", "Fan S. Noli", "The Thing of It Is... is a 1967 novel written by William Goldman about Amos McCracken, a 31-year-old man who has written a popular show tune and who is having marriage troubles.", "NFC Championship Game", "Tom Robinson", "maulay Culkin", "2001", "the port city of Aden, on the southern coast", "quickly to meet the needs of major national and international patient information projects and health system interoperability goals", "about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm)", "The leopard", "the service sector", "Florida", "\"\"la f\u00e9e verte\" (the green fairy) beverage", "DoubleScience ( Wednesdays, 6.30pm) \"a sitcom about two incompetent science teachers who work at a college that specialises in drama\"", "Bolton, Greater Manchester", "British-American", "the state recognizes no limits to its authority and strives to regulate every aspect of public and private life wherever feasible", "anarchists", "540,800", "British Sky Broadcasting Group plc"], "metric_results": {"EM": 0.15625, "QA-F1": 0.317835688312662}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false], "QA-F1": [0.4, 0.21052631578947367, 0.6666666666666666, 0.19999999999999998, 0.0, 0.0, 0.3076923076923077, 1.0, 0.0, 0.15384615384615385, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.25, 0.1111111111111111, 0.4, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5185185185185185, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-4073", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_squad-validation-7240", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-6389", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-2772"], "after_eval": {"predictions": ["believed to be the Myllokunmingia", "Joanne Wheatley", "brenda", "arbitrary integers", "cooling", "Les Paul", "Matthias Schoenaerts", "The Worm", "31 March 1909", "seven", "singing of German hymns", "Bury, Greater Manchester, England", "Benazir Bhutto", "American", "the Super Bowl", "Tom Robinson", "home alone", "July 2001", "Aden", "quickly", "around 17 nm", "Panthera pardus", "manufacturing", "Florida", "the green fairy", "david Mitchell", "Rivington Moor", "American", "every aspect of public and private life", "anarchists", "540,800", "BSkyB"], "metric_results": {"EM": 0.96875, "QA-F1": 0.98125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4188", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-2425", "mrqa_squad-validation-6709", "mrqa_squad-validation-2918"], "fixed_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-4073", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_squad-validation-7240", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-6389", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-2772"], "unfixed_ids": ["mrqa_naturalquestions-validation-8759"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.9999999980000001}, {"timecode": 53, "before_eval": {"predictions": ["Following the election of the UK Labour Party to government in 1997", "Levi's Stadium", "c 1600 from Bishopsgate with elaborately carved wood work and leaded windows, a rare survivor of the Great Fire of London, there is a brick portal from a London house of the English Restoration period", "\" Professor Moriarty to the Doctor's Sherlock Holmes\"", "Atticus Finch", "after the Seven Years' War", "raspberry", "the end of the Pleistocene", "catherine o'Leary", "Bronwyn Kathleen Bishop (n\u00e9e Setright", "guidance and intervention from the European empire to aid in the governing of a more evolved social structure", "king of spades", "Quantrill's Raiders", "domination or control by a group of people over another", "a violation of nature and the resulting psychological effects on the mariner and on all those who hear him", "kairobi", "Sir Derek George Jacobi", "Adam Smith", "25 June 1932", "violin", "Edward Anthony Spitzka (June 17, 1876 \u2013 September 4, 1922) was an American anatomist who autopsied (29 Oct 1901) the brain of Leon Czolgosz", "seasonal television specials", "chromosome", "Evey's mother", "10", "things that are a matter of custom or expectation", "Joudeh Al - Goudia family ( who were added to the original arrangement in the time of Saladin, the Muslim conqueror who seized the holy city from the Crusaders in 1187 )", "Wes Unseld", "1936", "nitrogen dioxide", "increased flooding and sedimentation", "Daniel Handler"], "metric_results": {"EM": 0.21875, "QA-F1": 0.287988362453823}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.375, 0.14814814814814814, 0.4, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-169", "mrqa_squad-validation-5390", "mrqa_hotpotqa-validation-4571", "mrqa_triviaqa-validation-776", "mrqa_squad-validation-9144", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_naturalquestions-validation-1161", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_squad-validation-6877", "mrqa_naturalquestions-validation-678", "mrqa_hotpotqa-validation-5614", "mrqa_naturalquestions-validation-6970", "mrqa_triviaqa-validation-177", "mrqa_triviaqa-validation-3268"], "after_eval": {"predictions": ["1997", "two", "c 1600", "Sherlock Holmes", "Atticus Finch", "1763", "cherry fruit", "~74,000 (BP = Before Present)", "great chicago fire", "Kathryn Jean Martin", "guidance and intervention", "hearts", "american civil war", "formal", "a violation of nature", "kenya", "John Gielgud", "edward elgar", "1952", "beethoven", "Charles Guiteau", "seasonal television specials, particularly its work in stop motion animation", "chromosome", "Evey's mother", "10", "the desire to prevent things that are indisputably bad", "the Sunni Muslim family", "Westley Sissel Unseld", "1912", "oxygen", "increased flooding and sedimentation", "unfortunate events"], "metric_results": {"EM": 0.90625, "QA-F1": 0.921875}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7700", "before_prediction": "\" Professor Moriarty to the Doctor's Sherlock Holmes\"", "after_prediction": "Sherlock Holmes"}, {"id": "mrqa_triviaqa-validation-2821", "before_prediction": "violin", "after_prediction": "beethoven"}], "retained_ids": ["mrqa_triviaqa-validation-3107", "mrqa_naturalquestions-validation-9368", "mrqa_hotpotqa-validation-4294", "mrqa_squad-validation-274", "mrqa_squad-validation-9354"], "fixed_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-169", "mrqa_hotpotqa-validation-4571", "mrqa_triviaqa-validation-776", "mrqa_squad-validation-9144", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_naturalquestions-validation-1161", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_squad-validation-6877", "mrqa_naturalquestions-validation-678", "mrqa_hotpotqa-validation-5614", "mrqa_naturalquestions-validation-6970", "mrqa_triviaqa-validation-177", "mrqa_triviaqa-validation-3268"], "unfixed_ids": ["mrqa_squad-validation-5390"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.7142857132653061}, {"timecode": 54, "before_eval": {"predictions": ["The Christmas Invasion", "the United States", "an expression of Priestley's socialist political principles", "March 9 to 18", "June 2017", "Romancing the Stone", "the seventh cranial nerve", "The 8th Habit", "Anishinaabeg", "medicines, sold tobacco and patent medicines", "warm", "pierowall", "foster global monetary cooperation", "Soma (stylized as SOMA) is a science fiction survival horror video game developed and published by Frictional Games for Microsoft Windows, OS X, Linux and PlayStation 4.", "\" Murder Request\"", "elicarnassus", "american wars of the early 90s", "annually in late January or early February", "Corinna", "the duodenum", "pastry", "Cuyler Reynolds", "Atlanta, Georgia", "american beer", "belfast", "the \" Black Ravens\" is a United States Navy electronic attack squadron that currently operates the EA-18G Growler carrier-based electronic warfare jet aircraft.", "saved something from the disaster", "typically found within a casino, ranging from card to slot machines", "Hermes, Dior, Cartier, Fendi, Gucci, Louis Vuitton, MaxMara, Celine, Tiffany & Co.", "\"Shoot Straight from Your Heart\"", "edith Wharton", "Kony Ealy"], "metric_results": {"EM": 0.09375, "QA-F1": 0.216700487012987}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.13333333333333333, 0.7272727272727273, 0.6666666666666666, 0.2666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 0.4444444444444444, 0.19999999999999998, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_hotpotqa-validation-2266", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_hotpotqa-validation-3620", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_hotpotqa-validation-2058", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "after_eval": {"predictions": ["Canadian broadcast, Christopher Eccleston recorded special video introductions for each episode ( including a trivia question as part of a viewer contest) and excerpts from the Doctor Who Confidential documentary were played over the closing credits", "purple heart medal", "a scathing critique of the hypocrisies of Victorian / Edwardian English society", "2018 ran from March 9 to 18", "2017", "the Michael Douglas film, The Jewel of the Nile, the sequel to the hit blockbuster film, Romancing the Stone", "the mouth", "The 7 Habits of Highly Effective People", "Odawa", "many other herbs", "tropical desert climate", "orkney", "secure financial stability", "22 September 2015", "Murder Request", "paris", "bees", "as early as January 3, and as late as February 12", "Corinna and seven-time Formula One World Champion Michael Schumacher", "duodenum by enterocytes of the duodenal lining", "tesco", "Cuyler Reynolds", "Lacoste, France", "whiskey", "gloucestershire", "Black Ravens", "recalled and replaced by Jeffery Amherst", "outside of casinos", "Gucci, Louis Vuitton, MaxMara", "Feels Like Love", "wuthering", "Chicago Bears"], "metric_results": {"EM": 0.875, "QA-F1": 0.9451923076923077}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7812", "before_prediction": "The Christmas Invasion", "after_prediction": "Canadian broadcast, Christopher Eccleston recorded special video introductions for each episode ( including a trivia question as part of a viewer contest) and excerpts from the Doctor Who Confidential documentary were played over the closing credits"}], "retained_ids": ["mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-773"], "fixed_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_hotpotqa-validation-2266", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_triviaqa-validation-1707", "mrqa_hotpotqa-validation-3620", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_hotpotqa-validation-2058", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "unfixed_ids": ["mrqa_naturalquestions-validation-5497", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-3095"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 55, "before_eval": {"predictions": ["2,000", "John Elway", "the Dutch in the Third Anglo -- Dutch War, only to be returned to England at the Treaty of Westminster", "Hurt after being dumped by her boyfriend, fellow Agent Eric Matthews ( who gets relocated to Miami ), she agrees to the reassignment", "Brittany, Cornwall, Ireland, Isle of Man, Scotland and Wales", "regenerated the body will replace it with stromal connective tissue to maintain tissue / organ function", "Ernie Els", "around the world", "pangea", "low wage", "1080 degrees", "bad", "Scott Mosier", "parete Postlethwaite", "weaving", "art of the book and architecture ; and also including ceramics, metal, glass, and gardens", "sepoys of the Company's army in the garrison town of Meerut, 40 miles northeast of Delhi ( now Old Delhi )", "DeMarcus Ware as time expired in the half", "Jack Nicholson -- Chinatown as J.J. `` Jake '' Gittes", "dan brown", "boxing, where a boxer who is still on their feet but close to being knocked down can be saved from losing by the bell ringing to indicate the end of the round", "the port city of Kaffa in the Crimea in 1347", "the Persian style of architecture", "Iranian", "parphemus", "Landwehr", "his work was published first", "as a preparation for the Feast of the Divine Mercy, celebrated each year on first Sunday after Easter", "accommodationism", "political machinations between Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' ) over, principally, the manner of England's government", "Niger\u2013 Congo", "a lower index of refraction, typically a cladding of a different glass, or plastic"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2979081845979098}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.11764705882352941, 0.33333333333333337, 1.0, 0.125, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.9142857142857143, 0.0, 0.0, 0.0, 0.9824561403508771, 0.15384615384615385, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.36363636363636365]}}, "error_ids": ["mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_triviaqa-validation-7689", "mrqa_hotpotqa-validation-4215", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_naturalquestions-validation-570", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7078"], "after_eval": {"predictions": ["2,000", "John Elway", "England", "gets relocated to Miami", "Brittany, Cornwall, Ireland, Isle of Man, Scotland and Wales", "Stromal cells", "tiger woods", "numerous", "texas", "a large amount of time (high supply) competing for a job that few require (low demand) will result in a low wage for that job", "1080", "Martin Scorsese", "Scott Mosier", "kevin spacey", "edmund cartwright", "ceramics", "sepoys of the Company's army in the garrison town of Meerut, 40 miles northeast of Delhi ( now Old Delhi )", "punt", "Art Carney", "Tom Hanks", "boxing, where a boxer who is still on their feet but close to being knocked down can be saved from losing by the bell ringing to indicate the end of the round", "Sicily and the south of Europe", "the Persian gardens", "German", "parphemus", "Menges", "often given priority because his work was published first", "Good Friday", "separationism", "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' ) over, principally, the manner of England's government", "Niger\u2013Congo", "cylinder of glass or plastic that runs along the fiber's length"], "metric_results": {"EM": 0.75, "QA-F1": 0.8782945415008108}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9142857142857143, 1.0, 1.0, 1.0, 0.9824561403508771, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 0.4705882352941177, 1.0, 0.8571428571428572]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7407", "before_prediction": "low wage", "after_prediction": "a large amount of time (high supply) competing for a job that few require (low demand) will result in a low wage for that job"}, {"id": "mrqa_squad-validation-3450", "before_prediction": "his work was published first", "after_prediction": "often given priority because his work was published first"}], "retained_ids": ["mrqa_squad-validation-5518", "mrqa_squad-validation-378", "mrqa_hotpotqa-validation-3062"], "fixed_ids": ["mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_hotpotqa-validation-4215", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_hotpotqa-validation-2699"], "unfixed_ids": ["mrqa_hotpotqa-validation-3264", "mrqa_naturalquestions-validation-4098", "mrqa_naturalquestions-validation-9459", "mrqa_triviaqa-validation-7689", "mrqa_naturalquestions-validation-570", "mrqa_naturalquestions-validation-7078"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.5999999988}, {"timecode": 56, "before_eval": {"predictions": ["Randy", "1922 to 1991", "predictions that can be tested in various ways", "business sponsors and individual donors", "moral conservatism, literalism, and the attempt \"to implement Islamic values in all spheres of life\"", "Tesla demonstrated a series of electrical effects previously performed throughout America and Europe", "8 bytes", "39, Newton was 26", "smart glasses -- an optical head - mounted display designed in the shape of a pair of eyeglasses", "value of the dollar had been pegged to the price of gold", "\u00dcbermensch", "transgender", "franny", "Robert \"Bumps\" Blackwell, Enotris Johnson, and Little Richard", "five", "teachers' mental and physical health, productivity, and students' performance", "kevin kita", "d'Artagnan", "when each of the variables is a perfect monotone function of the other", "michael y Yarra", "1932", "September 25, 1957", "glycerol, formaldehyde, glutaraldehyde, citric acid, acetic anhydride, and acetamide", "former Manchester United and Danish international goalkeeper Peter Schmeichel", "highest commissioned SS rank", "ERINys", "lowest known subaerial volcanic vents in the world, at 45 m ( 150 ft ) or more below sea level", "Ghost Stories", "Egypt, the only part of the country located in Asia", "Alison Steadman", "in the retina of mammalian eyes ( e.g. the human eye )", "kaupthing"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17192137971789506}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.47058823529411764, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08695652173913045, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-416", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-4640", "mrqa_hotpotqa-validation-1912", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "after_eval": {"predictions": ["Donna", "1922 to 1991", "predictions that can be tested in various ways", "the city council", "Islamism", "Tesla Polyphase System", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "13 years and 48 days", "optical head - mounted display", "oil was priced in dollars, oil producers' real income decreased", "niet Nietzsche", "technical director", "Paul McGann", "Robert \"Bumps\" Blackwell", "five books", "organizational change, relationships with students, fellow teachers, and administrative personnel, working environment, expectations to substitute, long hours with a heavy workload, and inspections", "Subaru", "aramis", "Pearson's correlation assesses linear relationships", "melbourne", "1932", "March 31, 1944", "organic solvents", "World's Best Goalkeeper", "Reichsf\u00fchrer-SS", "revenge", "a cinder cone volcano in the Danakil Depression, northeast of the Erta Ale Range in Ethiopia", "coldplay", "between the Mediterranean Sea to the north and the Red Sea in the south", "Melanie Walters", "in the fovea centralis", "Northern Rock PLC"], "metric_results": {"EM": 0.6875, "QA-F1": 0.8067071634505845}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8717948717948718, 0.0, 1.0, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.631578947368421, 1.0, 0.9, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1787", "before_prediction": "8 bytes", "after_prediction": "65,535 bytes ( 8 byte header + 65,527 bytes of data )"}], "retained_ids": ["mrqa_naturalquestions-validation-3372", "mrqa_hotpotqa-validation-658"], "fixed_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_squad-validation-416", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_hotpotqa-validation-627", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-4640", "mrqa_hotpotqa-validation-1912", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "unfixed_ids": ["mrqa_naturalquestions-validation-7080", "mrqa_triviaqa-validation-4390", "mrqa_triviaqa-validation-6223", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_naturalquestions-validation-6319"], "instant_fixing_rate": 0.6896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 57, "before_eval": {"predictions": ["Saturn", "samuel jonathan", "1.7 billion", "Bathurst", "April 1948", "inequality of opportunity", "penance and righteousness", "FeO (w\u00fcstite) is written as Fe1 \u2212 xO", "Marx Brothers", "many show signs of being subjected to high pressure shock waves that are generated during impact events", "half-penny sales tax", "david edmund Paradine", "tom Brady", "charles and duchy of wcestershire", "glucose", "Labor is strongest in Melbourne's working class western and northern suburbs, and the regional cities of Ballarat, Bendigo and Geelong", "His / Her Majesty's Ship", "All of the chicken sold is reared in South Africa", "October 15, 1997", "Psalms", "renovated the inside as part of his first construction project in Manhattan", "Iceland consisting of a Greenland shark (Somniosus microcephalus\") or other sleeper shark which has been cured with a particular fermentation process and hung to dry for four to five months", "pembroke", "parisare Pavese", "kevin edgeworth", "five", "paris", "Mark Antony and Rex Harrison", "American conservative author and commentator", "chicken schnitzel", "Sam the Sham", "up to three terms until 2015 where the three term limit and two year terms were replaced with a two four - year terms"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27252321004159236}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.2222222222222222, 0.6666666666666666, 0.0909090909090909, 0.0, 0.4, 1.0, 0.0, 0.0, 0.1, 0.25, 0.3636363636363636, 0.3333333333333333, 0.18181818181818182, 0.0, 0.058823529411764705, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.32]}}, "error_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-4067", "mrqa_squad-validation-7226", "mrqa_triviaqa-validation-6053", "mrqa_triviaqa-validation-5785", "mrqa_triviaqa-validation-7489", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_naturalquestions-validation-10657", "mrqa_hotpotqa-validation-3802", "mrqa_hotpotqa-validation-3544", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "after_eval": {"predictions": ["neptune", "james boswell", "60 million", "Bathurst in New South Wales", "in the 1980s", "inequality of opportunity", "penance and righteousness", "FeO", "marx", "materials melted near an impact crater", "Better Jacksonville Plan", "david frost", "Charles Haley", "gloucestershire", "carbon dioxide", "Labor", "`` United States Ship '' ( USS )", "South Africa", "July 8, 1997", "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "modernized the outside", "North Atlantic Ocean and Arctic Ocean", "henry vii", "henry", "henry", "five", "malaysia airlines", "egypt", "son", "veal", "Domingo \"Sam\" Samudio", "two four - year terms"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1567", "before_prediction": "1.7 billion", "after_prediction": "60 million"}], "retained_ids": ["mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-2255", "mrqa_naturalquestions-validation-4193", "mrqa_squad-validation-2869"], "fixed_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-4067", "mrqa_squad-validation-7226", "mrqa_triviaqa-validation-6053", "mrqa_triviaqa-validation-5785", "mrqa_triviaqa-validation-7489", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_naturalquestions-validation-10657", "mrqa_hotpotqa-validation-3802", "mrqa_hotpotqa-validation-3544", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "unfixed_ids": ["mrqa_triviaqa-validation-2303"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 58, "before_eval": {"predictions": ["Dutch", "in the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "a house edge of between 0.5 % and 1 %", "phagosomal membrane", "South Heaton in Newcastle", "1955", "henry vii", "200 horsepower", "Nikola Tesla", "Lutheranism", "Night Ranger", "Buzz, the Honey Nut Cheerios Bee", "\"Thocmentony\"", "organizational interventions, like changing teachers' schedules, providing support networks and mentoring, changing the work environment, and offering promotions and bonuses, may be effective in helping to reduce occupational stress among teachers", "economies with low levels of development have relatively equal distributions of wealth. As a country develops, it acquires more capital, which leads to the owners of this capital having more wealth and income and introducing inequality.", "henry", "Arthur H. Compton, the creator of the first nuclear reactor Enrico Fermi", "Angelina Jolie, Brad Pitt and Amal Clooney", "henry", "in 1982", "mainly civil servants recruited in special university classes", "large areas", "Q \u00d7 1, Z \u00d7 1", "ulnar nerve", "weighing scales and spring balances", "no man is an island", "Liao, Jin, and Song", "`` Han dynasty '' ( Hanchao \u6f22 \u671d )", "pigeons", "kinetic energy", "Attack the Block", "William Shakespeare's play Romeo and Juliet, in which Juliet seems to argue that it does not matter that Romeo is from her family's rival house of Montague, that is, that he is named `` Montague ''"], "metric_results": {"EM": 0.1875, "QA-F1": 0.35148340785676313}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.7272727272727273, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.7499999999999999, 1.0, 0.125, 0.15789473684210525, 0.0, 0.33333333333333337, 0.4444444444444445, 0.0, 0.4, 0.4, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.05714285714285715]}}, "error_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_squad-validation-5202", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_squad-validation-2057", "mrqa_squad-validation-7345", "mrqa_triviaqa-validation-5104", "mrqa_squad-validation-7880", "mrqa_hotpotqa-validation-4178", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-4817", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706", "mrqa_naturalquestions-validation-3470"], "after_eval": {"predictions": ["Dutch", "Central and Western Europe", "between 0.5 % and 1 %", "phagosomal", "in the Ouseburn valley", "1955", "henry v", "100\u20135,000", "Sir William Henry Bragg and William Lawrence Bragg", "German", "`` 3 Themes '' ( performed by David Foster )", "Honey Nut Cheerios", "\"Thocmentony\" meaning \" Shell Flower\" in Northern Paiute", "Organizational interventions, like changing teachers' schedules, providing support networks and mentoring, changing the work environment, and offering promotions and bonuses, may be effective in helping to reduce occupational stress among teachers", "levels of economic inequality", "taekwondo", "Enrico Fermi", "Angelina Jolie", "Donald Sutherland", "before the majority of their members quit and formed Faith No More.", "civil servants", "large areas", "Q", "ulnar nerve", "forces", "john donne", "Liao, Jin, and Song", "zh\u014dng ( \u4e2d ) meaning `` central '' or `` middle '', and gu\u00f3 ( \u570b / \u56fd ), representing `` state '' or '' states '' ; in contemporary usage, `` nation ''", "pdsa", "electromagnetic field", "Ant-Man", "Juliet"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8714226973684212}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.125, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5735", "before_prediction": "\"Thocmentony\"", "after_prediction": "\"Thocmentony\" meaning \" Shell Flower\" in Northern Paiute"}], "retained_ids": ["mrqa_hotpotqa-validation-5153", "mrqa_hotpotqa-validation-4035", "mrqa_squad-validation-4233", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-8193"], "fixed_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_squad-validation-7345", "mrqa_triviaqa-validation-5104", "mrqa_squad-validation-7880", "mrqa_hotpotqa-validation-4178", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-4817", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706", "mrqa_naturalquestions-validation-3470"], "unfixed_ids": ["mrqa_squad-validation-5202", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127"], "instant_fixing_rate": 0.8076923076923077, "instant_retention_rate": 0.8333333319444445}, {"timecode": 59, "before_eval": {"predictions": ["GE's four computer sales and service centers (Schenectady, Phoenix, Chicago, and Phoenix)", "the exoskeleton of insects, the shells and membranes of externally deposited eggs, and skin", "the Naturalization Act of 1790", "Matthew Vaughn", "2 %", "Mountbatten", "9 at the Century 16 multiplex ( operated by Cinemark ), located at the Town Center at Aurora shopping mall at 14300 E. Alameda Avenue", "James Edward Kelly", "neptune", "50th", "sanxian", "It's only fair that, from now on, you should pay more for oil. Let's say ten times more", "in the U.S. state of Kansas", "a yolk sac ( protruding from its lower part ) but no embryo", "Kelly Bundy", "Italy", "as they worked on the keels, boats that were used to transfer coal from the river banks", "her gaoler's family", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Mario Addison", "321,520", "June 12, 2017", "2005", "red deer", "kalapatthar", "``Generalfeldmarschall\" (Field Marshal) Helmuth Karl Bernhard von Moltke", "henry", "the ears of a hound dog", "as soon as 2019", "Cinerama Productions/Palomar theatrical library", "marx", "samoan t\u0101l\u0101"], "metric_results": {"EM": 0.125, "QA-F1": 0.22792276356861252}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.06896551724137931, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.08695652173913042, 0.4, 0.0, 0.0, 0.0, 0.14814814814814814, 0.888888888888889, 0.0, 1.0, 0.0, 0.125, 0.0, 0.9565217391304348, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_triviaqa-validation-2965", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_squad-validation-19", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-825", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_squad-validation-5887", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-2525"], "after_eval": {"predictions": ["lost money", "The waxy cuticle", "restricted naturalization to `` free white persons '' of `` good moral character ''", "Matthew Vaughn", "4 percent cumulative effect", "the Queen", "Theater 9", "Jim Kelly", "luthor", "24\u201310", "kabuki and bunraku", "renewal of hostilities in the Arab\u2013 Israeli conflict released the underlying economic pressure on oil prices", "the U.S. state of Kansas", "an anembryonic gestation", "Kelly Bundy", "vatican city", "keels", "the Queen's gaoler", "the exchange of genetic material between homologous chromosomes that results in recombinant chromosomes during sexual reproduction", "Jordan Norwood", "321,520", "June 12, 2017", "1996", "Denisovans", "kalapatthar crop.", "General Helmuth von Moltke, Chief of the German General Staff and Secretary of State for Home Affairs", "Shere Khan", "no conclusive evidence seems to exist", "2020 National Football League ( NFL ) season", "Selznick library", "les dennis", "Western Samoan Tala"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8517391304347826}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6956521739130435, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1035", "mrqa_hotpotqa-validation-5577", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-1917"], "fixed_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_squad-validation-19", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-825", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_squad-validation-5887", "mrqa_triviaqa-validation-1933"], "unfixed_ids": ["mrqa_triviaqa-validation-2965", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_triviaqa-validation-2525"], "instant_fixing_rate": 0.7857142857142857, "instant_retention_rate": 0.9999999975}, {"timecode": 60, "before_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "J. D. Salinger's novel \"The Catcher in the Rye\"", "The invading Normans and their descendants", "Merv", "Bendigo and its environs", "Thomas Jefferson", "She became a naturalized American citizen in 1994 and also received Hungarian citizenship in June 2007.", "July 1872", "the Boston and Maine Railroad's Southern Division", "James Lofton and Mark Malone as sideline reporters", "the left", "summer months", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts returned for their respective ninth, eighth, seventh and second series on The Ice Panel", "third \u00e9tude", "Thailand, Burma, Cambodia, Indonesia and Sri Lanka", "segues", "d Welsh poet Dylan Thomas", "tin and copper", "During the reign of King Beorhtric of Wessex ( 786 -- 802 ) three ships of `` Northmen '' landed at Portland Bay in Dorset", "South Australian town", "Flag Day in 1954", "50%", "In 1877 at Hooghly ( near Calcutta ) he instituted the use of fingerprints on contracts and deeds to prevent the then - rampant repudiation of signatures and he registered government pensioners'fingerprints", "Sexred", "Veronica Lodge", "neo-Nazi", "rik Mayall", "shrink in light of the successful landing, and NASA also had to make funds available for the development of the upcoming Space Shuttle. By 1971, the decision was made to also cancel missions 18 and 19.", "frequency f, wavelength \u03bb, or photon energy E.", "The story is a satire on corruption in the administration of criminal justice and the concept of the \"celebrity criminal\""], "metric_results": {"EM": 0.15625, "QA-F1": 0.32594498864686383}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.4347826086956522, 0.25, 0.6, 0.0, 0.0, 0.4, 0.0, 0.23529411764705882, 0.6666666666666666, 1.0, 0.0, 0.33333333333333337, 0.0, 0.17391304347826084, 1.0, 0.4444444444444445, 0.4, 0.5714285714285715, 0.0, 0.1904761904761905, 0.0, 1.0, 0.0, 0.06896551724137931, 0.0, 0.0, 1.0, 0.0, 0.358974358974359, 0.06666666666666667, 0.23529411764705882]}}, "error_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_hotpotqa-validation-949", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_squad-validation-2842", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_squad-validation-8492", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_triviaqa-validation-1284", "mrqa_squad-validation-4011", "mrqa_naturalquestions-validation-5798", "mrqa_hotpotqa-validation-3681"], "after_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark", "positions 14 - 15, 146 - 147 and 148 - 149", "The Catcher in the Rye", "Anglo-Saxons", "Mary", "Bendigo", "John Locke", "in 1994", "1872", "the Boston and Maine Railroad's Southern Division", "Boomer Esiason", "to the left of the dinner plate", "winter", "Jason Gardiner", "the third \u00e9tude", "Sri Lanka", "extensive use of segues", "dylan thomas", "iron age", "786 -- 802", "Hills", "Flag Day in 1954", "300,000", "In 1840", "S\u00e6ward", "Betty", "neo-Nazi", "thwaite", "shrink", "from 7023239999999999999 \u2660 2.4 \u00d7 10 Hz ( 1 GeV gamma rays ) down to the local plasma frequency of the ionized interstellar medium ( ~ 1 kHz )", "the \"celebrity criminal\""], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-425", "mrqa_hotpotqa-validation-1124", "mrqa_squad-validation-9053", "mrqa_naturalquestions-validation-6383", "mrqa_hotpotqa-validation-1971"], "fixed_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_hotpotqa-validation-949", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_squad-validation-2842", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_squad-validation-8492", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_squad-validation-4011", "mrqa_naturalquestions-validation-5798", "mrqa_hotpotqa-validation-3681"], "unfixed_ids": ["mrqa_triviaqa-validation-1284"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.9999999980000001}, {"timecode": 61, "before_eval": {"predictions": ["The Raigne of King Edward the Third", "john Hughes", "San Bernardino", "Judy Collins", "David Stenstrom", "the 2013 non-fiction book of the same name by David Finkel", "leapy luthor", "The Frost Report", "fell from his horse while hunting", "incitement to terrorism", "Henry and Liza", "historical figure", "Guadalupe Victoria", "oxygen", "Elk and Kanawha Rivers", "they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce", "'Bucks Point'", "to `` help bring creative projects to life ''", "Moses", "Old World fossil representatives", "in salts and never as the free elements", "Jonathan Daniel Hamm", "daniel smith", "thicker consistency and a deeper flavour than sauce", "Genetic sex", "neupommern", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "VH1's \"100 Greatest Artists of Hard Rock\"", "after AD 70", "1948", "electronic music", "when he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II"], "metric_results": {"EM": 0.125, "QA-F1": 0.2400252433969539}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "after_eval": {"predictions": ["Edward III", "shermer high school", "Riverside", "Glynis Johns", "1984 to 1985", "Fort Riley, Kansas", "little arrows", "Monty Python", "hunting", "incitement to terrorism", "two characters, called Henry and Liza", "first flume ride in Ireland", "Tamaulipas", "silicon", "Kanawha", "pinch in two", "'Bucks Point'", "global crowdfunding platform focused on creativity and merchandising", "mormon", "Old World fossil representatives", "group 1", "Jon Hamm", "sufjan stevens", "consistency", "biological sex", "papua new guinea", "L'Eglise du Saint-Esprit", "100 Greatest Artists of Hard Rock", "the empire fell", "1977", "kraftwerk", "report Hess's illegal May 1941 flight to Scotland"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1715", "before_prediction": "The Frost Report", "after_prediction": "Monty Python"}], "retained_ids": ["mrqa_squad-validation-9760", "mrqa_squad-validation-3115", "mrqa_hotpotqa-validation-2408"], "fixed_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "unfixed_ids": ["mrqa_naturalquestions-validation-9005"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 62, "before_eval": {"predictions": ["sleeps after it is separated from the body in death", "whiteness", "energy moves from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "the Monarch", "Canada", "Ballarat Bitter", "read therefore", "in Ricketts Glen State Park", "the song `` Can't Change Me, '' is as rhapsodically gorgeous as pop gets, putting a spin on true love that any reprobate slacker can relate to", "magma", "margaret hancock", "fee per unit of connection time", "the \"master builder\"", "In 1932 the German encyclopedia Knaurs Lexikon stated the length as 1,320 kilometres (820 miles) presumably a typographical error", "during the winter of the 2017 -- 18 network television season", "richest agricultural regions in the U.S. cattle and citrus were major industries until farmlands were turned into suburbs.", "Egypt", "Buzz Aldrin", "lorraine", "8.02 mi", "science", "during the production company vanity cards shown following the closing credits of most programs", "Kansas\u2013Nebraska Act of 1854", "2 Constant ( C\u03bc and C\u03b4 ) gene segments", "1910\u20131940", "11:28", "Start Here", "th Doctor Who", "Autobahn", "reproductive role", "Holberg", "poodle"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3802372685185185}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [0.19999999999999998, 1.0, 0.0, 1.0, 0.25, 0.4444444444444445, 0.125, 0.888888888888889, 0.14814814814814817, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.2222222222222222, 0.1111111111111111, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.1, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0]}}, "error_ids": ["mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-5396", "mrqa_squad-validation-7766", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_triviaqa-validation-3507", "mrqa_naturalquestions-validation-7270", "mrqa_triviaqa-validation-1698", "mrqa_squad-validation-4750", "mrqa_hotpotqa-validation-1510", "mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_squad-validation-3961", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_hotpotqa-validation-837", "mrqa_naturalquestions-validation-538", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_hotpotqa-validation-1692", "mrqa_triviaqa-validation-6254"], "after_eval": {"predictions": ["sleeps", "whiteness", "end", "the Monarch", "United Kingdom, Australia, Canada and the United States", "Ballarat Bitter is a 4.9% (abv) Australian beer, originally brewed in Ballarat, Australia by the Ballarat Brewing Company.", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "ricketts glen", "Can't Change Me", "magma", "hattie jacques", "fee per unit of information transmitted, such as characters, packets, or messages", "the \"master builder\" of mid-20th century New York City", "2010", "2017 -- 18 network television season on CBS and was the second U.S. Big Brother season to air outside the usual summer television season, the first being Big Brother 9 in 2008", "richest", "the Egyptian railway halt of El Alamein", "Neil Armstrong, Michael Collins and Buzz Aldrin", "moselle", "4145 ft above mean sea level", "intelligent design", "ABC on Demand to the beginning of the ABC show", "Kansas\u2013Nebraska Act", "V", "1910\u20131940", "11:28 left in the second quarter", "the upcoming 2007\u201308 season, \" Start Here\"", "master", "Radio-Activity", "endocrine ( hormonal ) systems and their physiological and behavioral effects, including gonadal differentiation, internal and external genital and breast differentiation, and differentiation of muscle mass, height, and hair distribution", "Baron of Holberg", "labradoodle"], "metric_results": {"EM": 0.75, "QA-F1": 0.8629328639251803}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.9600000000000001, 1.0, 1.0, 0.0689655172413793, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4878", "before_prediction": "lorraine", "after_prediction": "moselle"}, {"id": "mrqa_squad-validation-824", "before_prediction": "11:28", "after_prediction": "11:28 left in the second quarter"}, {"id": "mrqa_squad-validation-6026", "before_prediction": "Start Here", "after_prediction": "the upcoming 2007\u201308 season, \" Start Here\""}], "retained_ids": ["mrqa_squad-validation-9843", "mrqa_squad-validation-9570", "mrqa_squad-validation-4986", "mrqa_squad-validation-7440"], "fixed_ids": ["mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-5396", "mrqa_squad-validation-7766", "mrqa_naturalquestions-validation-6556", "mrqa_triviaqa-validation-3507", "mrqa_triviaqa-validation-1698", "mrqa_hotpotqa-validation-1510", "mrqa_squad-validation-9303", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_squad-validation-3961", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_hotpotqa-validation-837", "mrqa_naturalquestions-validation-538", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_hotpotqa-validation-1692", "mrqa_triviaqa-validation-6254"], "unfixed_ids": ["mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-7270", "mrqa_squad-validation-4750", "mrqa_naturalquestions-validation-8696", "mrqa_hotpotqa-validation-2057"], "instant_fixing_rate": 0.8, "instant_retention_rate": 0.571428570612245}, {"timecode": 63, "before_eval": {"predictions": ["Bank of China Tower", "heat addition (in the boiler) and rejection ( in the condenser)", "james kenasaki", "Operating System Principles", "Apr 23, 1564", "KKR & Co.", "fylde", "probabilistic (or \"Monte Carlo\" and deterministic algorithms", "Otis Redding", "eight days", "Hong Kong\u2013based, Cayman Islands registered Mandarin and Cantonese-language television broadcaster that serves the Chinese mainland and Hong Kong along with other markets with substantial Chinese viewers", "a narcissistic ex-lover who did the protagonist wrong", "catawba", "optical microscopy", "michael james brown", "james", "Sondheim", "the city of Strasbourg", "3", "the Iroquois Nations", "1993", "michael Foot", "ACL tears in his career, went down with a broken arm in the NFC Championship Game. Despite this, he insisted he would still find a way to play in the Super Bowl.", "malmullet", "mospondylus skull", "German", "2013", "belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "the boys in his class, led by Paul Baumer, are moved to join the army as the new 2nd Company", "31 - member Senate and a 150 - member House of Representatives", "whippoorwill", "orkneys"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12720338277944182}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.07407407407407407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 1.0, 0.0, 0.34146341463414637, 0.21052631578947367, 0.19999999999999998, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_triviaqa-validation-7598", "mrqa_squad-validation-5059", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_squad-validation-306", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "after_eval": {"predictions": ["Hong Kong", "constant pressure", "american family publishers", "use in the ARPANET", "William Shakespeare", "Kohlberg K Travis Roberts", "wyre", "deterministic algorithms", "Jimi Hendrix", "eight", "Phoenix Television", "Rihanna", "carowinds amusement park", "petrographic microscope", "mc hammer", "haitian revolution", "the cast members", "276,170 inhabitants", "2", "beads or shells", "Tian Tan Buddha", "guardian", "ACL tears", "castlebar", "jaw", "German", "1999", "their belief in the validity of the social contract", "Paul Baumer", "members", "edward hopper", "scotland"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-97", "before_prediction": "KKR & Co.", "after_prediction": "Kohlberg K Travis Roberts"}], "retained_ids": ["mrqa_hotpotqa-validation-4301"], "fixed_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_squad-validation-5059", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_squad-validation-306", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "unfixed_ids": ["mrqa_triviaqa-validation-7598", "mrqa_naturalquestions-validation-1533"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.4999999975}, {"timecode": 64, "before_eval": {"predictions": ["MTBF", "Jim Justice", "larvae", "Trey Parker and Matt Stone", "sukiyaki", "one of popular music's most poignant anthems of sorrow regarding the environment", "trial division", "consultant", "Preston, Lancashire, UK", "The Suite Life of Zack & Cody", "tuberculosis", "Saturn IB", "H. R. Haldeman", "brian baldwin", "inaugural award was made to John McCormick in 1972", "garter of the English Order of the Garter", "jaw", "badrutt's palace hotel", "charlie heen", "reform the lunisolar calendar to provide an accuracy of 365.2425 days of the year", "deadliest aviation accident to occur in India", "John Simm", "immediate judgement discrepancy, or cognitive bias, where a person making an initial assessment of another person, place, or thing will assume ambiguous information based upon concrete information", "New Orleans", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "macOS High Sierra", "Muhammad Ali", "trapezoid", "Diarmaid MacCulloch", "loire river", "17th Century sources referring to Cardinal Richelieu after he was named to head the royal council in 1624", "appropriates ( gives to, sets aside for ) money to specific federal government departments, agencies, and programs"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2519646684184321}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.16949152542372883, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.058823529411764705]}}, "error_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_squad-validation-4567", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_hotpotqa-validation-548", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_hotpotqa-validation-811", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "after_eval": {"predictions": ["bathtub", "the governor of West Virginia", "more like true larvae, as they live among the plankton and thus occupy a different ecological niche from their parents and attain the adult form by a more radical metamorphosis, after dropping to the sea-floor", "Kyle Broflovski, Eric Cartman, and Kenny McCormick", "sashimi", "sorrow regarding the environment", "Miller\u2013Rabin primality test", "consultant", "Preston", "The Suite Life of Zack & Cody", "bacillus calmette-gu\u00e9rin", "AS-205/208", "Rose Mary Woods", "bradley walsh", "Player of the Year", "saint george and the dragon raphael", "skull", "saint moritz", "charlie", "granaries were ordered built", "On March 27, 1977, two Boeing 747 passenger jets, KLM Flight 4805 and Pan Am Flight 1736, collided on the runway at Los Rodeos Airport (now Tenerife North Airport)", "John Simm", "when an individual noticing that the person in the photograph is attractive, well groomed, and properly attired, assumes, using a mental heuristic", "Speakeasies", "the final episode of the series", "macOS High Sierra, which was publicly released in September 2017", "kinshasa", "trapezium", "Diarmaid MacCulloch", "c\u00e9vennes", "1624", "continues the pre-existing appropriations at the same levels as the previous fiscal year ( or with minor modifications ) for a set amount of time"], "metric_results": {"EM": 0.8125, "QA-F1": 0.857112556561086}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.23529411764705882, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6923076923076924, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2542", "before_prediction": "Trey Parker and Matt Stone", "after_prediction": "Kyle Broflovski, Eric Cartman, and Kenny McCormick"}, {"id": "mrqa_triviaqa-validation-2173", "before_prediction": "tuberculosis", "after_prediction": "bacillus calmette-gu\u00e9rin"}], "retained_ids": ["mrqa_squad-validation-1312", "mrqa_hotpotqa-validation-4702", "mrqa_squad-validation-2560"], "fixed_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_hotpotqa-validation-548", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_hotpotqa-validation-811", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "unfixed_ids": ["mrqa_squad-validation-4567", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.5999999988}, {"timecode": 65, "before_eval": {"predictions": ["Territory of Colorado", "Arabic numerals as Super Bowl 50 as opposed to Super Bowl L", "Diary of a Wimpy Kid : The Long Haul", "four - letter suffix", "darius the Great", "serous pericardium", "Early Gothic", "Kentucky Derby", "verreaux sifaka", "The Boz", "1991", "DuMont Television Network", "Neyland Stadium in Knoxville, Tennessee", "due to Euler,", "2018", "henry is no longer alive", "apples", "gravitation", "nonconservative forces act to change the internal energies of the system", "scotland", "the applied force is opposed by static friction, generated between the object and the table surface", "sackerians", "sazerac whiskey", "\" Shut Up\"", "nahuatl", "Karina Smirnoff", "Seattle Seahawks", "St. Augustine", "four", "Private Mass", "dark blue", "mycelium"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2567307692307692}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6153846153846153, 0.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-2752", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-1923", "mrqa_squad-validation-5836", "mrqa_hotpotqa-validation-183", "mrqa_squad-validation-9021", "mrqa_naturalquestions-validation-1784", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_squad-validation-239", "mrqa_hotpotqa-validation-4174", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "after_eval": {"predictions": ["Cow Counties", "LI.", "Diary of a Wimpy Kid : The Long Haul", ". html", "pilgrimage", "heart", "Anglo-Saxon", "Kentucky Derby", "madagascar", "The Boz", "1991", "ABC-DuMont", "Birmingham, Alabama", "identity", "2020", "Isle of Man", "apple", "Gravity, or gravitation, is a natural phenomenon by which all things with mass are brought toward ( or gravitate toward ) one another, including objects ranging from atoms and photons, to planets and stars", "internal energies of the system", "bullfights", "the applied force is opposed by static friction, generated between the object and the table surface", "Sherlock Holmes", "rye", "\" Shut Up\"", "spanish", "Karina Smirnoff", "Arizona Cardinals", "St. Augustine", "one of the four founding members of the U-FLY Alliance", "a gift", "red", "mushroom"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8311999198717949}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-714", "mrqa_triviaqa-validation-3048", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-5505", "mrqa_hotpotqa-validation-875", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-5468"], "fixed_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_triviaqa-validation-2752", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-1923", "mrqa_squad-validation-5836", "mrqa_hotpotqa-validation-183", "mrqa_squad-validation-9021", "mrqa_naturalquestions-validation-1784", "mrqa_triviaqa-validation-5573", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_squad-validation-239", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "unfixed_ids": ["mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-4199", "mrqa_hotpotqa-validation-4174"], "instant_fixing_rate": 0.72, "instant_retention_rate": 0.9999999985714286}, {"timecode": 66, "before_eval": {"predictions": ["mustard", "to fund his Colorado Springs experiments", "the eastern shore of the Firth of Clyde, Scotland, at the north-western corner of the county of Ayrshire", "\"On the Computational Complexity of Algorithms\" by Juris Hartmanis and Richard Stearns (1965)", "from sea level and may vary depending on location", "Pandavas", "reduces that energy loss associated with hysteresis", "\"O\" theatre", "white rabbit", "South African Vice Consul Duke Kent-Brown", "O2", "pig", "apprenti", "better academic results", "Vanessa Block", "insano", "2p + 1 with p prime", "white", "raven", "http://www.example.com/index.html", "spanish", "`` Abigail ''", "two catechisms", "cheddar", "gases and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel", "Saint-Domingue", "disappearance during his return trip back to Wittenberg", "in 1963", "prokaryotic cell ( or organelle )", "Commissioners", "the traditional name or sometimes the Seven Years' War", "sattu"], "metric_results": {"EM": 0.15625, "QA-F1": 0.32078621779908545}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.125, 0.35294117647058826, 0.5882352941176471, 0.5, 1.0, 0.4444444444444445, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.28571428571428575, 0.0, 0.6153846153846154, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.07407407407407407, 1.0, 0.2222222222222222, 0.0, 0.4, 1.0, 0.13333333333333333, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_squad-validation-1853", "mrqa_squad-validation-10412", "mrqa_naturalquestions-validation-5927", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_squad-validation-7130", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_squad-validation-8980", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_squad-validation-2269", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "after_eval": {"predictions": ["tartare", "develop and produce a new lighting system", "Firth of Clyde", "\"On the Computational Complexity of Algorithms\"", "from sea level", "Raja Dhilu", "energy loss", "O", "eat me", "Duke Kent-Brown", "pure O", "man v food", "winklevoss twins depicted in the movie \"The Social Network\"", "produce better academic results", "Mitchell Block and Michael Sarnoski", "slide", "2p \u2212 1, where p is an arbitrary prime", "blue", "fox", "a protocol", "king george iv", "`` Shawn Takes a Shot in the Dark ''", "a theology of the cross", "mendip hills", "special training to ensure that ignition sources are minimized", "Saint-Domingue", "disappearance", "1976", "prokaryotic", "Commissioners", "Fourth Intercolonial War and the Great War for the Empire", "oven"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9201388888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6843", "before_prediction": "Pandavas", "after_prediction": "Raja Dhilu"}, {"id": "mrqa_squad-validation-2469", "before_prediction": "two catechisms", "after_prediction": "a theology of the cross"}], "retained_ids": ["mrqa_squad-validation-6945", "mrqa_hotpotqa-validation-1482", "mrqa_squad-validation-4300"], "fixed_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_squad-validation-1853", "mrqa_squad-validation-10412", "mrqa_naturalquestions-validation-5927", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_squad-validation-7130", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_squad-validation-8980", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_squad-validation-2269", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "unfixed_ids": ["mrqa_triviaqa-validation-3970"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.5999999988}, {"timecode": 67, "before_eval": {"predictions": ["high inequality goes hand-in-hand with weak labor movements and vice-versa", "port", "funk", "Sweden, Norway and Denmark", "Oscar II Land on the island of Spitsbergen in Svalbard, Norway", "desublimation", "a surname of Norman origin, deriving from the Norman given name Robert, meaning `` bright renown '' -- from the Germanic elements `` hrod '' meaning renown and `` beraht '' meaning bright", "Crossed: Badlands", "wonga", "Doctor of Philosophy", "1,388", "Otis Timson", "jack flash", "representatives appointed by governments and organizations", "$150,000 and $250,000 for primes with at least 100 million digits and 1 billion digits, respectively", "under the Kenya Independence Act 1963 of the United Kingdom", "Ohio", "first freshman to finish as the runner-up", "The Crowned Prince of the Philadelphia Mob", "\u201c Resign.\u201d", "romantic attraction, sexual attraction, or sexual behavior toward both males and females", "retained status superior to all others in health-related fields such as physicians and acupuncturists", "Big Eight Conference", "In the 1920s", "American", "Cleopatra VII Philopator", "The Butcher Brothers, also known as Mitchell Altieri and Phil Flores, who also directed the vampire film \"The Hamiltons\"", "fox", "philip and prejudice", "chloroplasts", "Salta, Chaco, Santa Fe, C\u00f3rdoba, Catamarca and Tucum\u00e1n", "265 million business records worldwide"], "metric_results": {"EM": 0.1875, "QA-F1": 0.33835345210345213}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.33333333333333337, 0.0, 0.0, 0.0, 0.4615384615384615, 1.0, 0.16, 0.0, 1.0, 0.5, 1.0, 0.0, 0.8, 0.16666666666666666, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.5714285714285715]}}, "error_ids": ["mrqa_squad-validation-7417", "mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4648", "mrqa_hotpotqa-validation-5297", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8526", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_naturalquestions-validation-1976", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_squad-validation-6327", "mrqa_hotpotqa-validation-3345", "mrqa_naturalquestions-validation-7089", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "after_eval": {"predictions": ["high inequality", "cyprus", "national parliaments", "Denmark\u2013 Norway\u2013Sweden", "island of Spitsbergen", "desublimation", "Norman origin", "the Vertigo series \"Preacher\"", "payday loans", "Doctor", "1,388", "Sarah's brother, Brian", "jumping jack flash", "government officials and climate change experts", "US$100,000", "1963", "Toledo", "freshman", "The Crowned Prince of the Philadelphia Mob", "Resign", "bisexual", "expressly defined in the Taih\u014d Code", "Pac-12 Conference", "the 1920s", "American", "Athenion", "Mean Girls", "john constable", "paris", "chromoplasts", "Salta", "265 million"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8571428571428572}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1385", "before_prediction": "wonga", "after_prediction": "payday loans"}, {"id": "mrqa_hotpotqa-validation-294", "before_prediction": "first freshman to finish as the runner-up", "after_prediction": "freshman"}], "retained_ids": ["mrqa_naturalquestions-validation-8643", "mrqa_squad-validation-4721", "mrqa_hotpotqa-validation-242", "mrqa_hotpotqa-validation-3626"], "fixed_ids": ["mrqa_squad-validation-7417", "mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4648", "mrqa_hotpotqa-validation-5297", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8526", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_naturalquestions-validation-1976", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-3345", "mrqa_naturalquestions-validation-7089", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "unfixed_ids": ["mrqa_hotpotqa-validation-5415", "mrqa_naturalquestions-validation-8911", "mrqa_squad-validation-6327", "mrqa_triviaqa-validation-3395"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.6666666655555555}, {"timecode": 68, "before_eval": {"predictions": ["Viceroyalty of New Spain", "Delaware", "jus sanguinis", "last starring role was as Boston police detective Barry Frost", "The King of Chutzpah", "P $ C", "energy", "tube", "English", "king Malcolm III", "the coffee shop Monk's", "upper bound", "american sitcom Friends", "the dot", "dieppe", "1961", "Tyler Posey", "New South Wales", "teaching", "parliaments", "paleontologists", "qualifications", "Laura Vallejo", "the final episode of the series", "2014 Sochi Games", "1939", "tolled ( quota ) highways", "redox", "eastern and interior Venezuela and the llanos of Colombia", "tsar", "Lagos", "conservative"], "metric_results": {"EM": 0.34375, "QA-F1": 0.3482142857142857}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_triviaqa-validation-4485", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8791", "mrqa_triviaqa-validation-2723", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-339", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_squad-validation-2052", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_naturalquestions-validation-921", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_triviaqa-validation-3089", "mrqa_naturalquestions-validation-2632"], "after_eval": {"predictions": ["1535", "Delaware", "Italian nationality law", "Lee Thompson Young", "The King of Chutzpah", "P $ C featuring T.I. & Lil Scrappy, Mike Jones featuring Nicole Wray, Trillville, Juvenile featuring Skip & Wacko, Nasty Nardo, 8Ball & MJG, Lil", "energy", "district line", "English", "london", "Monk's", "the time complexity of a problem", "green", "the dot", "Dieppe", "East Germany ), starting on ( by land ) West Berlin from virtually all of surrounding East Germany and East Berlin until government officials opened it in November 1989", "Dylan O'Brien", "New South Wales", "hard-to-fill positions", "shaolin", "dinosaur wars", "qualifications", "Laura Vallejo", "the final episode of the series", "curling", "1939", "autopistas, or tolled ( quota ) highways", "Rust is an iron oxide, a usually red oxide formed by the redox reaction of iron and oxygen in the presence of water or air moisture.", "South America", "russia", "approximately one year after Ultron's defeat in the nation of Sokovia at the hands of the Avengers", "conservative"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7899101645985518}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.8936170212765957, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.08695652173913045, 0.8, 1.0, 0.896551724137931, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1784", "before_prediction": "upper bound", "after_prediction": "the time complexity of a problem"}], "retained_ids": ["mrqa_hotpotqa-validation-1536", "mrqa_squad-validation-8626", "mrqa_squad-validation-7076", "mrqa_squad-validation-5777", "mrqa_triviaqa-validation-5185", "mrqa_squad-validation-2843", "mrqa_squad-validation-9493", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-2969", "mrqa_hotpotqa-validation-4275"], "fixed_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_triviaqa-validation-2723", "mrqa_triviaqa-validation-6896", "mrqa_triviaqa-validation-6302", "mrqa_hotpotqa-validation-1145", "mrqa_squad-validation-2052", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_hotpotqa-validation-2867", "mrqa_triviaqa-validation-3089"], "unfixed_ids": ["mrqa_triviaqa-validation-4485", "mrqa_naturalquestions-validation-8791", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-2632"], "instant_fixing_rate": 0.5714285714285714, "instant_retention_rate": 0.9090909082644627}, {"timecode": 69, "before_eval": {"predictions": ["Eisenhower Freeway", "Albert Einstein", "music became more expressive and emotional", "temperature profiles within the crust, the uplift of mountain ranges, and paleotopography", "North Kest even, Lincolnshire, England", "the Ming", "on a stretch of Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "Muhammad ibn Zakar\u012bya R\u0101zi", "Hellenismos", "the buttock and down the lower limb", "the German and UK Kennel Clubs", "unknown", "tea, horticultural produce, and coffee", "Barclays", "Joanna Cassidy as Rose Lindsey", "Red : The blood spilled by the heroes who died in the name of their countrymen's Fatherland and Freedom", "island agent", "break off the cathode", "Silver Gallery", "21.8 %", "higher than normal O2 exposure for a fee", "Yuan dynasty was the first time that non-native Chinese people ruled all of China", "Tony Orlando and Dawn", "within portions of several communes 25 km to the northeast of Paris", "parliaments", "Martha Wainwright", "1,462", "island island", "the 10th or 11th century, West Norse sailors explored and briefly settled on the shores of present - day Canada, according to Icelandic Sagas, but violent conflicts with the indigenous population ultimately led to the Norse abandoning those settlements", "parliaments", "north-wind", "1698"], "metric_results": {"EM": 0.09375, "QA-F1": 0.19945400035014005}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.25, 0.08333333333333333, 0.0, 0.6666666666666665, 0.0, 0.8125, 0.0, 0.0, 0.0, 0.0, 0.09523809523809523, 1.0, 0.0, 0.5714285714285715, 0.1, 0.0, 0.0, 0.4, 0.2857142857142857, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8645", "mrqa_naturalquestions-validation-8059", "mrqa_squad-validation-4929", "mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-6949", "mrqa_squad-validation-6464", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_naturalquestions-validation-3035", "mrqa_squad-validation-3610", "mrqa_squad-validation-8185", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_triviaqa-validation-5088", "mrqa_hotpotqa-validation-1381"], "after_eval": {"predictions": ["State Route 41", "Max Planck, Albert Einstein, Louis de Broglie, Arthur Compton, Niels Bohr and many others", "a dramatic expansion in the size of the orchestra and in the dynamic range and diversity of instruments used in this ensemble", "Thermochemical techniques", "North Kest even, Lincolnshire, England", "Qing", "on a stretch of Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "Abu al-Qasim al-Zahrawi", "Hellenic polytheist", "on the posterior aspect", "The long - hair gene is recessive", "author of the tune is unknown and it may originate in plainchant, but a 1619 attribution to John Bull is sometimes made", "tea, horticultural produce, and coffee", "foreign exchange", "Robert Hy Gorman as Walter Crandell", "Yellow : The crops and the fertile soil.", "lost in translation", "physically strike him", "silverware", "approximately 21.8 % of the world's population", "mild euphoric", "a period of foreign domination", "Irwin Levine and L. Russell Brown and produced by Hank Medress and Dave Appell, with Motown / Stax backing vocalist Telma Hopkins, Joyce Vincent Wilson and her sister Pamela Vincent on backing vocals", "France", "pete seeger", "Gary Lightbody", "hypermarket chain", "bhutan", "European colonization", "paul dukas", "boreas", "since 1864"], "metric_results": {"EM": 0.8125, "QA-F1": 0.9121529854465709}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2862", "before_prediction": "Tony Orlando and Dawn", "after_prediction": "Irwin Levine and L. Russell Brown and produced by Hank Medress and Dave Appell, with Motown / Stax backing vocalist Telma Hopkins, Joyce Vincent Wilson and her sister Pamela Vincent on backing vocals"}, {"id": "mrqa_hotpotqa-validation-37", "before_prediction": "1,462", "after_prediction": "hypermarket chain"}], "retained_ids": ["mrqa_squad-validation-8304"], "fixed_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8645", "mrqa_naturalquestions-validation-8059", "mrqa_squad-validation-4929", "mrqa_naturalquestions-validation-7910", "mrqa_squad-validation-6464", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_squad-validation-3610", "mrqa_squad-validation-8185", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_triviaqa-validation-5088", "mrqa_hotpotqa-validation-1381"], "unfixed_ids": ["mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-3035"], "instant_fixing_rate": 0.8620689655172413, "instant_retention_rate": 0.3333333322222222}, {"timecode": 70, "before_eval": {"predictions": ["paratroopers", "The New York and New Jersey campaign", "February 28, 2018", "near the end of his life, Tesla walked to the park every day to feed the pigeons and even brought injured ones into his hotel room to nurse back to health.", "Victorian plants", "cordovan leather", "Guthred", "1973", "produced by Walt Disney Animation Studios", "a loanword of the Visigothic word guma `` man ''", "Major General Miles Francis Stapleton Fitzalan-Howard, 17th Duke of Norfolk,", "Hebrew Alephbet", "from their June 2011 Milton Keynes performances, Australian and New Zealand tour", "chromium", "blue", "Cape Cod", "derived from the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s", "82.30'E longitude, in Mirzapur, Uttar Pradesh, which is nearly on the corresponding longitude reference line", "a \"theo-democracy\" based on the principles of: tawhid (unity of God) risala (prophethood) and khilafa (caliphate)", "Salman Khan", "Skip Tyler", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything '", "WBMA-LD", "two Nobel Peace Prizes", "whiskey", "physically strike him", "king james", "thirty articles affirming an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "force arising from an interaction as occurring at the vertex with an associated instantaneous change in the direction of the particle world lines", "Newton", "International Imitation Hemingway Competition", "Smith's Cove"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3332214528333663}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.19354838709677416, 0.0, 0.0, 0.5, 0.0, 0.0, 0.2857142857142857, 0.7499999999999999, 0.6666666666666666, 0.9565217391304348, 1.0, 0.0, 0.0, 0.10526315789473685, 0.4761904761904762, 0.35294117647058826, 0.0, 1.0, 0.08, 1.0, 1.0, 0.0, 0.0, 0.8, 0.2105263157894737, 0.0, 0.0, 0.28571428571428575, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_squad-validation-1632", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_naturalquestions-validation-710", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_triviaqa-validation-672", "mrqa_hotpotqa-validation-4323", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_naturalquestions-validation-7938", "mrqa_squad-validation-10477", "mrqa_squad-validation-361", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-2229"], "after_eval": {"predictions": ["jack higgins", "The New York and New Jersey campaign", "Ghost Island", "his hotel room", "car", "shoes", "Guthred or Guthfrith", "1972", "2013", "man", "Miles Fitzalan-Howard, 17th Duke of Norfolk", "boston", "their June 2011 Milton Keynes performances, Australian and New Zealand tour", "chromium", "blue", "Los Angeles, California", "the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s", "82.30'E longitude, in Mirzapur, Uttar Pradesh", "unity of God", "Sajjad Delafrooz", "Skip Tyler", "Latin : liberalis, `` worthy of a free person ''", "WBMA-LD", "two", "jack daniels", "he could feel a sharp stinging pain where it entered his body", "king james vi", "consists of thirty articles affirming an individual's rights", "straight", "Von Miller", "The Bad Hemingway Contest", "Oak Island"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8777149321266968}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7999999999999999, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4356", "before_prediction": "two Nobel Peace Prizes", "after_prediction": "two"}], "retained_ids": ["mrqa_hotpotqa-validation-4939", "mrqa_triviaqa-validation-6740", "mrqa_hotpotqa-validation-3270", "mrqa_squad-validation-5981"], "fixed_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_squad-validation-1632", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_naturalquestions-validation-710", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_naturalquestions-validation-4567", "mrqa_hotpotqa-validation-4323", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_squad-validation-10477", "mrqa_squad-validation-361", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-2229"], "unfixed_ids": ["mrqa_triviaqa-validation-2331", "mrqa_triviaqa-validation-672", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_naturalquestions-validation-7938"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 71, "before_eval": {"predictions": ["John D. Rockefeller", "42", "electrical, water, sewage, phone, and cable", "Saxe-Coburg and Gotha", "16,000", "no known case of any U.S. citizens buying Canadian drugs", "Dwight D. Eisenhower", "multi-purpose", "Khitan Liao and Jurchen Jin", "twelve", "Henley Royal Regatta", "Randal Keith Orton", "RuPaul", "as a liquid", "Sunday", "October 16, 2012", "Austria", "1996", "alpha efferent neurons", "antlers", "David Irving", "cabbage", "bop-A-Lula", "Yuan Dynasty", "heptathlon", "1565", "rapid expansion in telecommunication and financial activity", "king walley Scott", "Hugh Dickson", "Libertarianism", "london", "R&B"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3040932158119658}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.625, 0.1111111111111111, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-253", "mrqa_hotpotqa-validation-862", "mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_squad-validation-8291", "mrqa_naturalquestions-validation-2635", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-3689", "mrqa_hotpotqa-validation-5203", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "after_eval": {"predictions": ["oil magnate and wealthiest man in history John D. Rockefeller", "29", "electrical, water, sewage, phone, and cable", "Ernestine", "1,100", "There is no known case", "34th", "FieldTurf", "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "Ben Helm, Esq.", "Randy Orton", "Sam Waterston", "special insulated tankers", "Sunday evenings", "October 16, 2012", "Czech Republic", "2012, during a preseason exhibition game held in Sassari, Italy", "Somatic motor neurons", "velvet", "David Irving", "mark twain", "Gene Vincent", "Zhu Di", "king\u00a0 Gustav V of Sweden", "never contained the element lead", "tremendous growth in the service sector", "walter scott", "Lilian Bellamy", "political", "john key", "American R&B vocal group"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8779647435897435}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7849", "before_prediction": "John D. Rockefeller", "after_prediction": "oil magnate and wealthiest man in history John D. Rockefeller"}, {"id": "mrqa_triviaqa-validation-6938", "before_prediction": "Henley Royal Regatta", "after_prediction": "Ben Helm, Esq."}, {"id": "mrqa_hotpotqa-validation-4911", "before_prediction": "Sunday", "after_prediction": "Sunday evenings"}, {"id": "mrqa_squad-validation-8401", "before_prediction": "rapid expansion in telecommunication and financial activity", "after_prediction": "tremendous growth in the service sector"}], "retained_ids": ["mrqa_squad-validation-7123", "mrqa_squad-validation-173", "mrqa_hotpotqa-validation-5162"], "fixed_ids": ["mrqa_hotpotqa-validation-253", "mrqa_hotpotqa-validation-862", "mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_squad-validation-8291", "mrqa_naturalquestions-validation-2635", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_hotpotqa-validation-5203", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "unfixed_ids": ["mrqa_squad-validation-3689", "mrqa_triviaqa-validation-237"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.4285714279591837}, {"timecode": 72, "before_eval": {"predictions": ["Monk's Caf\u00e9", "The tradition of gift - giving is an old one, but it became associated with Christmas more recently. It is a relic of a pagan custom, namely, the winter solstice which in Europe occurs in December", "fourth-level Republican leader", "Nobel Prize seven", "Boolean satisfiability problem", "Operation Neptune", "john f kenna", "Patrick Moore", "alpaca fiber and mohair from Angora goats", "Muskogean", "Symbolic interactionism", "Long Island", "gesture in which the head is tilted in alternating up and down arcs along the sagittal plane", "Danny Concannon on the television series \"The West Wing\"", "snow and rain", "the Channel 4 game show \" Fifteen to One\"", "# 4 School of Public Health", "shottery", "marine mammals", "1883\u201384", "yellow", "Les Surfs", "fox river", "Freguesia de Nossa Senhora de F\u00e1tima", "produce \"de novo\"", "morrissey", "boeing", "satirical erotic romantic comedy", "Greg", "1750", "Puente Hills Mall, located in the City of Industry, California, United States", "l'Arc de triomphe"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18858719405594404}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false], "QA-F1": [0.4, 0.20512820512820512, 0.5, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.125, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30769230769230765, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_hotpotqa-validation-5478", "mrqa_squad-validation-3592", "mrqa_hotpotqa-validation-2192", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_naturalquestions-validation-3638", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "after_eval": {"predictions": ["Monk's Caf\u00e9", "in ancient Rome with gift - giving during the Saturnalia holiday", "the fourth-ranking Republican leader in the House", "Nobel Prize", "the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem", "the Battle of Iwo Jima", "runnymede", "xylophone", "hair, hair / fur ( including wool ) and feathers", "Apalachee", "Identity Theory", "the fictional town of West Egg on prosperous Long Island", "a gesture", "\"Field of Dreams\"", "temperatures", "Parliament", "# 4", "anne Hathaway", "narwhals", "1884", "trees", "A Pr\u00e9sent Tu Peux t'en Aller", "wis", "Macau, China", "divide", "smiths", "1969", "satirical erotic romantic comedy", "Melanie Owen", "who operated in Tennessee, Kentucky, Illinois, and Mississippi, in the late eighteenth century.", "Puente Hills Mall, located in the City of Industry, California, United States", "longchamp"], "metric_results": {"EM": 0.875, "QA-F1": 0.9305689102564103}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1760", "before_prediction": "Boolean satisfiability problem", "after_prediction": "the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem"}], "retained_ids": ["mrqa_hotpotqa-validation-3252", "mrqa_naturalquestions-validation-4018"], "fixed_ids": ["mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_hotpotqa-validation-5478", "mrqa_squad-validation-3592", "mrqa_hotpotqa-validation-2192", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_naturalquestions-validation-3638", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "unfixed_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-1507"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 73, "before_eval": {"predictions": ["to the northwest", "abraham", "light energy", "Boston", "Medal of Honor", "nearly 8 km from the Swedish coast to the artificial island Peberholm in the middle of the strait", "The Future", "1969", "epic historical drama", "Wahhabist", "buzzards", "drug management system development, deployment and optimization", "that first set of endosymbiotic events", "Danish pronunciation : ( \u02c8\u0251n\u0250sn\u0329 )", "Edward Trowbridge Collins Sr.", "November 2014", "when a country's influence is felt in social and cultural circles", "increased productivity, trade, and secular economic trends", "purple rain", "the 1890s", "April 24, 1905", "Soviet Union and Japan to form a Eurasian panregion", "200\u2013300", "his mind", "forces that act on one part of an object", "an alternate, but rarely used unit of mass", "the \" Polovtsian Dances\"", "belfast", "the government - owned Panama Canal Authority", "Vernier, Switzerland", "xylwig Buschmann", "\"The Today Show\""], "metric_results": {"EM": 0.1875, "QA-F1": 0.3573182026307027}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.9090909090909091, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.3846153846153846, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9043", "mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-3407"], "after_eval": {"predictions": ["northwest", "ishmael", "light", "Boston", "Native American tribes", "8 km", "The Future", "july 20", "film", "Saudi", "wake", "medication management system development, deployment and optimization", "first set of endosymbiotic events", "a Danish - Norwegian patronymic surname meaning `` son of Anders '' ( itself derived from the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew )", "Edward Trowbridge Collins Sr.", "Microsoft Windows, PlayStation 4, and Xbox One in September 2014", "soft power", "telecommunications, pharmaceuticals, aircraft, heavy machinery and other industries along with declines in low end, low skill industries such as clothing, toys, and other simple manufacturing", "a love song", "After World War I", "1947", "Deputy F\u00fchrer", "single", "all in his mind", "three-dimensional objects", "kilopond", "\"Polovetskie plyaski\"", "british", "government - owned Panama Canal Authority", "Vernier, Switzerland", "accordion", "\"PM Magazine\""], "metric_results": {"EM": 0.78125, "QA-F1": 0.8418133340830709}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.14814814814814814, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.3846153846153846, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7642", "before_prediction": "purple rain", "after_prediction": "a love song"}, {"id": "mrqa_hotpotqa-validation-4284", "before_prediction": "the \" Polovtsian Dances\"", "after_prediction": "\"Polovetskie plyaski\""}], "retained_ids": ["mrqa_squad-validation-139", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-1181", "mrqa_hotpotqa-validation-4383"], "fixed_ids": ["mrqa_squad-validation-9043", "mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-3407"], "unfixed_ids": ["mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-9530", "mrqa_hotpotqa-validation-2567", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753"], "instant_fixing_rate": 0.8076923076923077, "instant_retention_rate": 0.6666666655555555}, {"timecode": 74, "before_eval": {"predictions": ["the Gulf of Mexico and stretches to the tip of Florida", "Friedrich Nietzsche", "udora Welty", "Anglo-Frisian languages group", "waltham forest borough", "narrogen", "j. M. Coetzee", "DeWayne Warren", "2.01 ft", "smiths", "George Merrill and Shannon Rubicam of the band Boy Meets Girl", "Independence, Missouri", "In 1943, at the peak of World War II", "translation of the Old Testament", "wai Momi", "a \"consulting fee\" to get around Tesla's aversion to accept charity", "religious organizations or private individuals", "tolerance of civil disobedience", "ed Miliband", "China", "film scripts written by ghost writers, nonfiction books on military subjects, and video games", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s, with its coastal areas north from the Columbia River frequented by ships from all nations engaged in the maritime fur trade", "Instagram's own account", "Karlheinz Stockhausen", "1986", "beauty", "1922", "gluons", "the Apostles' Creed", "April 13, 2018", "smiths", "business magnate, investor, and philanthropist"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1993416305916306}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.4, 0.2222222222222222, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.1142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_triviaqa-validation-6002", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_naturalquestions-validation-3188", "mrqa_squad-validation-2371", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_naturalquestions-validation-9487", "mrqa_squad-validation-801", "mrqa_hotpotqa-validation-4964", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "after_eval": {"predictions": ["Atlantic ocean", "Richard Strauss", "wisbur", "Germanic", "bishopsgate", "new Jersey", "literature", "DeWayne Warren", "weir", "madonna", "written by George Merrill and Shannon Rubicam of the band Boy Meets Girl", "connected Independence, Missouri with Santa Fe, New Mexico", "1943", "translation", "hawaii", "paying his rent", "endowments", "non-violence", "ed Miliband", "East India Company", "novel", "British", "Selena Gomez", "hardcore", "1990", "legend", "23 December 2014", "as gluons", "German", "March 23, 2018", "shrek", "business"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6794", "before_prediction": "tolerance of civil disobedience", "after_prediction": "non-violence"}], "retained_ids": ["mrqa_naturalquestions-validation-9508", "mrqa_triviaqa-validation-4614"], "fixed_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_naturalquestions-validation-3188", "mrqa_squad-validation-2371", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_naturalquestions-validation-9487", "mrqa_squad-validation-801", "mrqa_hotpotqa-validation-4964", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "unfixed_ids": ["mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 75, "before_eval": {"predictions": ["in the first RFC published on the TCP protocol", "Andrea Palladio", "Eric Clapton", "Gaahl", "darts", "AMX - 50", "king james iv", "author Studs Terkel", "Persian Gulf", "1898", "a bronze statue designed by Thomas Crawford", "1963", "23 November 1963", "34", "\"Limbo\" is a 2D side-scrollers", "the state legislators of Assam", "350", "Gothic", "russia", "scrolls", "Environmental Protection Agency", "325", "tube", "Cher", "one person", "Luger P08", "Islamic prophet Muhammad", "Babur", "wis", "in mid-August and continues through mid-September", "manned", "spainair"], "metric_results": {"EM": 0.28125, "QA-F1": 0.36663690476190475}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.1111111111111111, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.4, 0.3333333333333333, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08, 0.5, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8685", "mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_hotpotqa-validation-4407", "mrqa_naturalquestions-validation-4619", "mrqa_hotpotqa-validation-1689", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4413", "mrqa_triviaqa-validation-1199", "mrqa_naturalquestions-validation-2006", "mrqa_squad-validation-3775", "mrqa_hotpotqa-validation-2646"], "after_eval": {"predictions": ["around the time when ARPANET was interlinked with NSFNET in the late 1980s", "Sir Christopher Wren", "Bert Jansch", "Kristian Eivind Espedal", "7", "Atelier de Construction d'Issy - Les - Moulineaux", "county of northumberland", "Studs Terkel", "qatar", "1902", "The Statue of Freedom", "1963", "17:16:20 GMT", "34 percent of the city's total population", "Limbo", "state legislatures", "350 government officials and climate change experts", "two to three barrel vaults", "napoleon", "scrolls dating back to the 12th century", "EPA", "325", "central line", "Goddess of Pop", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Luger P08", "Al-Masjid an-Nabaw\u012b", "The `` classic period '' of the Mughal Empire started in 1556 with the ascension of Akbar the Great to the throne", "magdalene laundries", "at night, allowing them to find their direction from the stars and orient themselves by detecting the Earth's magnetic field", "sequence", "SAS Group"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8332862350132086}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 0.0, 1.0, 0.918918918918919, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-551", "before_prediction": "Eric Clapton", "after_prediction": "Bert Jansch"}, {"id": "mrqa_squad-validation-7732", "before_prediction": "23 November 1963", "after_prediction": "17:16:20 GMT"}, {"id": "mrqa_squad-validation-683", "before_prediction": "34", "after_prediction": "34 percent of the city's total population"}, {"id": "mrqa_squad-validation-8525", "before_prediction": "350", "after_prediction": "350 government officials and climate change experts"}, {"id": "mrqa_naturalquestions-validation-4646", "before_prediction": "one person", "after_prediction": "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control"}, {"id": "mrqa_naturalquestions-validation-6482", "before_prediction": "Babur", "after_prediction": "The `` classic period '' of the Mughal Empire started in 1556 with the ascension of Akbar the Great to the throne"}], "retained_ids": ["mrqa_hotpotqa-validation-5643", "mrqa_squad-validation-903", "mrqa_hotpotqa-validation-4576"], "fixed_ids": ["mrqa_naturalquestions-validation-8685", "mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_hotpotqa-validation-4407", "mrqa_naturalquestions-validation-4619", "mrqa_hotpotqa-validation-1689", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4413", "mrqa_triviaqa-validation-1199", "mrqa_squad-validation-3775", "mrqa_hotpotqa-validation-2646"], "unfixed_ids": ["mrqa_naturalquestions-validation-2006"], "instant_fixing_rate": 0.9565217391304348, "instant_retention_rate": 0.3333333329629629}, {"timecode": 76, "before_eval": {"predictions": ["Tampa Bay defensive end Simeon Rice sacked Raiders quarterback Rich Gannon on third down, forcing Oakland to settle for kicker Sebastian Janikowski's 40 - yard field goal to give them a 3 -- 0 lead", "2010", "many bands, including a 1990 single by Saint Etienne", "novelization", "9 November 1967", "Colonization movement or Black Zionism", "The House is composed of Representatives who sit in congressional districts that are allocated to each of the 50 states on a basis of population as measured by the U.S. Census, with each district entitled to one representative", "trees", "The Boy in the Striped Pyjamas", "Conrad Lewis, a Canadian electrical engineer with two legally blind sisters", "fourteen", "Thrifty Automotive Group", "2013", "Medicaid", "Christian Goldbach", "Grease", "The Sudan or Sudan (, ; Arabic: \u0627\u0644\u0633\u0648\u062f\u0627\u0646 \u200e \"as-S\u016bd\u0101n\" ) also known as North Sudan since South Sudan's independence and officially the Republic of the Sudan", "federal government's nearly 700 million acres ( 2,800,000 km ) of subsurface mineral estate located beneath federal, state and private lands severed from their surface rights by the Homestead Act of 1862", "be reborn", "Bhpppavageete", "a heart rate that exceeds the normal resting rate", "\"Pluto\"", "his fellow actor, Richard Burbage, the leading tragedian of Shakespeare's time", "a type of \"blood poisoning\"", "Parliament", "achievement-oriented motivations", "discarded", "A Song of Ice and Fire", "You're the One for Me Fatty", "Fresh Fields is a British situation comedy written by John Roy Chapman and produced by Thames Television for ITV between 1984 and 1986.", "15 February 1998", "Twitch Interactive, a subsidiary of Amazon.com"], "metric_results": {"EM": 0.3125, "QA-F1": 0.350156009984639}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.05714285714285715, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.06451612903225806, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666669, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_hotpotqa-validation-3678", "mrqa_naturalquestions-validation-6258", "mrqa_squad-validation-9014", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-2550", "mrqa_naturalquestions-validation-6027", "mrqa_hotpotqa-validation-4510", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-956", "mrqa_naturalquestions-validation-2270", "mrqa_triviaqa-validation-7099", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591", "mrqa_hotpotqa-validation-4791"], "after_eval": {"predictions": ["Brad Johnson", "2018", "Neil Young", "film", "9 November 1967", "The Back-to- Africa movement", "Representatives", "mulberry", "Anomalisa", "2006", "fourteen", "Hertz", "2013", "Medicaid", "Leonhard Euler", "Grease", "buff-tipped skipper", "247.3 million", "reborn", "Shukratara", "Tachycardia", "The Bomb Factory", "derived from the legend of Amleth, preserved by 13th - century chronicler Saxo Grammaticus in his Gesta Danorum", "a type of \"blood poisoning\"", "Parliament", "achievement-oriented motivations", "discarded", "A Song of Ice and Fire", "morrissey", "fresh fields", "1994", "Amazon.com"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8635416666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5027", "before_prediction": "Colonization movement or Black Zionism", "after_prediction": "The Back-to- Africa movement"}, {"id": "mrqa_squad-validation-1927", "before_prediction": "be reborn", "after_prediction": "reborn"}], "retained_ids": ["mrqa_hotpotqa-validation-3337", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-1314", "mrqa_squad-validation-5031", "mrqa_squad-validation-9547", "mrqa_squad-validation-7323", "mrqa_squad-validation-3885", "mrqa_hotpotqa-validation-3634"], "fixed_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_hotpotqa-validation-3678", "mrqa_squad-validation-9014", "mrqa_hotpotqa-validation-2550", "mrqa_naturalquestions-validation-6027", "mrqa_hotpotqa-validation-4510", "mrqa_hotpotqa-validation-956", "mrqa_triviaqa-validation-7099", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591", "mrqa_hotpotqa-validation-4791"], "unfixed_ids": ["mrqa_naturalquestions-validation-6258", "mrqa_hotpotqa-validation-3232", "mrqa_naturalquestions-validation-10131", "mrqa_naturalquestions-validation-2270"], "instant_fixing_rate": 0.8181818181818182, "instant_retention_rate": 0.7999999992}, {"timecode": 77, "before_eval": {"predictions": ["New York Knickerbockers", "100-meter freestyle", "two previously unknown but related clades (genetic branches) of the Y. pestis genome associated with medieval mass graves", "east-west through the centre of Victoria", "four", "central", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "lofsongur", "island of islay", "troposphere", "central America", "The Fixx", "It is located on the eastern shore of Lake Fagnano, in the southern part of the Isla Grande de Tierra del Fuego.", "The Swiss Express", "the contrary idea that Islam is, or can be, apolitical is an error", "graphology", "quotient", "Matilda of Anjou", "K-pop artists After School, Orange Caramel, NU'EST, Han Dong Geun, Kye Bumzu, Seventeen and Pristin.", "Jack", "at any time after the auction", "north of this circle is known as the Arctic, and the zone just to the south is called the Northern Temperate Zone", "The show focuses on the original and founding ( `` mother '' ) charter, Sons of Anarchy Motorcycle Club, Redwood Original, referred to by the acronym SAMCRO or Sam Crow", "central Liverpool", "Great Yuan", "Song Il-gon", "1974", "Acura", "dangerous by-products of oxygen use in organisms. Parts of the immune system of higher organisms create peroxide, superoxide, and singlet oxygen to destroy invading microbes.", "food and clothing", "The Emperor of Japan", "naturally produced in the human body from the amino acids glycine and arginine"], "metric_results": {"EM": 0.25, "QA-F1": 0.3612937894691927}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.21052631578947367, 0.33333333333333337, 1.0, 0.0, 0.07407407407407407, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.125, 0.0, 0.2857142857142857, 0.125, 0.7894736842105263, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.45161290322580644, 0.0, 1.0, 0.16666666666666669]}}, "error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_squad-validation-4961", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_triviaqa-validation-6204", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-686"], "after_eval": {"predictions": ["New York Knickerbockers", "100-meter freestyle", "genetic branches", "east-west", "four times in the United States ( in 1932, 1960, 1980 and 2002 ) ; three times in France ( in 1924, 1968 and 1992 ) ; and twice each in Austria", "Wellington", "Indo - Pacific", "iceland", "islay", "troposphere", "greater antilles", "new wave rock band The Fixx", "1,382", "Forrest Gump", "Scholars and observers who don't believe that Islam is merely a political ideology", "handwriting", "quotient", "William Adelin", "Seventeen", "Timmy Sanders", "at any time after the auction but for strategic reasons it is best to do so at the conclusion of play so as not to give the opponents information about the lay of the cards", "most northerly of the five major circles of latitude as shown on maps of Earth", "Sons of Anarchy Motorcycle Club, Redwood Original, referred to by the acronym SAMCRO or Sam Crow", "liverpool", "\u5143\u671d", "Song Il-gon", "1974", "honda", "dangerous by-products of oxygen use in organisms. Parts of the immune system of higher organisms create peroxide, superoxide, and singlet oxygen to destroy invading microbes.", "sugarcane", "Masahiko Takeshita", "glycine"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8727667493796526}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7390", "before_prediction": "four", "after_prediction": "four times in the United States ( in 1932, 1960, 1980 and 2002 ) ; three times in France ( in 1924, 1968 and 1992 ) ; and twice each in Austria"}, {"id": "mrqa_hotpotqa-validation-1237", "before_prediction": "The Emperor of Japan", "after_prediction": "Masahiko Takeshita"}], "retained_ids": ["mrqa_naturalquestions-validation-70", "mrqa_triviaqa-validation-6883", "mrqa_triviaqa-validation-7615", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-2622", "mrqa_hotpotqa-validation-3732"], "fixed_ids": ["mrqa_squad-validation-4961", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_triviaqa-validation-6204", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-7610", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-686"], "unfixed_ids": ["mrqa_triviaqa-validation-6483", "mrqa_squad-validation-9520", "mrqa_squad-validation-3543"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.7499999990624999}, {"timecode": 78, "before_eval": {"predictions": ["21 June 2007", "healthcare professionals with specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "morgan", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic", "crim", "Anne of Green Gables", "hip joint", "votex", "lager", "east end", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1484", "T cells ( for cell - mediated, cytotoxic adaptive immunity ), and B cells", "written by a combination of electronic sound sources, live instrumental playing and digital signal processing", "1814", "101.325 kPa", "\u5927\u5143", "Gap", "The Indianapolis Times and the Cleveland Press", "Jurchen Aisin Gioro clan in Manchuria", "mortadella", "Fort Frontenac on the north shore of Lake Ontario", "friendship", "86.66% (757.7 sq mi or 1,962 km2) is land", "Tim Duncan", "DTIME(n2)", "the British blockade of the French coastline limited French shipping", "loud and dirty", "Don Von Tress", "chocolate confectionery"], "metric_results": {"EM": 0.09375, "QA-F1": 0.24014704171491297}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.3448275862068966, 0.0, 0.35294117647058826, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92, 0.0, 1.0, 0.3076923076923077, 0.21052631578947364, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 0.6153846153846153, 1.0, 0.0, 0.2666666666666667, 0.0, 0.14285714285714288, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_naturalquestions-validation-5838", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_squad-validation-7476", "mrqa_naturalquestions-validation-276", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-3616", "mrqa_triviaqa-validation-1465"], "after_eval": {"predictions": ["New Zealand Parliament as a private members bill by Green Party Member of Parliament Sue Bradford in 2005", "healthcare professionals with specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "red", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic Irish veterinary surgeon", "footpad", "shirley", "ligaments", "foyles", "carlsberg", "whitechapel", "plays a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "suitable substances, such as water", "1484", "lymph", "drum and bass electronic musician", "1806", "The enthalpy of fusion of a substance, also known as ( latent ) heat of fusion", "Commentaries on the Classic of Changes", "Chevron", "Cleveland Press", "Manchuria", "sausage", "capture Niagara, Crown Point and Duquesne, he proposed attacks on Fort Frontenac on the north shore of Lake Ontario", "friendship", "13.34%", "Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840", "computation time", "a poor harvest", "as loud and dirty as possible", "billy ray cyrus", "mars"], "metric_results": {"EM": 0.875, "QA-F1": 0.9125947475178819}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.10526315789473684, 0.3448275862068966, 1.0, 0.35294117647058826, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1219", "before_prediction": "neuro-orthopaedic", "after_prediction": "neuro-orthopaedic Irish veterinary surgeon"}], "retained_ids": ["mrqa_hotpotqa-validation-4280", "mrqa_squad-validation-6115"], "fixed_ids": ["mrqa_triviaqa-validation-1117", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_squad-validation-7476", "mrqa_naturalquestions-validation-276", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-3616", "mrqa_triviaqa-validation-1465"], "unfixed_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_naturalquestions-validation-5838"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 79, "before_eval": {"predictions": ["Sir Hiram Stevens Maxim", "1987", "The Forever People", "make direct representations to the Presiding Officer to nominate speakers", "Chesley Burnett", "October 12, 2017", "the `` Oath of Allegiance, '' 8 C.F.R. Part 337", "Kevin Whately", "shirley", "clay animation or \"clay-mation\"", "caucuses", "September of that year", "precedes the value", "the Industrial Revolution", "a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "Boletus edulis", "white Sox", "rugged terrain such as the Arctic", "the Mexico\u2013united States border", "the National Football Conference (NFC) champion Carolina Panthers", "a ribosome in the cytosol", "Town of Oyster Bay", "Ringo Starr", "shoppe", "gas turbines", "provided majority of members present at that time approved the bill either by voting or voice vote", "Calendar for Fixing the Seasons", "16 %", "japan", "Secretary of Defense", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "thirteen American colonies, then at war with the Kingdom of Great Britain, regarded themselves as thirteen independent sovereign states, no longer under British rule"], "metric_results": {"EM": 0.15625, "QA-F1": 0.31676894806185424}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.3157894736842105, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.4444444444444445, 0.5, 0.6666666666666666, 1.0, 0.0, 0.5, 0.6086956521739131, 0.0, 0.2222222222222222, 0.0, 1.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2846", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4529", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_hotpotqa-validation-3538", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "after_eval": {"predictions": ["Nathan Rothschild", "1996", "in April 2011, following the events of `` Lauren '', during an attack on the task force", "nominate speakers", "Sully", "October 12, 2017", "The United States Oath of Allegiance", "valerie", "geoffrey rush", "clay animation or \"clay-mation\"", "new hampshire", "1977", "the sign precedes the value ( for instance, \u20ac 10, not 10 \u20ac )", "the Industrial Revolution", "a radius 1.5 times the Schwarzschild radius", "Funki Porcini", "cubs", "the Arctic", "the Mexico\u2013united States border", "Carolina Panthers", "ribosome", "Oyster Bay", "Ringo Starr", "national space centre", "steam turbines with reduction gearing", "majority of members present at that time", "the Shoushi Li (\u6388\u6642\u66a6) or Calendar for Fixing the Seasons", "16 %", "caribbean", "as both a member of the United States House of Representatives and Senate", "arranged in grana", "the Second Continental Congress"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8881244164332399}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.2222222222222222, 1.0, 0.14285714285714288, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5366", "before_prediction": "Secretary of Defense", "after_prediction": "as both a member of the United States House of Representatives and Senate"}], "retained_ids": ["mrqa_naturalquestions-validation-10148", "mrqa_squad-validation-3256", "mrqa_squad-validation-2692", "mrqa_hotpotqa-validation-701"], "fixed_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4529", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_hotpotqa-validation-3538", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "unfixed_ids": ["mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-1672", "mrqa_hotpotqa-validation-2846", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 80, "before_eval": {"predictions": ["John Mills", "caribbean", "Piet van der Walt", "Shivnarine Chanderpaul", "fREEWAY", "Charles Silverstein", "all the major theatres of the Second World War", "since the price had also remained fairly stable versus other currencies and commodities.", "the l Luxembourg Mansion", "State Bar of Arizona", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "beer and soft drinks", "sunlight", "red", "discus fish", "1967", "Mondays", "22 miles", "1598", "on the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "geoffrey", "national Front", "Topeka, Kansas", "500", "rochdale", "hijab", "1894", "they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "Parachutes", "phowa and siddhi consciously determined to be reborn, often many times, in order to continue their Bodhisattva vow is called a Tulku", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.21875, "QA-F1": 0.30014123607873605}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.0, 0.15384615384615385, 0.0, 1.0, 0.4, 0.37037037037037035, 0.4, 0.0, 0.25, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-2148", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3056", "mrqa_hotpotqa-validation-3282", "mrqa_squad-validation-3699", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_naturalquestions-validation-7848", "mrqa_squad-validation-3570", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-2840", "mrqa_squad-validation-10182", "mrqa_triviaqa-validation-5904", "mrqa_squad-validation-4975", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129", "mrqa_squad-validation-1930"], "after_eval": {"predictions": ["Sir Thomas Daniel Courtenay", "dalziel and Pascoe", "Piet van der Walt", "Alastair Cook", "Robert L. Harman", "Edmund Valentine White III", "RAF Tangmere, West Sussex", "the oil shock", "paris", "West Virginia American Water", "electric potential generated by muscle cells when these cells are electrically or neurologically activated", "beer and soft drinks", "HgO", "star", "fish", "1967", "Mondays at 21:30 (KST)", "22 miles", "1629", "on the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "zsa Zsa Gabor", "national front", "near Philip Billard Municipal Airport", "additional French forces under Claude-Pierre Pecaudy de Contrec\u0153ur", "cooperative society", "the burqa", "Hong Kong", "not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "parachutes", "phowa and siddhi", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.625, "QA-F1": 0.7279801693404635}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.8333333333333333, 0.4, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2640", "before_prediction": "Mondays", "after_prediction": "Mondays at 21:30 (KST)"}, {"id": "mrqa_naturalquestions-validation-870", "before_prediction": "hijab", "after_prediction": "the burqa"}], "retained_ids": ["mrqa_hotpotqa-validation-3779", "mrqa_hotpotqa-validation-3406", "mrqa_squad-validation-4818", "mrqa_triviaqa-validation-2009", "mrqa_squad-validation-4042"], "fixed_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-2148", "mrqa_hotpotqa-validation-3056", "mrqa_squad-validation-3699", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_squad-validation-3570", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_squad-validation-3038", "mrqa_hotpotqa-validation-2840", "mrqa_triviaqa-validation-5904", "mrqa_squad-validation-4975", "mrqa_squad-validation-1930"], "unfixed_ids": ["mrqa_naturalquestions-validation-6474", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3282", "mrqa_naturalquestions-validation-7848", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_squad-validation-10182", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129"], "instant_fixing_rate": 0.6, "instant_retention_rate": 0.7142857132653061}, {"timecode": 81, "before_eval": {"predictions": ["one rotation of the crank and two piston strokes", "National Football Conference", "the show's 2005 revival", "as an adviser to churches in new territories", "USD 5.2 billion", "A rear - view mirror", "The Birds", "identify rock samples in the laboratory", "French & Saunders", "the European Parliament and the Council of the European Union", "car crash", "on either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Thomas Edison", "duo", "M\u00fcntzer's execution", "red hot poker", "a new entrance building", "caribbean", "caribaria", "barrel", "construction service firms", "St. Paul\u2019s Chapel", "`` Feed Jake '' is a song written by Danny `` Bear '' Mayo", "several hundred thousand", "photoelectric effect", "Noel Gallagher", "Max West", "the Midlands and the South West", "aluminium", "newspapers, television, radio, cable television, and other businesses", "Lakshmibai", "moxibustion"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3199586004273504}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.2222222222222222, 0.6666666666666666, 0.0, 0.25, 0.375, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.7692307692307693, 0.4, 0.2222222222222222]}}, "error_ids": ["mrqa_squad-validation-3267", "mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_squad-validation-914", "mrqa_hotpotqa-validation-3695", "mrqa_squad-validation-5288", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664", "mrqa_squad-validation-8265"], "after_eval": {"predictions": ["one", "American Football Conference", "series 1", "adviser", "on average USD 5.2 billion and for the Winter Games USD 3.1 billion dollars", "A rear - view mirror", "Cleopatra", "identifying rocks", "French & Saunders", "European Parliament and the Council of the European Union", "blackburn", "on either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Fred Ott", "heavy metal band", "the Swabian League at the Battle of Frankenhausen on 15 May 1525, followed by M\u00fcntzer's execution", "kniphofia", "the Spiral,", "us president barack obama", "knife", "9", "service firms", "christ church", "American country music band Pirates of the Mississippi", "some 30% of the city", "photoelectric effect", "Noel ( who had previously only sung lead on B-sides) instead of his brother, Liam", "Walter Maxwell West Sr.", "Cross Country", "bauxite", "newspapers, television, radio, cable television", "Lakshmibai, the Rani of Jhansi", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs"], "metric_results": {"EM": 0.84375, "QA-F1": 0.87734375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2287", "before_prediction": "M\u00fcntzer's execution", "after_prediction": "the Swabian League at the Battle of Frankenhausen on 15 May 1525, followed by M\u00fcntzer's execution"}, {"id": "mrqa_hotpotqa-validation-4831", "before_prediction": "Noel Gallagher", "after_prediction": "Noel ( who had previously only sung lead on B-sides) instead of his brother, Liam"}], "retained_ids": ["mrqa_naturalquestions-validation-8591", "mrqa_hotpotqa-validation-2973", "mrqa_squad-validation-4541", "mrqa_triviaqa-validation-296"], "fixed_ids": ["mrqa_squad-validation-3267", "mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_squad-validation-914", "mrqa_hotpotqa-validation-3695", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664", "mrqa_squad-validation-8265"], "unfixed_ids": ["mrqa_naturalquestions-validation-4809", "mrqa_triviaqa-validation-5598", "mrqa_squad-validation-5288"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.6666666655555555}, {"timecode": 82, "before_eval": {"predictions": ["921 ft", "Pauli repulsion", "the toe ( at the top of the cerebral hemisphere )", "24 hours later", "1945", "dachshund", "farmers grow new pigeon pea varieties, instead of maize, in particularly dry areas", "geologic, topographic, and natural ecosystem landscapes", "129", "Bunkhouse", "Puma", "an official school sport", "geese", "his friend and future rival, Jamukha, and his protector, Toghrul Khan of the Keraite tribe", "tentacles", "tumbo) Island and Conakry (Kaloum) peninsula", "Tagore", "Lawrence County State's Attorney John Fitzgerald, Chief Deputy Attorney General Charlie McGuigan, and attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "water on the ground surface enters the soil", "9", "film and short novels", "American-Canadian mystery-drama", "American animated television series \"Archer\"", "Gardnerville", "nucleic acid polymers deoxyribonucleic acid", "25-minute episodes", "American computer programmer", "Zapatista Army of National Liberation", "Bhushan Patel", "paris", "2003", "salt"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31998737473368577}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 0.5517241379310345, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2133", "mrqa_squad-validation-10390", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-2791", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-4493", "mrqa_naturalquestions-validation-9324", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_hotpotqa-validation-164", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "after_eval": {"predictions": ["scotland", "normal force", "face", "24 hours", "1945", "Dachshunds", "very drought resistant", "ocean islands, shorelines, beaches, and coastal plains, through the Transverse and Peninsular Ranges with their peaks, into the large and small interior valleys, to the vast deserts of California", "73", "Bed and breakfast", "Adidas", "a growing sport in southern California, particularly at the high school level, with increasing numbers of schools adding rugby as an official school sport", "september", "Jamukha, and his protector, Toghrul Khan", "tentacles", "guinea", "Tagore", "attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "runoff", "9", "video game", "American-Canadian mystery-drama", "Arrested Development", "Minden", "Nucleotides", "25-minute", "WikiLeaks", "mexico", "Tinu Suresh Desai", "othello", "at age 18 in 2003", "dead sea"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8560267857142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5592", "before_prediction": "Puma", "after_prediction": "Adidas"}, {"id": "mrqa_squad-validation-2748", "before_prediction": "an official school sport", "after_prediction": "a growing sport in southern California, particularly at the high school level, with increasing numbers of schools adding rugby as an official school sport"}, {"id": "mrqa_hotpotqa-validation-678", "before_prediction": "Gardnerville", "after_prediction": "Minden"}], "retained_ids": ["mrqa_hotpotqa-validation-4153", "mrqa_squad-validation-4616", "mrqa_naturalquestions-validation-4659", "mrqa_hotpotqa-validation-2361"], "fixed_ids": ["mrqa_triviaqa-validation-2133", "mrqa_squad-validation-10390", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-4493", "mrqa_naturalquestions-validation-9324", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_hotpotqa-validation-164", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "unfixed_ids": ["mrqa_squad-validation-2791", "mrqa_triviaqa-validation-863"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.571428570612245}, {"timecode": 83, "before_eval": {"predictions": ["mehan Pistolet", "North Africa", "a young girl", "architecture from the gothic, renaissance, baroque and neoclassical periods", "usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm", "the aboral organ", "birdeater", "scrooge", "6", "Berlin", "Maidstone", "kingdoms of Francia on the Lower Rhine, Burgundy on the Upper Rhine and Alemannia", "S\u00fcleyman-\u0131 Evvel", "1 -- 3", "james cameron", "difficult and intricate topics", "email", "ABC Radio, with Clear Channel Communications and Westwood One ( which had earlier purchased NBC's radio division, as well as the distribution rights to CBS's, and the Mutual Broadcasting System during the 1990s) as potential buyers", "Tahiti", "bacteria", "Traktor", "paris", "Steveston Outdoor pool", "alternating current", "Terry the Tomboy", "scarlet tanager", "South Australia", "Mach number", "approximately a `` drive - through '' or `` stop and go '' penalty", "North Atlantic Conference", "at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "british"], "metric_results": {"EM": 0.125, "QA-F1": 0.2024265630883278}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.14814814814814814, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8484848484848485, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_triviaqa-validation-3113", "mrqa_triviaqa-validation-271", "mrqa_triviaqa-validation-7486", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-3107", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_triviaqa-validation-5960", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_hotpotqa-validation-4966", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-8518", "mrqa_triviaqa-validation-5793"], "after_eval": {"predictions": ["Ast\u00e9rix", "Europe", "an illustration by Everest creative Maganlal Daiya back in the 1960s", "architectural", "bullets discharged into the air fall back down to the ground", "the aboral organ", "birdeater", "christmas carol", "Los angeles", "Cushman", "Sandwich, Faversham and Maidstone", "kingdoms", "Suleiman I", "7", "titanic", "Lego", "junk mail", "ABC Radio", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "detritus", "Rated R", "sea of galilee", "Vancouver", "alternating current", "Terry the Tomboy", "bird", "Australia", "2", "pit road speed", "North Atlantic Conference", "on location at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "victoria"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9348214285714286}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9142857142857143, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-4490", "mrqa_squad-validation-1159", "mrqa_hotpotqa-validation-1903", "mrqa_hotpotqa-validation-12"], "fixed_ids": ["mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_triviaqa-validation-271", "mrqa_triviaqa-validation-7486", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-3107", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_triviaqa-validation-5960", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_hotpotqa-validation-4966", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_triviaqa-validation-5793"], "unfixed_ids": ["mrqa_triviaqa-validation-3493", "mrqa_triviaqa-validation-3113", "mrqa_naturalquestions-validation-8518"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.9999999975}, {"timecode": 84, "before_eval": {"predictions": ["music", "13 years and 48 days", "Nathan Bedford Forrest", "Goths", "Ubiorum", "Montreal", "Brixton", "No. 60", "Secretary of Labor", "better fuel economy", "september", "evacuate the cylinder, choking it and giving excessive compression", "saguaro", "optic disc", "Carson City", "biologist", "Egyptians", "wis warfield", "posthumously in 1890", "ambassador to Ghana and to Czechoslovakia", "NBA Finals", "Emma Thompson and Alice Eve", "Chinese", "christmas", "travel literature, cartography, geography, and scientific education", "grandfather", "Chaplain to the Forces serving at the Tower of London and in Bengal, Caterham, South Africa (where he was Mentioned in despatches) and Portsmouth until his Archdeacon\u2019s appointment", "mexico", "57 kg", "the trunk, which is a combination of the thoracic, mammary, abdominal, naval, and coxal regions", "Lexus", "prison"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4287445309320309}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8571428571428571, 0.0, 0.4, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.08, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.07407407407407407, 0.0, 0.6666666666666666, 0.15384615384615385, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-370", "mrqa_hotpotqa-validation-3830", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_squad-validation-3364", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_naturalquestions-validation-10461", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_hotpotqa-validation-1810", "mrqa_naturalquestions-validation-3173", "mrqa_naturalquestions-validation-6660"], "after_eval": {"predictions": ["music to students", "26", "Major General Nathan Bedford Forrest", "Theodosius I", "town of the Ubii", "Ottawa", "brixton riots", "third", "Assistant Secretary for Administration and Management", "much better fuel economy", "squeeze", "evacuate the cylinder", "cactus", "optic chiasma", "Carson City", "biologist", "Egyptians", "marilyn monroe", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "Chief of Protocol", "2015", "Alice Eve", "bird nests created by edible - nest swiftlets using solidified saliva", "Part I", "travel literature, cartography, geography, and scientific education", "grandfather", "Chaplain", "People's Republic of China", "125 lb (57 kg)", "trunk", "Lexus", "as a prison"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8766392118863049}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false], "QA-F1": [0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9302325581395349, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5850", "before_prediction": "music", "after_prediction": "music to students"}, {"id": "mrqa_naturalquestions-validation-1147", "before_prediction": "Goths", "after_prediction": "Theodosius I"}, {"id": "mrqa_hotpotqa-validation-1628", "before_prediction": "Secretary of Labor", "after_prediction": "Assistant Secretary for Administration and Management"}], "retained_ids": ["mrqa_hotpotqa-validation-3359", "mrqa_squad-validation-8486", "mrqa_squad-validation-6728", "mrqa_squad-validation-8016", "mrqa_hotpotqa-validation-1645", "mrqa_triviaqa-validation-4696"], "fixed_ids": ["mrqa_squad-validation-370", "mrqa_hotpotqa-validation-3830", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_squad-validation-3364", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-989", "mrqa_hotpotqa-validation-1810", "mrqa_naturalquestions-validation-3173"], "unfixed_ids": ["mrqa_naturalquestions-validation-10461", "mrqa_triviaqa-validation-159", "mrqa_naturalquestions-validation-6660"], "instant_fixing_rate": 0.8695652173913043, "instant_retention_rate": 0.6666666659259258}, {"timecode": 85, "before_eval": {"predictions": ["Europe, North America, East Asia and South Asia", "10,000", "Stephen Crawford Young", "fall in American and Canadian English", "3000 metres", "October 13, 1980", "between 1765 and 1783", "mutiny or Murder", "heart", "at each place there are a bread roll ( generally on a bread plate, sometimes in the napkin ), napkin, and flatware", "september", "bilaterally symmetrical", "he did not consider the papacy part of the biblical Church", "1837", "November 27, 2017", "Bambi, a Life in the Woods", "efficient use of the available inputs", "from ages 12\u201318, while authors and readers of \"Young teen novels\" often define it as written for those aged 15 to the early 20s", "Retina Display", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "in school at a given time in the school day ( such as lunch, recess or after school)", "guinea", "Jane Austen", "lactobacilli", "at a school or other place of formal education", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Epsom Derby", "magazines and journals", "EE Harrier and Harrier Mini", "in the 1970s and'80s", "robert Ratzenberger", "a dose of 200 to 500 mg up to 7 ml"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2959598214285714}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.4, 0.0, 0.0, 0.3, 0.0, 0.0, 0.16666666666666666, 1.0, 0.0, 0.2, 0.0, 0.16, 1.0, 0.0, 0.125, 0.0, 0.0, 1.0, 0.2222222222222222, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 0.0, 0.16666666666666669]}}, "error_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-244", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-4854", "mrqa_triviaqa-validation-2508", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "after_eval": {"predictions": ["United States", "small", "Stephen Crawford Young", "fall", "3000 metres", "October 13, 1980", "1783", "henry hudson", "south africa", "at each place", "yeats", "a vertebral column ( spine )", "papacy was the Antichrist", "1837", "the sixth volume", "Bambi: Eine Lebensgeschichte aus dem Walde", "a point beneath the curve ( such as A ) indicates inefficiency", "12\u201318", "Retina Display", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "schools", "c\u00f4te d'Ivoire", "Jane Austen", "lactobacilli", "a school or other place of formal education", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "emily davison", "magazines and journals", "4G", "1987", "imola", "420 mg"], "metric_results": {"EM": 0.75, "QA-F1": 0.7925347222222222}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.25, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4719", "mrqa_triviaqa-validation-6151", "mrqa_hotpotqa-validation-5063", "mrqa_hotpotqa-validation-3220", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-6608", "mrqa_squad-validation-1566"], "fixed_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_triviaqa-validation-4854", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "unfixed_ids": ["mrqa_hotpotqa-validation-244", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-2508"], "instant_fixing_rate": 0.68, "instant_retention_rate": 0.9999999985714286}, {"timecode": 86, "before_eval": {"predictions": ["Native Americans", "thammasat", "South Sentinel Island", "FCA", "Aaron Taylor-Johnson", "black", "japan", "a gift", "Conservative", "Peter Davison, Colin Baker and Sylvester McCoy", "Islam", "Super Bowl XXVIII at the end of the 1993 season", "maquila", "Bigger Than Both of Us", "cells", "fourth studio album, \" Damn\"", "input string", "1787", "WJRT-TV and WTVG", "Great Lakes", "temperatures and sea levels have been rising at or above the maximum rates proposed during the last IPCC report in 2001", "the Anabaptists, Zwinglianism, and the papacy", "film playback singer, director, writer and producer", "southern whites", "Marie", "not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P.", "Association of Indian Universities", "drawing letters in the air ( `` penciling '' )", "un-consistent unification", "the All Stars", "he stood by their contents", "since the introduction of the scheme in 1980"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20591021825396824}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8750000000000001, 0.0, 0.2222222222222222, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.5, 0.0, 0.14285714285714285, 0.0, 0.25, 0.0, 1.0, 0.07999999999999999, 0.0, 0.33333333333333337, 0.5, 0.0, 0.0, 0.2857142857142857]}}, "error_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_squad-validation-782", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_squad-validation-1768", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_squad-validation-2331", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_triviaqa-validation-1431", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-6912"], "after_eval": {"predictions": ["Spanish", "thailand", "Andaman Islands", "Fiat Chrysler Automobiles N.V.", "Aaron Taylor-Johnson", "blue ivy", "japanese peace treaty", "a gift", "libertarian", "Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann", "hate them", "1993", "special economic zones", "\"Rich Girl\"", "nearly all living cells", "\"1989\" (2014)", "problem", "18 January 1788", "WTVG", "Erie canal", "actual sea level rise was above the top of the range", "Jews", "director", "the Confederacy", "Marie", "L", "Bangalore University", "penciling", "self-consistent unification models", "allstars", "confirmed", "1980"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-5195", "mrqa_squad-validation-2295", "mrqa_hotpotqa-validation-1379"], "fixed_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-782", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_squad-validation-1768", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_squad-validation-2331", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_triviaqa-validation-1431", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-6912"], "unfixed_ids": ["mrqa_squad-validation-9589"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.9999999966666667}, {"timecode": 87, "before_eval": {"predictions": ["on First Street in downtown Dayton, Ohio, United States", "electronic gaming machines", "as the New Tomorrowland project", "Mohammad Reza Pahlavi", "digital streams", "Life Savers", "Burbank, California", "Chinese", "due to the controversial and explicit nature", "Guetta", "carbon cycle", "activist", "recite the 42 negative confessions", "Donna Noble (Catherine Tate) with Mickey Smith (noel Clarke) and Jack Harkness (David Barrowman) recurring as secondary companion figures", "salvaging a country usually seen as one of the most stable and prosperous in Africa", "The Kree", "titanium metal", "\"Loud\" (2010)", "Kirenyaa", "star of newcomer", "domestic legislation", "an esoteric (as opposed to exoteric, or actions-oriented, e.g. the Five Pillars of Islam)", "toothbrush", "states being equally represented by two senators", "sherry", "Thutmose III", "a somewhat larger number of \"contributing authors\"", "Buck Owens and the Buckaroos", "Iraq", "political support", "Finding Nemo", "all England tennis club"], "metric_results": {"EM": 0.15625, "QA-F1": 0.33684440559440565}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3076923076923077, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285714, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.4, 0.0, 0.5714285714285715, 0.15384615384615385, 0.0, 0.15384615384615383, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.8571428571428571]}}, "error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_triviaqa-validation-7649", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_squad-validation-2122", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_hotpotqa-validation-5743", "mrqa_naturalquestions-validation-7409", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-2814"], "after_eval": {"predictions": ["First Street", "paper-based", "August 21, 1995", "Cyrus", "digital streams", "Life Savers", "on a sound stage in front of a live audience in Burbank, California", "Mongolian, Tibetan, and Chinese", "men who have sex with men", "Wiz Khalifa", "carbon cycle", "Property management", "against the feather of truth", "Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman)", "the two political parties would share power equally", "the Ruul", "titanium", "Loud", "Kirinyaga, Kirenyaa and Kiinyaa", "emmy", "domestic legislation of the Scottish Parliament", "actions-oriented", "hitler", "Article One of the United States Constitution", "vodka", "Khonsu", "ten to fifteen", "Buck Owens", "Kansas", "political support", "blue tang", "all england"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8552", "before_prediction": "a somewhat larger number of \"contributing authors\"", "after_prediction": "ten to fifteen"}], "retained_ids": ["mrqa_squad-validation-531", "mrqa_squad-validation-5648", "mrqa_squad-validation-3620", "mrqa_squad-validation-9565"], "fixed_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_triviaqa-validation-7649", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_squad-validation-2122", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_hotpotqa-validation-5743", "mrqa_naturalquestions-validation-7409", "mrqa_triviaqa-validation-6757"], "unfixed_ids": ["mrqa_triviaqa-validation-2814"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 88, "before_eval": {"predictions": ["older brother", "Janet Jackson", "The Gold Coast", "in order to create a test case as to the constitutionality of a law", "Selena Gomez", "8th", "Forbes", "159 beats per minute ( bpm )", "small bowel", "guitar", "\"public\" (state-controlled) and \"independent\"", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "Dan Dare, Pilot of the Future", "fictional", "the southwestern United States, Mexico, and Central America", "in exaggerating their seriousness", "sacerdotalism", "the 1970s", "half a million", "44 (or virtual channel 6 via PSIP)", "the Gaulish name R\u0113nos", "the financing activities section", "duke of galilee", "metropolitan counties", "Solange Knowles & Destiny's Child", "Ward", "Fryda Wolff", "NBA Rookie of the Year Award", "Rihanna", "Afghans", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.15625, "QA-F1": 0.32590996625923097}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.11764705882352942, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.8, 0.25, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_hotpotqa-validation-4843", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_hotpotqa-validation-5498", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "after_eval": {"predictions": ["brother", "Janet Jackson", "Gold Coast", "in order to create a test case as to the constitutionality of a law", "Instagram's own account", "8th", "Forbes Global 2000", "Tachycardia", "navel", "yardbirds", "South African Schools Act", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "venus", "fictional character", "arid lowland or mountainous shrubland, widely dispersed in dry open country with scattered brush", "in exaggerating their seriousness", "Pope", "the 90s", "half a million acres", "44", "the Gaulish name R\u0113nos", "the financing activities section", "national trust", "berkshire", "Destiny's Child", "Newton", "Amanda Leighton", "Eddie Gottlieb Trophy", "The Beatles", "grand assembly", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8147424879042526}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.11764705882352942, 0.5714285714285715, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4066", "mrqa_squad-validation-9246", "mrqa_naturalquestions-validation-5291", "mrqa_squad-validation-1733", "mrqa_squad-validation-8594"], "fixed_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_hotpotqa-validation-4843", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "unfixed_ids": ["mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-4351", "mrqa_squad-validation-6396", "mrqa_naturalquestions-validation-2264", "mrqa_hotpotqa-validation-5498"], "instant_fixing_rate": 0.6666666666666666, "instant_retention_rate": 0.9999999980000001}, {"timecode": 89, "before_eval": {"predictions": ["13", "a person violates a law in order to create a test case as to the constitutionality of a law", "House of Fraser", "Buncle", "veal", "time complexity", "Deadman's Gun", "m\u00e1laga airport", "the Philippines", "Z-ring", "emmy law", "1843", "the referendum in France", "director", "California Young Reader Medal", "Louis XVIII", "Superman IV: The Quest for Peace", "russia", "national airline", "all Native American tribal lands", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "Bob Neuwirth", "ODM candidate Raila Odinga", "homicides", "shrewsbury river festival", "Bergen County", "August 9, 2017", "mongol", "pragmatism", "USC Trojans", "Richard Bremmer", "sequential proteolytic activation of complement molecules"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26497668997668994}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.23076923076923078, 0.33333333333333337, 0.4, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-3776", "mrqa_triviaqa-validation-3639", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_hotpotqa-validation-5484", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_squad-validation-8423", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "after_eval": {"predictions": ["13", "neither conscientious nor of social benefit", "Army & Navy Stores", "Bonkyll Castle", "umami", "time complexity", "Far Away", "costa del sol", "Spanish", "proteins", "david Laws", "1843", "referendum in France and the referendum in the Netherlands", "rebecca", "middle America", "Napoleon", "January 30, 1930", "poland", "sabena", "American Samoa, but not on all Native American tribal lands", "Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "singer Janis Joplin with the poets Michael McClure and Bob Neuwirth", "Odinga", "homicides", "severn", "Bergen", "November 6, 2018", "liao", "sociological", "UCLA", "Richard Bremmer", "signal amplification"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9759615384615384}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23076923076923078, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-803", "mrqa_squad-validation-1700", "mrqa_hotpotqa-validation-2774", "mrqa_squad-validation-7251", "mrqa_naturalquestions-validation-1445"], "fixed_ids": ["mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-3776", "mrqa_triviaqa-validation-3639", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_hotpotqa-validation-5484", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_naturalquestions-validation-9419", "mrqa_squad-validation-8423", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "unfixed_ids": ["mrqa_squad-validation-9079"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.9999999980000001}, {"timecode": 90, "before_eval": {"predictions": ["allotrope", "reactive allotrope of oxygen", "The Daleks' Master Plan", "tragedy", "phylum", "fault", "magnetism", "complexity", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "f clef", "four zonal offices at Chennai, Delhi, Kolkata and Mumbai", "venus", "cognitive science", "Kitab Rudjdjar", "Gravitational force", "photolysis", "1998", "c. s. forester", "Grisha Alekandrovich Nikolaev", "Type I", "rootlets", "violet", "Ken Howard", "red", "New England Patriots", "antigenic variation", "A74(M)", "baku", "september", "A 30 - something man ( XXXX )", "Catherine Earnshaw", "178 Vivienne Westwood costumes"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3246527777777778}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 0.26666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-1689", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_naturalquestions-validation-3233", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-3988", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_squad-validation-6627", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "after_eval": {"predictions": ["allotrope", "lung tissue", "Black Guardian Trilogy", "\"Carmen\" perhaps the most famous \"op\u00e9ra comique\" is a tragedy", "cnidarians", "younger than the fault", "maxwell", "complexity classes", "civil disobedience", "stave", "20 regional offices and 11 sub-offices", "jelly roll morton", "professor of cognitive science", "Kitab Rudjdjar", "time", "one molecule of the pigment chlorophyll absorbs one photon and loses one electron", "2015", "gregory peck", "Grisha", "Type II hypersensitivity", "SURFACE AREA OF ROOTS", "dolly parton", "Jeanne Tripplehorn as Jacqueline Kennedy (Little Edie's cousin) and Ken Howard as Phelan Beale", "john virgo", "Broncos", "antigens", "heads north", "baku", "sydney", "XXXX", "Sarah Hurst in \"Easy Virtue\"", "Costiff"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9244791666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6812", "before_prediction": "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "after_prediction": "civil disobedience"}, {"id": "mrqa_squad-validation-10358", "before_prediction": "Gravitational force", "after_prediction": "time"}, {"id": "mrqa_hotpotqa-validation-3250", "before_prediction": "Ken Howard", "after_prediction": "Jeanne Tripplehorn as Jacqueline Kennedy (Little Edie's cousin) and Ken Howard as Phelan Beale"}], "retained_ids": ["mrqa_squad-validation-3496", "mrqa_squad-validation-1070", "mrqa_triviaqa-validation-3575"], "fixed_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-1689", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_naturalquestions-validation-3233", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-3988", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_squad-validation-6627", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.49999999916666665}, {"timecode": 91, "before_eval": {"predictions": ["40%", "catherine", "Mongolian patrimonial feudalism", "drury lane", "Afghanistan", "biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Australian-American", "100,000 writes", "paris", "marquesas Islands", "montgomery", "North Greenwich Arena", "gymnosperms", "Masters Tournament", "\"Korea\", is a 2012 South Korean sports drama film starring Ha Ji-won and Bae Doona.", "90% certain", "Bessemer process", "improved firearms", "1856", "liver", "deities and spirits", "stony creek granite that came from the Stony Creek Red Granite Company", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "gregillaz", "corvidae", "South Africa", "Four Weddings and a Funeral", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistan", "psilocin", "cuba and His Teddy Bear"], "metric_results": {"EM": 0.25, "QA-F1": 0.36344598633498065}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 0.15384615384615385, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.967741935483871, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4749", "mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-4471", "mrqa_hotpotqa-validation-2205", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_squad-validation-9812", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_hotpotqa-validation-277", "mrqa_triviaqa-validation-6594"], "after_eval": {"predictions": ["40%", "Catherine", "autocratic-bureaucratic system", "muffin man", "Pakistan", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "American", "around 100,000 writes", "spain", "pacific ocean", "montgomery", "North Greenwich Arena", "either on the surface of scales or leaves", "2015 Masters Tournament", "Korea", "at least 90% certain", "steel", "communication", "1856", "liver", "belief in many deities and spirits", "west point", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "blur", "birds", "Australia : 25 % of global woolclip ( 475 million kg greasy, 2004 / 2005 )", "Four Weddings and a Funeral", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistani", "psilocybin, psilocin and baeocystin", "cuba and His Teddy Bear"], "metric_results": {"EM": 0.625, "QA-F1": 0.717666071805066}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.4, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6824", "before_prediction": "South Africa", "after_prediction": "Australia : 25 % of global woolclip ( 475 million kg greasy, 2004 / 2005 )"}, {"id": "mrqa_hotpotqa-validation-1473", "before_prediction": "psilocin", "after_prediction": "psilocybin, psilocin and baeocystin"}], "retained_ids": ["mrqa_squad-validation-7551", "mrqa_triviaqa-validation-888", "mrqa_hotpotqa-validation-1412", "mrqa_hotpotqa-validation-4256", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-4229"], "fixed_ids": ["mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_hotpotqa-validation-2205", "mrqa_triviaqa-validation-544", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_squad-validation-9812", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_hotpotqa-validation-277"], "unfixed_ids": ["mrqa_triviaqa-validation-4749", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_hotpotqa-validation-1500", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_triviaqa-validation-6594"], "instant_fixing_rate": 0.5833333333333334, "instant_retention_rate": 0.7499999990624999}, {"timecode": 92, "before_eval": {"predictions": ["a field in Somerset County, Pennsylvania", "communism communism", "\" the Gentle Don\" or \"the Docile Don\"", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "sugarate", "July 25, 1898", "BitInstant", "Sky High", "flights", "steamboats", "Social Chapter", "Australia", "retina", "physics", "The Lone Ranger", "Sargent Shriver", "Landry's, Inc.", "George Mifflin Dallas", "David Naughton, Jenny Agutter and Griffin Dunne", "home guard", "at the Columbian Exposition, under a banner announcing the \" Tesla Polyphase System\" Tesla demonstrated a series of electrical effects previously performed throughout America and Europe", "john alcock and brown", "December 1978", "inversely to member state size", "propeller", "Irvine", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "rebecca sella", "November 20, 1942", "Hugues Capet, king of France", "Morning Edition"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4765489718614719}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true], "QA-F1": [0.33333333333333337, 0.0, 1.0, 0.25, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.3333333333333333, 1.0, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-6960", "mrqa_squad-validation-1400", "mrqa_triviaqa-validation-7185", "mrqa_hotpotqa-validation-4387", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_triviaqa-validation-1267", "mrqa_squad-validation-3189"], "after_eval": {"predictions": ["Pennsylvania", "marx", "\"the Gentle Don\" or \"the Docile Don\"", "attack on Pearl Harbor", "australia", "1898", "BitInstant", "\"Read It and Weep\" (2006)", "santo", "railway locomotives, ships, steamboats and road vehicles", "\"Social Chapter\"", "Australia", "photoreceptor cells", "operators", "The Adventures of Ozzie and Harriet", "President John F. Kennedy", "Landry's, Inc.", "Vice President George Mifflin Dallas", "David Naughton, Jenny Agutter and Griffin Dunne", "local defence volunteers", "Chicago", "alcock and brown", "1978", "weighted inversely to member state size", "kawasaki", "South Coast Metro", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "australia", "November 20, 1942", "little Hugos, or those who want Hugo", "Morning Edition"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8867897727272727}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3276", "before_prediction": "steamboats", "after_prediction": "railway locomotives, ships, steamboats and road vehicles"}, {"id": "mrqa_squad-validation-5811", "before_prediction": "The Lone Ranger", "after_prediction": "The Adventures of Ozzie and Harriet"}], "retained_ids": ["mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5281", "mrqa_squad-validation-4106", "mrqa_squad-validation-3063", "mrqa_hotpotqa-validation-1148", "mrqa_hotpotqa-validation-2067", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-2522"], "fixed_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_triviaqa-validation-6960", "mrqa_squad-validation-1400", "mrqa_triviaqa-validation-7185", "mrqa_hotpotqa-validation-4387", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_squad-validation-3189"], "unfixed_ids": ["mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-1267"], "instant_fixing_rate": 0.8095238095238095, "instant_retention_rate": 0.8181818174380164}, {"timecode": 93, "before_eval": {"predictions": ["pacific region", "another principal networking paradigm, circuit switching, a method which pre-allocates dedicated network bandwidth specifically for each communication session", "london Underground", "Utah", "gregory abbot", "Great Britain", "mid-size four - wheel drive luxury SUV", "greginald Leslie Forde", "manhattan parlors, and food-processing plants", "we want to practice Christian love toward them and pray that they convert", "two populations of rodents: one resistant to the disease, which act as hosts, keeping the disease endemic, and a second that lack resistance", "around 1200", "T'Pau", "geheime Staatspolizei, or Gestapo", "1815", "American Football Conference", "kimono", "north to the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts", "\"antiforms\"", "2015", "man", "a representation of a function as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "51st", "Transpacific Yacht Race, or Transpac", "German", "registered with the General Teaching Council for Scotland (GTCS)", "multinational corporation", "either yes or no, or alternately either 1 or 0", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula", "Company Picnic", "lie detector", "mass murder of hundreds orchestrated to get away with the murder of the future king"], "metric_results": {"EM": 0.125, "QA-F1": 0.2337655289028287}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.21052631578947367, 0.0, 0.06060606060606061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.33333333333333337, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.34782608695652173, 0.33333333333333337, 0.33333333333333337, 0.33333333333333337, 0.0, 0.0, 0.4615384615384615, 0.16666666666666669, 0.0, 1.0, 0.125]}}, "error_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-4204", "mrqa_triviaqa-validation-1548", "mrqa_squad-validation-5111", "mrqa_hotpotqa-validation-421", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-3298", "mrqa_squad-validation-2040", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "after_eval": {"predictions": ["alberta", "circuit switching", "green", "in nearly 100 locations across Utah, including : Mount Timpanogos, Ashley National Forest, Leeds, Snow Canyon State Park, St. George, Sundance Resort, Uinta National Forest", "golf", "France", "Mercedes - Benz", "barbadian", "Chief Wiggum", "convert", "two populations of rodents", "sometime between 124 and 800 CE, with some theories dating the earliest Polynesian settlements to the 10th or even 13th century", "British pop band T'Pau", "himmler", "1815", "American Football Conference", "seppuku", "in North America where it has a core population in Michigan and surrounding states and provinces", "synforms", "2016", "man's disobedience toward God", "infinite sum of terms", "51st Disney animated feature film.", "Transpac", "the German nuclear weapon project", "Provisional Registration", "explosives", "yes or no", "Gibraltar", "the Season 5 premiere, `` Weight Loss ''", "lie detector", "king henry i"], "metric_results": {"EM": 0.875, "QA-F1": 0.9354228670634921}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18750000000000003, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2870", "before_prediction": "north to the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts", "after_prediction": "in North America where it has a core population in Michigan and surrounding states and provinces"}], "retained_ids": ["mrqa_squad-validation-831", "mrqa_squad-validation-9", "mrqa_triviaqa-validation-2387"], "fixed_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-4204", "mrqa_triviaqa-validation-1548", "mrqa_squad-validation-5111", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_squad-validation-2040", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "unfixed_ids": ["mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-3298"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 94, "before_eval": {"predictions": ["the nucleus", "horror fiction", "alberta earldom c.1140", "alberta", "southeast of the city", "on the coast, named Puerto Rico ( Rich Port ), which had a suitable harbor", "on the French island of Guadeloupe in the Lesser Antilles, mainly in the commune of Deshaies", "Statute of Rageman", "1938", "63%", "outside the United States and Canada", "2016", "90% to 93% O2", "approximately 11 %", "flags of dependent territories and other areas of special sovereignty", "Chen's theorem", "kiel canal", "short-tempered", "1987", "dastardly & Muttley", "regulates the practice of pharmacists and pharmacy technicians", "Sir Walter Elliot", "1968", "chief petty officer", "led about 1,500 army troops and provincial militia on an expedition in June 1755 to take Fort Duquesne", "The Taliban", "1986", "Cork, Portarlington, Lisburn, Waterford and Youghal", "Indian singer Tanvi Shah", "Tom Coburn", "2014", "increased and the ground water level fell significantly. Dead branches dried up and the amount of forests on the flood plains decreased sharply."], "metric_results": {"EM": 0.15625, "QA-F1": 0.29028918997668995}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.3076923076923077, 0.7000000000000001, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.1, 1.0, 0.5, 0.923076923076923, 0.6666666666666666, 0.0, 0.0, 0.16000000000000003]}}, "error_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-3677", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_triviaqa-validation-3230", "mrqa_triviaqa-validation-5584", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_hotpotqa-validation-848", "mrqa_squad-validation-3306", "mrqa_naturalquestions-validation-7496", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "after_eval": {"predictions": ["Cell nuclei", "carrie", "tamar", "chinese", "the Southwest", "Puerto Rico", "the French island of Guadeloupe in the Lesser Antilles", "rigmarole", "1933", "63%", "American", "2015", "one bed", "45 %", "flags", "Chen's theorem", "belt", "harsher", "mid-March", "Dastardly & Muttley", "regulates the practice of pharmacists and pharmacy technicians", "Sir Walter Elliot", "1928", "E-4 through E-6 are called petty officers", "The expedition was a disaster", "The Taliban", "June 11, 1986", "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal", "Indian singer Tanvi Shah", "Kirk Humphreys", "1988", "increased"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8645833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6433", "before_prediction": "kiel canal", "after_prediction": "belt"}], "retained_ids": ["mrqa_squad-validation-3315", "mrqa_squad-validation-9001", "mrqa_squad-validation-6322", "mrqa_squad-validation-9737"], "fixed_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_hotpotqa-validation-848", "mrqa_squad-validation-3306", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "unfixed_ids": ["mrqa_squad-validation-3677", "mrqa_triviaqa-validation-3230", "mrqa_triviaqa-validation-5584", "mrqa_naturalquestions-validation-7496"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.7999999984}, {"timecode": 95, "before_eval": {"predictions": ["the \"richest 1 percent in the United States", "\"universal ruler\"", "red", "alain Giresse", "Lombardy", "ideal", "david Duchovny", "spiders", "the American newspaper magnate William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick, and aspects of Welles's own life", "parashah", "the s - block", "World Music Awards", "seven", "8\u20134\u20133 system", "the Muslim faith as a tool of the devil", "79", "banned the growing of coffee", "no French regular army troops were stationed in North America", "a compromise between the two", "stimulated his brain cells", "banshee", "Daniel Ken \"Daniel\" Inouye", "David Toms", "Bobb McKittrick", "corrugated metal sheets", "11", "Klaus and Marjorie Detterick", "The Portuguese", "less workers are required", "the university's science club in 1886", "the Manchus", "kronborg"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3056926169590643}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2727272727272727, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5, 0.0, 1.0, 0.4210526315789474, 0.0, 0.0, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7272727272727272, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_squad-validation-9135", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8572", "mrqa_squad-validation-2293", "mrqa_squad-validation-8288", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_squad-validation-1445", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-9985", "mrqa_squad-validation-7184", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-4796"], "after_eval": {"predictions": ["the \"richest 1 percent in the United States now own more wealth than the bottom 90 percent\"", "\"universal ruler\"", "red", "brazil", "Lombardy", "Prime ideals", "The X-Files", "cave", "William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick, and aspects of Welles's own life", "a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week", "the s - block of the periodic table of elements", "\"World's Best Selling Russian Artist\"", "28", "7\u20134\u20132\u20133 system", "exposed to scrutiny", "79 official PGA Tour events, second only to Sam Snead, and six ahead of Jack Nicklaus with 73 wins", "banned the growing of coffee, introduced a hut tax, and the landless were granted less and less land in exchange for their labour", "no French regular army troops were stationed in North America, and few British troops. New France was defended by about 3,000 troupes de la marine, companies of colonial regulars (some of whom had significant woodland combat experience)", "a compromise between the two. One defendant accused of illegally protesting nuclear power, when asked to enter his plea, stated, \"I plead for the beauty that surrounds us\"", "exercise", "banshee", "Daniel Ken \"Daniel\" Inouye", "David Toms", "`` Mean Joe '' Greene : four as a defensive tackle, two as a special assistant for player personnel, all with the Pittsburgh Steelers", "paper-made honeycomb structures", "11 free suburban weekly newspapers together covering the Adelaide metropolitan area", "Burt Hammersmith", "Prince Henry", "a downward pressure on wages", "the university's science club in 1886", "Kangxi Emperor ( r. 1661 -- 1722 )", "Elsinore"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6613676956158292}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 0.06451612903225806, 0.1, 1.0, 1.0, 0.75, 0.0, 0.2857142857142857, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.7272727272727272, 0.28571428571428575, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2159", "before_prediction": "79", "after_prediction": "79 official PGA Tour events, second only to Sam Snead, and six ahead of Jack Nicklaus with 73 wins"}, {"id": "mrqa_hotpotqa-validation-5033", "before_prediction": "11", "after_prediction": "11 free suburban weekly newspapers together covering the Adelaide metropolitan area"}], "retained_ids": ["mrqa_squad-validation-6130", "mrqa_triviaqa-validation-2178", "mrqa_hotpotqa-validation-717", "mrqa_triviaqa-validation-2900"], "fixed_ids": ["mrqa_triviaqa-validation-5295", "mrqa_squad-validation-9135", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8572", "mrqa_squad-validation-2293", "mrqa_squad-validation-8288", "mrqa_squad-validation-1445", "mrqa_naturalquestions-validation-9985", "mrqa_squad-validation-7184", "mrqa_triviaqa-validation-4796"], "unfixed_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-2894", "mrqa_naturalquestions-validation-6129", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639"], "instant_fixing_rate": 0.5384615384615384, "instant_retention_rate": 0.6666666655555555}, {"timecode": 96, "before_eval": {"predictions": ["silicates of magnesium and iron", "Xanthippus, a Spartan mercenary", "The Dome of the Rock", "Private-Private Partnering", "the word is used to translate several Hebrew words, including Hod ( \u05d4\u05d5\u05d3 ) and kabod", "computer hardware and television", "Bulgaria", "4,577 nautical miles (8,477 km)", "Army, Navy and other services", "The Man with One Red Shoe", "Renhe Sports Management Ltd, 100 % owned by Xiu Li Dai and Yongge Dai. 25 % Owned by Narin Niruttinanon", "Kansas City Royals", "salvation and subsequently eternal life is not earned by good deeds but is received only as a free gift of God's grace through faith in Jesus Christ as redeemer from sin", "oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen", "They also spread beyond Europe to the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec, where they were accepted and allowed to worship freely.", "cannonball", "2006", "74", "the Ministry of War", "1162", "1928", "Porsche 944", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "1971", "The \"Huguenot Street Historic District\" in New Paltz has been designated a National Historic Landmark site and contains the oldest street in the United States of America.", "American Christian rock band Needtobreathe", "the Iranian Islamic Revolution and apolitical Islam was a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970\"", "1986", "cake or biscuit", "converging lenses, only if the object is placed further away from the mirror / lens than the focal point and this real image is inverted", "gravitational", "1988"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3523480018328685}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.25, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0, 0.5714285714285715, 0.5714285714285715, 0.0, 0.2857142857142857, 0.0, 0.23529411764705882, 0.6285714285714286, 0.3720930232558139, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6363636363636364, 0.0, 0.4666666666666667, 1.0, 0.0, 0.0, 0.16666666666666666, 0.0909090909090909, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_squad-validation-3876", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-3057", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "after_eval": {"predictions": ["oxides of silicon", "Xanthippus", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "Public-Private Partnering", "St. Augustine renders it as clara notitia cum laude, `` brilliant celebrity with praise ''", "microsoft", "Bulgaria", "617.1", "Army, Navy", "wild palms", "Yongge Dai", "phillies", "faith in Jesus Christ as redeemer from sin", "oxygen is the third-most abundant element in the universe, after hydrogen and helium", "they were accepted and allowed to worship freely", "angular rotation", "2006", "75", "the Ministry of War", "1162", "bolivia", "924", "acts as a primer, by polymerizing the first few glucose molecules", "shaft", "the oldest street in the United States of America", "American Christian rock band Needtobreathe", "Americans", "on the shore of Lake Erie in downtown", "the Jaffa cake should be considered a cake for tax purposes", "inverted", "strong, electromagnetic", "fiji"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9627976190476191}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7657", "before_prediction": "The Dome of the Rock", "after_prediction": "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem"}], "retained_ids": ["mrqa_hotpotqa-validation-5490", "mrqa_hotpotqa-validation-1088", "mrqa_squad-validation-8189", "mrqa_squad-validation-6158", "mrqa_naturalquestions-validation-8272"], "fixed_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_squad-validation-3876", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-3057", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "unfixed_ids": ["mrqa_squad-validation-2100"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.8333333319444445}, {"timecode": 97, "before_eval": {"predictions": ["6th", "every good work designed to attract God's favor", "suburb", "The National Era", "during the American Civil War", "wildberry", "July 1, 2005", "a few drops", "a little girl ( Addy Miller ), but she turns out to be a zombie", "long island", "vice president, Speaker of the House of Representatives, President pro tempore of the Senate, and then the heads of federal executive departments who form the Cabinet of the United States", "the optic chiasm", "the Continental Edison Company in France", "quote Shelley's Masque of Anarchy", "the Gararish", "Jai Courtney as John `` Jack '' McClane, Jr", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "the Holy Land", "phillies", "science fiction drama", "26", "Tesla's demonstration of his induction motor and Westinghouse's subsequent licensing of the patent, both in 1888, put Tesla firmly on the \"AC\" side of the so-called \"War of Currents\"", "kolkata", "Billy Gibbons of ZZ Top", "Juliet", "the \"father of the Mongols\" especially among the younger generation", "indeed caused by chlorine and bromine from manmade organohalogens", "a combined concert/lecture by British progressive folk-rock band Gryphon", "australia", "fomenting rebellion in many of Great Britain", "Psych", "the planned Nazi pre-emptive nuclear strike on Japan, `` Operation Dandelion, '' is apparently being prevented only by Hitler's personal refusal to authorise it"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23416959198209197}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.3333333333333333, 1.0, 0.3076923076923077, 0.0, 0.33333333333333337, 0.0, 0.7499999999999999, 0.0, 0.0, 0.4444444444444445, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 0.07407407407407407, 0.0, 0.0, 0.0, 0.6, 0.19999999999999998, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_hotpotqa-validation-3785", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7679", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-2504", "mrqa_naturalquestions-validation-1680", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_squad-validation-1423", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_squad-validation-6228", "mrqa_naturalquestions-validation-654", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-1081", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "after_eval": {"predictions": ["6th season", "trust in Christ be stronger", "suburb", "in The National Era, an abolitionist periodical, starting with the June 5, 1851, issue", "the field of battle", "blackberries", "April 26, 2005", "a few drops", "Addy Miller", "wild island", "Speaker of the House of Representatives", "pretectal nucleus", "Continental Edison Company", "free India", "Semitic people", "Mary Elizabeth Winstead as Lucy McClane", "pulmonary heart disease ( cor pulmonale ), which is usually caused by difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "the medieval city of Halych", "Vanity Fair", "science fiction drama", "26", "AC", "india", "Canadian rock band Nickelback", "Tybalt", "father of the Mongols", "chlor and bromine from manmade organohalogens", "a rock concert", "australia", "roger casement", "Psych is an American detective comedy-drama", "as - yet - unknown purpose"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8500744047619047}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-3475", "mrqa_hotpotqa-validation-2802", "mrqa_squad-validation-359"], "fixed_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7679", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_squad-validation-1423", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_squad-validation-6228", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "unfixed_ids": ["mrqa_hotpotqa-validation-3785", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-2504", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-654", "mrqa_triviaqa-validation-1081"], "instant_fixing_rate": 0.7931034482758621, "instant_retention_rate": 0.9999999966666667}, {"timecode": 98, "before_eval": {"predictions": ["the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ), when taking into consideration the full extent and duration of its after effects", "\"SKUM\"", "S6 Edge+", "Britannica", "photoreceptor proteins that sense light, found even in unicellular organisms, called `` eyespots ''", "frollo", "fossil sequences in which there was datable material, converting the old relative ages into new absolute ages", "heaviest album of all", "scotstral accompaniment", "in San Francisco, California with offices in New York City and Atlanta", "high unemployment, poverty, low profits, deflation, plunging farm incomes, and lost opportunities for economic growth and personal advancement", "ex as a noun is assumed to refer to a former sexual or romantic partner, especially a former spouse", "Fairy Tale Origins", "cilician coast", "\"citizenship\" so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for rights", "Jacking", "music licensing contracts", "the Baltimore teenagers Ivan Ashford, Markel Steele, Cameron Brown, Tariq Al - Sabir and Avery Bargasse", "wild palms", "Sultans", "the end of the post-war communist control of the country and the reintroduction of a free-market economy", "caribbean", "much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast", "Penrose stairs", "Hannaford Brothers Company", "whatIs.com", "Germ\u00e1n Efromovich", "limited period of time", "kabuki", "Madame Medusa", "between the three towns of Doncaster, Scunthorpe and Gainsborough", "in the United States was instituted by a New England cotton mill so that Jewish workers would not have to work on the Sabbath from sundown Friday to sundown Saturday"], "metric_results": {"EM": 0.125, "QA-F1": 0.22362146237908434}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.4878048780487805, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.4, 0.09999999999999999, 0.47619047619047616, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.1111111111111111, 0.0, 0.5, 0.0, 1.0, 0.30769230769230765, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_hotpotqa-validation-2978", "mrqa_triviaqa-validation-6634", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_triviaqa-validation-1474", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533", "mrqa_naturalquestions-validation-2713"], "after_eval": {"predictions": ["the most devastating stock market crash in the history of the United States", "SKUM", "The S7 series", "turin", "photoreceptor proteins that sense light, found even in unicellular organisms, called `` eyespots ''", "notre dame de paris", "fossil sequences in which there was datable material, converting the old relative ages into new absolute ages", "heaviest album of all", "libretto", "San Francisco, California", "an economic recession", "a former sexual or romantic partner, especially a former spouse", "king henry ivy", "cilician coast", "\"citizenship\"", "floor work", "friends", "Steve Earle", "kent", "a line of committed and effective Sultans", "World War II", "colne", "acquired a photosynthetic cyanobacterial endosymbiont more recently", "optical illusion", "Hannaford", "theatre", "Germ\u00e1n Efromovich", "time in exchange for detailed public disclosure of an invention", "kabuki", "American actor and drag queen Divine", "Isle of Axholme", "1908"], "metric_results": {"EM": 0.8125, "QA-F1": 0.843482905982906}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-222", "mrqa_naturalquestions-validation-2213", "mrqa_hotpotqa-validation-5011", "mrqa_hotpotqa-validation-4093"], "fixed_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_hotpotqa-validation-2978", "mrqa_triviaqa-validation-6634", "mrqa_triviaqa-validation-1952", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-9421", "mrqa_squad-validation-4433", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_triviaqa-validation-1474", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533", "mrqa_naturalquestions-validation-2713"], "unfixed_ids": ["mrqa_squad-validation-5008", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-4550"], "instant_fixing_rate": 0.7857142857142857, "instant_retention_rate": 0.9999999975}, {"timecode": 99, "before_eval": {"predictions": ["Doctor Who", "india", "elstow", "he issued the Edict of Fontainebleau", "a Gender pay gap in favor of males in the labor market", "Woody's horse", "December 19, 1967", "economic growth", "in 1997 by Bloomsbury", "October 1, 2017", "in Washington, D.C. on a 99 acre campus", "wis", "Toronto, Ontario, Canada", "a saint", "France's claim to the region was superior to that of the British", "a balance sensor consisting of a statolith", "yosemite national park", "field trips", "Nikolai Trubetzkoy", "Judge Roy Bean", "French company R2E Micral CCMC officially appeared in September 1980 at the Sicob show in Paris", "1800 to 1850", "on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "using animals for entertainment purposes and abusing them", "Twink", "Trinidad and Tobago", "india", "9 are coprime", "porto", "Bhaktivedanta Manor", "giant jellyfish or the hair jelly", "Mammals"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3302256710151447}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.5, 0.0, 0.0, 0.13333333333333333, 0.2105263157894737, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 0.14814814814814817, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.23076923076923078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_naturalquestions-validation-3651", "mrqa_hotpotqa-validation-3347", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_squad-validation-10231", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-4961", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-251", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794"], "after_eval": {"predictions": ["Seventh", "national prohibition", "grace abounding", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "Gender", "horse", "May 5, 1939", "economic growth by collecting resources from colonies, in combination with assuming political control by military and political means", "1997", "October 1, 2017", "Washington, D.C.", "wicked witch", "Toronto", "holy servant of Christ", "As to the Summons you send me to retire, I don't think myself obliged to obey it", "a balance sensor consisting of a statolith, a solid particle supported on four bundles of cilia, called \"balancers\"", "yosemite national park", "study halls", "Prince Nikolai Sergeyevich Trubetzkoy", "saloon-keeper", "R2E Micral CCMC", "originated in Europe toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "Pope Gregory I the Great", "his own opinions changed", "Chlo\u00eb Alexandra Adele Emily Agnew", "calypso", "bloody sunday", "one", "portugal", "in the village of Aldenham", "capillata", "Mammals"], "metric_results": {"EM": 0.8125, "QA-F1": 0.9111174242424243}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.88, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9926", "before_prediction": "economic growth", "after_prediction": "economic growth by collecting resources from colonies, in combination with assuming political control by military and political means"}, {"id": "mrqa_hotpotqa-validation-1086", "before_prediction": "a saint", "after_prediction": "holy servant of Christ"}, {"id": "mrqa_squad-validation-4494", "before_prediction": "a balance sensor consisting of a statolith", "after_prediction": "a balance sensor consisting of a statolith, a solid particle supported on four bundles of cilia, called \"balancers\""}, {"id": "mrqa_hotpotqa-validation-5590", "before_prediction": "Nikolai Trubetzkoy", "after_prediction": "Prince Nikolai Sergeyevich Trubetzkoy"}], "retained_ids": ["mrqa_naturalquestions-validation-5630", "mrqa_triviaqa-validation-4000", "mrqa_hotpotqa-validation-2779"], "fixed_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_naturalquestions-validation-3651", "mrqa_hotpotqa-validation-3347", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-4961", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-251", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794"], "unfixed_ids": ["mrqa_squad-validation-3130", "mrqa_squad-validation-10231"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.4285714279591837}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.164375, "QA-F1": 0.2806648505849209}, "overall_error_number": 2674, "overall_instant_fixing_rate": 0.8506231781274923, "final_instream_test": {"EM": 0.6559375, "QA-F1": 0.7233830622414}, "final_upstream_test": {"EM": 0.65, "QA-F1": 0.7717272576807381}}}