{"model_update_steps": 1950, "method_class": "index_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1014_init_mean_dm_simple.train_args.json', indexing_method='biencoder', inference_query_size=1, init_memory_cache_path='exp_results/data_streams/1014_init_mean_biencoder_init_memory.pkl', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/index_based/ckpt_dir/1014_MixedAllErrors_T=50_biencoder_M=U+I_rs=32_rq=1_rank=most_similar_mir=no(0)_seed=567_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/index_based/ckpt_dir/1014_MixedAllErrors_T=50_biencoder_M=U+I_rs=32_rq=1_rank=most_similar_mir=no(0)_seed=567_ckpts/', replay_candidate_size=0, replay_frequency=1, replay_size=32, save_all_ckpts=0, skip_instant_eval=True, total_steps=10000, use_mir=False, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='exp_results/data_streams/mrqa.nq_train.memory.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion", "john Leslie", "Virginia Wade", "Gary Morris", "the anterolateral corner of the spinal cord", "1966", "radioisotope thermoelectric generator", "product or policy that is open and honest", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "koran,kuran reader", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs", "acmthompson", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "$130", "May and June 2010"], "metric_results": {"EM": 0.125, "QA-F1": 0.18128501248113316}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 1.0, 0.25000000000000006, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.07407407407407407, 0.0, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work via automobile or mass transit", "second year", "Masaharu Iwata", "Terry Reid", "non- peer- reviewed sources", "Variations", "North America", "Andr\u00e9 3000", "rookies", "Akhenaten", "Theodore Roosevelt", "from 2010 to 2012", "four", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "is an opera in four acts by French composer Georges Bizet", "Matt Winer", "1689", "Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.0625, "QA-F1": 0.2968648181883476}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.9019607843137255, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.4444444444444445, 0.4, 1.0, 0.0, 0.5, 0.8571428571428571, 1.0, 0.3636363636363636, 0.0, 0.18181818181818182, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_hotpotqa-validation-3242", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 3, "before_eval": {"predictions": ["id", "baijan", "id", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006 British Academy Television Award for Best Drama Series", "Least of the Great Powers", "the efferent nerves that directly innervate muscles", "babbage", "bums", "baze", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "bambi", "cement City, Texas", "the Democratic Unionist Party", "23 July 1989", "the US", "gurus often exercising a great deal of control over the lives of their disciples", "control purposes", "bamboula", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins", "bile duct", "berenice Abbott"], "metric_results": {"EM": 0.09375, "QA-F1": 0.14235197368421051}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 4, "before_eval": {"predictions": ["Austria", "at Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program", "British progressive folk-rock band Gryphon", "1898", "Januarius", "the man chosen to meet God on Sinai and receive the Law on behalf of God\u2019s chosen people", "at elevation 2 meters above sea level", "tetanus", "bounding the time or space used by the algorithm", "ring", "Lieutenant Commander Steve McGarrett", "Eddie Leonski", "Jack", "a mixture of phencyclidine and cocaine", "bunker", "1934", "the Reverse - Flash", "3 - day observance known as Allhallowtide", "Ewing Kauffman", "baku", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the duchy of Prussia", "can be significantly impaired in one ( or several ) of the four communication modalities following acquired brain injury or have significant decline over a short time period ( progressive aphasia )", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotationating discs", "Splodgenessabounds"], "metric_results": {"EM": 0.25, "QA-F1": 0.3573660714285714}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.6666666666666666, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0]}}, "error_ids": ["mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 5, "before_eval": {"predictions": ["lester Young", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "a soft wool fabric with a colorful swirled pattern of curved shapes", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "2 : 44 p.m. EDT", "swannee whistle", "a genetically engineered plant", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "the Department of Physics, Cochin University of science and Technology", "Parietal cells ( also known as oxyntic or delomorphous cells )", "a distant ancestor of the \"superior\" placental mammals", "September 13, 1994", "a new device", "imperial rule", "1840", "make a defiant speech, or a speech explaining their actions", "George Scherff", "kinks", "a greater tendency to take on debts", "often associated with the transfer of heat", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "a way of housing a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17616744066047474}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 6, "before_eval": {"predictions": ["clopedia2", "to prevent the flame from being blown out", "Illinois", "1998", "fossil city", "tourist", "90-60's", "unaided independent school", "dolph Camilli", "times sign", "BAFTA Television Award", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "d. Eisenhower National Airport", "monatomic", "popular for its resort feel and nearby open spaces", "june", "fossil", "fossil fruit", "common", "widow - maker infarction due to a high death risk", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land", "Indian Ocean near Grande Comore, Comoros Islands", "crore", "Norwegian", "fossil fuels"], "metric_results": {"EM": 0.0, "QA-F1": 0.07230998168498169}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.46153846153846156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "Maya group", "few", "authorized army branch insignia", "Kairi", "both inner city blacks, who wanted more involvement in government", "director", "near the Black Sea", "the last book accepted into the Christian biblical canon", "Beyonc\u00e9", "buttermens", "for gallantry", "most popular show", "1950s", "work oxen for haulage", "1998", "a priest", "23.1", "18 - season career", "family member", "long-term environmental changes", "8-track cartridge", "tangential force", "Terrell Suggs", "decide on all the motions and amendments", "a voyage of adventure", "Abraham Gottlob Werner", "marlborough", "present-day Charleston", "\"quiescent\" stance", "Adam Karpel", "panzer"], "metric_results": {"EM": 0.28125, "QA-F1": 0.38747519841269845}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "georgeppe Antonio 'Nino' Farina", "37.7", "6.4 nanometers apart", "the eighth and eleventh episodes of the season", "Kyle Busch", "400 games", "adrenal glands", "liberal arts ( artes liberales )", "Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "Eureka", "1918", "2018", "waldock", "law firm", "Pottawatomie County", "orangutan", "general relativity", "The church tower", "EastEnders star Danny Dyer", "Toronto", "wales", "110 miles (177 km )", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six", "not guilty", "psychotherapeutic theories and associated techniques", "Quentin Coldwater", "acidic bogs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.35789930555555555}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2666666666666667, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian", "Ear Institute at the University College London", "almond paste", "reduces the efficiency of photosynthesis", "capture images of different animals and humans perform various actions", "White House", "The Krypto Report", "triplet", "flour", "president", "citizens", "George, Margrave of Brandenburg-Ansbach", "Kamba version", "3D computer-animated comedy film", "Bloomingdale Firehouse", "acting", "C. W. Grafton", "liquid crystal", "Americans", "IPod Classic", "My Sassy Girl", "drain the body of used up and broken down components in a liquid and gaseous state", "The Edge of Night", "non-combustible substances that corrode", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "ATP", "organic carbon", "formula", "medium and heavy-duty diesel trucks", "testes"], "metric_results": {"EM": 0.25, "QA-F1": 0.3752029530347608}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.8421052631578948, 1.0, 0.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 1.0, 0.19999999999999998, 0.4, 0.0, 0.3333333333333333, 0.17391304347826086, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-1327", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744)", "Walter Reed Army Hospital in Washington, D.C. from 1942 to 1945", "three legal systems", "Las Vegas", "status code", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "a Dubliner tried to kill Benito Mussolini", "a saint addicted to excessive self-abnegation", "menhirs", "Victoria resided with her mother prior to acceding the throne", "the base 10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "a new era of social history and kitchen-sink realism in living museums", "the MGM Grand Garden Special Events Center", "a virtual museum dedicated to Italian fashion designer Valentino", "Ronnie Hillman", "all-encompassing", "1987", "60", "Eagle Ridge Mall", "Pel\u00e9", "reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Barney Fife", "the shooter must be at least 18 or 21 years old ( or have a legal guardian present )", "Bacha", "novelist and poet", "Jamestown", "Rouen Cathedral", "tree growth stages"], "metric_results": {"EM": 0.21875, "QA-F1": 0.37181186868686866}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.9333333333333333, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.2222222222222222, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "\"Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "The TEU", "absolute zero", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "alexander", "the bridge is longer from shore to shore", "trams", "tunisia", "panegyric", "the Bulgars", "killed", "Volkswagen Beetle", "joseph kansas", "North American Technate", "Queen Elizabeth I", "infection, irritation, or allergies", "ascend the tower every day", "the Vittorio Emanuele II Gallery and Piazza della Scala", "catfish aquaculture", "atomic number 53", "James and D.J. Looney as Young Sparrow and DJ Dragon Nutz", "Iraq", "a co-op of grape growers", "mann on a mission", "joseppe Verdi", "1952", "the Charlotte Hornets", "`` speed limit '' omitted and an additional panel stating the type of hazard ahead.", "Jean F kernel ( 1497 -- 1558 ), a French physician", "the back of the head"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2055807550292844}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.4444444444444445, 0.09090909090909091, 0.22222222222222224, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 12, "before_eval": {"predictions": ["Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "d'armes", "Margaret Thatcher", "Dan Fouts", "2014", "The stability, security, and predictability of British law and government", "Minos", "Ignacy Jan Paderewski", "ferrey", "norway", "New South Wales", "Fort Williams (the latter two located on the Oneida Carry between the Mohawk River and Wood Creek at present-day Rome, New York)", "dandy", "eata", "Orwell", "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \"regnum Bohemia\"", "Gregg Popovich", "not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "adaptive immune system", "under the tutelage of his uncle", "a musician", "norway", "December 1, 1969", "american", "duke of edinburgh", "California State Automobile Association", "\"alone\"", "Cinderella", "delayed the sealing of the hatch", "due to a fear of seeming rude"], "metric_results": {"EM": 0.125, "QA-F1": 0.23002753180771757}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.11764705882352941, 0.3076923076923077, 0.0, 0.2424242424242424, 0.4, 0.0, 0.33333333333333337, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.631578947368421]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-6924"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Jason Lee", "Napoleon", "bakers", "3.7 percent", "negative", "Garthy &\u00a0T Travis", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni", "discipline problems with the Flight Director's orders during their flight", "sportology Stack Exchange", "paddington", "amyotrophic lateral sclerosis ( ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "mid 1970s", "Torah", "the western coast of Italy", "first and only U.S. born world grand prix champion", "the quintessential New Orleans art form -- a jazz funeral without a body", "mid November", "Facebook", "mohnbeugel (with ground nuts)", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Seattle, WA", "King George's War", "cheated on Miley", "rock music subgenres had emerged", "Fort Saint Anthony", "daguerreotypes", "a Mediterranean climate, with infrequent rain and many sunny days"], "metric_results": {"EM": 0.125, "QA-F1": 0.23146983225108225}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4444444444444445, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.25, 0.0, 1.0, 0.2222222222222222, 0.28571428571428575, 1.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "American sympathizer in the American Revolutionary War", "River Phoenix", "FX option", "electromagnetic waves", "Wahhabi/ Salafi", "nine", "Dimensions in Time", "Surveyor 3", "January 1981", "luteinizing hormone", "baptismal theology", "\"some priest whose name was Martin Luther\"\u2014may his body and soul be bound up in hell", "john Robertson", "slowing the vehicle", "Cheyenne", "appearance of fossils in sedimentary rocks", "Hanna- Barbera", "the Veneto region of Northern Italy", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "fox", "maryland", "Alexander Hleb", "state sector", "2 February 1940", "poverty", "a god of the Ammonites, as well as Tyrian Melqart and others", "sclera", "Uncle Fester", "\"Danno\" Williams"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22621985058845673}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.43478260869565216, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 0.0, 0.5, 0.5, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["being bitten by radioactive/genetically-altered spiders", "Part 2", "the Flatbush section of Brooklyn, New York City", "San Antonio", "Akon, Christina Aguilera and Taio Cruz", "brian huygens", "a friend and publicist", "brian clifton", "masons'marks", "March 12, 1948", "Gateshead", "a Yogiism, or quotation from Yogi Berra", "The neck", "1898", "professional wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "diahann Carroll in \"Claudine\"", "Curtiss Jenny JN-4HM", "art", "gorillas", "March 15, 1945", "absolute temperature", "leaking through the whistle-blowing website", "Julius Robert Oppenheimer", "bicuspid", "his brother, Menelaus", "25 November 2015", "tallahassee", "prefabricated housing projects", "brian buchledickens", "WOTV"], "metric_results": {"EM": 0.0625, "QA-F1": 0.09409340659340659}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 16, "before_eval": {"predictions": ["galileo", "cow's milk cheese", "benedict", "the lateral side of the tibia", "ferguside royal clan", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "October 29, 1985", "Amway", "Mauritius", "Thomas Sowell", "Speaker of the Lok Sabha", "Golden Globe Award", "Tanzania", "Chad", "60-mile-wide", "an open work crown", "Crowley brought back Samuel so that they could help him find Purgatory, the afterlife of monsters, and that Samuel has been working for him", "London", "French, English and Spanish", "fred fred", "U.S. Marshals", "The Heirs\" (2013)", "supply chain management", "Mars rover", "Stanislaw August Poniatowski", "a method of elimination to reduce the simultaneous equations to a single equation with only one unknown", "freda Davis", "three mystic apes", "sheepskin", "Honolulu"], "metric_results": {"EM": 0.15625, "QA-F1": 0.19315476190476188}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.06666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.21428571428571425, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-2287"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["belgian soft cheese", "Deadpool", "August 6, 1845", "gamma ray emission ( energy of 514 keV )", "James Zeebo", "sovereign states", "president of the United States", "\"Teach the Controversy\" campaign", "Bumblebee", "Australian", "30 months", "geographic area", "lower", "a private liberal arts college", "Roy Warren Spencer", "\"antiforms\" or where it buckles downwards, creating \"synforms\"", "June 9, 2015", "\"Veyyil\"", "Grace Nail Johnson", "Keith Richards", "at least one prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "180th", "Adult Swim", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat", "33", "grape", "Annual Conference Cabinet", "bronze", "William Hartnell's poor health"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2854305926916221}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 0.8, 0.2222222222222222, 0.0, 1.0, 0.3333333333333333, 0.0, 0.23529411764705882, 0.25, 0.08333333333333333, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-3573", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 18, "before_eval": {"predictions": ["the genocide against the Tutsi", "Co-teachers work in sync with one another", "500 metres", "Nasim Pedrad", "the entertainment division", "the straight - line distance from A to B", "12", "South Kensington Museum", "Henry VIII", "the Chagos archipelago", "dundee", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "lithgow Palace in Scotland", "\"Grindhouse\" fake trailer", "lena davenport", "digital transmission", "the Swiss cantons of Thurgau and St. Gallen", "Tesla Gigafactory 1", "821", "Virgin Media", "gas", "Kim Hyun-ah", "the races of highest'social efficiency'", "transposition", "Dino Paul Crocetti", "President Woodrow Wilson", "rubileogeia", "the fifth season", "the kray twins", "Hockey Club Davos", "Michael Patrick Smith", "a lightning strike"], "metric_results": {"EM": 0.125, "QA-F1": 0.1982638888888889}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.4, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_hotpotqa-validation-4068", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_naturalquestions-validation-10490"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "Norman Macdonnell", "aragon", "11.1", "trans-Pacific flight", "Sharman Joshi", "usually have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "the factorial (p \u2212 1)! + 1 is divisible by p", "Ana", "Cherry Hill", "The Duel", "f. O. Matthiessen", "venus peltier", "comedy - drama", "blackstar", "Star Plus", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "In 1889", "Nicki Minaj", "slave of duty", "Huguenot", "venus fagioli", "friedrich Engels", "\"Drawn Together\"", "William the Conqueror", "Sde Dov Airport", "two degrees of freedom", "Corinthian and Saronic Gulfs", "blood", "Guinness World Records", "Southern Progress Corporation"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25238320707070705}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.25, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-3049", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 20, "before_eval": {"predictions": ["gas turbines", "David Feldman", "drawings", "karl marx ( ) (born Dante Terrell Smith", "kaleidoscope", "in British Columbia, in the Abbotsford, Vancouver and Langley areas", "AS-205", "ribosomal RNA", "kookaburra", "six", "Shalita Grant", "'Friends\"", "Kozunak ( Bulgarian : \u043a\u043e\u0437\u0443\u043d\u0430\u043a, Bulgarian pronunciation : ( kozu\u02c8nak ) )", "Belfast", "a heliocentric orbit", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "trust God's word", "karl marx", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "\" My Love from the Star\"", "San Jose", "sea wasp", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Native American tradition", "\"the most giving Super Bowl ever\"", "29.7", "karl marx marx"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3804330065359477}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.4444444444444445, 0.4, 0.0, 1.0, 0.5294117647058824, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier - Rebecca", "various registries", "human blood", "Yazoo", "22 April 1894", "a black hole", "\"the soul does not sleep (anima non sic dormit) but wakes (sed vigilat) and experiences visions\"", "cede the former", "Willie Nelson and Kris Kristofferson", "periodicals", "private", "a French pirate", "Lewis", "Charles Dickens", "non-profit, ECOSOC non-governmental organization", "carbohydrates", "2001", "(i.e. exceeds any given number)", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "R\u00e5", "tribes in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British)", "Orthodox Christians", "James Bond", "640 \u00d7 1136", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "quarterback", "Larry Gatlin & the Gatlin Brothers Band"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2870709662069956}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.4, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.888888888888889, 0.0, 0.23529411764705882, 1.0, 1.0, 0.6153846153846153, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.15384615384615385]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-3627", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "MSC Crociere S. p.A.", "trait\u00e9 de la science des Finances", "his friends, Humpty Dumpty and Kitty Softpaws", "Liberals", "Royalists", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "placed on the heads of Christians", "al\u00e9a seydoux", "20,000 leagues under the sea", "Augustus Waters", "14 September 1547", "Tony Blair", "\u2018 Often damaging\"", "June 11, 1973", "Kenya", "critical quotations", "alison i \"The Magnificent\"", "an active supporter of the League of Nations", "Cargill", "AMC Entertainment Inc.", "\"The Gang\"", "3 October 1990", "March 1, 2018", "weak force", "daedalus", "Martin Luther King III", "Manhattan Project", "Chronicles of Barsetshire", "vast"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23635461760461757}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 0.4444444444444445, 0.0, 0.33333333333333337, 0.1111111111111111, 0.0909090909090909, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.8, 0.0, 0.0, 0.5714285714285715, 0.0, 0.1818181818181818, 0.0, 0.4, 0.0, 0.2, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_naturalquestions-validation-1328", "mrqa_squad-validation-2828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion", "EBV", "about two-thirds", "1934 Austin seven box saloon", "j Javier (Luna)", "red", "Dreamland", "Animated Feature", "European Union institutions", "American record for the most time in space (381.6 days)", "Death Wish Coffee", "CAL IPSO satellite", "celandine flowers", "John F. Kennedy", "Ronnie Schell", "artemisinin-based therapy", "Mumbai, Maharashtra", "east of Ireland", "1939", "2017 / 18 Divisional Round game", "possibly 1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "midlands of the river Niger Benue trough to over 2,000 mm ( 78.7 in ) along the south western escarpment of the Jos Plateau", "dambala", "Incudomalleolar joint", "bobby riggs", "Leucippus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth", "log-space reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.21875, "QA-F1": 0.35634875541125544}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.5, 0.25, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 0.08, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-542", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 24, "before_eval": {"predictions": ["2017 -- 15", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "the Duke of Cumberland", "gold", "WBC and lineal titles", "moluccas", "Saturday", "Albany", "arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "1990", "J.R. R. Tolkien", "Peyton Manning", "Selena Gomez", "join a polytechnic or other technical college and study for four years in high school or secondary school", "bingo", "Eugene", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze Rug", "the nine circles of Hell", "two Mongols and a Muslim", "along the coast", "the Friars Minor Conventual (O.F.M. Conv))", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts, which are sticky and adhere to prey", "Jon M. Chu", "Mission Specialist for mission STS-51-L.", "it will retreat to its den and winter will persist for six more weeks", "mitterrand"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3382763203108948}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.9600000000000001, 0.0, 0.5714285714285715, 0.0, 0.0, 0.45454545454545453, 0.0, 0.0, 0.5, 0.7692307692307693, 0.0, 0.4, 0.0, 0.4, 1.0, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.0, 0.33333333333333337, 0.5957446808510638, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-4417", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 25, "before_eval": {"predictions": ["alpine skiing, cross-country skiing, ski jumping, nordic combined, snowboarding and freestyle skiing", "slave", "over 50 million singles", "states'rights to expand slavery", "1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "lyda Elizabeth", "iteratively", "geese", "the move from the manufacturing sector to the service sector", "jagera peoples", "Sylvester McCoy", "August 14, 1848", "lower rates of social goods", "juveniles are capable of reproduction before reaching the adult size and shape", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "epic verse", "2,664 rooms", "bendy iPhone", "chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "facility management services", "Symphony No. 7", "garonne", "1603", "ranked above the two personal physicians of the Emperor", "marzipan", "praying only for knowledge of His will for us and the power to carry that out", "wrigley"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3408977480852481}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.33333333333333337, 0.7200000000000001, 0.4615384615384615, 0.923076923076923, 0.0, 0.6666666666666666, 0.5, 0.2857142857142857, 0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 0.07142857142857144, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "south", "an investment technique outlined by Joel Greenblatt that uses the principles of value investing", "true history of the Kelly Gang", "Haleiwa Ali'i Beach Park", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "tennis", "4,000", "Khagan", "Heathcliff", "river", "spice", "The Simpsons Spin-Off Showcase", "Barry Parker", "San Bernardino", "Grey Street", "Albany High School for Educating People of Color", "Rashtrapati Bhavan", "Sergeant First Class", "Shaw", "seek jury nullification", "Cee - Lo", "Anglican", "mammy two Shoes", "battlecruiser Renown", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "redistributive", "1757"], "metric_results": {"EM": 0.1875, "QA-F1": 0.33093434343434347}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5454545454545454, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 27, "before_eval": {"predictions": ["l.A.", "mcdaniel geldof", "red berry", "birmingham", "\" Big Mamie\"", "birmingham", "the \"eternal outsider, the sardonic drifter\" someone who rebels against the social structure", "a light sky-blue color caused by absorption in the red", "the peasants had to work for free on church land", "1963", "February 7", "the internal thylakoid system", "aline charigot", "Melbourne", "B SkyB has no veto", "the fourth season", "electrostrong interaction", "availability of skilled tradespeople", "birmingham", "A simple iron boar crest", "polytechnics became new universities", "Jack Beasley", "James", "25 - yard line", "the Latin centum", "about 7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "birmingham", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "group"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2561045725108225}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.5, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.0, 0.375, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 28, "before_eval": {"predictions": ["the Muslim faith as a tool of the devil", "Chris Weidman", "seek jury nullification", "Harishchandra", "held and expressed an irreligious world view which was met with controversy", "Professor Eobard Thawne", "slivovitz", "a US$10 a week raise over Tesla's US$18 per week salary", "1875", "member states", "oboe", "an advisor to non-profits such as the Bill & Melinda Gates Foundation and The Global Fund to Fight AIDS, Tuberculosis and Malaria", "acrophobia", "Living Doll", "Crohn's disease", "Ondemar Dias", "Raya Yarbrough", "Arizona", "mcdaniel", "Charles L. Hutchinson", "Old Testament", "brown", "local talent", "Football League", "tegan", "mcdale", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "birrattsville", "1332", "dodo bird", "by focusing on negative or negative thoughts people can bring positive or negative experiences into their life", "renoir"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3119047619047619}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 0.14285714285714288, 1.0, 0.0, 0.5, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 1.0, 1.0, 0.8888888888888888, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 29, "before_eval": {"predictions": ["poisonous", "886 AD", "to finance his own projects with varying degrees of success", "24 Hours of Le Mans", "360", "Beijing", "Darian Stewart", "the parallelogram rule of vector addition", "public speaking", "364", "a neutron source", "starry starry night", "lower-pressure steam", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the Imperial Secretariat", "Doctor Who Theme", "National Basketball Development League", "gillingham", "St. Mary's County", "T. J. Ward", "2,615", "Pyeongchang", "a nickname for athlete Colin Kaepernick ( although he prefers \"Kap\")", "a password recovery tool for Microsoft Windows", "Homeless Man", "American designers who made significant historical contributions to the development of modern architecture and furniture", "Brazil", "abraham lincoln", "the smallest subfield", "ginger", "53%", "photosynthesis"], "metric_results": {"EM": 0.125, "QA-F1": 0.21950280112044818}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.8, 0.0, 0.0, 0.38095238095238093, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705, 0.6666666666666666, 0.11764705882352941, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_squad-validation-7914", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-8873"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "an outgoing, eccentic, big - hearted, loving, sweet, and thoughtful elephant and teacher", "arpers Ferry", "arthur booth", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "BBC UKTV", "arthur", "demographics and economic ties", "three or more", "The Kickoff Game", "narcolepsy", "arctic monkeys", "mcd Ecclestone", "arthur", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "A computer program", "rural-based National Party of Australia", "marduk", "arthur", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "viacom", "The Coral Sea is a marginal sea of the South Pacific off the northeast coast of Australia, and classified as an interim Australian bioregion.", "Article 7", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Evan Jonigkeit", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "president of India", "National Lottery", "Apollo", "katherine of aragon", "to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12169788818637502}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.1904761904761905, 0.6666666666666666, 0.12121212121212122, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4000000000000001]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 31, "before_eval": {"predictions": ["Selena", "Peter", "sarajevo", "national team", "Newell Highway", "polly", "a horse is 15 hands", "largest mall in the United States in terms of total floor area ( including Nickelodeon Universe ), and the twelfth largest in the world", "civil disobedience defendants choose to make a defiant speech", "Andrew Adamson", "liszt Strauss", "his own men", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "polly", "the RAF", "encourage growth", "Ibrium", "national tour", "Polish-Jewish", "a variety of political groups that supported the Spanish coup of July 1936 against the Second Spanish Republic, including the Falange, the CEDA, and two rival monarchist claimants : the Alfonsists and the Carlists", "polly", "polly", "an estimated 390 billion", "Washington Street", "May 10, 1976", "five", "polly", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "polly", "Lenin", "surtania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2625868055555555}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.375, 1.0, 0.0, 0.0, 0.37037037037037035, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.45000000000000007, 0.0, 0.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 32, "before_eval": {"predictions": ["an orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "beer", "gender test", "Matt Jones", "kalium", "extreme circumstances, a driver may attempt to jackknife the vehicle deliberately in order to halt it following brake failure", "CD4+ and CD8+", "generally paid on graduated scales, with income depending on experience", "fruit", "Heading Out to the Highway", "James Bond, Moonraker", "$299", "Michael Oppenheimer", "England national team", "\"degrees of privilege\" to which they were entitled institutionally and legally, so a person's standing within the classes was not a guarantee of their standing", "No Night Today", "Convention", "5,922", "December 5, 1991", "the title character in Luc Besson's \"Valerian and the City of a Thousand Planets\"", "Phoenix Suns", "the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "the Stern-Plaza in Potsdam", "the boxing match between WBC/WBA heavyweight champion Joe Frazier (26\u20130, 23 KOs) and Ring magazine/lineal heavyweight champion", "23 March 1991", "lily-of-the-valley", "Dealey Plaza", "Nairobi", "the chalk ridge line west of the Needles breached to form the island", "Anno 2053"], "metric_results": {"EM": 0.125, "QA-F1": 0.22517887205387205}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.14814814814814814, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.5, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "is a controversial Canadian-American Roman Catholic priest based in the United States near Detroit at Royal Oak, Michigan's National Shrine of the Little Flower church", "1967", "is the amount charged by a bookmaker, or \"bookie\" for taking a bet from a gambler", "the twelfth most populous city in the United States", "115", "bridge", "is involved in oncogenesis, either by gene mutation, or chromosome translocation, or simply by over-expression", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Tevye", "Mississippi", "Japan", "bridge", "Yunnan- Fu", "Mumbai", "Broken Hill and Sydney", "2005", "all punishments and granted them salvation were in error", "The Doctor's Daughter", "may", "Carlos The Jackal", "The project must adhere to zoning and building code requirements. Constructing a project that fails to adhere to codes does not benefit the owner", "1879", "paternal great-grandmother", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "enthusiasm", "Russo- Japanese", "Datsun 810", "Arkansas", "Oslo county"], "metric_results": {"EM": 0.125, "QA-F1": 0.16110809449171518}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "wartnell", "Threatening government officials", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "boulangere", "0.2 inhabitants per square kilometre", "wick Graham", "France", "Ian Paisley", "Bataan Death March", "litas", "september", "United States", "by Sherry Rowland and Mario Molina", "c. 1886", "second sophomore", "Stanwyck's bedroom window", "juba", "a circular movement of an object around a center ( or point ) of rotation", "Johnny Darrell", "carotid artery disease", "a Belgian law requiring all margarine to be in cube shaped packages", "Euler's totient function", "wax", "binary strings", "third", "orange", "Toyota Corona", "Kurt Vonnegut", "king and queen of Corona"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2181013431013431}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.42857142857142855, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "supply and demand", "Emma Watson", "brain, muscles, and liver", "afghanistan", "Washington Redskins", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "William Howard Ashton", "national security, big oil companies and bribery and corruption", "rising inequality in the United States and elsewhere is the most important problem. Increasing inequality harms economic growth. High and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Broward County", "Lee Byung-hun", "changing display or audio settings quickly", "king Charles I", "from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "if the income share of the top 20 percent (the rich) increases", "Beauty and the Beast", "afghanistan", "Tyler \" Ty\" Mendoza", "Alamo", "a seal illegally is broken", "United Methodist Church", "Brian Liesegang", "Don Hahn", "Port Moresby", "adolescent Baby Boomers", "National Association for the Advancement of Colored People", "1963\u20131989", "Titanic", "sudden death of incumbent leader John Smith", "what happens when a witch and a mortal fall in love and get married", "6500 - 1500 BC"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3227902306027306}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, false], "QA-F1": [0.5, 0.28571428571428575, 0.0, 0.4, 0.0, 0.0, 0.25, 1.0, 0.0, 0.06060606060606061, 0.0, 0.0, 0.4, 1.0, 0.4615384615384615, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_triviaqa-validation-6450", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Kevin Costner", "north pole", "president harding", "Cobham\u2013Edmonds thesis", "human, or humanoid aliens", "Seal", "March 2012", "jazz club", "Muhammad Ali", "Coldplay", "Spain", "to civil disobedients", "Julius Caesar", "2%", "1979", "James Halliday", "decision problem", "lecouvreur", "heart", "Miasma theory", "imperial", "mountain ranges", "president", "significant production of peaches as early as 1571, with exports to other states occurring around 1858", "butterfly", "$12", "flat rate", "david hartland", "a member of Davies' team ( Roger Scantlebury) met Lawrence Roberts at the 1967 ACM Symposium on Operating System Principles and suggested it for use in the ARPANET", "roughly west", "Sudan"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2687003968253968}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.4, 0.0, 0.5, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_triviaqa-validation-4069", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "three of his ribs were broken", "7 December 2000", "Post Alley", "mother-of-pearl", "February 20, 1978", "haggis", "Walter Mondale", "96", "first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "president harding", "black", "Jericho in the Levant region", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Harry Kane", "small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "many events and festivals", "sweeteness", "1991", "albert star system", "7 January 1936", "ten years", "twenty- three", "Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Ron Dahl Tomasson, Abel Xavier, Gheorghe Popescu, Florin R\u0103ducioiu, Maniche, Marko Marin, Eduardo Vargas and Obafemi Martins", "defiant speech", "cream", "Boston, Massachusetts"], "metric_results": {"EM": 0.1875, "QA-F1": 0.25091036414565826}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35294117647058826, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.39999999999999997, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_naturalquestions-validation-969", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "dragon", "The primary catalyst for secession was slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "The History of Little Goody Two - Shoes", "It has the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east ).", "gathering money from the public", "Eden and Thorgan", "commissioned officers are given a one - time stipend when commissioned to purchase their required uniform items", "Paul Freeman", "741", "Norman Painting", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "Suez Canal", "60", "journalist", "the fact that there is no revising chamber", "pillbox hat", "the points of algebro-geometric objects", "most of the items in the collection", "does not satisfy the criteria for a medium of exchange", "glycine receptor", "The Alta Wind Energy Center in California", "1945", "13 June 2003", "Eddy Shah", "Raquel the Rhino", "in sequence with each heartbeat"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2345341341664871}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 1.0, 0.05714285714285714, 0.47058823529411764, 0.28571428571428575, 0.23529411764705882, 0.0, 0.0, 0.0, 0.15384615384615383, 0.0, 1.0, 0.2857142857142857, 1.0, 0.6, 0.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-3320", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 39, "before_eval": {"predictions": ["capital city", "Dan Conner", "checkpoint Charlie", "president harding", "Jean Parker (born Lois Mae Green, August 11, 1915 and November 30, 2005) was an American film and stage actress.  She landed her first screen test while still in high school.", "violence", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "kuskus", "1977", "Carl Sagan", "New York", "william herschel", "2003", "March", "NTV, an Italian company which is Europe's first private open access operator of 300 km/h (186 mph) high-speed trains", "the second Sunday of March", "relative units", "woman", "two", "August 10, 1933", "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Sochi, Russia", "those who already hold wealth", "B. Traven", "It is themed to the Disney-Pixar film \" Finding Nemo\" and named after Crush, a green sea turtle character from the film.", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "too much money chasing too few goods", "black bear, white-tailed deer, raccoon, coyote, grey squirrel, chipmunk, and other small rodents", "264,152", "Princeton, New Jersey", "the German Empire", "high pressure or an electric current"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2721829640947288}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.3636363636363636, 0.19999999999999998, 0.11764705882352941, 0.0, 0.14285714285714288, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_hotpotqa-validation-5233", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-489", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "arajevo", "Isabella (Belle) Baumfree", "Vulcan", "1623\u201340", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "The antichrist of 2 Thessalonians 2", "Aristotle", "Moses, an adopted Egyptian prince who becomes the deliverer of his real brethren, the enslaved Hebrews, and therefore leads the Exodus to Mount Sinai, where he receives, from God, the Ten Commandments", "anti-inflammatory molecules, such as cortisol and catecholamines", "vUHMOaD/JVI aiAQBAJA jaMOJOD", "Kevin Kolb", "one of the uses of money", "the force of law, if based on the authority derived from statute or the Constitution itself", "ch\u00e2teau de chambord", "when the Mongols placed the Uighurs of the Kingdom of Qocho over the Koreans at the court the Korean King objected", "Sochi, Russia", "right-handed knights preferred to keep to the left in order to have their right arm nearer to an opponent", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "At the insistence of NASA Administrator Webb", "south australia", "your doreen was born in Brixton, South London, in September 1923 and worked as a shorthand typist for the Director of Public Prosecutions at Temple", "30", "the Secret Intelligence Service", "100 billion", "kai su, teknon", "the photolysis of ozone by light of short wavelength", "4 - inch", "Queen City", "is an American federal law that imposes liability on persons and companies ( typically federal contractors ) who defraud governmental programs. It is the federal Government's primary litigation tool in combating fraud against the Government"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23881540334665335}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.13333333333333333, 0.14285714285714288, 0.0, 0.09523809523809522, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.16, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-1571", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_triviaqa-validation-4123", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Indian", "Gaels", "Brag", "d\u00edsir", "European or Eurasian cave lion", "Russian film industry", "flooding and sedimentation", "Washington metropolitan area", "GTPase responsible for endocytosis in the eukaryotic cell", "User State Migration Tool ( USMT )", "Ordos City", "flying disc", "PPG Paints Arena, Pittsburgh, Pennsylvania", "philry wall", "2001", "Wilbur, a pig who was almost killed due to being a runt", "1984", "quasars", "Monsoon", "Romansh", "elisabeth II", "5AA", "Q Branch (or later Q Division) the fictional research and development division of the British Secret Service", "Paul and Timothy", "the division of labour, productivity, and free markets", "Gerard Marenghi", "afrah's Next Chapter", "Nebula Award", "united Kingdom general election", "king dav", "Elvis Presley"], "metric_results": {"EM": 0.125, "QA-F1": 0.18454071969696967}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.05, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.5, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 42, "before_eval": {"predictions": ["david carradine", "cavatelli, acini di pepe, pastina, orzo, etc. ), lentils, or grated parmesan cheese", "brian", "independence from the Duke of Savoy through an alliance between the city-state of Geneva and the Swiss Confederation", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "chartered", "mistreatment from government officials", "Danish", "centre-back", "jonathan", "the duodenum", "the disaccharide sucrose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "daniel e. Greene", "By functions ; Introverted Sensing ( Si ), Extverted Feeling ( Te ) and Extroverted Intuition ( Ne )", "Thursday", "white", "the appropriateness of the drug therapy (e.g. drug choice, dose, route, frequency, and duration of therapy) and its efficacy", "Mars", "feats of exploration", "the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "st. elmo", "The Education Service Contracting scheme of the government", "bamba", "The benefits of good works could be obtained by donating money to the church", "colonies", "two forces, one pointing north, and one pointing east", "new laws or amendments to existing laws as a bill", "Jack Murphy Stadium", "hierarchy theorems"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31820185023310027}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.7000000000000001, 0.0, 0.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.375, 0.5, 0.0, 0.4, 0.0, 1.0, 0.6923076923076924, 1.0, 1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-6735", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_squad-validation-6369", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-7034", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 43, "before_eval": {"predictions": ["Niagara Falls", "tiles", "Indiana", "temple", "French", "a sailor coming home from a round trip", "domain name www.example.com", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "Py", "products are intentionally mostly made without ingredients that are: chemically derived, have a negative environmental impact, or are tested on animals", "egypt", "Rigoletto", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally.", "third-most abundant element in the universe", "iKEA", "216", "egypt", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Algernod Lanier Washington", "the Outfield", "Croatia", "Michael Edwards", "railway locomotives", "eddie thatcher", "third quarter ( also known as last quarter )", "egypt", "Yuan T. Lee", "Kentucky, Virginia, and Tennessee", "many areas of technology incidental to rocketry and manned spaceflight", "Mitochondrial Eve", "615 square kilometers", "egypt"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2870293841220699}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.3333333333333333, 0.21052631578947367, 0.0, 0.08333333333333334, 0.0, 0.0, 0.11764705882352941, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-3812", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 44, "before_eval": {"predictions": ["Wakanda", "high school teachers are generally paid on graduated scales, with income depending on experience. Teachers with more experience and higher education earn more than those with a standard bachelor's degree and certificate.", "England and Wales Cricket Board ( ECB )", "meyer", "football", "campaign setting", "2003", "867 feet", "the Hebrew name Immanu'el ( \u05e2\u05b4\u05de\u05b8\u05bc\u05e0\u05d5\u05bc\u05d0\u05b5\u05dc \u202c, which means `` God with us. ''", "Shape of You", "Christopher Lee as Count Dooku / Darth Tyranus", "8th", "sprightly folktale", "all health care settings, but the clinical pharmacy movement initially began inside hospitals and clinics. Clinical pharmacists often collaborate with physicians and other healthcare professionals to improve pharmaceutical care.", "more integral within the health care system. Rather than simply dispensing medication, pharmacists are increasingly expected to be compensated for their patient care skills.", "treble clef", "Gabriel Alberto Azucena", "12951 / 52 Mumbai Rajdhani Express - maximum speed including halts 12049 / 50 : Agra Cantonment - H. Nizamuddin Gatimaan Express - 160 km / h", "Rome", "December 1, 2009", "Estelle Sylvia Pankhurst", "meastricht", "Lord Chancellor of England", "meyer", "Arun Jaitley", "Irish", "ancient cult activity", "meyer Bronte", "energy-storage molecules", "space telescope", "us to respond to God by leading a Spirit-filled and Christ-like life aimed toward love", "Christ lag"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2686145859859095}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.27777777777777773, 0.4, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 0.7272727272727273, 0.0, 0.0, 0.25, 0.5882352941176471, 0.0, 0.0, 0.4, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 45, "before_eval": {"predictions": ["spillane", "Cleveland Browns", "perique", "under `` the immortal Hawke ''", "death penalty", "a stout man with a \"practice chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "sweden", "chr\u00e9tien de Troyes", "Mangal Pandey of the 34th BNI", "V Alaudae, a Celtic legion recruited from Gallia Narbonensis and XXI, possibly a Galatian legion from the other side of the empire", "Cartwright clan", "four", "curling", "eighth series", "Pebble Beach", "St. Louis", "French", "Henry Daniel Mills", "\"LOVE Radio\"", "Boston Red Sox", "the court", "travolta", "David Dobkin", "brought several hundred thousand US and allied non-Muslim military personnel to Saudi Arabian soil to put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "Fox News Specialists", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Command/ Service Module", "San Francisco Bay Area at Santa Clara, California", "a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Landing Barge, Kitchen or LBK was a landing craft used to support amphibious landings in North Western Europe during and after the Normandy invasion in the Second World War.", "Mediterranean Sea"], "metric_results": {"EM": 0.1875, "QA-F1": 0.25402358058608054}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.07142857142857142, 0.0, 0.0, 0.4166666666666667, 0.4, 0.4, 0.07142857142857142, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_triviaqa-validation-455", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_hotpotqa-validation-3509", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 46, "before_eval": {"predictions": ["bat-and-ball", "the seafloor itself moves ( and also carries the continents with it ) as it expands from a central axis", "take that, East 17 and Boyzone", "youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "the development of safety lamps, Stephenson's Rocket, Lord Armstrong's artillery, Be-Ro flour, Joseph Swan's electric light bulbs, and Charles Parsons' invention of the steam turbine", "their knowledge of Native American languages as a basis to transmit coded messages", "Einstein", "the absenceistence of the ultraviolet catastrophe", "Premier League club Swansea City", "pre-Raphaelite", "Elizabeth Weber", "an earlier Funcom game, \"The Secret World\"", "hundreds", "Waiting for Guffman", "1999", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "apple", "partial funding", "5% abv draught beer", "production of more of at least one good without sacrificing the production of any other good", "Chu'Tsai", "Liz", "least onerous", "lago di como", "White", "multinational retail corporation", "passion fruit", "The Natya Shastra is the foundational treatise for classical dances of India, and this text is attributed to the ancient scholar Bharata Muni", "the sand grains cause a scrubbing noise as they rub against each other when walked on", "golf", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "jonathan harding"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4100009042681456}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.1, 0.5, 0.5384615384615384, 0.08, 0.06896551724137931, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.1818181818181818, 1.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.18181818181818182, 0.0689655172413793, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_squad-validation-5157", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_squad-validation-3913", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 47, "before_eval": {"predictions": ["florida", "taghrooda", "Burnley", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "hiatus", "leeds", "star", "260", "heathrow", "relatively defined spatially as a specific geographic area and functionally as a set of social networks", "Landon Jones", "monophyletic", "insecticide toxicology", "catechism questions", "a pH indicator, a color marker, and a dye", "about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "63.2 million", "John and Charles Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Campbellsville", "daredevil driver", "Yaz in the musical romance drama film \" Across the Universe\" (2007)", "cuba", "arranged marriage to Chino, a friend of Bernardo's", "XXXTentacion", "stagnant wages for the working class amidst rising levels of property income for the capitalist class"], "metric_results": {"EM": 0.25, "QA-F1": 0.35608453401603557}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.5, 0.5384615384615384, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.10526315789473682]}}, "error_ids": ["mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 48, "before_eval": {"predictions": ["Anthony John Herrera", "Good Kid, M.A.D City", "Yosemite National Park", "Interventive treatment", "3", "The Methodist Church", "Ray Charles", "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "UNESCO", "Matur Maker", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "every good work designed to attract God's favor is a sin", "annuity", "Anakin Skywalker", "Buffalo Bill", "justice resides", "the French Union", "1914", "cuba", "halal", "Arthur Russell", "that the basics of Christian faith would not just be learned by rote, \"the way monkeys do it\" but understood", "Wylie Draper", "political role for Islam", "George Beadle's office", "Robert Marvin \"Bobby\" Hull", "Pittsburgh Steelers", "several existing conditions such as war, famine, and weather"], "metric_results": {"EM": 0.21875, "QA-F1": 0.34696119852369856}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.22222222222222218, 0.0, 1.0, 0.5, 0.25, 1.0, 0.0, 0.18181818181818182, 0.16666666666666669, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 0.4, 0.0, 0.16666666666666666, 1.0, 0.6153846153846153]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-4774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 49, "before_eval": {"predictions": ["vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL", "Timur", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "Ravenna", "12", "georgia", "1937", "improved", "biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane.", "He even lost control of the patents he had generated since he had assigned them to the company in lieu of stock.", "Georgian-born Soviet revolutionary and political leader", "Gregor Mendel", "abortion, broadcasting policy, civil service, common markets for UK goods and services, constitution, electricity, coal, oil, gas, nuclear energy, defence and national security, drug policy, employment, foreign policy and relations with Europe,", "Las Vegas Outlaws (XFL)", "3,600", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "110", "georgia cukor", "Horus", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Wisconsin v. Yoder", "imperialism", "usually tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population", "energy", "georgia", "Ruth Elizabeth \"Bette\" Davis", "georgia", "7 December 2004"], "metric_results": {"EM": 0.1875, "QA-F1": 0.310246003996004}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 1.0, 0.0, 0.18181818181818182, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.5238095238095238, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.16125, "QA-F1": 0.2617353561990274}, "overall_error_number": 1342, "overall_instant_fixing_rate": 0.0, "final_instream_test": {"EM": 0.72, "QA-F1": 0.7823411070528841}, "final_upstream_test": {"EM": 0.716, "QA-F1": 0.8165271287428559}}}