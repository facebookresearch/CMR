{"model_update_steps": 2590, "method_class": "index_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='exp_results/data_streams/bart_index.init_memory.pkl', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/index_based/ckpt_dir/1001v2_MixedAllErrors_T=100_index_M=U+I_rs=32_rq=3_rank=most_similar_mir=no(0)_seed=2021_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/index_based/ckpt_dir/1001v2_MixedAllErrors_T=100_index_M=U+I_rs=32_rq=3_rank=most_similar_mir=no(0)_seed=2021_ckpts/', replay_candidate_size=0, replay_frequency=3, replay_size=32, save_all_ckpts=0, skip_instant_eval=True, total_steps=10000, use_mir=False, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=100, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='exp_results/data_streams/mrqa.nq_train.memory.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "philanthropy", "neded on Mar 31, 2007", "Virginia Wade", "Gary Morris", "the anterolateral system", "1966", "for scientific observation", "product or policy that is open and honest", "The Stock Market crash in New York", "New York Stadium", "norman Tebbit", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "the final revelation of God the Final Testament", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs show Summary", "the great heroism or of the most conspicuous courage in circumstances of extreme danger", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "DC Comics", "May and June 2010"], "metric_results": {"EM": 0.1875, "QA-F1": 0.267216810966811}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.5, 0.0, 0.4444444444444445, 1.0, 0.5, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "sports, among them cricket, rallying, football, rugby union and boxing", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetic acid", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "sprawl leads to urban decay and a concentration of lower income residents in the inner city", "is not yet a senior", "Bothtec", "Terry Reid", "reports from government agencies and non-governmental organizations", "Elgar", "North America", "Andr\u00e9 3000", "rookies", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "marie fille de Perth", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23423421824157117}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.8235294117647058, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.3243243243243243, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 3, "before_eval": {"predictions": ["id", "baijan", "c + angle d = 180 degrees", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006", "is the leading nation of the Uniting for Consensus", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "boggling array of products that makes it almost impossible to finalise a choice without undertaking an inventory", "baze", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "bambi", "cement City, Texas", "the Democratic Unionist Party (DUP )", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "for control purposes", "bamboula", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor with 2 GB of RAM, either 16 or 32 GB of internal storage, and a 2300 mAh battery", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins were more complex than DNA", "bile duct or artery", "berenice Abbott"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12744701976715983}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.45161290322580644, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-6341", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "retrieved_ids": ["mrqa_naturalquestions-train-66866", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-83474", "mrqa_naturalquestions-train-51238", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-train-46904", "mrqa_naturalquestions-train-14012", "mrqa_naturalquestions-train-34340", "mrqa_triviaqa-validation-5026", "mrqa_naturalquestions-train-59943", "mrqa_naturalquestions-train-47736", "mrqa_triviaqa-validation-6351", "mrqa_naturalquestions-train-44067", "mrqa_naturalquestions-train-54288", "mrqa_naturalquestions-train-60822", "mrqa_naturalquestions-train-21281", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-train-86408", "mrqa_naturalquestions-train-25863", "mrqa_naturalquestions-train-47999", "mrqa_naturalquestions-train-824", "mrqa_triviaqa-validation-6351", "mrqa_naturalquestions-train-66866", "mrqa_naturalquestions-train-43791", "mrqa_naturalquestions-train-68703", "mrqa_naturalquestions-train-19182", "mrqa_naturalquestions-train-51238", "mrqa_naturalquestions-train-3220", "mrqa_naturalquestions-train-67071", "mrqa_naturalquestions-train-51350", "mrqa_naturalquestions-train-37993", "mrqa_naturalquestions-train-68895"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "Januarius", "man chosen to meet God on Sinai and receive the Law on behalf of God\u2019s chosen people", "coney Island museum", "tetanus disease", "bounding the time or space used by the algorithm", "round brilliant-cut", "Alex O'Loughlin", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "bunker", "never", "the Reverse - Flash", "All Souls'Day", "1968", "Azerbaijan", "new converts", "Mona Vanderwaal", "Geoffrey Boycott", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America, and Quebec", "formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Splodgenessabounds"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3516369047619048}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_naturalquestions-validation-2900", "mrqa_triviaqa-validation-5168", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 5, "before_eval": {"predictions": ["june and August of 1764", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "Renfrewshire", "Paspahegh Indians", "atrium", "South Dakota", "5 : 25 p.m. UTC", "swanee or swannee whistle", "sunflowers", "used to start fires, hunt, and bury their dead", "1962", "parietal cells", "placental", "September 13, 1994", "g. j. Guiteau", "imperial rule", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "lazing", "a greater tendency to take on debts", "entropy increases", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "as a way of housing a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.09375, "QA-F1": 0.16921977124183007}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "The glass chimney needs a `` throat '', or slight constriction, to create the proper draft for complete combustion of the fuel", "Illinois", "1998", "city-owned parks and parkways", "island in the Mediterranean Sea situated", "90-60's", "unaided school", "dolph Camilli", "times sign", "BAFTA Television Award", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "d. Eisenhower National Airport", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "dads", "tanflies", "blood", "widow - maker infarction due to a high death risk", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "near Grande Comore, Comoros Islands", "`` - s ''", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.0, "QA-F1": 0.053980654761904764}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "retrieved_ids": ["mrqa_naturalquestions-train-5473", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-71615", "mrqa_naturalquestions-train-66825", "mrqa_naturalquestions-train-83658", "mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-21529", "mrqa_naturalquestions-train-80300", "mrqa_naturalquestions-train-35002", "mrqa_naturalquestions-train-7638", "mrqa_naturalquestions-train-46650", "mrqa_triviaqa-validation-3901", "mrqa_naturalquestions-train-9056", "mrqa_triviaqa-validation-1792", "mrqa_naturalquestions-train-35002", "mrqa_naturalquestions-train-53108", "mrqa_naturalquestions-train-50473", "mrqa_naturalquestions-train-31449", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-train-11503", "mrqa_naturalquestions-train-1337", "mrqa_naturalquestions-train-34795", "mrqa_naturalquestions-train-37244", "mrqa_naturalquestions-train-49927", "mrqa_naturalquestions-train-28545", "mrqa_naturalquestions-train-9637", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-train-48406", "mrqa_naturalquestions-train-47928", "mrqa_triviaqa-validation-4054"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules", "The U.S. Army Chaplain insignia", "Kairi", "the suburbs, who wanted more services and more control over the central city", "director", "near the Black Sea", "the last book accepted into the Christian biblical canon", "Beyonc\u00e9", "negative", "for \u201cacts of the greatest heroism or of the most conspicuous courage in circumstances of extreme danger.", "16 million", "1950s", "work oxen for haulage", "1998", "a priest", "third most abundant chemical element in the universe", "18 - season career", "family member", "long-term environmental changes", "William Powell Lear", "the unbalanced centripetal force felt by any object", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "Anne", "present-day Charleston", "the Muslim Brotherhood in Palestine took a \"quiescent\" stance towards Israel, focusing on preaching, education and social services, and benefiting from Israel's \"indulgence\" to build up a network of mosques and charitable organizations", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "German"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2635109352880937}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.06451612903225806, 0.23529411764705882, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "georgeppe Antonio 'Nino'Farina", "44.0", "6.4 nanometers apart", "the eighth and eleventh episodes of the season", "Kyle Busch", "400", "adrenal glands", "liberal arts", "the Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "Eureka", "1868", "2018", "george warnock", "law firm", "Pottawatomie County", "The tuatara, a lizard - like reptile native to New Zealand", "The Albert Einstein formulated his theory of general relativity (GR )", "The church tower", "walford", "george Birks and Sons in 1953", "foreign", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychotherapeutic theories and associated techniques", "Quentin Coldwater", "acidic bogs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3361731150793651}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.375, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 9, "before_eval": {"predictions": ["the English phrase `` I Seek You ''", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "sweetened sheeps\u2019 milk ricotta", "photosynthesis", "high-dress ball held at Devonshire House in 1897 to celebrate Queen Victoria's diamond jubilee", "White House", "the alt-right movement", "triplet", "water", "president", "citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "a meat cold storage facility", "acting", "C. W. Grafton", "liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod Classic", "Sassy Girl", "prevent damage to the body", "The Edge of Night", "non-combustible substances that corrode, such as iron, contained very little", "pedagogy", "vaskania from the Megan Hieron Synek Demon ( \u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd ) book of prayers", "the root respiration", "carbon stored in soils", "death", "medium and heavy- Duty diesel trucks", "testes"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3764216357966358}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 0.36363636363636365, 0.6666666666666666, 1.0, 0.918918918918919, 1.0, 0.0, 0.4, 0.15384615384615383, 1.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "retrieved_ids": ["mrqa_naturalquestions-train-64590", "mrqa_hotpotqa-validation-1897", "mrqa_naturalquestions-train-80201", "mrqa_naturalquestions-train-23512", "mrqa_naturalquestions-train-55709", "mrqa_naturalquestions-train-30259", "mrqa_naturalquestions-train-38504", "mrqa_naturalquestions-train-28437", "mrqa_naturalquestions-train-40979", "mrqa_naturalquestions-train-82478", "mrqa_naturalquestions-train-63521", "mrqa_naturalquestions-train-68967", "mrqa_naturalquestions-train-57692", "mrqa_naturalquestions-train-77220", "mrqa_naturalquestions-train-13385", "mrqa_naturalquestions-train-83473", "mrqa_naturalquestions-train-34683", "mrqa_naturalquestions-train-215", "mrqa_naturalquestions-train-82748", "mrqa_naturalquestions-train-9107", "mrqa_naturalquestions-train-59801", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-47479", "mrqa_naturalquestions-train-58365", "mrqa_naturalquestions-train-27887", "mrqa_triviaqa-validation-6351", "mrqa_naturalquestions-train-52189", "mrqa_squad-validation-4185", "mrqa_naturalquestions-train-71403", "mrqa_naturalquestions-train-52050", "mrqa_naturalquestions-train-64590", "mrqa_naturalquestions-train-83148"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 10, "before_eval": {"predictions": ["1688", "yellow fever", "three legal systems", "Las Vegas, Nevada", "status line", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "Benito Mussolini", "1862", "menhirs", "Queen Victoria", "hydrogen ion", "1947", "the MGM Grand Garden Special Events Center", "Chicago History Museum", "Ronnie Hillman", "all-encompassing", "8 November 2016", "60 percent of the state's total land surface", "Eagle Ridge Mall", "Pel\u00e9", "Victory Garden", "Monastir / Tunisia / Africa", "fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present )", "Ward", "novelist and poet", "Jamestown", "Monet", "tree growth stages"], "metric_results": {"EM": 0.21875, "QA-F1": 0.35080492424242427}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.8, 1.0, 0.5, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.25, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 11, "before_eval": {"predictions": ["1967", "Traumnovelle", "other factors are accounted for", "The TEU", "ice melting", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "the first man to fly across the channel Louis Bleriot", "longer", "Dublin", "cricket bat", "joseidon", "the Bulgars", "died in battle", "Volkswagen", "Arkansas", "European Union", "Queen Elizabeth II", "infection, irritation, or allergies", "the most - visited paid monument in the world", "the Vittorio Emanuele II Gallery and Piazza della Scala", "catfish aquaculture", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "Evermoist", "Kuwait", "a co-op of grape growers", "Anthony Mann", "Verdi", "1952", "Los Angeles Lakers", "Max Speed", "Jean F kernel ( 1497 -- 1558 ), a French physician", "the back of the head"], "metric_results": {"EM": 0.25, "QA-F1": 0.34990864935717875}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.5, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 0.22222222222222224, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 12, "before_eval": {"predictions": ["Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government", "Minos and Kokalos", "29 June 1941", "jose Gener y Batet", "byker grove", "Forbes", "Johnson", "John Carroll Lynch", "tunisia", "Orwell", "Bohemia", "Gregg Popovich", "secularism", "for creative reasons", "adaptive immune system", "under the tutelage of his uncle Juan Nepomuceno Guerra", "a musician", "nodel", "December 1, 1969", "President Dwight Eisenhower", "jK Rowling", "California State Automobile Association", "faith", "Cinderella", "delayed the sealing of the hatch", "due to a lack of understanding of the legal ramifications"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25674585490761964}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.8, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-2886", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-6924"], "retrieved_ids": ["mrqa_naturalquestions-train-17468", "mrqa_naturalquestions-train-58830", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-train-74228", "mrqa_naturalquestions-train-39827", "mrqa_squad-validation-108", "mrqa_naturalquestions-train-60641", "mrqa_naturalquestions-train-17000", "mrqa_hotpotqa-validation-1201", "mrqa_naturalquestions-train-8707", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-80827", "mrqa_naturalquestions-train-49757", "mrqa_triviaqa-validation-1935", "mrqa_naturalquestions-train-32005", "mrqa_naturalquestions-train-51350", "mrqa_naturalquestions-train-7909", "mrqa_naturalquestions-train-49463", "mrqa_naturalquestions-train-16915", "mrqa_naturalquestions-train-51350", "mrqa_naturalquestions-train-28130", "mrqa_naturalquestions-train-13963", "mrqa_naturalquestions-train-12142", "mrqa_naturalquestions-train-56348", "mrqa_naturalquestions-train-83023", "mrqa_naturalquestions-train-38514", "mrqa_naturalquestions-train-15892", "mrqa_naturalquestions-train-19752", "mrqa_naturalquestions-train-14699", "mrqa_naturalquestions-train-31580", "mrqa_naturalquestions-train-36180", "mrqa_naturalquestions-train-61318"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister", "president of Guggenheim Partners", "Jason Lee", "Napoleon's army", "casket letters", "3.7 percent of the entire student population", "negative", "Matt Willis and Charlie Quirke", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "100", "paddington", "amyotrophic lateral sclerosis (ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "October 17, 1938", "Torah or Bible", "on the western coast of Italy", "Phil Hill, who went on to become the first and only U.S. born world grand prix champion", "quintessential New Orleans art form -- a jazz funeral without a body", "mid November", "Facebook", "bajgiel", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Seattle", "King George's War", "he cheated on Miley", "Punk", "Fort Snelling, Minnesota", "pinhole camera", "infrequent rain"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25760619588744593}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.25, 0.0, 1.0, 0.2, 0.0, 0.3333333333333333, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 14, "before_eval": {"predictions": ["Beauty and the Breast", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "Chicago's first permanent non-native settler", "maryland", "FX option", "electromagnetic waves", "a Wahhabi/ Salafi", "men at any party -- right along with insurance agents", "Children in Need", "Surveyor 3 unmanned lunar probe", "January 1981", "luteinizing hormone", "baptism", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "john Robertson", "slowing the vehicle", "Cheyenne", "appearance of fossils in sedimentary rocks", "Hanna-barbera", "Cortina d'Ampezzo", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "maryland", "casket letters", "Timo Hildebrand", "public services", "October", "weak government institutions", "a god of the Ammonites", "eye", "Uncle Fester", "Charles Whitman"], "metric_results": {"EM": 0.125, "QA-F1": 0.21876998614130966}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 0.0, 0.25, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "San Antonio", "King da 5'9\" ( Bad) and Eminem ( Evil)", "jupiter (now known as the Galilean moons)", "a friend and publicist", "hana", "masons'marks", "Theodore Haynes (1988) and Julia Rose (1989)", "Gateshead", "The horn line at the end is performed by the Phenix Horns from Earth, Wind & Fire", "uterus and uterine tubes", "1898", "professional wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "Vito Corleone", "jenny jN-4HT", "art", "chimpanzees", "March 15, 1945", "absolute temperature", "the private intelligence firm Stratfor and releasing the leaks through the whistle-blowing website", "Julius Robert Oppenheimer", "bicuspid", "his brother, Menelaus", "3 December", "tallahassee", "prefabricated housing projects", "London", "WWSB and WOTV"], "metric_results": {"EM": 0.125, "QA-F1": 0.1830357142857143}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "retrieved_ids": ["mrqa_naturalquestions-train-29696", "mrqa_naturalquestions-train-10949", "mrqa_naturalquestions-train-53606", "mrqa_naturalquestions-train-58694", "mrqa_triviaqa-validation-6119", "mrqa_naturalquestions-train-21309", "mrqa_naturalquestions-train-82122", "mrqa_naturalquestions-train-14250", "mrqa_naturalquestions-train-61414", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-5325", "mrqa_naturalquestions-train-62065", "mrqa_naturalquestions-train-41621", "mrqa_naturalquestions-train-24696", "mrqa_naturalquestions-train-85346", "mrqa_triviaqa-validation-6385", "mrqa_naturalquestions-train-72123", "mrqa_naturalquestions-train-73434", "mrqa_naturalquestions-train-24912", "mrqa_naturalquestions-train-84265", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-train-53909", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-37698", "mrqa_naturalquestions-train-3768", "mrqa_naturalquestions-train-45764", "mrqa_naturalquestions-train-58577", "mrqa_naturalquestions-train-23912", "mrqa_naturalquestions-train-49810", "mrqa_naturalquestions-train-60387", "mrqa_naturalquestions-train-85021", "mrqa_naturalquestions-train-39439"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 16, "before_eval": {"predictions": ["bistro tables", "buder Basil", "blessed", "on the lateral side of the tibia", "ferguside royal clan", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "October 29, 1985", "Amway", "Mauritius", "Thomas Sowell", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "Sinatra Sings Great Songs from Great Britain", "tANU", "Chad", "GMAT Sentence Correction (SC)", "an open work crown", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a vampire", "Fulham, Greater London, England", "French, English and Spanish", "florida", "U.S. Marshals", "What's Up (TV series)", "supply chain management", "jPL-Caltech/MSSS", "Poland's Last King and English Culture", "polynomial algebra", "joseph smith", "The three wise monkeys", "sheepskin and Merino Wool", "Honolulu County"], "metric_results": {"EM": 0.0625, "QA-F1": 0.10669642857142857}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["dymock", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "decay energy of 687 keV", "James Zeebo", "sovereign states", "president of the United States", "The Discovery Institute (DI)", "Sam's captured parents", "Australian", "military service for men was 30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "opportunities will vary by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Roy Spencer", "\"antiforms\"", "June 9, 2015", "V. Prakash Kumar", "James Weldon Johnson", "Keith Richards -- guitar solo, bass guitar, backing vocals", "at least one prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "a joint civil-military public airport on the west side of the city of Bangor, Maine, to become Bangor International Airport but has since continued to host Maine Air National Guard units", "students learn from teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "at which longitude is defined to be 0 \u00b0", "Adult Swim", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat of the National Basketball Association (NBA)", "33", "grapevines", "Annual Conference Cabinet", "hockey player Hannah Macleod", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2658251763046018}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 0.0, 0.0, 0.0, 0.36734693877551017, 0.19999999999999998, 0.16, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4347826086956522, 0.24242424242424243, 0.07407407407407407, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-3573", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 18, "before_eval": {"predictions": ["the genocide against the Tutsi", "social networking support", "400 metres relay", "Vili Fualaau and Mary Kay Letourneau", "ABC News", "distance covered by a vehicle ( for example as recorded by an odometer ), person, animal, or object along a curved path from a point A to a point B", "12", "the Great Exhibition of 1851", "King Edward I of England", "the Chagos Archipelago", "dundee", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "darnley", "\"Grindhouse\" fake trailer", "dave davenport", "digital transmission", "the Swiss- Austrian border", "lithium-ion battery", "821", "Sky channels", "liquid", "Kim Hyun-ah", "the races of highest'social efficiency'", "d major", "the \"Queen of Cool\"", "President Wilson and the American delegation from the Paris Peace Conference", "dave davis", "the fifth season", "dave dors", "Hockey Club Davos", "Michael Crawford", "Aibak's successor and son - in - law Iltutmish"], "metric_results": {"EM": 0.125, "QA-F1": 0.2885213744588745}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.3636363636363636, 0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666665, 0.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 0.4, 0.4, 0.25]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_hotpotqa-validation-4068", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "retrieved_ids": ["mrqa_naturalquestions-train-32795", "mrqa_naturalquestions-train-6688", "mrqa_naturalquestions-train-24436", "mrqa_naturalquestions-train-43248", "mrqa_naturalquestions-train-53080", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-train-71231", "mrqa_naturalquestions-train-31350", "mrqa_naturalquestions-train-42632", "mrqa_naturalquestions-train-49719", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-train-46861", "mrqa_naturalquestions-train-27665", "mrqa_naturalquestions-train-42705", "mrqa_naturalquestions-train-46161", "mrqa_naturalquestions-train-55239", "mrqa_naturalquestions-train-18797", "mrqa_naturalquestions-train-17900", "mrqa_naturalquestions-train-75322", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-7767", "mrqa_naturalquestions-train-61743", "mrqa_naturalquestions-train-65495", "mrqa_naturalquestions-train-85615", "mrqa_naturalquestions-train-62864", "mrqa_hotpotqa-validation-5256", "mrqa_naturalquestions-train-23881", "mrqa_naturalquestions-train-22759", "mrqa_naturalquestions-train-78345", "mrqa_naturalquestions-train-84048", "mrqa_naturalquestions-train-62445", "mrqa_naturalquestions-train-80958"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "Norman Macdonnell", "aragon", "11.1", "trans-Pacific flight", "Sharman Joshi", "sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "prime", "Ana", "Cherry Hill", "Season 4", "Maybe", "fred cheney", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "blackstar", "India", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1974", "Nicki Minaj", "slave of duty", "surnames", "f1", "friedrich", "Tara Lyn Charendoff", "William the Conqueror", "the outskirts of Lod", "two", "the Corinthian and Saronic Gulfs", "blood samples", "Guinness World Records", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.1875, "QA-F1": 0.25880681818181817}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.25, 1.0, 0.8, 0.0, 0.0, 0.0, 0.08333333333333334, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-3049", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-2627"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 20, "before_eval": {"predictions": ["gas turbines", "David Feldman", "the Sackler Centre for arts education", "yasiin bey ( ) (born Dante Terrell Smith", "David Brewster", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "AS-205", "ribosomal", "kingfisher", "six", "Shalita Grant as Sonja Percy, ATF Agent / NCIS Special Agent ( seasons 2 -- 4 ; recurring previously )", "I Swear", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak )", "paul maskey (Sinn Fein)", "heliocentric orbit", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Kenyan English", "trust God's word rather than violence", "aman Pamuk", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "\"My Love from the Star\" (2013)", "San Jose", "octopus", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "\"the most giving Super Bowl ever\"", "29.7", "freudian"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30106421356421353}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.48484848484848486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 21, "before_eval": {"predictions": ["from a Czech word, robota, meaning `` forced labor ''", "dust jacket", "various registries", "blood transfusion", "Yazoo", "22 April 1894", "black hole", "\"in this life\" (homo enim in hac vita) tired from his daily labour", "as defence of their North American colonies would no longer be an issue and also because they already had ample places from which to obtain sugar", "Willie Nelson and Kris Kristofferson", "mary Manson & Woods", "12 California State University campuses (Bakersfield, Channel Islands, Dominguez Hills, Fullerton, Los Angeles, Long Beach, Northridge, Pomona, San Bernardino, San Diego, San Marcos, and San Luis Ob", "French", "Lewis", "Charles Dickens and Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "there must be infinitely many primes", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "huldra", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "James Bond", "0.30 in ( 7.6 mm )", "colt Teofilo", "the Western Atlantic ctenophore Mnemiopsis leidyi", "\"Menace II Society\"", "backup", "Larry Gatlin & the Gatlin Brothers"], "metric_results": {"EM": 0.1875, "QA-F1": 0.299342204197806}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.4210526315789474, 1.0, 1.0, 0.0, 0.0, 0.23529411764705882, 1.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.3333333333333333, 0.0, 0.7692307692307693, 1.0, 0.19999999999999998, 0.16666666666666666]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "retrieved_ids": ["mrqa_naturalquestions-train-6494", "mrqa_naturalquestions-train-1467", "mrqa_naturalquestions-train-34340", "mrqa_naturalquestions-train-63620", "mrqa_naturalquestions-train-52224", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-69289", "mrqa_naturalquestions-train-9712", "mrqa_triviaqa-validation-4486", "mrqa_naturalquestions-train-45978", "mrqa_hotpotqa-validation-779", "mrqa_naturalquestions-train-64615", "mrqa_hotpotqa-validation-779", "mrqa_naturalquestions-train-64528", "mrqa_naturalquestions-train-10617", "mrqa_naturalquestions-train-60641", "mrqa_naturalquestions-train-68448", "mrqa_naturalquestions-train-76561", "mrqa_naturalquestions-train-10038", "mrqa_naturalquestions-train-26007", "mrqa_naturalquestions-train-54343", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-train-34415", "mrqa_naturalquestions-train-66951", "mrqa_naturalquestions-train-8770", "mrqa_naturalquestions-train-26295", "mrqa_naturalquestions-train-38333", "mrqa_naturalquestions-train-8315", "mrqa_naturalquestions-train-22090", "mrqa_naturalquestions-train-46054", "mrqa_naturalquestions-train-85256"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "Mediterranean Shipping Company S.A. ( MSC ), the world's second biggest container shipping operator", "1934", "his friends, Humpty Dumpty and Kitty Softpaws", "Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres", "Royalists", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "on their foreheads as a visible cross", "al\u00e9a seydoux", "20,000 leagues under the sea", "Augustus Waters, an ex- Basketball player and amputee", "1619", "Tony Blair", "\u2018expensive damaging\u2019, along with alcohol, tobacco and gambling", "June 11, 1973", "Kenya", "a chronological collection of critical quotations about William Shakespeare and his works", "alison I", "an active supporter of the League of Nations", "Cargill", "Cineplex Entertainment", "\"The Gang\" a group of debauched self- centered friends who run the Irish bar Paddy's Pub in South Philadelphia", "3 October 1990", "March 1, 2018", "The weak force is due to the exchange of the heavy W and Z bosons", "daedalus", "Martin Luther King III", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas that have been left undeveloped"], "metric_results": {"EM": 0.125, "QA-F1": 0.2611521856766422}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.4, 0.42857142857142855, 0.0, 0.4444444444444445, 0.0, 0.33333333333333337, 0.1111111111111111, 0.08695652173913045, 0.0, 0.0, 0.6250000000000001, 1.0, 1.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.1818181818181818, 0.0, 0.0, 0.19047619047619047, 0.2, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_squad-validation-2828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 23, "before_eval": {"predictions": ["an additional $105 billion in growth to the country's economy over five years", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "javier (Luna) was SO hot and romantic. The way his body moved was amazing", "zinc silicate primer and vinyl topcoats", "Luna Park", "Howl's Moving Castle", "European Union institutions", "(381.6 days)", "nine", "CAL IPSO satellite", "celandine", "U.S. ambassador's residence with New York Times columnist James `` Scotty '' Reston", "Ronnie Schell", "artemisinin- Based therapy", "Mumbai, Maharashtra", "the east", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "midlands of the river Niger Benue trough to over 2,000 mm ( 78.7 in ) along the south western escarpment of the Jos Plateau", "dambala", "Incudomalleolar joint", "brian riggs", "Democritus", "Santa Clara Marriott", "duke barenboim", "political power generated by wealth", "log-space reductions", "Corey Brown"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3076804098679099}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.3076923076923077, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.3636363636363636, 1.0, 0.0, 0.08, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt", "alchemy", "WBA title", "moluccas", "Saturday", "Albany ( in the Quarto version ) or Edgar", "arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "1990", "The Lord of the Rings: The Return of the King", "Peyton Manning", "Selena Gomez", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program and learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "bingo", "Eugene", "high buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze Rug", "the nine circles of Hell", "Mongols and a Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor Conventual (O.F.M. Conv\")", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "Mission Specialist for mission STS-51-L", "due to clear weather", "mitterr"], "metric_results": {"EM": 0.125, "QA-F1": 0.30350901725901724}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 1.0, 0.0, 0.4, 0.0, 1.0, 0.2857142857142857, 0.9600000000000001, 0.0, 0.0, 0.0, 0.0, 0.6486486486486487, 0.0, 0.0, 0.5, 0.7692307692307693, 0.0, 0.4, 0.0, 0.5, 0.2222222222222222, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.21621621621621626, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "retrieved_ids": ["mrqa_triviaqa-validation-5168", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-train-71254", "mrqa_naturalquestions-train-31102", "mrqa_naturalquestions-train-19954", "mrqa_naturalquestions-train-49152", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-36957", "mrqa_naturalquestions-train-83443", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-train-73534", "mrqa_naturalquestions-train-69260", "mrqa_triviaqa-validation-2959", "mrqa_hotpotqa-validation-2262", "mrqa_naturalquestions-train-64654", "mrqa_naturalquestions-train-67513", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-train-4972", "mrqa_triviaqa-validation-3420", "mrqa_naturalquestions-train-12896", "mrqa_naturalquestions-train-27314", "mrqa_naturalquestions-train-41621", "mrqa_naturalquestions-train-19806", "mrqa_naturalquestions-train-51238", "mrqa_naturalquestions-train-18064", "mrqa_naturalquestions-train-25865", "mrqa_naturalquestions-train-10038", "mrqa_naturalquestions-train-58053", "mrqa_naturalquestions-train-46200", "mrqa_naturalquestions-train-56859", "mrqa_triviaqa-validation-7767", "mrqa_naturalquestions-train-10053"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 25, "before_eval": {"predictions": ["swimming", "Sarah", "over 50 million singles", "states'rights to expand slavery", "1923 and 1925", "the Orlando\u2013Kissimmee\u2013 Sanford, Florida Metropolitan Statistical Area", "January 19, 1962", "Frigate", "Quingdao", "iteratively", "American Buff geese", "the move from the manufacturing sector to the service sector", "jagera", "Peter Davison, Colin Baker and Sylvester McCoy", "August 14, 1848", "lower rates of health and social problems", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "John Wesley ( 1703 -- 1791 ) and his younger brother Charles ( 1707 -- 1788 ), as a movement within the Church of England in the 18th century", "A Chorus Line", "2,664 rooms and 220 suites", "iPhone 6", "through a chute beneath his or her feet", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning services, support services, property services, catering services, security services and facility management services", "Symphony No. 7 in A major, Op. 92", "dordogne", "uncertain, though a performance at Wilton House in 1603 has been suggested as a possibility", "ranked above the two personal physicians of the Emperor", "mirliton", "made direct amends to such people wherever possible, except when to do so would injure them or others", "Chicago Cubs"], "metric_results": {"EM": 0.125, "QA-F1": 0.3158986234353881}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.3333333333333333, 0.25, 0.33333333333333337, 0.4615384615384615, 0.11764705882352941, 0.0, 0.33333333333333337, 1.0, 0.923076923076923, 0.3636363636363636, 0.4444444444444445, 0.6, 0.0, 0.14285714285714288, 0.22222222222222224, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_naturalquestions-validation-6545", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "south", "Magic formula investing", "true history", "Haleiwa Ali'i Beach Park", "1910", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "tennis", "4,000", "the founder of the Yuan dynasty", "Catherine Earnshaw", "canal", "cinnamon", "The Simpsons Spin-Off Showcase", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "a portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre", "Albany High School for Educating People of Color", "Rashtrapati Bhavan", "a non-commissioned officer in the United States Army's premier special operations unit, the 1st Special Forces Operational Detachment- Delta (1SFOD-D) or \" Delta Force\"", "Anakin Skywalker", "seek jury nullification", "Cee - Lo", "The Church of England was legally established in the colony in 1619, and authorities in England sent in 22 Anglican clergyman by 1624", "1954", "king George V class battleship", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "January 11, 1755 or 1757"], "metric_results": {"EM": 0.15625, "QA-F1": 0.33078744172494173}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false], "QA-F1": [0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.4, 0.5454545454545454, 0.0, 0.0, 1.0, 0.8, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8000000000000002]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-7435", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_squad-validation-6148", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_hotpotqa-validation-4585", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 27, "before_eval": {"predictions": ["alsivar", "casket letters", "dewberry", "o Orion", "USS \"Massachusetts\"", "niger", "the \"eternal outsider, the sardonic drifter\" someone who rebels against the social structure", "a light sky-blue color caused by absorption in the red ( in contrast with the blue color of the sky, which is due to Rayleigh scattering of blue light)", "casket letters", "1963", "The Hawks played.500 basketball in February, which included a 99\u201398 victory over the Detroit Pistons", "the internal thylakoid system", "aline charigot", "Grand Annual Steeplechase at Warrnambool and the Australian International Airshow at Geelong", "The channel which can get carriage on a suitable beam of a satellite at 28 \u00b0 East is entitled to access to B SkyB's EPG for a fee", "the fourth season", "gravitational", "availability of skilled tradespeople", "diamond", "A simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period", "Northumbria University was voted 'best New University' by The Times Good University Guide 2005 and also won a much coveted company award", "curtin", "Lofton", "on kickoffs at the 25 - yard line", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "by faith", "ludwig smith", "can be produced with constant technology and resources per unit of time, such that more of one good could be produced only by diverting resources from the other good, resulting in less production of it", "antwerp", "company"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18217284360376468}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.3076923076923077, 0.08333333333333334, 0.0, 0.0, 0.631578947368421, 1.0, 1.0, 1.0, 0.8, 0.0, 0.45454545454545453, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-994", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "retrieved_ids": ["mrqa_naturalquestions-train-69270", "mrqa_naturalquestions-train-62627", "mrqa_triviaqa-validation-5487", "mrqa_naturalquestions-train-50214", "mrqa_naturalquestions-train-38161", "mrqa_naturalquestions-train-80729", "mrqa_naturalquestions-train-30083", "mrqa_naturalquestions-train-61465", "mrqa_naturalquestions-train-4691", "mrqa_naturalquestions-train-18524", "mrqa_naturalquestions-train-79078", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-train-39038", "mrqa_naturalquestions-train-60612", "mrqa_naturalquestions-train-87336", "mrqa_naturalquestions-train-72300", "mrqa_naturalquestions-train-50473", "mrqa_naturalquestions-train-7961", "mrqa_naturalquestions-train-68895", "mrqa_triviaqa-validation-6901", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-1306", "mrqa_naturalquestions-train-35943", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-train-68441", "mrqa_naturalquestions-train-20416", "mrqa_naturalquestions-train-76238", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-23390", "mrqa_naturalquestions-train-4322"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 28, "before_eval": {"predictions": ["The Turk", "Chris Weidman", "seek jury nullification", "Harishchandra", "writer", "Professor Eobard Thawne", "gyom Kippur", "a US\u201310 a week raise over Tesla's US\u201318 per week salary", "1875", "member states on a voluntary basis", "clarinets", "McKinsey's offices in Silicon Valley and India", "gyphidiophobia", "2000", "Crohn's disease or ulcerative colitis", "Francisco de Orellana", "Raya Yarbrough", "Arizona", "michael dokes", "Charles L. Hutchinson", "Old Testament", "UPS", "local talent", "Football League", "tristan Farnon", "pemberton", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "lincoln", "1340", "dodo bird", "people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "on the Buses"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30017715419501134}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 0.5, 1.0, 0.0, 0.3333333333333333, 0.0, 0.8333333333333333, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 0.2040816326530612, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_squad-validation-4309", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_squad-validation-8190", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 29, "before_eval": {"predictions": ["holly berries", "886 AD", "his own projects", "24 Hours of Le Mans", "Xbox 360", "Los Angeles", "safety Darian Stewart", "parallelogram rule of vector addition", "joseph darrow", "364", "Neutron sources", "starry starry night", "the bore, and often the stroke", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "Doctorin' the Tardis", "National Basketball Development League (NBDL)", "gillingham", "St. Mary's County", "T. J. Ward", "2,615 at the 2010 census", "Pyeongchang", "athlete", "a password recovery tool for Microsoft Windows", "Captain John Guidry", "were husband and wife American designers who made significant historical contributions to the development of modern architecture and furniture", "Brazil", "Steve Redgrave", "either Q or the finite field with p elements", "heartburn", "from 53% in Botswana to -40% in Bahrain", "NADPH"], "metric_results": {"EM": 0.125, "QA-F1": 0.2795401493930906}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.4, 0.0, 0.0, 0.47058823529411764, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.058823529411764705, 0.0, 0.2857142857142857, 0.0, 0.0, 0.9333333333333333, 1.0, 0.2222222222222222, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-9036", "mrqa_squad-validation-7445", "mrqa_squad-validation-8873"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "Katie", "arpers Ferry", "Basil Fawlty", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "BBC UKTV", "mikael", "demographics and economic ties", "three or more", "The Kickoff Game", "narcolepsy", "arctic monkeys", "monza", "karlan grant", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "instructions", "The centre-right Liberal Party", "marduk", "katnajokull glacier", "largest source of foreign direct investment", "karlan d. Daniels", "off the northeast coast of Australia", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Evan Jonigkeit", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "k. Kamaraj", "National Lottery", "arthur", "2016", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.0625, "QA-F1": 0.10298633658008657}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.12121212121212122, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "retrieved_ids": ["mrqa_naturalquestions-train-23969", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-80555", "mrqa_naturalquestions-train-18614", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-train-2860", "mrqa_triviaqa-validation-1306", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-2884", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-train-42206", "mrqa_triviaqa-validation-639", "mrqa_naturalquestions-train-76561", "mrqa_naturalquestions-train-45745", "mrqa_naturalquestions-train-1327", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-22851", "mrqa_naturalquestions-train-68895", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-train-39439", "mrqa_triviaqa-validation-6351", "mrqa_naturalquestions-train-8492", "mrqa_naturalquestions-train-87942", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-train-82140", "mrqa_naturalquestions-train-58312", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-3515", "mrqa_naturalquestions-train-15888", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-3945"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 31, "before_eval": {"predictions": ["Yolanda Sald\u00edvar", "spain", "spain", "worsley", "Newell Highway", "mitcharf", "a horse is 15 hands", "a shopping mall located in Bloomington, Minnesota, United States ( a suburb of the Twin Cities )", "because, according to the U.S. Court of Appeals for the First Circuit, her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "Andrew Adamson, Kelly Asbury and Conrad Vernon", "zigeunerbaron", "his own men", "emissions resulting from human activities", "polly", "the RAF", "reduce growth in relatively poor countries but encourage growth", "Ishar- Damu", "skylab", "Polish-Jewish", "a variety of political groups that supported the Spanish coup of July 1936 against the Second Spanish Republic, including the Falange, the CEDA, and two rival monarchist claimants : the Alfonsists and the Carlists", "Anything Goes", "spain", "390 billion", "Washington Street", "May 10, 1976", "five", "lohan", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "1978", "Paul the Apostle", "1915", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1461924343358167}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.0588235294117647, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.45000000000000007, 0.0, 0.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_hotpotqa-validation-1444", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 32, "before_eval": {"predictions": ["an orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "b Bavarian", "women's 800 metres", "Matt Jones", "alkali", "in order to halt it following brake failure", "T cell", "relatively low salaries", "genetically engineered", "Heading Out to the Highway", "Moonraker", "3 million", "Michael Oppenheimer", "England national team", "entitled institutionally and legally", "No Night Today", "Convention", "5,922", "December 5, 1991", "2016", "Philadelphia 76ers", "The modern Santa Claus grew out of traditions surrounding the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas", "Potsdam", "WBC/WBA heavyweight champion Joe Frazier", "23 March 1991", "Sunday", "the historic West End district of downtown Dallas", "Nairobi", "the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3252108134920635}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.125, 0.0, 0.0, 0.5, 0.0, 0.25, 0.6666666666666666, 0.8571428571428571, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\"Boston Herald\" Rumor Clinic", "1967", "\"bookie\" for taking a bet from a gambler", "the twelfth most populous city in the United States", "115", "araboudjan", "It triggers a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus, causing changes in gene expression", "lower", "bass", "Tevye", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country, hugging the east side of the Mississippi River and its tributaries", "japan", "bridge", "Yunnan- Fu", "Mumbai", "Broken Hill and Sydney", "2005", "buyers from all punishments and granted them salvation were in error", "\"The Doctor's Daughter\"", "september", "bridge", "things that are a matter of custom or expectation", "1879", "daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "enthusiasm", "korea", "Nissan", "1979 to 1981, and again from 1983 to 1992", "Buskerud and Telemark"], "metric_results": {"EM": 0.15625, "QA-F1": 0.21763073141749611}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1081081081081081, 0.0, 0.0, 0.0, 0.12121212121212123, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "retrieved_ids": ["mrqa_naturalquestions-train-67181", "mrqa_naturalquestions-train-29945", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-train-19752", "mrqa_naturalquestions-train-6506", "mrqa_naturalquestions-train-42769", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-26211", "mrqa_naturalquestions-train-62064", "mrqa_naturalquestions-train-52050", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-20817", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-train-41269", "mrqa_naturalquestions-train-26876", "mrqa_naturalquestions-train-24162", "mrqa_squad-validation-7301", "mrqa_naturalquestions-train-66791", "mrqa_triviaqa-validation-3714", "mrqa_naturalquestions-validation-824", "mrqa_naturalquestions-train-39157", "mrqa_triviaqa-validation-3901", "mrqa_naturalquestions-train-1307", "mrqa_naturalquestions-train-23444", "mrqa_naturalquestions-train-80827", "mrqa_naturalquestions-train-43791", "mrqa_naturalquestions-train-78579", "mrqa_naturalquestions-train-58603", "mrqa_naturalquestions-train-9081", "mrqa_naturalquestions-train-396", "mrqa_squad-validation-7572", "mrqa_naturalquestions-train-58577"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 34, "before_eval": {"predictions": ["Chairman", "Norman Hartnell", "Threatening government officials", "Veronica", "Victorian College of the Arts", "Germany", "onions", "0.2 inhabitants per square kilometre", "William Edward Graham Niven", "France", "Ian Paisley", "bataan Death March", "euro", "Graham McPherson", "the United States", "1974", "1886", "Sam Bradford", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Maximus Decimus Meridius", "pole", "Johnny Darrell", "a disease in which a waxy substance called plaque builds up inside the carotid arteries", "vegetable fat", "Euler's totient function", "ear wax", "the set of all connected graphs", "Busiest airports in the United States by international passenger traffic", "orange", "Honda Accord", "Kurt Vonnegut", "princess Rapunzel"], "metric_results": {"EM": 0.15625, "QA-F1": 0.21029838217338215}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.14285714285714288, 0.6153846153846153, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_hotpotqa-validation-3982", "mrqa_naturalquestions-validation-951", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "based on the interplay of supply and demand, which determines the prices of goods and services", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "the brain, muscles, and liver", "urecchiette", "Washington Redskins", "in the courtyard adjoining the Assembly Hall", "William Howard Ashton", "wyo", "promoting social dislocation, unrest and conflict", "Broward County", "Song Kang-ho, Lee Byung-hun", "changing display or audio settings quickly", "king Charles I of England", "from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "declines over the medium term", "Beauty and the Beast", "South Africa", "Tyler \" Ty\" Mendoza", "Alamo de Parras", "a seal illegally is broken", "the UMC", "Brian Liesegang", "Roger Allers and Rob Minkoff", "Port Moresby, Papua New Guinea", "David Seville", "National Association for the Advancement of Colored People", "1963\u20131989", "untinkable ship", "William Rodgers", "William Asher", "ancient and classical language"], "metric_results": {"EM": 0.25, "QA-F1": 0.3891998626373626}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 0.11111111111111112, 0.14285714285714288, 0.4, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.7499999999999999, 0.4615384615384615, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 36, "before_eval": {"predictions": ["National Broadcasting Company", "Amber Laura Heard", "sun", "football", "Cobham\u2013Edmonds thesis", "part of the story by requesting exposition from the Doctor and manufacturing peril for the Doctor to resolve. The Doctor regularly gains new companions and loses old ones ; sometimes they return home or find new causes", "Best Male Pop Vocal Performance", "March 2012", "jazz", "Muhammad Ali", "Coldplay", "Spain", "to civil disobedients", "Julius Caesar", "2", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "decision problem", "Hexham", "heart", "Miasma theory", "drinkware made to hold either a British ( `` imperial '' ) pint of 20 imperial fluid ounces ( 568 ml ) or an American pint of 16 US fluid ounces", "mountain ranges", "imperial war flag of the Holy Roman Empire", "significant production of peaches as early as 1571, with exports to other states occurring around 1858", "nettle", "end", "flat rate", "Top Of The Pops", "to build a nationwide network in the UK", "roughly west", "Sudan"], "metric_results": {"EM": 0.25, "QA-F1": 0.3275946275946276}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.4, 0.0, 0.23076923076923078, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "retrieved_ids": ["mrqa_triviaqa-validation-1551", "mrqa_squad-validation-6915", "mrqa_naturalquestions-train-13352", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-train-78997", "mrqa_naturalquestions-train-5558", "mrqa_naturalquestions-train-16782", "mrqa_triviaqa-validation-946", "mrqa_naturalquestions-train-49463", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-train-50792", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-9984", "mrqa_naturalquestions-train-66044", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-train-34003", "mrqa_naturalquestions-train-46161", "mrqa_naturalquestions-train-16951", "mrqa_naturalquestions-train-79942", "mrqa_naturalquestions-train-17355", "mrqa_naturalquestions-train-24957", "mrqa_naturalquestions-train-53606", "mrqa_naturalquestions-train-26324", "mrqa_naturalquestions-train-70108", "mrqa_triviaqa-validation-5429", "mrqa_naturalquestions-train-61880", "mrqa_naturalquestions-train-49664", "mrqa_naturalquestions-train-9081", "mrqa_naturalquestions-train-11503", "mrqa_naturalquestions-validation-3840", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-4402"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "his back was severely wrenched and three of his ribs were broken", "2007", "Post Alley under Pike Place Market", "mother-of-pearl", "February", "stomach", "Walter Mondale", "96", "the first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "japan", "a black background representing the circle with glossy gold letters", "the alluvial plain", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Carlos Tevez", "large birds or mammals", "events and festivals", "riper grapes", "1991", "polyphemus", "7 January 1936", "lifetime protection", "twenty-four", "Carl Sagan", "Much of the city's tax base dissipated", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Poulsen", "defiant speech", "cream", "Boston, Massachusetts"], "metric_results": {"EM": 0.3125, "QA-F1": 0.34959935897435895}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_hotpotqa-validation-104", "mrqa_hotpotqa-validation-513", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "buffalo", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "The History of Little Goody Two - Shoes", "the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east )", "gathering money from the public", "Thorgan", "commissioned officers are given a one - time stipend when commissioned to purchase their required uniform items. Officers then maintain proper fit and appearance of their uniform items throughout their career", "Don Jeffrey \" Jeff\" Meldrum", "741 weeks", "Phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "suez canal", "60", "journalist", "the fact that there is no revising chamber", "rudolph", "the points of algebro-geometric objects, via the notion of the spectrum of a ring", "those were newly accessioned into the collection, and card catalogs", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "glycine", "Iowa", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation.", "Lord's", "bridge", "Louis Prima", "in sequence with each heartbeat"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30692602253323314}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.09523809523809523, 0.0, 1.0, 0.0606060606060606, 0.47058823529411764, 0.4, 0.12903225806451613, 0.4444444444444445, 0.0, 1.0, 0.15384615384615383, 0.0, 1.0, 0.2857142857142857, 1.0, 0.6, 0.0, 0.0, 0.6153846153846153, 0.06451612903225806, 0.0, 1.0, 0.3846153846153846, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-3320", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 39, "before_eval": {"predictions": ["Republic of Taiwan", "Dan Conner", "Checkpoint Charlie", "President John F. Kennedy", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "keskes", "the 1980s", "John M. Grunsfeld", "New York", "williams", "2000", "buck fawn", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "the relative units of force and mass", "woman", "two", "August 10, 1933", "The Golden Gate Bridge", "Vancouver", "those who already hold wealth", "B. Traven", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "oil", "wooded areas", "264,152", "Princeton", "the United States", "high pressure or an electric current"], "metric_results": {"EM": 0.34375, "QA-F1": 0.42962344028520494}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "retrieved_ids": ["mrqa_naturalquestions-train-62448", "mrqa_naturalquestions-train-34229", "mrqa_naturalquestions-train-28545", "mrqa_naturalquestions-train-3454", "mrqa_naturalquestions-train-75754", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-train-49719", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-80958", "mrqa_triviaqa-validation-3238", "mrqa_naturalquestions-train-557", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-train-66819", "mrqa_naturalquestions-train-67689", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-validation-10406", "mrqa_triviaqa-validation-2722", "mrqa_naturalquestions-train-6172", "mrqa_naturalquestions-train-64931", "mrqa_naturalquestions-train-62065", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-56048", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-train-83407", "mrqa_naturalquestions-train-77573", "mrqa_naturalquestions-train-20678", "mrqa_naturalquestions-train-75292", "mrqa_naturalquestions-train-60641", "mrqa_squad-validation-7352", "mrqa_triviaqa-validation-2802", "mrqa_naturalquestions-train-45745", "mrqa_naturalquestions-train-20155"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgis", "every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "prophecy", "Aristotle", "Charlton Heston", "anti-inflammatory molecules", "war", "new Orleans Saints", "A medium of exchange", "the force of law, if based on the authority derived from statute or the Constitution itself. The ability to make such orders is also based on express or implied Acts of Congress that delegate to the President some degree of discretionary power", "son et lumi\u00e8re", "When the Mongols placed the Uighurs of the Kingdom of Qocho over the Koreans at the court the Korean King objected", "Sochi, Russia", "right", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "At the insistence of NASA Administrator Webb, North American removed Harrison Storms as Command Module program manager. Webb also reassigned Apollo Spacecraft Program Office (ASPO) Manager Joseph Francis Shea, replacing him with George Low", "state vote", "shorthand typist", "30", "Secret Intelligence Service", "100 billion", "polly", "photosynthesis", "4 - inch", "Queen City", "an American federal law that imposes liability on persons and companies ( typically federal contractors ) who defraud governmental programs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2737955620768121}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15384615384615383, 0.5555555555555556, 0.0, 0.09523809523809522, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_squad-validation-3617", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Hindi", "Gaels", "Three-card brag", "d\u00edsir", "lion", "Russian film industry", "sediment load", "Washington metropolitan area", "newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment, both at the cell surface ( particularly caveolae internalization ) as well as at the Golgi apparatus", "The User State Migration Tool ( USMT )", "Ordos City China Science Flying Universe Science and Technology Co.", "pie tins", "Taco Bell Arena, Boise, Idaho", "Jewry Wall Museum", "Section 30 of the Teaching Council Act 2001", "Ron Messick as William B. White as Henry Fussy, a boy of about Fern's age, whom she soon starts spending time with while Wilbur is at the fair", "mid-1988", "quasars", "Northeast Monsoon or Retreating Monsoon", "Romansh", "Tudor king", "MIX 94.5", "Q Branch (or later Q Division)", "Philippi in Greece", "the division of labour, productivity, and free markets", "Gerard Marenghi", "Whitney Houston", "Hugo Award", "tanzania", "sheep", "written by Hugo Peretti, Luigi Creatore, and George David Weiss"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2871635959526585}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 1.0, 0.0, 0.96875, 0.0, 0.33333333333333337, 0.0, 0.25, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.2857142857142857, 0.0, 0.0, 0.5, 0.0, 0.3636363636363636, 0.0, 0.0, 0.4615384615384615]}}, "error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 42, "before_eval": {"predictions": ["Daryl Hannah", "cavatelli, acini di pepe, pastina, orzo, etc.", "brian", "independence from the Duke of Savoy", "the Roentgen rays", "questions about the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "physicians, lawyers, engineers, and accountants", "mistreatment from government officials", "King of Scandinavia", "centre-back", "Egypt", "the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position )", "glucose and galactose", "the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "Paul Laxalt", "Extroverted Feeling ( Fi )", "Thursday", "yellow", "the appropriateness of the drug therapy (e.g. drug choice, dose, route, frequency, and duration of therapy) and its efficacy", "Mars", "feats of exploration", "the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "bobby", "The Private Education Student Financial Assistance", "horse", "to raise money to rebuild St. Peter's Basilica in Rome", "colonies", "two forces, one pointing north, and one pointing east", "Bills", "Qualcomm Stadium", "the time and space hierarchy theorems"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3525249539761923}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.9333333333333333, 0.0, 0.0, 0.21052631578947367, 0.11764705882352941, 0.0, 0.0, 0.0, 1.0, 1.0, 0.7222222222222222, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6923076923076924, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.19999999999999998, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_squad-validation-1429", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "retrieved_ids": ["mrqa_naturalquestions-train-5004", "mrqa_naturalquestions-train-293", "mrqa_hotpotqa-validation-5526", "mrqa_triviaqa-validation-3808", "mrqa_naturalquestions-train-24947", "mrqa_squad-validation-2428", "mrqa_triviaqa-validation-6941", "mrqa_naturalquestions-train-67597", "mrqa_hotpotqa-validation-5526", "mrqa_naturalquestions-train-21281", "mrqa_naturalquestions-train-40541", "mrqa_naturalquestions-train-30389", "mrqa_naturalquestions-train-37019", "mrqa_naturalquestions-train-79237", "mrqa_naturalquestions-train-15440", "mrqa_naturalquestions-train-46652", "mrqa_naturalquestions-train-62840", "mrqa_naturalquestions-validation-4165", "mrqa_naturalquestions-train-63821", "mrqa_squad-validation-1705", "mrqa_naturalquestions-train-10001", "mrqa_naturalquestions-train-7959", "mrqa_naturalquestions-train-69829", "mrqa_naturalquestions-train-58577", "mrqa_naturalquestions-train-80958", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-train-87196", "mrqa_naturalquestions-train-63918", "mrqa_naturalquestions-train-7004", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-train-32005", "mrqa_hotpotqa-validation-3774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 43, "before_eval": {"predictions": ["robin", "square", "Indiana", "temple square", "French", "a \"homeward bounder\" a sailor coming home from a round trip", "domain names www.example.com and example.com", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "Py", "natural-ing recipe- only personal care products", "robin", "Rigoletto", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally.", "third-most abundant element in the universe", "furniture chain store IKEA", "216 countries and territories around the world", "football", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Algernod Lanier Washington", "the Outfield", "Croatia", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film", "railway locomotives", "robin", "third quarter ( also known as last quarter )", "rob robin", "chemists Glenn T. Seaborg, the developer of the actinide concept and Nobel Prize winning novelist Saul Bellow, political philosopher and author Allan Bloom", "Kentucky, Virginia, and Tennessee", "technology incidental to rocketry and manned spaceflight", "Mitochondrial Eve", "The Spokane Indian Reservation is located in eastern Washington, centered in Stevens County, but also includes two small parcels of land (totaling about 1.52 acres) in Lincoln County, including part of the Spokane River", "magi"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20294547643618852}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.25, 0.21052631578947367, 0.0, 0.6, 0.0, 0.0, 0.11764705882352941, 0.33333333333333337, 0.4, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.21052631578947367, 0.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 44, "before_eval": {"predictions": ["Wakanda", "high test scores", "2003", "cricket", "sweden", "campaign setting", "2003", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "Shape of You", "Christopher Lee as Count Dooku / Darth Tyranus", "second", "picture book", "all health care settings", "increased patient health outcomes and decreased costs to the health care system", "Empty Garbage Before Dad Flips", "Gabriel Alberto Azucena (born September 23, 1988) who goes by the stage name Gawvi, formerly G-Styles", "12034", "between the Piazza di Spagna at the base and Piazzo Trinit\u00e0 dei Monti", "December 1, 2009", "Estelle Sylvia Pankhurst", "meastricht treaty", "philosophical advocate and practitioner of the scientific method during the scientific revolution", "london", "Ministry of Corporate Affairs", "Irish", "ancient cult activity as far back as 7th century BCE. Numa Pompilius is believed to have built this temple along with the original Regia and House of the Vestal Virgins in its original form.", "bont\u00eb", "oxygen", "space telescope", "Sanctifying Grace", "Christ lag"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2944534632034632}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.19999999999999998, 0.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.0, 0.7272727272727273, 1.0, 0.0, 1.0, 0.39999999999999997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 45, "before_eval": {"predictions": ["me", "Detroit Lions", "perique", "under `` the immortal Hawke ''", "death penalty", "frail", "mexico", "rich Fisher king is the son of the king who is served from the grail", "Mangal Pandey of the 34th BNI", "V Alaudae, a Celtic legion recruited from Gallia Narbonensis and XXI, possibly a Galatian legion from the other side of the empire", "Cartwright", "four of the 50 states", "curling", "in 2011 during the eighth series of the UK version of The X Factor", "Pebble Beach", "Los Angeles", "French", "Henry Mills", "\"LOVE Radio\"", "Miami Marlins", "Cook County", "travolta", "Don Henkel", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "Fox News Specialists", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "San Francisco Bay Area at Santa Clara, California", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Normandy landings (codenamed Operation Neptune) were the landing operations on Tuesday, 6 June 1944 (termed D-Day) of the Allied invasion of Normandy in Operation Overlord during World War II.", "Mediterranean Sea"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22717550050524188}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.4166666666666667, 0.16666666666666669, 0.4, 0.07142857142857142, 0.13793103448275862, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_hotpotqa-validation-3509", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "retrieved_ids": ["mrqa_naturalquestions-train-13488", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-train-23098", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-train-62048", "mrqa_naturalquestions-train-74301", "mrqa_naturalquestions-train-44124", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-train-36180", "mrqa_naturalquestions-train-39439", "mrqa_naturalquestions-train-4618", "mrqa_triviaqa-validation-1588", "mrqa_naturalquestions-train-76300", "mrqa_naturalquestions-train-4516", "mrqa_naturalquestions-train-19395", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-24615", "mrqa_naturalquestions-train-14415", "mrqa_naturalquestions-train-85298", "mrqa_naturalquestions-train-72653", "mrqa_naturalquestions-train-34", "mrqa_naturalquestions-train-64528", "mrqa_naturalquestions-train-36180", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-22308", "mrqa_naturalquestions-train-42060", "mrqa_naturalquestions-train-34624", "mrqa_triviaqa-validation-7215", "mrqa_naturalquestions-train-22654", "mrqa_naturalquestions-train-21514", "mrqa_naturalquestions-train-33619", "mrqa_naturalquestions-train-12258"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 46, "before_eval": {"predictions": ["p Pittsfield, Massachusetts", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That", "being one of the youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "the development of safety lamps, Stephenson's Rocket, Lord Armstrong's artillery, Be-Ro flour, Joseph Swan's electric light bulbs, and Charles Parsons' invention of the steam turbine", "their knowledge of Native American languages as a basis to transmit coded messages", "Galileo Galilei and Sir Isaac Newton", "quantum electrodynamics (or QED) which fully describes all electromagnetic phenomena as being mediated by wave\u2013particles known as photons", "Hong Kong First Division League club Happy Valley", "lily", "Elizabeth Weber", "a first-person psychological horror adventure game", "hundreds", "Waiting for Guffman", "1999", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "apple", "partial funding", "5% abv draught beer", "inefficient", "Chu'Tsai", "Liz", "the least onerous", "lago di Como", "Grissom, White, and Chaffee", "an American multinational retail corporation", "paris", "the ancient scholar Bharata Muni", "The geological properties of a white silica sand found at Basin Head are unique in the province ; the sand grains cause a scrubbing noise as they rub against each other when walked on", "paris", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "imperial crown"], "metric_results": {"EM": 0.28125, "QA-F1": 0.35143025729282745}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.4827586206896552, 0.08, 0.06896551724137931, 0.0, 0.09999999999999999, 0.0, 0.0, 0.0, 0.1818181818181818, 1.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.046511627906976744, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_squad-validation-5157", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 47, "before_eval": {"predictions": ["gore", "taghrooda", "Burnley", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "hiatus", "l Leeds", "star", "260", "Heathrow Express", "often social communities with considerable face-to-face interaction among members", "William Strauss and Neil Howe", "monophyletic", "insecticide toxicology", "specific catechism questions", "a pH indicator, a color marker, and a dye", "about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "63.2 million", "John Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Campbellsville", "mike", "appearing as Jude in the musical romance drama film \"Crossing Over\" (2007)", "mike", "work in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "Jocelyn Flores", "downward pressure on wages"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3086978381096028}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.5384615384615384, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666669, 0.0, 0.5555555555555556, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 48, "before_eval": {"predictions": ["Anthony Herrera", "Good Kid, M.A.D City", "Yosemite", "Interventive treatment", "3", "The Methodist Church", "ray char Charles", "During his epic battle with Frieza", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "UNESCO", "Anfernee Simons and Thon's brother, Matur Maker", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California", "sin", "annuity", "Anakin Skywalker", "Buffalo Bill", "no place where justice resides", "the French Union", "It insisted on its neutral rights, which included allowing private corporations and banks to sell or loan money to either side.", "dry", "cuba", "Arthur Russell (born Charles Arthur Russell, Jr. May 21, 1951 and April 4, 1992) was an American cellist, composer, singer, and musician whose work spanned a disparate range of styles.", "memorised by the people themselves", "Wylie Draper", "political role for Islam", "the university's off- campus rental policies", "Robert Marvin \"Bobby\" Hull", "New England Patriots", "famine, and weather"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3672371031746032}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.22222222222222218, 0.0, 1.0, 0.22222222222222224, 0.25, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.4, 0.2666666666666667, 0.4, 0.6666666666666665, 0.16666666666666666, 0.0, 0.8571428571428571]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "retrieved_ids": ["mrqa_naturalquestions-train-76315", "mrqa_naturalquestions-train-40184", "mrqa_naturalquestions-train-23881", "mrqa_naturalquestions-train-78579", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-1758", "mrqa_naturalquestions-train-8896", "mrqa_naturalquestions-train-2860", "mrqa_naturalquestions-train-31987", "mrqa_naturalquestions-train-8619", "mrqa_naturalquestions-train-49722", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-train-5946", "mrqa_naturalquestions-train-68182", "mrqa_naturalquestions-train-76437", "mrqa_naturalquestions-train-18261", "mrqa_naturalquestions-train-5734", "mrqa_naturalquestions-train-23387", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-train-28007", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-train-40062", "mrqa_naturalquestions-train-26322", "mrqa_naturalquestions-train-83407", "mrqa_naturalquestions-train-18874", "mrqa_hotpotqa-validation-5637", "mrqa_naturalquestions-train-7204", "mrqa_naturalquestions-train-58080", "mrqa_naturalquestions-train-81426", "mrqa_naturalquestions-train-10038", "mrqa_naturalquestions-train-60655", "mrqa_naturalquestions-train-70658"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 49, "before_eval": {"predictions": ["vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL", "Genghis Khan", "\"Losing My Religion\" is a song by the American alternative rock band R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "Ravenna", "12", "chiraptophobia", "1937", "improved", "biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "he had assigned them to the company in lieu of stock", "Marxist and a Leninist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "3,600", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "falcon", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Meyer v. Nebraska", "the policies of major powers, or simply, general-purpose aggressiveness.", "tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population", "ATP energy", "berlin", "Ruth Elizabeth \"Bette\" Davis", "jonathan", "7 December 2004"], "metric_results": {"EM": 0.125, "QA-F1": 0.27822043702980803}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.0, 0.42857142857142855, 0.18181818181818182, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.888888888888889, 0.0, 1.0, 0.1111111111111111, 0.10526315789473685, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.5365853658536585, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 50, "before_eval": {"predictions": ["leg workouts", "Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "160km / hour between Delhi to Agra", "The Rock", "Big Machine Records", "The issues of conflicting territorial claims between British and French colonies in North America were turned over to a commission to resolve, but it reached no decision", "the Hindu sage Valmiki", "Epistle to Ramsay", "every two to six years ( depending on the positions being filled with most positions good for four years )", "Chinese", "fan interviews, previews and reviews of Arsenal matches", "2016", "Dan Castellaneta", "2007", "Wicked Twister", "subtraction", "Atlas ICBM", "whether or not the shoe was banged on the desk of the United Nations", "unclear as to how or whether this connection is relevant on microscales", "supernatural psychological horror", "originate in the House of Representatives", "The Revenant", "the evening of the same day", "Blue (Da Ba Dee\") is a song by the Italian music group Eiffel 65.", "Constitution", "Faurot Field", "Annette Charles as Charlene `` Cha - Cha '' DiGregorio", "the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return.", "5", "kahramanmara\u015f", "If the car is slowed initially by manual use of the automatic gear box"], "metric_results": {"EM": 0.09375, "QA-F1": 0.25664251008001004}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.1081081081081081, 0.5, 0.0, 1.0, 0.2727272727272727, 0.6666666666666666, 0.0, 0.45454545454545453, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.4, 0.15384615384615385, 0.6666666666666666, 1.0, 0.0, 0.8400000000000001, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7291", "mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_naturalquestions-validation-7707", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-290", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239", "mrqa_naturalquestions-validation-3022"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 51, "before_eval": {"predictions": ["third", "the base of the right ventricle", "the Red Queen from the sequel, Through the Looking - Glass", "Los Angeles", "Alex Breckenridge as Monique Valentine, Sebastian's superficial girlfriend", "seven", "Schr\u00f6dinger equation", "dick", "Ashland is home to Scribner-Fellows State Forest", "public schools", "Ghostface mask", "Roger Staubach", "AC induction motor and transformer", "Eric Morecambe", "Queens of the Stone Age", "the port of Nueva Espa\u00f1a to the Spanish coast", "Lucy Muringo Gichuhi (n\u00e9e Munyiri)", "1775\u20131795", "Empiricism", "w Somerset maugham", "Pabst Brewing Company", "redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "Peter Dinklage", "Wednesday mascot, Ozzie Owl", "Content is `` something that is to be expressed through some medium, as speech, writing or any of various arts ''", "Saint Peter ( the keeper of the `` keys to the kingdom '' )", "``An Act to provide for the better government of Ireland\"", "nguy\u00ean \u00d0\u00e1n", "Gebhard v Consiglio dell\u2019 Ordine degli Avvocati e Procuratori di Milano", "Belarus", "1835", "Elizabeth I"], "metric_results": {"EM": 0.15625, "QA-F1": 0.28492514430014426}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 0.6666666666666666, 0.05555555555555555, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.33333333333333337, 0.2666666666666667, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.19999999999999998, 0.3636363636363636, 0.4, 0.0, 0.4444444444444445, 1.0, 0.0, 0.14285714285714288, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_hotpotqa-validation-596", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "retrieved_ids": ["mrqa_triviaqa-validation-935", "mrqa_naturalquestions-train-45115", "mrqa_naturalquestions-train-32157", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-2860", "mrqa_naturalquestions-train-60918", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-7311", "mrqa_naturalquestions-train-41085", "mrqa_hotpotqa-validation-3872", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-train-49997", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-train-4469", "mrqa_naturalquestions-train-58694", "mrqa_naturalquestions-train-36855", "mrqa_triviaqa-validation-3280", "mrqa_naturalquestions-train-81061", "mrqa_naturalquestions-train-74764", "mrqa_naturalquestions-train-41621", "mrqa_squad-validation-2428", "mrqa_naturalquestions-train-6579", "mrqa_naturalquestions-train-29954", "mrqa_squad-validation-7382", "mrqa_naturalquestions-train-80384", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-2389", "mrqa_naturalquestions-train-18884", "mrqa_naturalquestions-train-27576", "mrqa_naturalquestions-train-51426", "mrqa_naturalquestions-train-82478", "mrqa_naturalquestions-train-30649"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 52, "before_eval": {"predictions": ["Myllokunmingia", "Edd Kimber, Joanne Wheatley, John Whaite, Frances Quinn, Nancy Birtwhistle, Nadiya Hussain, Candice Brown and Sophie Faldo", "belle williams", "the imaginary unit", "`` asphyxia '' ( cutting off the oxygen supply )", "wednesday", "Carey Mulligan, Matthias Schoenaerts, Michael Sheen, Tom Sturridge and Juno Temple", "The Worm", "16 December 1908", "the best five card poker hand from any combination of the seven cards of the five community cards", "German hymns", "Bury Football Club", "Benazir Bhutto", "The Thing of It Is... is a 1967 novel written by William Goldman about Amos McCracken, a 31-year-old man who has written a popular show tune and who is having marriage troubles.", "the NFC Championship Game", "Tom Robinson", "Buzz", "began in September 2000 at Leavesden Film Studios and in London, with production ending in July 2001", "the port city of Aden", "quickly to meet the needs of major national and international patient information projects and health system interoperability goals", "cytoplasmic ribosomes (around 17 nm vs 25 nm)", "leopard", "service sector", "Florida", "\"la f\u00e9e verte\" ( the green fairy) beverage", "dav smit", "Bolton", "British", "every aspect of public and private life wherever feasible", "anarchist", "Just under 540,800 students", "British Sky Broadcasting Group plc"], "metric_results": {"EM": 0.125, "QA-F1": 0.2789739135133872}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.21052631578947367, 0.0, 0.0, 0.0, 0.0, 0.3076923076923077, 1.0, 0.0, 0.125, 0.6666666666666666, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0, 0.1, 0.4, 0.1111111111111111, 0.5454545454545454, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8750000000000001, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-4073", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-6389", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-6709", "mrqa_squad-validation-2918", "mrqa_squad-validation-2772"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 53, "before_eval": {"predictions": ["1997", "Levi's Stadium", "c 1600 from Bishopsgate with elaborately carved wood work and leaded windows", "Doctor's archenemy", "paul p Peck", "after the Seven Years' War", "Lost Coast Brewery", "~74,000 (BP = Before Present)", "catherine o'Leary", "Bronwyn Bishop", "guidance", "pogo hearts", "jayhawker", "more direct rule though still containing perceivable kinds of dominance", "explores a violation of nature and the resulting psychological effects on the mariner and on all those who hear him", "kairobi", "John Gielgud", "Adam Smith", "25 June 1932", "parma", "James A. Garfield", "seasonal television specials", "genome", "Evey's mother", "10", "bridge collapses or explosions", "Joudeh Al - Goudia family", "Wes Unseld", "1912", "nitrogen dioxide", "increased flooding and sedimentation", "Daniel Handler"], "metric_results": {"EM": 0.25, "QA-F1": 0.32387248168498173}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.4, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-169", "mrqa_squad-validation-5390", "mrqa_squad-validation-7700", "mrqa_triviaqa-validation-3107", "mrqa_hotpotqa-validation-4571", "mrqa_triviaqa-validation-776", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_naturalquestions-validation-1161", "mrqa_triviaqa-validation-595", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_triviaqa-validation-2821", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_naturalquestions-validation-9368", "mrqa_squad-validation-6877", "mrqa_naturalquestions-validation-678", "mrqa_hotpotqa-validation-5614", "mrqa_triviaqa-validation-177", "mrqa_triviaqa-validation-3268"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 54, "before_eval": {"predictions": ["The Christmas Invasion", "the United States", "an expression of Priestley's socialist political principles", "March 9 to 18", "October 2016", "The Jewel of the Nile", "the seventh cranial nerve", "8th Habit", "The Odawa ( also Ottawa or Odaawaa) said to mean \"traders\" are an Indigenous American ethic group who primarily inhabit land in the northern United States and southern Canada", "many other herbs not listed", "most comfortable climatic conditions of the year", "pierowall", "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "22 September 2015", "Murder Request", "a person's point of weakness", "zagreb university", "annually in late January or early February", "Michael Schumacher", "the duodenum", "curved croissants", "Cuyler Reynolds", "Lacoste, France", "mashepotamia 9500bc", "cricketing elite", "American Navy electronic attack squadron", "saved something from the disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac", "most casinos are commonly called casino games", "Americana Manhasset", "\"Shoot Straight from Your Heart\"", "Jane Austen", "Kony Ealy"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2829177676968625}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.13333333333333333, 0.7272727272727273, 0.0, 0.375, 0.0, 0.0, 0.07692307692307693, 1.0, 0.0, 0.0, 0.4827586206896552, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 0.3636363636363636, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_hotpotqa-validation-2058", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "retrieved_ids": ["mrqa_hotpotqa-validation-1136", "mrqa_naturalquestions-train-40609", "mrqa_naturalquestions-train-48528", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-35968", "mrqa_naturalquestions-train-2630", "mrqa_triviaqa-validation-5261", "mrqa_naturalquestions-train-51334", "mrqa_hotpotqa-validation-3774", "mrqa_naturalquestions-train-50602", "mrqa_triviaqa-validation-1877", "mrqa_naturalquestions-train-21281", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6901", "mrqa_naturalquestions-train-52915", "mrqa_naturalquestions-train-49469", "mrqa_hotpotqa-validation-118", "mrqa_naturalquestions-train-72549", "mrqa_naturalquestions-train-6631", "mrqa_naturalquestions-train-35355", "mrqa_naturalquestions-train-24615", "mrqa_hotpotqa-validation-3669", "mrqa_naturalquestions-train-54810", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-train-48741", "mrqa_naturalquestions-train-2187", "mrqa_naturalquestions-train-17167", "mrqa_naturalquestions-train-32795", "mrqa_triviaqa-validation-3945", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-train-63395"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 55, "before_eval": {"predictions": ["2,000", "Denver's Executive Vice President of Football Operations", "France", "Gracie the new `` face '' of the FBI", "The Celtic nations are territories in western Europe where Celtic languages or cultural traits have survived.", "When a cell can not be regenerated the body will replace it with stromal connective tissue to maintain tissue / organ function", "golf", "Sierra Sky Park Airport is a residential airport community born of a unique agreement in transportation law to allow personal aircraft and automobiles to share certain roads", "pangea", "a low wage for that job", "octagon", "\"Rock With You\"", "Scott Mosier", "dave kujan", "weaving", "the art of the Persian Safavid dynasty from 1501 to 1722, in present - day Iran and Caucasia", "the Company's army", "Newton was sacked by DeMarcus Ware as time expired in the half", "Jack Nicholson", "the Inferno", "boxing", "the port city of Kaffa in the Crimea in 1347", "the Persian style of architecture", "Iranian", "parphemus", "Landwehr", "his work was published first", "as a preparation for the Feast of the Divine Mercy, celebrated each year on first Sunday after Easter", "accommodationism", "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' )", "the Niger\u2013 Congo language family", "a lower index of refraction, typically a cladding of a different glass, or plastic"], "metric_results": {"EM": 0.0625, "QA-F1": 0.14637966200466201}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.09523809523809525, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999999, 0.42857142857142855, 0.0, 0.0, 0.06666666666666667, 0.15384615384615385, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.36363636363636365]}}, "error_ids": ["mrqa_squad-validation-378", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_hotpotqa-validation-3062", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_squad-validation-7407", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_triviaqa-validation-7689", "mrqa_hotpotqa-validation-4215", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_naturalquestions-validation-570", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7078"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 56, "before_eval": {"predictions": ["Randy", "1922 to 1991", "predictions that can be tested in various ways", "business sponsors and individual donors", "moral conservatism, literalism, and the attempt \"to implement Islamic values in all spheres of life\"", "Tesla demonstrated a series of electrical effects previously performed throughout America and Europe,:76 included using high-voltage, high-frequency alternating current to light a wireless gas-discharge lamp", "8 bytes", "39, Newton was 26", "information in a smartphone - like, hands - free format", "increased their reserves (by expanding their money supplies) in amounts far greater than before", "zerathustra", "model for one of the characters in Jordan Mechner's game \"Prince of Persia\"", "kevin williams", "Robert \"Bumps\" Blackwell, Enotris Johnson, and Little Richard", "five", "negatively impact teachers' mental and physical health, productivity, and students' performance.", "kemmetrical", "d'Artagnan", "when each of the variables is a perfect monotone function of the other.", "kevin", "1932", "March 31, 1944", "methanol, ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid", "Peter Boles\u0142aw Schmeichel MBE (] ; born 18 November 1963) is a Danish former professional footballer who plays as a goalkeeper for Premier League club Leicester City and the Denmark national team.", "highest commissioned SS rank", "erinys", "lowest known subaerial volcanic vents in the world, at 45 m ( 150 ft ) or more below sea level", "musicBrainz", "between the Mediterranean Sea to the north and the Red Sea to a south, and is a land bridge between Asia and Africa", "Alison Steadman", "the retina of mammalian eyes ( e.g. the human eye )", "financial services"], "metric_results": {"EM": 0.125, "QA-F1": 0.2022204923699489}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.07692307692307691, 1.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.23076923076923075, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.08695652173913045, 0.0, 0.7142857142857143, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-416", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-4640", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 57, "before_eval": {"predictions": ["Saturn", "edmund Burke", "60 million", "Bathurst", "April 1948", "In inequality of opportunity was higher", "Psalms, the books of Hebrews, Romans, and Galatians", "Fe1 \u2212 xO", "Marx Brothers", "pitted with micrometeoroid impact craters", "The Better Jacksonville Plan", "david paradine", "Charles Haley", "paris", "carbon dioxide", "National Party of Australia", "United States Ship", "reared", "October 15, 1997", "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "modernized the outside of the building and renovated the inside", "North Atlantic Ocean and Arctic Ocean", "wales", "Robert Louis Stevenson", "tom Sly", "five", "texas", "Elizabeth Taylor played the part opposite Richard Burton as Mark Antony and Rex Harrison as Julius Caesar", "son of writer William F. Buckley Jr. and socialite Patricia Buckley.", "kevin gutenbrunner", "Sam the Sham", "three"], "metric_results": {"EM": 0.1875, "QA-F1": 0.34543650793650793}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.6666666666666666, 0.2, 0.0, 0.6666666666666666, 0.20000000000000004, 1.0, 0.5, 1.0, 0.0, 1.0, 0.28571428571428575, 0.8571428571428571, 0.0, 0.3333333333333333, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-1567", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-2255", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-4067", "mrqa_triviaqa-validation-6053", "mrqa_triviaqa-validation-5785", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_hotpotqa-validation-3802", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "retrieved_ids": ["mrqa_naturalquestions-train-85795", "mrqa_naturalquestions-train-39508", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-2802", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-train-72853", "mrqa_naturalquestions-train-64950", "mrqa_triviaqa-validation-5261", "mrqa_naturalquestions-train-82140", "mrqa_naturalquestions-train-35181", "mrqa_naturalquestions-train-57406", "mrqa_triviaqa-validation-7184", "mrqa_triviaqa-validation-3393", "mrqa_naturalquestions-train-67500", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-train-87143", "mrqa_hotpotqa-validation-2682", "mrqa_triviaqa-validation-5057", "mrqa_triviaqa-validation-6956", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-1099", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-6119", "mrqa_naturalquestions-train-73275", "mrqa_naturalquestions-train-59740", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-6683", "mrqa_naturalquestions-train-43677", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-2808", "mrqa_naturalquestions-train-47470", "mrqa_triviaqa-validation-2959"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 58, "before_eval": {"predictions": ["Dutch", "begins in the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "allow the player to acquire an advantage without deviating from basic strategy", "phagosomal membrane", "in areas such as South Heaton in Newcastle but once dominated the streetscape on both sides of the Tyne", "1955", "henry vii", "200 horsepower", "Sir William Henry Bragg and William Lawrence Bragg", "Lutheranism", "Night Ranger", "Honey Nut Cheerios Bee", "``Thocmentony\"", "Organizational interventions, like changing teachers' schedules, providing support networks and mentoring, changing the work environment, and offering promotions and bonuses, may be effective in helping to reduce occupational stress among teachers", "levels of economic inequality", "james boswell", "Arthur H. Compton", "Angelina Jolie, Brad Pitt and Amal Clooney", "henry", "1979", "mainly civil servants recruited in special university classes", "large areas", "E \u00d7 12", "the medial epicondyle of the humerus from posteriorly, or inferiorly with the elbow flexed", "simple devices", "john donne", "Liao, Jin, and Song", "`` central '' or `` middle ''", "malaysia", "ionized material is projected with sufficient momentum to cause some secondary impact damage in addition to causing high thermal damage", "Attack the Block", "Juliet"], "metric_results": {"EM": 0.28125, "QA-F1": 0.39621775793650793}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.4, 0.8571428571428571, 1.0, 0.125, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_squad-validation-5202", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-1443", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-5104", "mrqa_squad-validation-7880", "mrqa_hotpotqa-validation-4178", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-10351", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 59, "before_eval": {"predictions": ["a time- sharing system, based on Kemney's work at Dartmouth", "the exoskeleton of insects, the shells and membranes of externally deposited eggs, and skin", "the Naturalization Act of 1790", "Matthew Vaughn", "around 2 %", "royal family", "Century 16 multiplex", "James Edward Kelly", "neptune", "The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference", "kabuki and bunraku", "Because course [the price of oil] is going to rise", "5 mi east of Everest on highway K-20.", "Transvaginal ultrasonography", "Kelly Bundy", "Italy", "keels", "Sir William Douglas, 1st Earl of Douglas", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Mario Addison", "321,520", "2017 Major League Baseball (MLB) First-Year Player Draft began on June 12, 2017", "2005", "red deer", "tajikistan", "Helmuth von Moltke", "Raksha ( \u0930\u0915\u094d\u0937\u093e Rak\u1e63\u0101, `` protection '' ; Indian wolf )", "the ears of a hound dog", "2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )", "Cinerama Productions/Palomar theatrical library", "malaysia", "samoan tala"], "metric_results": {"EM": 0.125, "QA-F1": 0.22276084799861973}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.9565217391304348, 0.0, 1.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_triviaqa-validation-2965", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_squad-validation-19", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_hotpotqa-validation-5253", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-825", "mrqa_hotpotqa-validation-1917", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_squad-validation-5887", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-2525"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 60, "before_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "The Catcher in the Rye", "the Anglo-Saxons", "Alexandria", "Bendigo", "Thomas Jefferson", "June 2007", "In 1909 he became world- famous for making the first flight across the English Channel in a heavier than air aircraft, winning the prize of \u00a31,000 offered by the \" Daily Mail\" newspaper.", "Boston and Maine Railroad's Southern Division", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters. Jim Gray will anchor the pre-game and halftime coverage", "the West, forks, plate, butter knife, and napkin generally are placed to the left of the dinner plate, and knives, spoons, stemware and tumblers, cups, and saucers to the right", "summer months", "Phillip Schofield and Christine Bleakley returned to co-present", "Quatre \u00e9tudes de rythme (1949\u201350)", "Thailand, Burma, Cambodia, Indonesia and Sri Lanka", "segues", "d Welsh poet Dylan Thomas", "indus Valley civilization", "6 January 793", "second platform", "Flag Day in 1954", "around 300,000", "1858", "Sexred", "In Issues # 603 -- 605, the story switches and Archie proposes marriage to Betty instead of to Veronica", "neo-Nazi ideology with ethnic European paganism and opposition to \"foreign\" religions such as Christianity, Islam and Judaism", "henry peeves the poltergeist in the first Harry Potter film", "reduced Apollo 20. NASA's yearly budget also began to shrink in light of the successful landing, and NASA also had to make funds available for the development of the upcoming Space Shuttle.", "inversely proportional to the wave frequency, so gamma rays have very short wavelengths that are fractions of the size of atoms, whereas wavelengths on the opposite end of the spectrum can be as long as the universe", "The story is a satire on corruption in the administration of criminal justice and the concept of the \"celebrity criminal\""], "metric_results": {"EM": 0.21875, "QA-F1": 0.33082383223080414}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.4347826086956522, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.125, 0.32258064516129037, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.1111111111111111, 0.0, 0.3888888888888889, 0.18518518518518515, 0.23529411764705882]}}, "error_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_hotpotqa-validation-2715", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-9053", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_hotpotqa-validation-1971", "mrqa_triviaqa-validation-1284", "mrqa_squad-validation-4011", "mrqa_naturalquestions-validation-5798", "mrqa_hotpotqa-validation-3681"], "retrieved_ids": ["mrqa_naturalquestions-train-21248", "mrqa_naturalquestions-train-66044", "mrqa_naturalquestions-train-1096", "mrqa_naturalquestions-train-71415", "mrqa_naturalquestions-train-25052", "mrqa_naturalquestions-train-75876", "mrqa_naturalquestions-train-22559", "mrqa_naturalquestions-train-24227", "mrqa_naturalquestions-train-7909", "mrqa_hotpotqa-validation-389", "mrqa_naturalquestions-train-72905", "mrqa_naturalquestions-train-58365", "mrqa_naturalquestions-train-8315", "mrqa_naturalquestions-train-42379", "mrqa_naturalquestions-train-34331", "mrqa_naturalquestions-train-9735", "mrqa_hotpotqa-validation-987", "mrqa_naturalquestions-train-35311", "mrqa_naturalquestions-train-65805", "mrqa_naturalquestions-train-17119", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-train-17039", "mrqa_naturalquestions-train-81626", "mrqa_naturalquestions-train-40318", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-train-29447", "mrqa_naturalquestions-train-81286", "mrqa_naturalquestions-train-87227", "mrqa_naturalquestions-train-69376", "mrqa_naturalquestions-train-4107", "mrqa_naturalquestions-train-36638", "mrqa_naturalquestions-train-14250"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 61, "before_eval": {"predictions": ["The Two Noble Kinsmen", "glenbrook", "Riverside", "Judy Collins", "Out of Control", "the 2013 non-fiction book of the same name by David Finkel", "liza tarbuck", "The Frost Report", "fell from his horse while hunting and died because of the injury", "incitement to terrorism", "Henry and Liza", "the first flume ride in Ireland", "Guadalupe Victoria", "oxygen", "Elk and Kanawha Rivers", "They circulate and are moved around within plant cells, and occasionally pinch in two to reproduce.", "'Bucks Point'", "to `` help bring creative projects to life ''", "The Church of Latter-day Saints", "Old World fossil representatives", "the group 1 elements, excluding hydrogen ( H ), which is nominally a group 1 element but not normally considered to be an alkali metal", "Jonathan Daniel Hamm", "Michigan", "thicker consistency and a deeper flavour than sauce", "the presence or absence of a Y chromosome", "new zealand", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "VH1's \"100 Greatest Artists of Hard Rock\"", "AD 70", "from 1977 to 1989", "electronic music", "to report Hess's illegal May 1941 flight to Scotland to Hitler"], "metric_results": {"EM": 0.1875, "QA-F1": 0.34206634922095447}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.25, 0.0, 0.4, 0.0, 0.923076923076923, 0.0, 0.4, 0.0, 0.8421052631578948]}}, "error_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 62, "before_eval": {"predictions": ["sleep after it is separated from the body in death", "white", "energy moves from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "the Monarch", "United Kingdom, Australia, Canada and the United States", "Ballarat Bertie", "therefore", "Ricketts Glen State Park", "unveils a desire to be reckoned with as an openly wounded and unabashedly portentous rock balladeer", "magma", "harridan Grizelda Pugh", "fee per unit of connection time", "Robert Moses", "2010", "the winter of the 2017 -- 18 network television season", "cattle and citrus were major industries until farmlands were turned into suburbs", "Egypt", "Buzz Aldrin", "moselle", "4145 ft above mean sea level", "American philosopher of science", "the production company vanity cards shown following the closing credits of most programs", "Kansas\u2013Nebraska Act", "2 Constant ( C\u03bc and C\u03b4 ) gene segments", "1910\u20131940", "11:28 left in the second quarter", "Start Here", "geoffrey beevers", "Autobahn (album)", "endocrine", "Baron", "poodle"], "metric_results": {"EM": 0.25, "QA-F1": 0.3507571460980036}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.13333333333333333, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.25, 0.0, 0.0, 0.4444444444444445, 0.0, 0.5, 0.0, 0.10526315789473685, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0689655172413793, 0.5, 0.0]}}, "error_ids": ["mrqa_squad-validation-2339", "mrqa_squad-validation-9843", "mrqa_naturalquestions-validation-5396", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-7270", "mrqa_triviaqa-validation-1698", "mrqa_squad-validation-4750", "mrqa_hotpotqa-validation-1510", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_squad-validation-3961", "mrqa_triviaqa-validation-4878", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_naturalquestions-validation-538", "mrqa_squad-validation-824", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_hotpotqa-validation-1692", "mrqa_triviaqa-validation-6254"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 63, "before_eval": {"predictions": ["Singapore", "constant pressure", "joseph smith", "ARPANET", "he died in 1616", "Kohlberg K Travis Roberts", "fleetwood", "probabilistic (or \"Monte Carlo\")", "Ravi Shankar", "eight days after their initial broadcast", "Cayman Islands", "a narcissistic ex-lover who did the protagonist wrong", "catawba", "petrographic microscope", "mike", "james walvin", "Sondheim", "Strasbourg", "3.762", "a system of recording important things", "1993", "The Daily Mirror", "ACL tears", "millais", "dura mater", "German", "2013", "their belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "Professor Kantorek", "31 - member Senate and a 150 - member House of Representatives", "kerosene lamps", "orkney"], "metric_results": {"EM": 0.125, "QA-F1": 0.16770833333333335}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.38095238095238093, 0.0, 0.19999999999999998, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-189", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_hotpotqa-validation-97", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_triviaqa-validation-7598", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "retrieved_ids": ["mrqa_naturalquestions-train-11805", "mrqa_triviaqa-validation-946", "mrqa_squad-validation-4626", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-48215", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-train-84715", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-train-6794", "mrqa_naturalquestions-train-73434", "mrqa_triviaqa-validation-7578", "mrqa_triviaqa-validation-5071", "mrqa_triviaqa-validation-1276", "mrqa_squad-validation-3181", "mrqa_triviaqa-validation-3420", "mrqa_naturalquestions-train-45547", "mrqa_squad-validation-10386", "mrqa_squad-validation-1705", "mrqa_naturalquestions-train-10586", "mrqa_naturalquestions-train-48976", "mrqa_naturalquestions-train-53606", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-69842", "mrqa_triviaqa-validation-2722", "mrqa_naturalquestions-train-9240", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-2682", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-140", "mrqa_naturalquestions-train-38329"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 64, "before_eval": {"predictions": ["failure rate", "The governor is sworn in the January following the November election", "larvae", "Trey Parker and Matt Stone", "kansai", "one of popular music's most poignant anthems of sorrow regarding the environment", "trial division", "consultant", "Preston", "The Suite Life of Zack & Cody", "bladder cancer", "Saturn IB", "H. R. Haldeman", "brentford", "Wilfried Zaha", "r Raphael Sanzio", "brain surgery", "Swiss Alps", "charliesheen", "reform the lunisolar calendar to provide an accuracy of 365.2425 days of the year", "crash killed all 349 people on board both planes", "glister", "an individual noticing that the person in the photograph is attractive, well groomed, and properly attired", "New Orleans", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "macOS High Sierra", "Frazier", "triangle", "Bishop Martin Sasse", "Loire river", "17th Century", "provides funding for operations, personnel, equipment, and activities"], "metric_results": {"EM": 0.125, "QA-F1": 0.22514883877915792}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.16666666666666666, 0.6666666666666666, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.05405405405405406, 0.0, 0.5531914893617021, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07407407407407407]}}, "error_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_squad-validation-4567", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_triviaqa-validation-2173", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_hotpotqa-validation-811", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_squad-validation-2560", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 65, "before_eval": {"predictions": ["California State Legislature and signed by the State governor John B. Weller", "Arabic numerals", "Diary of a Wimpy Kid : The Long Haul", "the recommended. html filename extension", "pilgrimage", "heart", "Early Gothic", "Kentucky Derby", "sifaka", "Brian Keith Bosworth (born March 9, 1965) nicknamed \"The Boz\" is a former American professional football player who played as a linebacker for the Seattle Seahawks in the National Football League (NFL)", "1991", "DuMont Television Network", "Birmingham, Alabama", "the following identity ( Basel problem) due to Euler,", "2020", "bee gee", "tanyaY", "gravitation", "nonconservative forces act to change the internal energies of the system", "matador or a member of his cuadrilla or team", "the applied force is opposed by static friction, generated between the object and the table surface", "ormond sacker", "sazerac", "Big for Your Boots", "nahuatl", "Corbin Bleu and Karina Smirnoff became the runners - up, and Jack Osbourne and Cheryl Burke received third place", "the Arizona Cardinals", "Florida", "four", "Private Mass", "kedah", "mycelium"], "metric_results": {"EM": 0.21875, "QA-F1": 0.28897935945633313}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.07142857142857142, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.6153846153846153, 0.0, 0.2666666666666667, 0.0, 0.0, 0.0, 0.0, 0.21052631578947367, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-1923", "mrqa_hotpotqa-validation-2442", "mrqa_squad-validation-5836", "mrqa_squad-validation-9021", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-7605", "mrqa_hotpotqa-validation-875", "mrqa_triviaqa-validation-2383", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-5468", "mrqa_hotpotqa-validation-4174", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 66, "before_eval": {"predictions": ["mayonnaise", "to further develop and produce a new lighting system", "the eastern shore of the Firth of Clyde, Scotland, at the north-western corner of the county of Ayrshire", "On the Computational Complexity of Algorithms", "from sea level and may vary depending on location", "the Pandavas", "Magnetically soft ( low coercivity ) iron is used for the cores in electromagnets", "La Nouba", "white rabbit", "Duke Kent-Brown", "O2", "bratwurst", "apprentice", "They schools tend to produce better academic results than government schools formerly reserved for other race groups", "Vanessa Block", "insane", "2p + 1 with p prime", "white", "raven", "http://www.example.com/index.html", "brian", "`` Goodbye, Abigail. ''", "two catechisms", "cheddar", "Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen", "Saint-Domingue", "disappearance", "in 1963", "prokaryotic cell ( or organelle )", "Commissioners", "the traditional name or sometimes the Seven Years' War", "bread"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33251712543991957}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [0.0, 0.888888888888889, 0.35294117647058826, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.38095238095238093, 0.28571428571428575, 0.0, 0.6153846153846154, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.08333333333333334, 1.0, 1.0, 0.0, 0.4, 1.0, 0.13333333333333333, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_squad-validation-10412", "mrqa_naturalquestions-validation-5927", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_squad-validation-7130", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_squad-validation-8980", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "retrieved_ids": ["mrqa_naturalquestions-train-28761", "mrqa_naturalquestions-train-53606", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-10631", "mrqa_naturalquestions-train-55873", "mrqa_naturalquestions-train-72123", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-4298", "mrqa_naturalquestions-train-14956", "mrqa_naturalquestions-train-44839", "mrqa_naturalquestions-train-79266", "mrqa_triviaqa-validation-6689", "mrqa_squad-validation-8966", "mrqa_naturalquestions-train-33678", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-820", "mrqa_naturalquestions-validation-2663", "mrqa_naturalquestions-train-13920", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-6373", "mrqa_naturalquestions-train-11357", "mrqa_squad-validation-8979", "mrqa_naturalquestions-train-44626", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-train-62864", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-6259", "mrqa_naturalquestions-train-80708", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-train-946"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 67, "before_eval": {"predictions": ["high inequality", "konstantine drougos", "duddy Bolden", "Sweden, Norway and Denmark", "Oscar II Land on the island of Spitsbergen in Svalbard, Norway", "desublimation", "Norman origin, deriving from the Norman given name Robert, meaning `` bright renown '' -- from the Germanic elements `` hrod '' meaning renown and `` beraht '' meaning bright", "Preacher", "wonga", "Doctor of Philosophy", "1,388", "Otis Timson", "toothless, bearded hag", "government officials and climate change experts", "$150,000 and $250,000", "1963", "Ohio and briefly attended the University of Pittsburgh before transferring to Mount Union, where he played defensive line", "runner-up", "The Crowned Prince of the Philadelphia Mob", "\u201c Resign.\u201d", "romantic attraction, sexual attraction, or sexual behavior toward both males and females, or romantic or sexual attraction to people of any sex or gender identity", "status superior to all others in health-related fields such as physicians and acupuncturists", "Big 12 Conference", "1920s", "American", "Cleopatra VII Philopator", "April Fool's Day", "mill stream of Flatford mill", "catherine de Bourgh", "chloroplasts", "Santiago del Estero Province", "more than 265 million business records worldwide"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3676753198492329}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.4615384615384615, 1.0, 0.17391304347826084, 0.5, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445]}}, "error_ids": ["mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4648", "mrqa_hotpotqa-validation-5297", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8837", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-294", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_squad-validation-6327", "mrqa_hotpotqa-validation-3345", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 68, "before_eval": {"predictions": ["Nuevo Reino de Le\u00f3n", "Delaware", "the law of Italy governing the acquisition, transmission and loss of Italian citizenship", "last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "King of Chutzpah", "P $ C", "energy", "john l Beck", "Nepali", "Glasgow Association for the Higher Education of Women", "the coffee shop Monk's", "upper and lower bounds on the minimum amount of time required by the most efficient algorithm solving a given problem", "The Pilot", "the dot", "Dieppe", "1961 to 1989", "Tyler Posey", "Buckland Valley near Bright", "hard-to-fill positions", "Songshan Mountain", "brontosaurus", "qualifications", "Kelli Goss", "the final episode of the series", "Jennifer Jones", "1939", "automaticistas, or tolled ( quota ) highways", "redox", "the major transportation system for eastern and interior Venezuela and the llanos of Colombia", "tyler iv", "Siberia", "political spectrum"], "metric_results": {"EM": 0.25, "QA-F1": 0.27529761904761907}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.0, 0.0, 0.38095238095238093, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_triviaqa-validation-4485", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8791", "mrqa_triviaqa-validation-2723", "mrqa_squad-validation-7076", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-339", "mrqa_squad-validation-1784", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_squad-validation-2843", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_naturalquestions-validation-921", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_triviaqa-validation-3089", "mrqa_naturalquestions-validation-2632", "mrqa_hotpotqa-validation-4275"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 69, "before_eval": {"predictions": ["Eisenhower Freeway", "Louis de Broglie", "music became more expressive and emotional, expanding to encompass literary, artistic, and philosophical themes", "Thermochemical techniques", "Western District", "Ming", "near major hotels and in the parking areas of major Chinese supermarkets", "Abu al-Qasim al-Zahrawi", "Hellenismos", "the lower back", "the long - hair gene is recessive", "unknown", "tea, horticultural produce, and coffee", "Barclays", "Christina Applegate as Sue Ellen `` Swell '' Crandell", "the blood spilled by the heroes who died in the name of their countrymen's Fatherland and Freedom", "peter dinklage", "break off the cathode, pass out of the tube, and physically strike him", "Silver Gallery", "21.8 %", "pharmacological effect", "the beginning of an infinite number of beings, the foundation of peace and happiness, state power, the dream of many peoples, besides it there is nothing great or precious", "Tony Orlando and Dawn", "Paris", "peter Seeger", "Jonny Quinn (drums) and Johnny McDaid (piano, guitar, backing vocals)", "1,462 hypermarkets", "island of man", "West Norse sailors", "dukas", "Boreas", "1698"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3320828414402431}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.35294117647058826, 0.125, 1.0, 0.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.0, 1.0, 0.09523809523809523, 1.0, 0.0, 0.4444444444444445, 0.10526315789473682, 0.0, 0.42857142857142855, 0.4, 0.2857142857142857, 0.0, 0.06896551724137932, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8645", "mrqa_naturalquestions-validation-8059", "mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_naturalquestions-validation-3035", "mrqa_squad-validation-3610", "mrqa_squad-validation-8185", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_hotpotqa-validation-37", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_hotpotqa-validation-1381"], "retrieved_ids": ["mrqa_naturalquestions-train-69270", "mrqa_naturalquestions-train-34220", "mrqa_naturalquestions-train-28923", "mrqa_hotpotqa-validation-5822", "mrqa_triviaqa-validation-5068", "mrqa_naturalquestions-train-64654", "mrqa_naturalquestions-train-25549", "mrqa_naturalquestions-train-73275", "mrqa_naturalquestions-train-17917", "mrqa_naturalquestions-train-40770", "mrqa_naturalquestions-train-31251", "mrqa_naturalquestions-train-30455", "mrqa_hotpotqa-validation-5", "mrqa_naturalquestions-validation-921", "mrqa_hotpotqa-validation-452", "mrqa_naturalquestions-train-33786", "mrqa_naturalquestions-train-27314", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-train-6049", "mrqa_naturalquestions-train-8810", "mrqa_squad-validation-1612", "mrqa_naturalquestions-train-50358", "mrqa_triviaqa-validation-6398", "mrqa_squad-validation-9984", "mrqa_naturalquestions-train-21281", "mrqa_triviaqa-validation-639", "mrqa_naturalquestions-train-21090", "mrqa_naturalquestions-train-23035", "mrqa_naturalquestions-train-25813", "mrqa_naturalquestions-train-42433", "mrqa_naturalquestions-train-9023", "mrqa_triviaqa-validation-2701"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 70, "before_eval": {"predictions": ["london", "New York and New Jersey campaign", "February 28, 2018", "the park", "Australia will no longer be a base for the global car industry", "cordwainer", "Viking army based in Yorkshire, and that subsequently Eadred purchased land from him, using it to endow the bishopric of St Cuthbert", "1973", "Elsa with the help of Kristoff, Sven, and Olaf", "a loanword of the Visigothic word guma `` man ''", "Major General Miles Francis Stapleton Fitzalan-Howard, 17th Duke of Norfolk", "alephbet", "June 2011 Milton Keynes performances, Australian and New Zealand tour", "chromium", "white", "home from their vacation in Cape Cod", "the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "82.30'E longitude, in Mirzapur, Uttar Pradesh, which is nearly on the corresponding longitude reference line", "unity of God", "Salman Khan", "Skip Tyler", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything '", "WBMA-LD", "two Nobel Peace Prizes", "Jack Daniel's Old No. 7 Brand front chest logo", "a sharp stinging pain where it entered his body, and again at the place where it passed out", "king james I of Great Britain", "first step in the process of formulating the International Bill of Human Rights, which was completed in 1966, and came into force in 1976, after a sufficient number of countries had ratified them", "a straight line (see world line) traveling through time, which normally increases up or to the right in the diagram", "Newton for Carolina and Von Miller for Denver", "Nobel Prize in Literature", "Kingsford, Michigan"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3599293609655452}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.7499999999999999, 0.0, 0.9523809523809523, 1.0, 0.0, 0.0, 0.2105263157894737, 0.4761904761904762, 1.0, 0.0, 1.0, 0.08, 1.0, 1.0, 0.3636363636363636, 0.5925925925925926, 0.9090909090909091, 0.10526315789473685, 0.21052631578947367, 0.4, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_squad-validation-1632", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_naturalquestions-validation-710", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_triviaqa-validation-672", "mrqa_hotpotqa-validation-4323", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_naturalquestions-validation-7938", "mrqa_squad-validation-10477", "mrqa_squad-validation-361", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-2229"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 71, "before_eval": {"predictions": ["John D. Rockefeller", "42", "electrical, water, sewage, phone, and cable facilities", "Saxe-Coburg and Gotha", "1,100", "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription", "Dwight David \"Ike\" Eisenhower", "multi-purpose", "Tang, Song, as well as Khitan Liao and Jurchen Jin", "twelve", "Henley Royal Regatta", "Randal Keith Orton", "Jane Fonda", "special insulated tankers", "Sunday evenings through the entirety of that night's primetime schedule", "October 16, 2012", "Austria", "In 2012, during a preseason exhibition game held in Sassari, Italy, Olympiacos starter and former NBA player Joey Dorsey ended up breaking the glass of a backboard against Dinamo Sassari", "Somatic motor neurons", "antlers", "David Irving", "cauliflower", "rock and roll and rockabilly", "the Hongwu Emperor of the Ming Dynasty", "decathlon", "1565", "rapid expansion in telecommunication and financial activity", "fair Maid of Perth", "Caroline Sterling, n\u00e9e Bone, formerly Pemberton", "Libertarianism", "Helen Clark", "American R&B"], "metric_results": {"EM": 0.25, "QA-F1": 0.3776470057720058}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.45454545454545453, 0.0, 0.0, 0.9523809523809523, 0.1111111111111111, 1.0, 0.4, 0.0, 0.8, 0.19999999999999998, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_hotpotqa-validation-253", "mrqa_hotpotqa-validation-862", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_squad-validation-8291", "mrqa_naturalquestions-validation-2635", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-3689", "mrqa_hotpotqa-validation-4911", "mrqa_hotpotqa-validation-5203", "mrqa_naturalquestions-validation-1975", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 72, "before_eval": {"predictions": ["Monk's Caf\u00e9", "ancient Rome with gift - giving during the Saturnalia holiday, which took place that month", "fourth-most Republican leader in the House", "seven", "the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem", "Operation Neptune", "john smith", "peter", "alpaca fiber and mohair from Angora goats", "a Muskogean language called Apalachee", "a theory, and the critiques apply the criteria for a `` good '' theory to something that does not claim to be a theory", "the fictional town of West Egg on prosperous Long Island", "a gesture in which the head is tilted in alternating up and down arcs along the sagittal plane", "Mark, Kevin Costner's brother-in-law", "climate was like millions of years ago (see oxygen isotope ratio cycle)", "Parliament", "# 4 School of Public Health in the country", "shakespeare", "depths up to 600 m", "1883\u201384", "joseph smith", "Les Surfs as `` A Pr\u00e9sent Tu Peux t'en Aller''' French also recorded", "fox river", "Macau Peninsula, Macau", "separate to form new pyrenoids, or be produced \"de novo\"", "johnsey", "boeing", "satirical erotic romantic comedy", "Connie", "1768 ( probably, c. 1748)", "Puente Hills Mall, located in the City of Industry, California, United States", "l'Arc de Triomphe"], "metric_results": {"EM": 0.125, "QA-F1": 0.3091898233345602}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false], "QA-F1": [0.4, 0.7272727272727274, 0.8000000000000002, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 0.4, 0.10526315789473684, 1.0, 0.125, 0.0, 0.7000000000000001, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.4, 0.9, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_squad-validation-1760", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-1359", "mrqa_hotpotqa-validation-5478", "mrqa_squad-validation-3592", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_naturalquestions-validation-3638", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "retrieved_ids": ["mrqa_naturalquestions-train-18868", "mrqa_naturalquestions-train-83106", "mrqa_triviaqa-validation-4298", "mrqa_naturalquestions-train-47470", "mrqa_naturalquestions-train-16490", "mrqa_triviaqa-validation-3664", "mrqa_naturalquestions-train-8810", "mrqa_naturalquestions-train-755", "mrqa_naturalquestions-train-78402", "mrqa_squad-validation-9984", "mrqa_naturalquestions-train-35494", "mrqa_naturalquestions-train-57521", "mrqa_naturalquestions-train-87250", "mrqa_naturalquestions-train-69875", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-train-60667", "mrqa_naturalquestions-train-7959", "mrqa_naturalquestions-train-13642", "mrqa_naturalquestions-train-81327", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5068", "mrqa_naturalquestions-train-78621", "mrqa_naturalquestions-train-70465", "mrqa_triviaqa-validation-3420", "mrqa_naturalquestions-train-69860", "mrqa_naturalquestions-train-69875", "mrqa_naturalquestions-train-53264", "mrqa_naturalquestions-train-86362", "mrqa_naturalquestions-train-36076", "mrqa_naturalquestions-train-40261"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 73, "before_eval": {"predictions": ["a course to the northwest, through the present North Sea", "ishmael", "energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+)", "Boston", "the 10th Cavalry Regiment of the United States Army", "4 km", "The Future", "1969", "American composer", "Wahhabism or Salafism", "jellyfish", "information technology departments or for healthcare information technology vendor companies", "the first set of endosymbiotic events", "Danish - Norwegian patronymic surname meaning `` son of Anders '' ( itself derived from the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew )", "Edward Trowbridge Collins Sr.", "November 2014", "when a country's influence is felt in social and cultural circles", "increased productivity, trade, and secular economic trends", "a love song", "the early 20th century", "1989", "Deputy F\u00fchrer", "200\u2013300", "his mind", "structure and forces that act on one part of an object", "an alternate, but rarely used unit of mass", "the \"Gliding Dance of the Maidens\" from the \"Polovtsian Dances\" in the opera \"Prince Igor\"", "tain", "the government - owned Panama Canal Authority", "Vernier, Switzerland", "aeoline", "The Today Show"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2983615890688259}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.10526315789473684, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.8, 0.0, 0.0, 0.3076923076923077, 0.0, 0.3846153846153846, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9043", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9530", "mrqa_triviaqa-validation-7642", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_hotpotqa-validation-4284", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-3407"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 74, "before_eval": {"predictions": ["the Gulf of Mexico and stretches to the tip of Florida", "Friedrich Nietzsche", "nellie", "Frisian languages", "east of London", "wis 6, 1937", "dave marr", "DeWayne Warren", "20 ft", "hard Candy", "George Merrill and Shannon Rubicam of the band Boy Meets Girl", "near the end of the El Camino Real de Tierra Adentro which carried trade from Mexico City", "1943", "translation", "wai Momi", "a type of unspecified settlement", "religious organizations or private individuals", "tolerance of civil disobedience", "ed Miliband", "China in American colonies", "film scripts written by ghost writers, nonfiction books on military subjects, and video games", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s, with its coastal areas north from the Columbia River frequented by ships from all nations engaged in the maritime fur trade", "Instagram", "John Sebastian Bach, Karlheinz Stockhausen, Terry Riley, Philip Glass and Moondog", "1990", "She stopped to rest on a sandy beach by the village of Warszowa", "22 July 1930", "gluons, which form part of the virtual pi and rho mesons", "written each article of the Creed to express the character of the Father, the Son, or the Holy Spirit", "March 23, 2018", "\"Gosford Park\"", "business magnate, investor, and philanthropist"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2690729107848673}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.08695652173913045, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.1142857142857143, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_triviaqa-validation-6002", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_squad-validation-801", "mrqa_hotpotqa-validation-4964", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 75, "before_eval": {"predictions": ["around the time when ARPANET was interlinked with NSFNET in the late 1980s", "Inigo Jones", "Eric Clapton", "Gaahl", "baseball", "AMX - 50", "bannockburn", "author of the New York Times bestseller Before I Fall Lauren Oliver, Pulitzer Prize winning novelist Philip Roth, Canadian-born Pulitzer Prize and Nobel Prize for Literature winning writer Saul Bellow", "bani", "1902", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "1963", "17:16:20 GMT", "30 percent", "Limbo", "the state legislators of Assam", "350 government officials and climate change experts", "roof of the choir side - aisles at Durham Cathedral", "neptune", "a Japanese term that can be translated as `` comic ''", "Environmental Protection Agency", "523 km", "wis", "music arranger", "one person", "Luger P08", "Al-Masjid an-Nabawi", "Akbar the Great", "john", "on the U.S. Gulf Coast during the first week of April", "manned", "spanish"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2771139705882353}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.16666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.25, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0]}}, "error_ids": ["mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_naturalquestions-validation-4619", "mrqa_squad-validation-7732", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-9546", "mrqa_squad-validation-8525", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_squad-validation-903", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4413", "mrqa_naturalquestions-validation-6482", "mrqa_triviaqa-validation-1199", "mrqa_naturalquestions-validation-2006", "mrqa_squad-validation-3775", "mrqa_hotpotqa-validation-2646"], "retrieved_ids": ["mrqa_naturalquestions-train-74223", "mrqa_naturalquestions-train-70592", "mrqa_naturalquestions-train-69875", "mrqa_naturalquestions-train-17936", "mrqa_naturalquestions-train-42768", "mrqa_naturalquestions-train-42632", "mrqa_hotpotqa-validation-811", "mrqa_naturalquestions-train-30811", "mrqa_naturalquestions-train-51088", "mrqa_triviaqa-validation-6689", "mrqa_naturalquestions-train-84539", "mrqa_triviaqa-validation-7018", "mrqa_squad-validation-3018", "mrqa_naturalquestions-train-55114", "mrqa_naturalquestions-train-85836", "mrqa_naturalquestions-train-38504", "mrqa_naturalquestions-train-48630", "mrqa_naturalquestions-train-43631", "mrqa_naturalquestions-train-1807", "mrqa_triviaqa-validation-2938", "mrqa_naturalquestions-train-24946", "mrqa_naturalquestions-train-61743", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-7592", "mrqa_naturalquestions-train-74279", "mrqa_triviaqa-validation-6351", "mrqa_squad-validation-3971", "mrqa_naturalquestions-train-58545", "mrqa_triviaqa-validation-4298", "mrqa_naturalquestions-train-12315", "mrqa_naturalquestions-train-36185", "mrqa_naturalquestions-train-44690"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 76, "before_eval": {"predictions": ["Tampa Bay defensive end Simeon Rice sacked Raiders quarterback Rich Gannon on third down, forcing Oakland to settle for kicker Sebastian Janikowski's 40 - yard field goal to give them a 3 -- 0 lead", "2018", "Neil Young", "novelization", "9 November 1967", "Back-to- Africa movement", "elected", "mulberry tree", "The Theory of Everything", "Conrad Lewis", "2017 - 12 - 10", "Firefly Car Rental", "2010 to 2013", "Medicare", "Christian Goldbach", "Grease", "Netrobalane canopus", "Alaska, Arizona, California, Colorado, Idaho, Montana, Nevada, New Mexico, Oregon, Utah, Washington and Wyoming", "reborn", "Bhavageete", "Tachycardia, also called tachyarrhythmia", "Novadius DeMun Wilburn", "Richard Burbage", "blood poisoning", "Parliament of the United Kingdom at Westminster", "achievement", "discarded", "A Song of Ice and Fire", "you're the one for me,fatty", "fresh fields", "15 February 1998", "Amazon.com"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33035714285714285}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 0.25, 0.6666666666666666, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-7535", "mrqa_hotpotqa-validation-5027", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-3678", "mrqa_hotpotqa-validation-1314", "mrqa_naturalquestions-validation-6258", "mrqa_squad-validation-9014", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-2550", "mrqa_naturalquestions-validation-6027", "mrqa_squad-validation-1927", "mrqa_hotpotqa-validation-4510", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-956", "mrqa_naturalquestions-validation-2270", "mrqa_squad-validation-5031", "mrqa_squad-validation-9547", "mrqa_squad-validation-7323", "mrqa_triviaqa-validation-7099", "mrqa_naturalquestions-validation-9591"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 77, "before_eval": {"predictions": ["Toronto Huskies", "400-meter freestyle", "genetic branches", "east-west through the centre of Victoria", "four", "new zealand", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "lofs\u00f6ngur", "islay", "troposphere", "Lesser Antilles", "The Fixx", "67,038", "The Swiss Express", "supporters", "graphology", "added to its constituency seats in allocating the second seat", "William the Conqueror", "After School", "Jack", "at any time after the auction", "north of this circle is known as the Arctic, and the zone just to the south is called the Northern Temperate Zone", "a outlaw motorcycle club with many charters in the United States as well as overseas", "Walker Art Gallery", "Great Yuan", "Song Il-gon", "1964 to 1974 model years", "Acura", "dangerous", "food and clothing", "The Emperor of Japan", "in the human body from the amino acids glycine and arginine"], "metric_results": {"EM": 0.1875, "QA-F1": 0.31753058862433864}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.07407407407407407, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 0.0, 0.2857142857142857, 0.125, 0.14285714285714288, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.6666666666666666, 0.0, 1.0, 0.19999999999999998]}}, "error_ids": ["mrqa_naturalquestions-validation-70", "mrqa_triviaqa-validation-6483", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_triviaqa-validation-6204", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_hotpotqa-validation-3732", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-686"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 78, "before_eval": {"predictions": ["2005", "specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "brown", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic Irish veterinary surgeon", "bootlegger", "alexandra Lynde", "fibrous joint", "votex", "heineken", "east end of london", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "proteins called reaction centres that contain green chlorophyll pigments", "1484", "T cells ( for cell - mediated, cytotoxic adaptive immunity )", "electronic sound sources, live instrumental playing and digital signal processing", "1814", "enthalpy", "D\u00e0 Yu\u00e1n", "Gap", "The Indianapolis Times and the Cleveland Press", "Jurchen Aisin Gioro clan in Manchuria", "baloney", "Fort Frontenac on the north shore of Lake Ontario and an expedition through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec", "friendship", "13.34% (116.7 sq mi or 302 km2)", "Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840", "DTIME(n2)", "a poor harvest in 1757, a difficult winter, and the allegedly corrupt machinations of Fran\u00e7ois Bigot", "loud and dirty as possible", "achy breaky heart", "chocolate confectionery"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2663651341563493}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.15384615384615385, 0.0, 0.35294117647058826, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92, 0.0, 1.0, 0.2, 0.26666666666666666, 0.0, 0.15384615384615385, 0.0, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 0.42857142857142855, 1.0, 0.25, 1.0, 0.0, 0.631578947368421, 0.9090909090909091, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_naturalquestions-validation-5838", "mrqa_hotpotqa-validation-1219", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_squad-validation-7476", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-3616", "mrqa_triviaqa-validation-1465"], "retrieved_ids": ["mrqa_squad-validation-1688", "mrqa_hotpotqa-validation-3870", "mrqa_naturalquestions-train-23581", "mrqa_squad-validation-7042", "mrqa_naturalquestions-train-60814", "mrqa_naturalquestions-train-28545", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-5997", "mrqa_squad-validation-8185", "mrqa_naturalquestions-train-42274", "mrqa_hotpotqa-validation-1394", "mrqa_naturalquestions-train-64654", "mrqa_naturalquestions-train-23475", "mrqa_naturalquestions-train-45127", "mrqa_naturalquestions-train-76033", "mrqa_naturalquestions-train-45598", "mrqa_naturalquestions-train-47971", "mrqa_naturalquestions-train-32091", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-train-64654", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-train-53464", "mrqa_naturalquestions-train-52050", "mrqa_naturalquestions-train-24615", "mrqa_naturalquestions-train-9223", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-3664", "mrqa_naturalquestions-validation-1294", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-10355"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 79, "before_eval": {"predictions": ["Sir Hiram Stevens Maxim", "1987", "February 2011", "make direct representations", "Chesley Burnett \"Sully\" Sullenberger III", "October 12, 2017", "an allegiance oath that must be taken by all immigrants who wish to become United States citizens", "The Dead of Jericho", "shirley smith", "clay animation or \"clay-mation\"", "Iowa", "September of that year", "precedes the value ( for instance, \u20ac 10, not 10 \u20ac )", "the Industrial Revolution", "a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "porcini", "white Sox", "rugged terrain such as the Arctic", "the Mexico\u2013united States border", "The American Football Conference (AFC) champion Denver Broncos", "a ribosome in the cytosol", "the Town of Oyster Bay in southeastern Nassau County, New York, on Long Island, east of New York City", "Ringo Starr", "shoppe", "reciprocating", "either by voting or voice vote", "Shoushi Li (\u6388\u6642\u66a6) or Calendar for Fixing the Seasons", "2 %", "japan", "Secretary of Defense", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "thirteen American colonies, then at war with the Kingdom of Great Britain, regarded themselves as thirteen independent sovereign states, no longer under British rule"], "metric_results": {"EM": 0.15625, "QA-F1": 0.31901724006987164}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.35714285714285715, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.9473684210526316, 1.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 0.0, 0.0, 0.0, 0.4, 0.2222222222222222, 0.0, 1.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2846", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4529", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_hotpotqa-validation-3538", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 80, "before_eval": {"predictions": ["John Mills", "new jersey", "Pohamba Shifeta", "Sachin Tendulkar", "fREEWAY", "Charles Silverstein", "Tangmere, West Sussex", "the dollar price of oil had risen by less than two percent per year", "paulo pauli", "State Bar of Arizona", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "beer and soft drinks", "HgO", "red", "the Amazon river", "1967", "Mondays", "22 miles", "1598", "the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "george Auguste", "margaret", "Topeka, Kansas", "500", "rochdale", "the veil", "1894", "they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "parlophone", "phowa", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.1875, "QA-F1": 0.261173433048433}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13333333333333336, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.4, 0.37037037037037035, 0.4, 0.0, 0.5, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-2148", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3056", "mrqa_hotpotqa-validation-3282", "mrqa_squad-validation-3699", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_naturalquestions-validation-7848", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-2009", "mrqa_hotpotqa-validation-2840", "mrqa_squad-validation-10182", "mrqa_triviaqa-validation-5904", "mrqa_naturalquestions-validation-870", "mrqa_squad-validation-4975", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129", "mrqa_squad-validation-1930"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 81, "before_eval": {"predictions": ["one", "National Football Conference", "In series 1, Cybermen in series 2, the Macra and the Master in series 3, the Sontarans and Davros in series 4, and the Time Lords (Rassilon)", "an adviser", "USD 5.2 billion", "A rear - view mirror ( or rearview mirror )", "The Birds", "identify rock samples in the laboratory", "French & Saunders", "the European Parliament and the Council of the European Union", "car crash", "on either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Thomas Edison", "trio", "M\u00fcntzer's execution", "red hot poker", "a new entrance building", "maryland", "paris", "barrel", "construction service firms (e.g. engineering, architecture) and construction managers (firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project)", "valparaiso, Indiana", "Feed Jake", "several hundred thousand", "photoelectric effect", "Noel ( who had previously only sung lead on B-sides) instead of his brother, Liam", "Max West", "Central Trains East Coast", "aluminium", "newspapers, television, radio, cable television, and other businesses", "Lakshmibai", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3507909125188537}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.16, 1.0, 0.375, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5294117647058824, 0.0, 0.0, 0.0, 1.0, 0.125, 0.3333333333333333, 0.0, 0.0, 0.7692307692307693, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8591", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_squad-validation-914", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-3695", "mrqa_squad-validation-5288", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664"], "retrieved_ids": ["mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-train-84677", "mrqa_squad-validation-8811", "mrqa_naturalquestions-train-22308", "mrqa_naturalquestions-train-2314", "mrqa_naturalquestions-train-84933", "mrqa_naturalquestions-train-21771", "mrqa_naturalquestions-train-58779", "mrqa_naturalquestions-train-17363", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-train-16692", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-train-27665", "mrqa_naturalquestions-train-35002", "mrqa_naturalquestions-train-61742", "mrqa_triviaqa-validation-6373", "mrqa_naturalquestions-train-25158", "mrqa_naturalquestions-train-72872", "mrqa_naturalquestions-train-18920", "mrqa_naturalquestions-train-83020", "mrqa_squad-validation-3018", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-85027", "mrqa_naturalquestions-train-67839", "mrqa_triviaqa-validation-1578", "mrqa_naturalquestions-train-67513", "mrqa_naturalquestions-train-57147", "mrqa_triviaqa-validation-1954", "mrqa_naturalquestions-validation-1989", "mrqa_triviaqa-validation-7336", "mrqa_naturalquestions-train-86260", "mrqa_naturalquestions-train-44589"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 82, "before_eval": {"predictions": ["british", "electric clouds overlap, Pauli repulsion (due to fermionic nature of electrons) follows resulting in the force that acts in a direction normal to the surface interface between two objects", "the toe ( at the top of the cerebral hemisphere )", "24 hours later", "April 20, 1945", "dachshund", "a consortium led by the International Crops Research Institute for the Semi-Arid Tropics", "geologic", "129", "Bunkhouse", "rudolf dassler", "an official school sport", "geese", "his friend and future rival, Jamukha", "tentacles and prey", "pacific port", "Tagore", "Lawrence County State's Attorney John Fitzgerald, Chief Deputy Attorney General Charlie McGuigan, and attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "water on the ground surface enters the soil", "9.9ft", "film and short novels", "American-Canadian mystery-drama television series", "American animated television series \"Archer\"", "Gardnerville", "Nucleotides", "25-minute episodes", "Julian Paul Ecuador", "zapatista army of national Liberation", "Tinu Suresh Desai", "green with jealousy", "2003", "salt"], "metric_results": {"EM": 0.15625, "QA-F1": 0.30191399835796384}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.14285714285714288, 0.0, 0.8, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.5517241379310345, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2133", "mrqa_squad-validation-10390", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-2791", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_triviaqa-validation-5592", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_squad-validation-4616", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-2361", "mrqa_hotpotqa-validation-4493", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 83, "before_eval": {"predictions": ["alberto Aleandro Uderzo", "North Africa", "a young girl", "architecture from the gothic, renaissance, baroque and neoclassical periods", "usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm", "the aboral organ (at the opposite end from the mouth)", "birdeater", "scrooge", "northridge earthquake", "Conway", "Maidstone", "kingdoms of Francia on the Lower Rhine, Burgundy on the Upper Rhine and Alemannia", "Sultan S\u00fcleyman-\u0131 Evvel", "4 ( etiology of disease ) ; 5 ( body part affected ) ; 6 ( severity of illness ) ; and 7 ( placeholder for extension of the code to increase specificity )", "Titanic", "difficult and intricate topics", "electronic junk mail", "ABC Radio, with Clear Channel Communications and Westwood One ( which had earlier purchased NBC's radio division, as well as the distribution rights to CBS's, and the Mutual Broadcasting System during the 1990s)", "Tahiti", "detritus from the settlement of the sedimentation", "Rated R", "september", "Steveston Outdoor pool in Richmond, BC", "electricity supply system", "Terry the Tomboy", "scarlet tanager", "South Australia", "Mach number", "pit road speed", "North Atlantic Conference", "at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "british"], "metric_results": {"EM": 0.15625, "QA-F1": 0.301680297424512}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.14814814814814814, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.4, 0.15384615384615385, 0.0, 0.08695652173913045, 1.0, 0.0, 0.8, 0.12903225806451613, 0.14285714285714288, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8484848484848485, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_squad-validation-4490", "mrqa_triviaqa-validation-3113", "mrqa_triviaqa-validation-271", "mrqa_triviaqa-validation-7486", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-3107", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_squad-validation-1159", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-8518", "mrqa_triviaqa-validation-5793"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 84, "before_eval": {"predictions": ["music", "13 years and 48 days", "General Nathan Bedford Forrest", "Theodosius I", "Ubiorum", "in front of only 700 fans", "Brixton", "60", "Assistant Secretary for Administration and Management", "better fuel economy", "september", "evacuate the cylinder", "trees", "optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Carson City", "biologist", "Egyptians", "duke and duchess", "Poems : Series 1", "United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States", "NBA Finals", "Emma Thompson and Alice Eve", "edible - nest swiftlets using solidified saliva", "christmas", "travel literature, cartography, geography, and scientific education", "prince", "Chaplain to the Forces", "pacific nation", "125 lb", "thoracic", "Lexus", "a prison"], "metric_results": {"EM": 0.21875, "QA-F1": 0.4012251984126984}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2222222222222222, 0.8571428571428571, 0.0, 1.0, 0.0, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.24000000000000002, 0.2857142857142857, 0.0, 0.5714285714285715, 0.7499999999999999, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-370", "mrqa_hotpotqa-validation-3830", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1628", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_naturalquestions-validation-10461", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1645", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_hotpotqa-validation-1810", "mrqa_naturalquestions-validation-3173", "mrqa_naturalquestions-validation-6660"], "retrieved_ids": ["mrqa_triviaqa-validation-6969", "mrqa_naturalquestions-train-52296", "mrqa_naturalquestions-train-49152", "mrqa_naturalquestions-train-53006", "mrqa_naturalquestions-train-74251", "mrqa_naturalquestions-train-42135", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-811", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-5746", "mrqa_naturalquestions-train-41656", "mrqa_triviaqa-validation-3113", "mrqa_naturalquestions-train-43841", "mrqa_triviaqa-validation-781", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-train-68187", "mrqa_naturalquestions-train-7712", "mrqa_naturalquestions-train-76196", "mrqa_naturalquestions-train-36503", "mrqa_naturalquestions-train-17468", "mrqa_naturalquestions-train-74165", "mrqa_naturalquestions-train-57237", "mrqa_hotpotqa-validation-1975", "mrqa_naturalquestions-train-33306", "mrqa_naturalquestions-train-66915", "mrqa_naturalquestions-train-46311", "mrqa_naturalquestions-train-44716", "mrqa_naturalquestions-train-22760", "mrqa_naturalquestions-train-59078", "mrqa_naturalquestions-train-2851", "mrqa_naturalquestions-train-17684", "mrqa_hotpotqa-validation-1850"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 85, "before_eval": {"predictions": ["Europe, North America, East Asia and South Asia", "magnitude 3.0, and only about 15\u201320 are greater than magnitude 4.0", "Stephen Crawford Young (born 11 December 1956 in Glasgow, Scotland) is a Scottish musician, and the rhythm guitarist and backing vocalist for the Australian hard rock band, AC/DC.", "Autumn marks the transition from summer to winter, in September ( Northern Hemisphere ) or March ( Southern Hemisphere ), when the duration of daylight becomes noticeably shorter and the temperature cools down considerably", "3000 metres", "October 13, 1980", "1765", "george hudwig", "heart", "napkin", "Yeats", "bilaterally symmetrical", "he did not consider the papacy part of the biblical Church", "1837", "Yen Press", "Bambi, a Life in the Woods", "point on the frontier indicates efficient use of the available inputs ( such as points B, D and C in the graph )", "from ages 12\u201318, while authors and readers of \"Young teen novels\" often define it as written for those aged 15 to the early 20s", "the Apple A6X chip and the Lightning connector", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "in school at a given time in the school day ( such as lunch, recess or after school)", "guinea", "elizabeth bennet", "lactobacilli", "at a school or other place of formal education", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "elizabeth davison", "Ben Johnston", "EE", "in the 1970s and'80s", "ro Roland Ratzenberger", "a dose of 200 to 500 mg up to 7 ml"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23497767857142857}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.21428571428571425, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.16666666666666666, 1.0, 0.0, 0.2, 0.32, 0.16, 0.0, 0.0, 0.125, 0.0, 0.0, 1.0, 0.2222222222222222, 0.4444444444444445, 0.5, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669]}}, "error_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_hotpotqa-validation-4719", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-244", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-4854", "mrqa_squad-validation-1566", "mrqa_triviaqa-validation-2508", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 86, "before_eval": {"predictions": ["Native Americans", "thammasat", "South Sentinel Island", "FCA", "Aaron Taylor- Johnson", "blue", "san Francisco", "a gift", "Conservative", "Peter Davison, Colin Baker and Sylvester McCoy", "conservative", "Super Bowl XXVIII at the end of the 1993 season", "maquiladora", "Bigger Than Both of Us", "in human and animals as a short - lived product in biochemical processes", "\"Bad Blood\"", "the output corresponding to the given input", "13 May 1787", "WJRT-TV", "Great Lakes", "above the top of the range", "the Anabaptists, Zwinglianism, and the papacy", "film playback singer, director, writer and producer", "southern whites", "Marie", "it is not known if L ( the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P", "Association of Commonwealth Universities", "penciling", "unification", "the Allstars", "he stood by their contents", "August 1, 2016"], "metric_results": {"EM": 0.125, "QA-F1": 0.2678129451566952}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.8, 1.0, 0.0, 0.8750000000000001, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6153846153846153, 0.0, 0.25, 0.0, 1.0, 0.07407407407407407, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5195", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_squad-validation-782", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_squad-validation-1768", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_squad-validation-2331", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_squad-validation-10506", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-6912"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 87, "before_eval": {"predictions": ["on First Street in downtown Dayton, Ohio, United States", "electronic gaming machines", "2009", "the last Shah of Iran", "digital streams", "American Broadcasting Company", "Burbank, California", "Mongolian, Tibetan, and Chinese languages", "Due to the controversial and explicit nature", "Meghan Trainor", "carbon cycle", "tenant management", "spend eternity in Gehenna or heaven for their sin", "Donna Noble (Catherine Tate) with Mickey Smith (noel Clarke) and Jack Harkness (Anna Barrowman) recurring as secondary companion figures", "salvaging a country usually seen as one of the most stable and prosperous in Africa", "Kree", "titanium", "\"Loud\" (2010)", "the Kikuyu, Embu and Kamba words Kirinyaga, Kirenyaa and Kiinyaa", "george kenzie kenzie", "domestic legislation", "actions-oriented", "toothbrush", "the state being equally represented by two senators, regardless of its population, serving staggered terms of six years ; with fifty states presently in the Union, there are 100 U.S. Senators", "whiskey", "Thutmose III", "ten to fifteen", "Buck Owens and the Buckaroos", "Kansas", "political support", "moorish fish", "Wimbledon"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3521699909567556}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.888888888888889, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5714285714285714, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6153846153846153, 0.0, 0.5714285714285715, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-2196", "mrqa_squad-validation-5648", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_squad-validation-8552", "mrqa_hotpotqa-validation-5743", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-2814"], "retrieved_ids": ["mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-5822", "mrqa_triviaqa-validation-5057", "mrqa_naturalquestions-train-21281", "mrqa_naturalquestions-train-51238", "mrqa_naturalquestions-train-8742", "mrqa_naturalquestions-train-35002", "mrqa_naturalquestions-train-7402", "mrqa_naturalquestions-train-49152", "mrqa_naturalquestions-train-67764", "mrqa_naturalquestions-train-29021", "mrqa_triviaqa-validation-3493", "mrqa_triviaqa-validation-6689", "mrqa_naturalquestions-validation-9227", "mrqa_naturalquestions-train-27042", "mrqa_naturalquestions-train-23029", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-train-30622", "mrqa_triviaqa-validation-6002", "mrqa_naturalquestions-train-811", "mrqa_naturalquestions-train-19223", "mrqa_hotpotqa-validation-3232", "mrqa_naturalquestions-train-54157", "mrqa_squad-validation-5360", "mrqa_naturalquestions-train-11217", "mrqa_naturalquestions-train-52318", "mrqa_naturalquestions-train-63821", "mrqa_naturalquestions-train-87571", "mrqa_naturalquestions-train-65943", "mrqa_naturalquestions-train-35057", "mrqa_naturalquestions-train-42660", "mrqa_naturalquestions-train-57692"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 88, "before_eval": {"predictions": ["Fabio Cannavaro", "smith family", "The Gold Coast", "conscientious lawbreakers must be punished", "Selena Gomez", "Hawaiian Airlines (Hawaiian: \"\" ) is the largest airline in Hawaii.", "Forbes", "Tachycardia > 159 beats per minute ( bpm )", "small bowel", "guitar", "\"public\" (state-controlled) and \"independent\"", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "norman wright", "eponymous", "southwestern United States, Mexico, and Central America", "a financial self- interest", "sacerdotalism", "discontinued", "estimated half a million", "44 (or virtual channel 6 via PSIP)", "Gaulish name R\u0113nos, which was adapted in Roman-era geography (1st century BC) as Greek \u1fec\u1fc6\u03bd\u03bf\u03c2 ( Rh\u0113nos) Latin Rhenus", "cash from investors such as banks and shareholders, as well as the outflow of cash to shareholders as the company generates income", "duke of smith", "emily of scilly", "Solange Knowles & Destiny's Child", "Ward", "Matt Lowe", "Eddie Gottlieb Trophy", "Elvis Presley", "Afghans", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1938785173160173}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.25, 0.2857142857142857, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-4066", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_hotpotqa-validation-4843", "mrqa_squad-validation-9246", "mrqa_naturalquestions-validation-5291", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_hotpotqa-validation-5498", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 89, "before_eval": {"predictions": ["217", "a protestor who attempts to escape punishment by committing the crime covertly and avoiding attribution, or by denying having committed the crime", "House of Fraser", "Bonkyll Castle ( also variously spelled Bonkyl, Boncle, Buncle, Bunkle or Bonkill) was a medieval fortress situated in the eastern Scottish Borders", "veal stock", "time complexity", "Deadman's Gun", "Costa del Sol", "Philippines", "filaments", "margaret margaret", "1843", "the referendum in the Netherlands", "Stanley Kubrick", "middle America", "Napoleon", "January 30, 1930", "the Hel Peninsula on the Baltic Sea", "Belgium national airline", "all Native American tribal lands", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "Janis Joplin with the poets Michael McClure and Bob Neuwirth", "Odinga", "homicides", "wroxeter", "Bergen County", "August 9, 2017", "qatar", "pragmatism", "USC Trojans", "Richard Bremmer", "sequential proteolytic activation of complement molecules"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3844358492384808}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.1904761904761905, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.23076923076923078, 0.9473684210526316, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-803", "mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-3776", "mrqa_triviaqa-validation-3639", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 90, "before_eval": {"predictions": ["allotrope", "reactive allotrope", "Black Guardian Trilogy", "tragedy", "phylum", "cut", "mack", "complexity classes", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "clef", "four zonal offices at Chennai, Delhi, Kolkata and Mumbai", "black Bottom", "a self-referential time-related adage", "Kitab Rudjdjar", "Gravitational force", "photolysis", "1998\u20132002", "captain", "Callen", "Type I", "rootlets ( branch roots )", "v Violet Newstead", "Jeanne Tripplehorn as Jacqueline Kennedy (Little Edie's cousin) and Ken Howard as Phelan Beale", "red", "New England Patriots", "epitopes", "A74(M", "Absheron peninsula", "september park", "Morty", "Rebecca", "Vivienne Westwood"], "metric_results": {"EM": 0.21875, "QA-F1": 0.26639384920634923}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.28571428571428575, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-3497", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_naturalquestions-validation-3233", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-3988", "mrqa_hotpotqa-validation-3250", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_squad-validation-6627", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-3575", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274"], "retrieved_ids": ["mrqa_triviaqa-validation-6063", "mrqa_naturalquestions-train-68182", "mrqa_naturalquestions-train-67693", "mrqa_squad-validation-9043", "mrqa_naturalquestions-train-1915", "mrqa_naturalquestions-train-33446", "mrqa_naturalquestions-train-34003", "mrqa_naturalquestions-train-82495", "mrqa_naturalquestions-train-8443", "mrqa_naturalquestions-train-58293", "mrqa_triviaqa-validation-4890", "mrqa_naturalquestions-train-1669", "mrqa_naturalquestions-train-38589", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-train-74056", "mrqa_naturalquestions-train-24615", "mrqa_triviaqa-validation-6478", "mrqa_naturalquestions-train-35002", "mrqa_naturalquestions-train-65495", "mrqa_squad-validation-6396", "mrqa_naturalquestions-train-18524", "mrqa_naturalquestions-train-9107", "mrqa_naturalquestions-train-39918", "mrqa_naturalquestions-train-37544", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-2382", "mrqa_triviaqa-validation-6969", "mrqa_naturalquestions-train-86861", "mrqa_naturalquestions-train-2544", "mrqa_triviaqa-validation-2959"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 91, "before_eval": {"predictions": ["46%", "Catherine", "Mongolian patrimonial feudalism", "mortury lane", "neighboring Pakistan", "biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Australian", "100,000 writes", "king philip II", "marquesas", "tuscaloosa", "North Greenwich Arena", "ovules in their unfertilized state", "The 2015 Masters Tournament", "Chiba, Japan", "90%", "henry Bessemer process", "improved firearms", "1856", "Hepatocytes", "many deities and spirits, including the belief that spirits are found in non-human beings and objects such as animals, the waves, and the sky", "stony creek granite that came from the Stony Creek Red Granite Company", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "gregillaz", "corvids", "South Africa", "Love Actually", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistan", "psilocybin, psilocin and baeocystin", "robert de niro"], "metric_results": {"EM": 0.125, "QA-F1": 0.2658765418905362}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.47058823529411764, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.967741935483871, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7551", "mrqa_triviaqa-validation-4749", "mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-4471", "mrqa_hotpotqa-validation-2205", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-888", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_squad-validation-9812", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_hotpotqa-validation-4229", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-1473"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 92, "before_eval": {"predictions": ["into a field in Somerset County, Pennsylvania", "communism", "\"the Gentle Don\" or \"the Docile Don\"", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "pacific", "July 25, 1898", "BitInstant", "\"Fame\", Debbie Berwick on \"Phil of the Future\"", "flights", "steamboats", "Social Chapter", "Australia", "as few as 5 photoreceptor cells", "quantized", "The Adventures of Ozzie and Harriet", "Eunice Kennedy Shriver", "Landry's, Inc.", "Polk was a member of the Democratic Party and an adherent of Jacksonian democracy and Manifest Destiny", "David Naughton, Jenny Agutter and Griffin Dunne", "national army", "Chicago", "ludbergh", "1978", "inversely to member state size", "propeller", "Irvine business centers of The Irvine Spectrum, West Irvine, and international corporations headquartered at the University of California, Irvine", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "rugby union", "1942", "Hugues Capet, king of France", "Morning Edition"], "metric_results": {"EM": 0.375, "QA-F1": 0.4884537337662338}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, true], "QA-F1": [0.2857142857142857, 0.0, 1.0, 0.25, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.28571428571428575, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-5811", "mrqa_hotpotqa-validation-5895", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-6960", "mrqa_triviaqa-validation-7185", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_triviaqa-validation-1267", "mrqa_hotpotqa-validation-3052", "mrqa_squad-validation-3189"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 93, "before_eval": {"predictions": ["prairie region", "a method which pre-allocates dedicated network bandwidth specifically for each communication session, each having a constant bit rate and latency between nodes", "district line", "Utah", "paris", "Great Britain", "mid-size four - wheel drive luxury SUV", "black", "in the town meeting", "we want to practice Christian love toward them and pray that they convert", "two populations of rodents: one resistant to the disease, which act as hosts, keeping the disease endemic, and a second that lack resistance", "around 1200, Tahitian explorers found and began settling the area", "T'Pau", "geheime Staatspolizei", "1815", "American Football Conference", "kimono (clothes) or a tant\u014d (knife)", "Michigan and surrounding states and provinces. Populations are more scattered outside the core area, and the edges of its known distribution range north to the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts", "\"synforms\".", "2015", "man's disobedience toward God", "a representation of a function as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "\"Winnie the Pooh\" (2011)", "America's Cup", "German", "\"Provisional Registration\" is given by the GTCS", "commercial explosives and blasting systems to the mining, quarrying, oil and gas and construction markets, a supplier of sodium cyanide for gold extraction, and a specialist provider of ground support services in mining and tunnelling", "either yes or no, or alternately either 1 or 0", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula", "`` Company Picnic ''", "lie detector", "manhattan coast"], "metric_results": {"EM": 0.125, "QA-F1": 0.24187400637808248}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.06060606060606061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.33333333333333337, 0.07142857142857142, 0.4, 0.0, 1.0, 1.0, 0.0, 0.6296296296296297, 1.0, 0.0, 0.0, 0.34782608695652173, 0.0, 0.0, 0.33333333333333337, 0.5, 0.06060606060606061, 0.4615384615384615, 0.16666666666666669, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-4204", "mrqa_triviaqa-validation-1548", "mrqa_naturalquestions-validation-2870", "mrqa_hotpotqa-validation-421", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-3298", "mrqa_squad-validation-2040", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "retrieved_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-5997", "mrqa_naturalquestions-train-38985", "mrqa_triviaqa-validation-2723", "mrqa_naturalquestions-train-167", "mrqa_naturalquestions-train-16389", "mrqa_triviaqa-validation-2007", "mrqa_naturalquestions-train-18907", "mrqa_naturalquestions-train-53232", "mrqa_triviaqa-validation-7189", "mrqa_squad-validation-9984", "mrqa_naturalquestions-train-17368", "mrqa_naturalquestions-train-49100", "mrqa_naturalquestions-train-43791", "mrqa_triviaqa-validation-5686", "mrqa_naturalquestions-train-72472", "mrqa_naturalquestions-train-84328", "mrqa_triviaqa-validation-7184", "mrqa_naturalquestions-validation-142", "mrqa_hotpotqa-validation-3232", "mrqa_naturalquestions-train-26147", "mrqa_naturalquestions-train-65943", "mrqa_naturalquestions-train-84083", "mrqa_naturalquestions-train-6494", "mrqa_squad-validation-2372", "mrqa_triviaqa-validation-6185", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-train-55282", "mrqa_naturalquestions-train-44654", "mrqa_naturalquestions-train-83658", "mrqa_naturalquestions-train-57523", "mrqa_naturalquestions-validation-10406"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 94, "before_eval": {"predictions": ["the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm, and the nuclear matrix ( which includes the nuclear lamina ), a network within the nucleus", "horror fiction", "tin", "alberta", "southeast of the city", "in the southwestern part of the island", "Guadeloupe in the Lesser Antilles, mainly in the commune of Deshaies", "Statute of Rageman", "1938", "about 63% compared with an actual efficiency of 42% for a modern coal-fired power station", "outside the United States and Canada", "2015, 2016", "90% to 93% O2", "approximately 11 %", "special sovereignty", "Goldbach's conjecture", "kiel canal", "harsh", "1987", "Yankee Doodle Pigeon", "regulates the practice of pharmacists and pharmacy technicians", "Sir Walter Elliot", "1968", "chief petty officer", "led about 1,500 army troops and provincial militia", "the Deobandi movement", "June 11, 1986", "Cork, Portarlington, Lisburn, Waterford and Youghal", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash in Hindi, Urdu and Punjabi", "Tom Coburn", "Short Circuit", "increased and the ground water level fell significantly. Dead branches dried up and the amount of forests on the flood plains decreased sharply"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20479109432234432}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6250000000000001, 0.0, 0.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.923076923076923, 0.2857142857142857, 0.0, 0.0, 0.16000000000000003]}}, "error_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_squad-validation-3315", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-3677", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-9001", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_triviaqa-validation-3230", "mrqa_triviaqa-validation-5584", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_squad-validation-9737", "mrqa_squad-validation-3306", "mrqa_naturalquestions-validation-7496", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 95, "before_eval": {"predictions": ["the \"richest 1 percent in the United States", "universal ruler", "red", "alain Giresse", "the Italian Alps", "ideal", "david Duchovny", "fish toad", "Charles Foster Kane", "parashah", "the s - block", "World Music Awards", "six", "8\u20134\u20134 system", "exposed to scrutiny", "79", "banned the growing of coffee", "no French regular army troops", "creative plea", "stimulated his brain cells", "banshee", "Daniel Inouye", "Jack Nicklaus", "Charles Haley", "corrugated metal", "11 free suburban weekly newspapers", "Dean Stanton", "The Portuguese", "a downward pressure", "the university's science club", "the Jurchen Aisin Gioro clan", "Helsing\u00f8r"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30135233918128657}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.6666666666666666, 0.4444444444444444, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-717", "mrqa_squad-validation-9135", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8288", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_squad-validation-1445", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_hotpotqa-validation-5033", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-9985", "mrqa_squad-validation-7184", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-4796"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 96, "before_eval": {"predictions": ["silicon (silica SiO2, as found in granite and quartz) aluminium (aluminium oxide Al2O3, in bauxite and corundum)", "Marcus Atilius Regulus", "The Dome of the Rock", "Public- private Partnering", "brilliant celebrity with praise", "Xenix", "Bulgaria around the political parties IMRO \u2013 Bulgarian National Movement (IMRO) and National Front for the Salvation of Bulgaria (NFSB)", "8,477 km", "Army, Navy and other services", "Mr. Destiny (1990) in the Goosebumps PC video game, alongside Adam West as \"The Galloping Gazelle\"", "Renhe Sports Management Ltd, 100 % owned by Xiu Li Dai and Yongge Dai. 25 % Owned by Narin Niruttinanon", "philadelphia", "eternal life is not earned by good deeds but is received only as a free gift of God's grace through faith in Jesus Christ as redeemer from sin", "hydrogen and helium", "They also spread beyond Europe to the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec, where they were accepted and allowed to worship freely.", "the cannonball ( assumed constant ) v", "2006", "74", "the Ministry of War", "1162", "el Che or simply Che", "Porsche 944", "acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "1971", "The \"Huguenot Street Historic District\" in New Paltz has been designated a National Historic Landmark site and contains the oldest street in the United States of America.", "American Christian rock band Needtobreathe", "is a creation of Americans to explain the Iranian Islamic Revolution and apolitical Islam was a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970\"", "1986", "cake or biscuit", "Real images can be produced by concave mirrors and converging lenses, only if the object is placed further away from the mirror / lens than the focal point and this real image is inverted.", "electromagnetic, weak, and gravitational", "Ganilau and Ratu Sir Kamisese Mara"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3391557075731063}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.1111111111111111, 0.0, 1.0, 0.4, 0.47058823529411764, 0.0, 0.10526315789473684, 1.0, 0.5714285714285715, 0.0, 0.2857142857142857, 0.0, 0.25806451612903225, 0.42857142857142855, 0.3720930232558139, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.4666666666666667, 1.0, 0.0689655172413793, 0.0, 0.16666666666666666, 0.06451612903225806, 0.3333333333333333, 0.0]}}, "error_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_hotpotqa-validation-5490", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-3057", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "retrieved_ids": ["mrqa_naturalquestions-train-44589", "mrqa_naturalquestions-train-55414", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-train-12311", "mrqa_triviaqa-validation-667", "mrqa_naturalquestions-train-44643", "mrqa_naturalquestions-train-47895", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-5983", "mrqa_naturalquestions-train-82157", "mrqa_naturalquestions-train-73950", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-train-31830", "mrqa_naturalquestions-train-77486", "mrqa_squad-validation-8095", "mrqa_naturalquestions-train-7332", "mrqa_naturalquestions-train-82427", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-2313", "mrqa_naturalquestions-train-6457", "mrqa_triviaqa-validation-7484", "mrqa_naturalquestions-train-11357", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-4668", "mrqa_naturalquestions-train-49463", "mrqa_naturalquestions-train-85910", "mrqa_naturalquestions-train-7381", "mrqa_naturalquestions-train-68734", "mrqa_squad-validation-10312", "mrqa_hotpotqa-validation-2682"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 97, "before_eval": {"predictions": ["third", "every good work designed to attract God's favor is a sin", "suburb", "The National Era", "the American Civil War", "blackberry", "July 1, 2005", "a few drops of the liquid were produced in either case so no meaningful analysis could be conducted", "a little girl ( Addy Miller )", "boston", "Vice president", "the optic chiasm", "the Continental Edison Company in France", "the campaign for a free India", "The 1911 Encyclop\u00e6dia Britannica describes the Gararish as a semi-nomadic, semi-agricultural tribe", "Yuliya Snigir as Irina Komarova", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "the Holy Land from Galicia", "charmed and willing to be ingratiated", "science fiction", "26", "incandescent lamps of a slightly different design", "jute mills", "Canadian rock band Nickelback", "The son of Montague", "the \"father of the Mongols\"", "the ozone hole was indeed caused by chlorine and bromine from manmade organohalogens, the Montreal Protocol was strengthened at a 1990 meeting in London", "a combined concert/lecture by British progressive folk-rock band Gryphon", "island continent of australia", "the 203rd Brandenburg Regiment", "Psych is an American detective comedy-drama television series created by Steve Franks", "the planned Nazi pre-emptive nuclear strike on Japan, `` Operation Dandelion, '' is apparently being prevented only by Hitler's personal refusal to authorise it"], "metric_results": {"EM": 0.125, "QA-F1": 0.2659409167221667}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.3333333333333333, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.5714285714285715, 0.14285714285714288, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0909090909090909, 0.0, 0.0, 0.0, 0.625, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_hotpotqa-validation-3785", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_squad-validation-3475", "mrqa_naturalquestions-validation-7679", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-2504", "mrqa_naturalquestions-validation-1680", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_hotpotqa-validation-2802", "mrqa_squad-validation-1423", "mrqa_triviaqa-validation-2161", "mrqa_hotpotqa-validation-212", "mrqa_naturalquestions-validation-654", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-1081", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 98, "before_eval": {"predictions": ["was the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ), when taking into consideration the full extent and duration of its after effects", "\"SKUM\"", "S6 Edge+", "Turin", "photoreceptor proteins that sense light, found even in unicellular organisms, called `` eyespots ''", "paris", "rock units, and these absolute dates could be applied to fossil sequences in which there was datable material, converting the old relative ages into new absolute ages", "heaviest album of all", "choruses", "in San Francisco, California with offices in New York City and Atlanta", "a major worldwide economic downturn", "ex as a noun is assumed to refer to a former sexual or romantic partner, especially a former spouse", "henry ivy", "cypress", "\"citizenship\" so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for rights", "foot-oriented steps combined with fluid movements in the torso, as well as floor work", "I'll Be There for You", "the Baltimore teenagers Ivan Ashford, Markel Steele, Cameron Brown, Tariq Al - Sabir and Avery Bargasse", "kent countryside", "Sultans", "the end of the post-war communist control of the country and the reintroduction of a free-market economy", "chinese", "By most chloroplasts originate from that first set of endosymbiotic events, Paulinella chromatophora is an exception that acquired a photosynthetic cyanobacterium Synechococcus", "penrose stairs", "Wynantskill is located at the north town line and the northeast corner of the town of North Greenbush", "a conceptual barrier between those presenting some kind of a communication and those receiving it", "Synergy Group", "a limited period of time in exchange for detailed public disclosure of an invention", "ch\u00f4nin", "Stritch", "between the three towns of Doncaster, Scunthorpe and Gainsborough", "1908"], "metric_results": {"EM": 0.15625, "QA-F1": 0.29553415334665334}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.47619047619047616, 1.0, 0.0, 1.0, 1.0, 0.4, 0.14285714285714288, 1.0, 0.0, 0.4, 0.3333333333333333, 0.47619047619047616, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2857142857142857, 0.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.18181818181818182, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_hotpotqa-validation-2978", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_triviaqa-validation-1474", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_hotpotqa-validation-4093", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 99, "before_eval": {"predictions": ["Ron Grainer", "in 1919 was the ban of manufacture, sale or transportation of intoxicating liquors", "elstow", "sent missionaries", "Gender pay gap", "Jessie", "December 19, 1967", "economic growth", "in 1997 by Bloomsbury", "October 1, 2017", "Washington, D.C.", "wis", "Toronto, Ontario, Canada", "Saint Elgiva", "told Washington that France's claim to the region was superior to that of the British", "a balance sensor consisting of a statolith", "vedal fall", "extracurricular activities", "Prince Nikolai Sergeyevich Trubetzkoy", "held court in his saloon along the Rio Grande on a desolate stretch of the Chihuahuan Desert of southwest Texas", "by the studies and developments department of the French firm R2E Micral in 1980 at the request of the company CCMC specializing in payroll and accounting", "1800 to 1850", "in the 1969 revision of the Roman Rite, an alternative formula ( based on Mark 1 : 15 ) was introduced and given first place `` Repent, and believe in the Gospel ''", "The book explores what those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "Twink", "Caribbeans", "derry", "infinitely many", "porto", "Bhaktivedanta Manor", "giant jellyfish or the hair jelly", "Mammals"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2813782051282051}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.13333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.24000000000000002, 0.23076923076923078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_naturalquestions-validation-3651", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_hotpotqa-validation-1086", "mrqa_squad-validation-10231", "mrqa_triviaqa-validation-4000", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-5590", "mrqa_hotpotqa-validation-4961", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-251", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794"], "retrieved_ids": ["mrqa_squad-validation-9984", "mrqa_squad-validation-1942", "mrqa_naturalquestions-train-3192", "mrqa_triviaqa-validation-1028", "mrqa_naturalquestions-train-60089", "mrqa_naturalquestions-train-22530", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-train-36750", "mrqa_hotpotqa-validation-4164", "mrqa_naturalquestions-train-8124", "mrqa_naturalquestions-train-50948", "mrqa_naturalquestions-train-56257", "mrqa_naturalquestions-train-33739", "mrqa_triviaqa-validation-5997", "mrqa_squad-validation-7445", "mrqa_naturalquestions-train-72472", "mrqa_triviaqa-validation-1053", "mrqa_naturalquestions-train-23421", "mrqa_naturalquestions-train-49277", "mrqa_naturalquestions-train-41085", "mrqa_naturalquestions-train-25813", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-train-79850", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-train-57784", "mrqa_naturalquestions-train-22865", "mrqa_naturalquestions-train-74438", "mrqa_triviaqa-validation-2959", "mrqa_naturalquestions-train-3106", "mrqa_naturalquestions-train-36561"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.17125, "QA-F1": 0.2830686282228226}, "overall_error_number": 2652, "overall_instant_fixing_rate": 0.0, "final_instream_test": {"EM": 0.6840625, "QA-F1": 0.75187218712681}, "final_upstream_test": {"EM": 0.707, "QA-F1": 0.8126912956307745}}}