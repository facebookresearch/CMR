08/16/2021 13:38:08 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/16/2021 13:38:08 - INFO - __main__ - dataset_size=10474, num_shards=6, local_shard_id=2
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/16/2021 13:38:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/16/2021 13:38:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/16/2021 13:38:09 - INFO - __main__ - Start tokenizing ... 1746 instances
08/16/2021 13:38:09 - INFO - __main__ - Printing 3 examples
08/16/2021 13:38:09 - INFO - __main__ - Context: Oxygen is present in the atmosphere in trace quantities in the form of carbon dioxide (CO2). The Earth's crustal rock is composed in large part of oxides of silicon (silica SiO2, as found in granite and quartz), aluminium (aluminium oxide Al2O3, in bauxite and corundum), iron (iron(III) oxide Fe2O3, in hematite and rust), and calcium carbonate (in limestone). The rest of the Earth's crust is also made of oxygen compounds, in particular various complex silicates (in silicate minerals). The Earth's mantle, of much larger mass than the crust, is largely composed of silicates of magnesium and iron. | Question: Oxygen exists in the atmosphere by way of what?
08/16/2021 13:38:09 - INFO - __main__ - ['carbon dioxide']
08/16/2021 13:38:09 - INFO - __main__ - Context: Oxygen is present in the atmosphere in trace quantities in the form of carbon dioxide (CO2). The Earth's crustal rock is composed in large part of oxides of silicon (silica SiO2, as found in granite and quartz), aluminium (aluminium oxide Al2O3, in bauxite and corundum), iron (iron(III) oxide Fe2O3, in hematite and rust), and calcium carbonate (in limestone). The rest of the Earth's crust is also made of oxygen compounds, in particular various complex silicates (in silicate minerals). The Earth's mantle, of much larger mass than the crust, is largely composed of silicates of magnesium and iron. | Question: Silicates of magnesium and iron make up of the Earth's ___ ?
08/16/2021 13:38:09 - INFO - __main__ - ['mantle', "The Earth's mantle"]
08/16/2021 13:38:09 - INFO - __main__ - Context: Oxygen is present in the atmosphere in trace quantities in the form of carbon dioxide (CO2). The Earth's crustal rock is composed in large part of oxides of silicon (silica SiO2, as found in granite and quartz), aluminium (aluminium oxide Al2O3, in bauxite and corundum), iron (iron(III) oxide Fe2O3, in hematite and rust), and calcium carbonate (in limestone). The rest of the Earth's crust is also made of oxygen compounds, in particular various complex silicates (in silicate minerals). The Earth's mantle, of much larger mass than the crust, is largely composed of silicates of magnesium and iron. | Question: In what compound is oxygen found in small amounts in the atmosphere?
08/16/2021 13:38:09 - INFO - __main__ - ['carbon dioxide']
08/16/2021 13:38:09 - INFO - __main__ - Tokenizing Input ...
08/16/2021 13:38:11 - INFO - __main__ - Tokenizing Input ... Done!
08/16/2021 13:38:11 - INFO - __main__ - Tokenizing Output ...
08/16/2021 13:38:11 - INFO - __main__ - Tokenizing Output ... Done!
08/16/2021 13:38:11 - INFO - __main__ - Loaded 1746 examples from dev data
08/16/2021 13:38:11 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/16/2021 13:38:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/16/2021 13:38:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/16/2021 13:38:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/16/2021 13:38:17 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/16/2021 13:38:21 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/28 [00:00<?, ?it/s]Infernece:   4%|▎         | 1/28 [00:04<02:06,  4.69s/it]Infernece:   7%|▋         | 2/28 [00:09<01:59,  4.61s/it]Infernece:  11%|█         | 3/28 [00:13<01:56,  4.65s/it]Infernece:  14%|█▍        | 4/28 [00:18<01:51,  4.64s/it]Infernece:  18%|█▊        | 5/28 [00:23<01:48,  4.73s/it]Infernece:  21%|██▏       | 6/28 [00:28<01:45,  4.80s/it]Infernece:  25%|██▌       | 7/28 [00:33<01:40,  4.79s/it]Infernece:  29%|██▊       | 8/28 [00:37<01:35,  4.78s/it]Infernece:  32%|███▏      | 9/28 [00:43<01:32,  4.88s/it]Infernece:  36%|███▌      | 10/28 [00:48<01:30,  5.03s/it]Infernece:  39%|███▉      | 11/28 [00:53<01:26,  5.10s/it]Infernece:  43%|████▎     | 12/28 [00:59<01:25,  5.33s/it]Infernece:  46%|████▋     | 13/28 [01:05<01:22,  5.51s/it]Infernece:  50%|█████     | 14/28 [01:10<01:14,  5.35s/it]Infernece:  54%|█████▎    | 15/28 [01:16<01:14,  5.70s/it]Infernece:  57%|█████▋    | 16/28 [01:22<01:09,  5.76s/it]Infernece:  61%|██████    | 17/28 [01:28<01:04,  5.86s/it]Infernece:  64%|██████▍   | 18/28 [01:34<00:56,  5.69s/it]Infernece:  68%|██████▊   | 19/28 [01:40<00:53,  5.97s/it]Infernece:  71%|███████▏  | 20/28 [01:46<00:46,  5.78s/it]Infernece:  75%|███████▌  | 21/28 [01:51<00:39,  5.65s/it]Infernece:  79%|███████▊  | 22/28 [01:56<00:32,  5.39s/it]Infernece:  82%|████████▏ | 23/28 [02:02<00:28,  5.66s/it]Infernece:  86%|████████▌ | 24/28 [02:07<00:21,  5.39s/it]Infernece:  89%|████████▉ | 25/28 [02:12<00:15,  5.20s/it]Infernece:  93%|█████████▎| 26/28 [02:16<00:10,  5.05s/it]Infernece:  96%|█████████▋| 27/28 [02:21<00:04,  4.96s/it]Infernece: 100%|██████████| 28/28 [02:23<00:00,  4.00s/it]Infernece: 100%|██████████| 28/28 [02:23<00:00,  5.12s/it]
08/16/2021 13:40:44 - INFO - __main__ - Starting inference ... Done
