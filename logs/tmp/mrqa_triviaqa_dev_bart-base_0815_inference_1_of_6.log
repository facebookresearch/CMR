08/16/2021 13:33:25 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/16/2021 13:33:25 - INFO - __main__ - dataset_size=7784, num_shards=6, local_shard_id=1
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/16/2021 13:33:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/16/2021 13:33:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/16/2021 13:33:26 - INFO - __main__ - Start tokenizing ... 1298 instances
08/16/2021 13:33:26 - INFO - __main__ - Printing 3 examples
08/16/2021 13:33:26 - INFO - __main__ - Context: Charles Martell & Son - Stinking BishopCharles Martell & Son - Stinking Bishop  Publications  Stinking Bishop  Description: Full fat pasteurised cows’ milk soft cheese made with vegetarian rennet.  The rind is washed in perry which gives it its characteristic flavour, brown/pink rind and pungent smell.  The cheese is supported with a beechwood lath and is wrapped in waxed paper.  Nominal weight  6 weeks from despatch date  Packaging  Beechwood lath and waxed paper  Waxed Paper and Wooden Box  Please note this cheese has a natural rind and may therefore carry mould spots of varying interesting hues from time to time.  History: A monastic type of cheese which owes its origin to the Cistercian order of monks who once farmed the pastures of  Hunts Court Farm whence it was launched in 1994.  As with many monastic cheeses, this variety is matured in humid cave-like conditions. The rind is washed in perry because the 100 or so varieties of perry pear known nationally are peculiar to this part of Gloucestershire and its border areas.  One of these varieties is ‘Stinking Bishop’, a name which seems appropriate for this cheese.  The Stinking Bishop pear was in turn named after a local mid 19th Century farmer called Frederick Bishop.  He earned himself the nick-name 'Stinking Bishop' because of his riotous behaviour.  He once took a cow to market and determined to drink the proceeds before he went home - he did, and then when the kettle was too slow to boil he shot it!  Pricing for Stinking Bishop:  Stinking Bishop - Cheese.comStinking Bishop - Cheese.com  Find over 1750 specialty cheeses from 74 countries in the world's greatest cheese resource  Stinking Bishop  Stinking Bishop is a full fat pasteurised cow's milk soft cheese made by Charles Martell & Son since 1972 at their Laurel Farm in Dymock, England. Milk of rare Gloucester cattle is used to produce the cheese though sometimes their milk is mixed with the milk of Fresian cattle.  Made with vegetarian rennet, this cheese is also suitable for vegetarians. The rind is washed in perry, an alcoholic drink made with the local variety of Stinking Bishop pear, which gives the cheese its name. The alcoholic wash gives the cheese its distinctive pungent aroma and brown/pink rind colour. As a result of the natural rind, changeable hues of mold spots appear on the cheese from time to time.  This unique cheese dates its history to the Cistercian order of monks. To keep up with the tradition of monastic cheeses, Stinking Bishop is also matured in humid cave-like conditions.  The colour of the cheese paste varies from white-yellow to beige, with an orange to grey rind. It is available in 5lbs wheels, each measuring 8-inches in diameter and 2-inches deep. The affinage takes from six to eight weeks. Stinking Bishop is produced in very limited quantities but its stinky smell has made it very popular in the United Kingdom and abroad.  Made from pasteurized cow 's milk  Stinking Bishop | British Soft Cheese | Soft CheeseStinking Bishop | British Soft Cheese | Soft Cheese  British Soft Cheese     Stinking Bishop  This famous washed rind cheese has steadily grown in popularity and always been a favourite of ours here at Just Cheese. Stinking Bishop is the name of the pear variety which is made into perry and used to wash the cows milk cheese. The result is a sweet fruity cheese which is buttery and indulgent. As with most wash rind cheese, the odour can be incredibly pungent which helps this highly saught after cheese live up to its name.  Country of Origin  Stinking Bishop - The Cheese ShedStinking Bishop - The Cheese Shed  Stinking Bishop  « swipe to see more images »  Stinking Bishop  price  from £32.90  This cheese is not run-of-the-mill. There's no doubt that Charles Martell has created a cheese of great distinction, smelly for sure, think Pont L'Eveque or Epoisses, but with a delightful taste – sweetish and, despite what the smell might suggest, actually not overwhelmingly strong.  Stinking Bishop is available as a whole 500g cheese. | Question: Stinking Bishop is a variety of which fruit?
08/16/2021 13:33:26 - INFO - __main__ - ['pear']
08/16/2021 13:33:26 - INFO - __main__ - Context: Marble Arch - Famous WondersMarble Arch  Marble Arch  View Larger Map  The Marble Arch is a monument located at the Oxford Street, Edgware Road and Park Lane junction, in Westminster, London, England. The monument is made from Carrara marble. The Marble Arch used to be located in front of Buckingham Palace, but it was moved in the year of 1851.  The History of the Marble Arch  The Marble Arch is quite old, as it was built back in the year of 1825. It was designed by John Nash. The arch was originally intended to be used as a ceremonial entrance to Buckingham Palace and it served this purpose until it was relocated.  The Design  The arch’s design is unique, and is actually based on the design of the Arc de Triomphe du Carrousel, which is located in Paris, as well as the Arch of Constantine, which can be found over in Rome. The arch was originally designed to include sculptures that depicted the victories of British forces during the Napoleonic Wars. An architectural model of the monument was made back in 1826, and if you are interested in viewing it, then you can do so at the Victoria and Albert Museum, which is also located in London.  A man by the name of John Flaxman was picked to create the sculpture, but he died before he could complete it in 1826. The job was then split up between three men, who were J.C.F. Rossi, Sir Richard Westmacott and Edward Hodges Baily.  Getting To The Arch  If you are interested in visiting the arch, then there are a few ways to reach it. The easiest way to get to the arch is to simply drive there, as there is plenty of parking around the arch. However, keep in mind that you may have to pay some money to park. Another easy way to reach the arch is by taking the tube. The tube station is right near the arch, and the station is named after the Marble Arch.  Visiting the Arch  The Marble Arch is one of the most well-known monuments in all of the UK. This structure is unique and the design of it is simply amazing. The arch is also located by many different shops, which are considered to be some of the best shops located in London. Many people will visit some of the nearby shops after they pay a visit to the Marble Arch.  London Famous Landmarks  Marble Arch in London, England | ExpediaMarble Arch in London, England | Expedia  Marble Arch in London, England | Expedia  Marble Arch Marble Arch, current page  Previous image, 2 total items.  Next image, 2 total items.  Marble Arch  Admire the intricate sculptures on this grand three-arched monument, which is modeled on Rome’s Arch of Constantine.  Marble Arch is an elegant triumphal arch with three bays. Although the arch was initially constructed as part of Buckingham Palace, the monument now stands on a plaza beside Hyde Park. Take photos of your family in front of one of the most iconic structures in the city.  Built for the royal family in the early 1800s, Marble Arch retains its regal allure despite having been moved to a different location in 1851. Numerous theories circulate as to why it was relocated: some say it was because the central arch was too narrow for the royal stage coach, others say it needed to be moved out of the way to make way for a palace extension.  Well-known architect John Nash, who also worked on the palace itself, took inspiration for the design from Rome’s Arch of Constantine. Like the famous ancient monument, Marble Arch contains one large portal with two smaller arches either side. Above the arches are carved reliefs representing England, Scotland and Ireland.  Make like royalty and pass under the central arch. This entrance was initially reserved only for use by Britain’s royal family and members of the King’s Troop Royal Horse Artillery. Imagine yourself as a reigning monarch as you go through.  Enjoy a picturesque stroll through the vast Hyde Park. Go boating on Serpentine Lake, listen to open- | Question: Marble Arch in London was once the ceremonial entrance to which British palace?
08/16/2021 13:33:26 - INFO - __main__ - ['buckingham palace']
08/16/2021 13:33:26 - INFO - __main__ - Context: Monster Mackinaw and Kokanee Chrome | Gary Lewis OutdoorsMonster Mackinaw and Kokanee Chrome | Gary Lewis Outdoors  Monster Mackinaw and Kokanee Chrome  By Gary Lewis  A light breeze riffled the glassy surface as we pulled away from the dock. We watched the depth finder and Dana pointed the bow toward the eastern end of Oregon's Odell Lake. It was a rare day in the Cascades, warm for this early in the morning. Today we would be fishing deep, down to 140 feet, hoping to connect with a big mackinaw.  Many years ago, when first I fished for mackinaw, I looked out across that big, gray, wind-chopped lake and wondered where a person should start. I spent a couple of days trying and eventually caught a few fish, but I wasn't satisfied. Something about the mammoth trophies on the wall of the lodge told me that I had a lot more to learn.  Lake trout, also called mackinaw are, in fact, members of the char family. But whatever you call them, they are creatures of cool, deep-water lakes. And they are predators whose primary feed is smaller fish, up to one-third their own size. Since their preferred temperature range is from 48 to 52 degrees, lake trout are commonly found in depths of 50 to 150 feet. In the spring, however, and in late fall and winter, when temperatures near the surface cool, big lakers can be caught in shallow water.  In many lakes, kokanee are the preferred food, but other species such as chubs, whitefish, squawfish, rainbows, cutthroats, and bull trout might be on the menu.  Macks are slow-growing fish. In most waters it takes ten or eleven years to grow a five-pound fish. Lake trout can live as long as 40 years. The largest lake trout on record was caught with a net in Saskatchewan's Lake Athabasca. The fish weighed 102 pounds.  Lake trout may be found at different depths during the course of a day. Some fish will be chasing kokanee, slashing through a ball of bait at 80 feet, feeding until they are full, then dropping down to the 100 to 150 foot depth to rest and digest their food. They compensate for changes in water pressure by burping air through a duct connecting their swim bladder to their esophagus.  My friend Dana Knepper of Central Oregon Spinnerbaits in Crescent Lake has spent more time chasing mackinaw than anyone else I know and he loves to catch the big fish. Dana fishes from an 18-foot Starcraft, equipped with a 90 hp Mercury outboard, and two Cannon downriggers.  Using a downrigger on each side of the boat, we trolled flashers and large M-2 Flatfish baited with nightcrawlers. Dana began marking mackinaw on the depth finder right away. My daughter Jennifer kept watch, wondering which one of those little pixels representing predatory lake trout would follow the lure and smash it.   We were in the right place to catch a big one. Odell's lake trout fishery was established by stocking efforts in the early 1900s, and Oregon's current state record lake trout was caught in Odell in 1984. That fish tipped the scales at 40 pounds, eight ounces. Most of the fish you'll catch will run between five and 15 pounds, but the Oregon Department of Fish and Wildlife has recorded lake trout in the 50-pound range. Anglers come from all over the Northwest for the chance at boating one and many do, but what most anglers don't know is that there are strategies that will help you land the biggest fish. Once you know the secrets to catching these monster mackinaw, you can boat more big ones, wherever you fish.  LAKE TROUT TACTICS  When fishing for lake trout, use medium to medium-heavy spinning or baitcasting gear with ten- to 25-pound test line. This is a great time to use braided line because it does not stretch and deepwater bites are felt - and responded to - faster.  The braided main line is clipped to the downrigger with a quick disconnect that allows the fisherman to "pop" the line free and fight the fish without being tied | Question: What type of creature is a Kokanee?
08/16/2021 13:33:26 - INFO - __main__ - ['fish', 'fishes']
08/16/2021 13:33:26 - INFO - __main__ - Tokenizing Input ...
08/16/2021 13:33:36 - INFO - __main__ - Tokenizing Input ... Done!
08/16/2021 13:33:36 - INFO - __main__ - Tokenizing Output ...
08/16/2021 13:33:36 - INFO - __main__ - Tokenizing Output ... Done!
08/16/2021 13:33:36 - INFO - __main__ - Loaded 1298 examples from dev data
08/16/2021 13:33:36 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/16/2021 13:33:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/16/2021 13:33:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/16/2021 13:33:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/16/2021 13:33:45 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/16/2021 13:33:50 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/21 [00:00<?, ?it/s]Infernece:   5%|▍         | 1/21 [00:06<02:19,  6.97s/it]Infernece:  10%|▉         | 2/21 [00:13<02:12,  6.95s/it]Infernece:  14%|█▍        | 3/21 [00:20<02:04,  6.90s/it]Infernece:  19%|█▉        | 4/21 [00:27<01:57,  6.89s/it]Infernece:  24%|██▍       | 5/21 [00:34<01:51,  6.94s/it]Infernece:  29%|██▊       | 6/21 [00:41<01:45,  7.03s/it]Infernece:  33%|███▎      | 7/21 [00:48<01:39,  7.07s/it]Infernece:  38%|███▊      | 8/21 [00:56<01:32,  7.13s/it]Infernece:  43%|████▎     | 9/21 [01:03<01:25,  7.08s/it]Infernece:  48%|████▊     | 10/21 [01:09<01:16,  6.96s/it]Infernece:  52%|█████▏    | 11/21 [01:16<01:09,  6.91s/it]Infernece:  57%|█████▋    | 12/21 [01:23<01:02,  6.89s/it]Infernece:  62%|██████▏   | 13/21 [01:30<00:55,  6.94s/it]Infernece:  67%|██████▋   | 14/21 [01:37<00:49,  7.04s/it]Infernece:  71%|███████▏  | 15/21 [01:45<00:42,  7.14s/it]Infernece:  76%|███████▌  | 16/21 [01:52<00:35,  7.14s/it]Infernece:  81%|████████  | 17/21 [01:59<00:28,  7.15s/it]Infernece:  86%|████████▌ | 18/21 [02:06<00:21,  7.06s/it]Infernece:  90%|█████████ | 19/21 [02:13<00:13,  6.98s/it]Infernece:  95%|█████████▌| 20/21 [02:20<00:07,  7.10s/it]Infernece: 100%|██████████| 21/21 [02:22<00:00,  5.63s/it]Infernece: 100%|██████████| 21/21 [02:22<00:00,  6.80s/it]
08/16/2021 13:36:13 - INFO - __main__ - Starting inference ... Done
