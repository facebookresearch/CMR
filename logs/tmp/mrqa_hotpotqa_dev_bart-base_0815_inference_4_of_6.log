08/16/2021 13:36:17 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/16/2021 13:36:17 - INFO - __main__ - dataset_size=5901, num_shards=6, local_shard_id=4
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/16/2021 13:36:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/16/2021 13:36:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/16/2021 13:36:18 - INFO - __main__ - Start tokenizing ... 983 instances
08/16/2021 13:36:18 - INFO - __main__ - Printing 3 examples
08/16/2021 13:36:18 - INFO - __main__ - Context: Hannah Montana Hits Remixed  Hannah Montana Hits Remixed is the second remix album by American pop recording artist Miley Cyrus, in the role of the character Hannah Montana.  It was the fifth "Hannah Montana" album released on August 19, 2008, exclusively at American Wal-Mart stores.  The album features singles from both of the previous television soundtracks, "Hannah Montana" and "Hannah Montana 2".  Several writers and producers worked on the songs, mainly Matthew Gerrard and Robbie Nevil.  The album peaked at number one hundred-three in "Billboard" 200 and at four in Top Kid Audio.  All songs were remixed by music producers Marco Marinangeli and Simone Sello.   Miley Cyrus  Miley Ray Cyrus (born Destiny Hope Cyrus; November 23, 1992) is an American singer, songwriter, and actress.  After playing minor roles in the television series "Doc" and the film "Big Fish" in her childhood, she became a teen idol starring as the character Miley Stewart in the Disney Channel television series "Hannah Montana" in 2006.  Her father Billy Ray Cyrus also starred in the show.  She subsequently signed a recording contract with Hollywood Records, and her debut studio album "" (2007) was certified triple-platinum by the Recording Industry Association of America (RIAA) having shipped over three million units.  She released her second album "Breakout" and launched her film career as a voice actress in the animated film "Bolt" in 2008. | Question: In what year was the singer whose second remix album was "Hannah Montana Hits Remixed" born?
08/16/2021 13:36:18 - INFO - __main__ - ['1992']
08/16/2021 13:36:18 - INFO - __main__ - Context: Kurt Schaefer  Kurt Schaefer (born October 27, 1965) is a former Republican member of the Missouri Senate, representing the 19th District from 2009–2017.  In 2016, Schaefer ran against Josh Hawley for Missouri Attorney General, but was defeated for the Republican nomination in the August 2 primary.   Josh Hawley  Joshua David Hawley (born December 31, 1979) is an American lawyer and politician who serves as the 42nd and current Attorney General of Missouri. | Question: What political party is the current Attorney General of Missouri associated with?
08/16/2021 13:36:18 - INFO - __main__ - ['Republican']
08/16/2021 13:36:18 - INFO - __main__ - Context: Dionne Bunsha  Dionne Bunsha is an award-winning journalist from Mumbai, India, who has written about suicide deaths among farmers, religious strife in India, human rights, threats to the Indian environment and a range of other crucial issues.  She worked most recently for "Frontline" magazine.  Bunsha is the author of "" (2006).   Frontline (magazine)  Frontline is a fortnightly English language magazine published by The Hindu Group of publications from Chennai, India.  R Vijaya Sankar is the editor-in-chief of the magazine.  As a current affairs magazine, it covers domestic and International news.  "Frontline" gives a prominent place to various issues of development and hindrances in the Indian states.  Apart from topics of politics and political economy, it also covers a wide range of topics including Arts, books, cinema, Science and English language. | Question: Dionne Bunsha worked most recently for the magazine published by what company?
08/16/2021 13:36:18 - INFO - __main__ - ['The Hindu Group']
08/16/2021 13:36:18 - INFO - __main__ - Tokenizing Input ...
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Input ... Done!
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Output ...
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Output ... Done!
08/16/2021 13:36:21 - INFO - __main__ - Loaded 983 examples from dev data
08/16/2021 13:36:21 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/16/2021 13:36:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/16/2021 13:36:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/16/2021 13:36:22 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/16/2021 13:36:26 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/16/2021 13:36:31 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/16 [00:00<?, ?it/s]Infernece:   6%|▋         | 1/16 [00:06<01:44,  6.98s/it]Infernece:  12%|█▎        | 2/16 [00:13<01:36,  6.87s/it]Infernece:  19%|█▉        | 3/16 [00:19<01:25,  6.55s/it]Infernece:  25%|██▌       | 4/16 [00:25<01:15,  6.31s/it]Infernece:  31%|███▏      | 5/16 [00:32<01:11,  6.54s/it]Infernece:  38%|███▊      | 6/16 [00:37<01:00,  6.08s/it]Infernece:  44%|████▍     | 7/16 [00:43<00:55,  6.22s/it]Infernece:  50%|█████     | 8/16 [00:50<00:50,  6.30s/it]Infernece:  56%|█████▋    | 9/16 [00:55<00:41,  5.88s/it]Infernece:  62%|██████▎   | 10/16 [00:59<00:32,  5.39s/it]Infernece:  69%|██████▉   | 11/16 [01:04<00:27,  5.43s/it]Infernece:  75%|███████▌  | 12/16 [01:11<00:23,  5.79s/it]Infernece:  81%|████████▏ | 13/16 [01:17<00:17,  5.72s/it]Infernece:  88%|████████▊ | 14/16 [01:22<00:11,  5.76s/it]Infernece:  94%|█████████▍| 15/16 [01:28<00:05,  5.71s/it]Infernece: 100%|██████████| 16/16 [01:31<00:00,  4.76s/it]Infernece: 100%|██████████| 16/16 [01:31<00:00,  5.69s/it]
08/16/2021 13:38:02 - INFO - __main__ - Starting inference ... Done
