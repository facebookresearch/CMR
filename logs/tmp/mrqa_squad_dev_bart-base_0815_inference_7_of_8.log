08/15/2021 15:49:55 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/15/2021 15:49:55 - INFO - __main__ - dataset_size=10474, num_shards=8, local_shard_id=7
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/15/2021 15:49:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/15/2021 15:49:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/15/2021 15:49:56 - INFO - __main__ - Start tokenizing ... 1309 instances
08/15/2021 15:49:56 - INFO - __main__ - Printing 3 examples
08/15/2021 15:49:56 - INFO - __main__ - Context: In the centre of Basel, the first major city in the course of the stream, is located the "Rhine knee"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin. | Question: What is the bend of Rhine in Basel called?
08/15/2021 15:49:56 - INFO - __main__ - ['Rhine knee']
08/15/2021 15:49:56 - INFO - __main__ - Context: In the centre of Basel, the first major city in the course of the stream, is located the "Rhine knee"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin. | Question: What is the boundary between the High and Upper Rhine?
08/15/2021 15:49:56 - INFO - __main__ - ['Central Bridge']
08/15/2021 15:49:56 - INFO - __main__ - Context: In the centre of Basel, the first major city in the course of the stream, is located the "Rhine knee"; this is a major bend, where the overall direction of the Rhine changes from West to North. Here the High Rhine ends. Legally, the Central Bridge is the boundary between High and Upper Rhine. The river now flows North as Upper Rhine through the Upper Rhine Plain, which is about 300 km long and up to 40 km wide. The most important tributaries in this area are the Ill below of Strasbourg, the Neckar in Mannheim and the Main across from Mainz. In Mainz, the Rhine leaves the Upper Rhine Valley and flows through the Mainz Basin. | Question: How long is the Upper Rhine Plain?
08/15/2021 15:49:56 - INFO - __main__ - ['300 km long']
08/15/2021 15:49:56 - INFO - __main__ - Tokenizing Input ...
08/15/2021 15:49:57 - INFO - __main__ - Tokenizing Input ... Done!
08/15/2021 15:49:57 - INFO - __main__ - Tokenizing Output ...
08/15/2021 15:49:57 - INFO - __main__ - Tokenizing Output ... Done!
08/15/2021 15:49:57 - INFO - __main__ - Loaded 1309 examples from dev data
08/15/2021 15:49:57 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/15/2021 15:49:58 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/15/2021 15:49:58 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/15/2021 15:49:58 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/15/2021 15:50:03 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/15/2021 15:50:10 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/21 [00:00<?, ?it/s]Infernece:   5%|▍         | 1/21 [00:06<02:10,  6.50s/it]Infernece:  10%|▉         | 2/21 [00:12<02:00,  6.34s/it]Infernece:  14%|█▍        | 3/21 [00:18<01:52,  6.28s/it]Infernece:  19%|█▉        | 4/21 [00:24<01:44,  6.17s/it]Infernece:  24%|██▍       | 5/21 [00:30<01:37,  6.08s/it]Infernece:  29%|██▊       | 6/21 [00:36<01:30,  6.02s/it]Infernece:  33%|███▎      | 7/21 [00:42<01:25,  6.08s/it]Infernece:  38%|███▊      | 8/21 [00:48<01:17,  5.93s/it]Infernece:  43%|████▎     | 9/21 [00:53<01:11,  5.92s/it]Infernece:  48%|████▊     | 10/21 [00:58<01:01,  5.60s/it]Infernece:  52%|█████▏    | 11/21 [01:04<00:56,  5.63s/it]Infernece:  57%|█████▋    | 12/21 [01:10<00:51,  5.77s/it]Infernece:  62%|██████▏   | 13/21 [01:16<00:47,  5.92s/it]Infernece:  67%|██████▋   | 14/21 [01:23<00:41,  5.98s/it]Infernece:  71%|███████▏  | 15/21 [01:29<00:36,  6.14s/it]Infernece:  76%|███████▌  | 16/21 [01:35<00:31,  6.22s/it]Infernece:  81%|████████  | 17/21 [01:42<00:24,  6.24s/it]Infernece:  86%|████████▌ | 18/21 [01:48<00:18,  6.15s/it]Infernece:  90%|█████████ | 19/21 [01:52<00:11,  5.70s/it]Infernece:  95%|█████████▌| 20/21 [01:57<00:05,  5.34s/it]Infernece: 100%|██████████| 21/21 [01:59<00:00,  4.37s/it]Infernece: 100%|██████████| 21/21 [01:59<00:00,  5.69s/it]
08/15/2021 15:52:09 - INFO - __main__ - Starting inference ... Done
