08/16/2021 13:38:08 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/16/2021 13:38:08 - INFO - __main__ - dataset_size=10474, num_shards=6, local_shard_id=4
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/16/2021 13:38:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/16/2021 13:38:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/16/2021 13:38:09 - INFO - __main__ - Start tokenizing ... 1745 instances
08/16/2021 13:38:09 - INFO - __main__ - Printing 3 examples
08/16/2021 13:38:09 - INFO - __main__ - Context: Civil disobedients have chosen a variety of different illegal acts. Bedau writes, "There is a whole class of acts, undertaken in the name of civil disobedience, which, even if they were widely practiced, would in themselves constitute hardly more than a nuisance (e.g. trespassing at a nuclear-missile installation)...Such acts are often just a harassment and, at least to the bystander, somewhat inane...The remoteness of the connection between the disobedient act and the objectionable law lays such acts open to the charge of ineffectiveness and absurdity." Bedau also notes, though, that the very harmlessness of such entirely symbolic illegal protests toward public policy goals may serve a propaganda purpose. Some civil disobedients, such as the proprietors of illegal medical cannabis dispensaries and Voice in the Wilderness, which brought medicine to Iraq without the permission of the U.S. Government, directly achieve a desired social goal (such as the provision of medication to the sick) while openly breaking the law. Julia Butterfly Hill lived in Luna, a 180-foot (55 m)-tall, 600-year-old California Redwood tree for 738 days, successfully preventing it from being cut down. | Question: Civil disobedients have chosen many different kinds of what type of behaviors?
08/16/2021 13:38:09 - INFO - __main__ - ['illegal acts', 'illegal']
08/16/2021 13:38:09 - INFO - __main__ - Context: Civil disobedients have chosen a variety of different illegal acts. Bedau writes, "There is a whole class of acts, undertaken in the name of civil disobedience, which, even if they were widely practiced, would in themselves constitute hardly more than a nuisance (e.g. trespassing at a nuclear-missile installation)...Such acts are often just a harassment and, at least to the bystander, somewhat inane...The remoteness of the connection between the disobedient act and the objectionable law lays such acts open to the charge of ineffectiveness and absurdity." Bedau also notes, though, that the very harmlessness of such entirely symbolic illegal protests toward public policy goals may serve a propaganda purpose. Some civil disobedients, such as the proprietors of illegal medical cannabis dispensaries and Voice in the Wilderness, which brought medicine to Iraq without the permission of the U.S. Government, directly achieve a desired social goal (such as the provision of medication to the sick) while openly breaking the law. Julia Butterfly Hill lived in Luna, a 180-foot (55 m)-tall, 600-year-old California Redwood tree for 738 days, successfully preventing it from being cut down. | Question: Bedau notes that illegal protests towards public policy may serve as what purpose?
08/16/2021 13:38:09 - INFO - __main__ - ['just a harassment', 'propaganda']
08/16/2021 13:38:09 - INFO - __main__ - Context: Civil disobedients have chosen a variety of different illegal acts. Bedau writes, "There is a whole class of acts, undertaken in the name of civil disobedience, which, even if they were widely practiced, would in themselves constitute hardly more than a nuisance (e.g. trespassing at a nuclear-missile installation)...Such acts are often just a harassment and, at least to the bystander, somewhat inane...The remoteness of the connection between the disobedient act and the objectionable law lays such acts open to the charge of ineffectiveness and absurdity." Bedau also notes, though, that the very harmlessness of such entirely symbolic illegal protests toward public policy goals may serve a propaganda purpose. Some civil disobedients, such as the proprietors of illegal medical cannabis dispensaries and Voice in the Wilderness, which brought medicine to Iraq without the permission of the U.S. Government, directly achieve a desired social goal (such as the provision of medication to the sick) while openly breaking the law. Julia Butterfly Hill lived in Luna, a 180-foot (55 m)-tall, 600-year-old California Redwood tree for 738 days, successfully preventing it from being cut down. | Question: What group of civil disobedients brought medicine to Iraq without the permission of the government?
08/16/2021 13:38:09 - INFO - __main__ - ['Voice in the Wilderness']
08/16/2021 13:38:09 - INFO - __main__ - Tokenizing Input ...
08/16/2021 13:38:11 - INFO - __main__ - Tokenizing Input ... Done!
08/16/2021 13:38:11 - INFO - __main__ - Tokenizing Output ...
08/16/2021 13:38:12 - INFO - __main__ - Tokenizing Output ... Done!
08/16/2021 13:38:12 - INFO - __main__ - Loaded 1745 examples from dev data
08/16/2021 13:38:12 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/16/2021 13:38:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/16/2021 13:38:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/16/2021 13:38:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/16/2021 13:38:17 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/16/2021 13:38:21 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/28 [00:00<?, ?it/s]Infernece:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it]Infernece:   7%|▋         | 2/28 [00:09<02:05,  4.84s/it]Infernece:  11%|█         | 3/28 [00:14<02:00,  4.82s/it]Infernece:  14%|█▍        | 4/28 [00:18<01:54,  4.77s/it]Infernece:  18%|█▊        | 5/28 [00:24<01:52,  4.88s/it]Infernece:  21%|██▏       | 6/28 [00:29<01:49,  4.97s/it]Infernece:  25%|██▌       | 7/28 [00:34<01:45,  5.02s/it]Infernece:  29%|██▊       | 8/28 [00:38<01:37,  4.87s/it]Infernece:  32%|███▏      | 9/28 [00:44<01:37,  5.11s/it]Infernece:  36%|███▌      | 10/28 [00:49<01:30,  5.02s/it]Infernece:  39%|███▉      | 11/28 [00:53<01:23,  4.89s/it]Infernece:  43%|████▎     | 12/28 [00:59<01:19,  5.00s/it]Infernece:  46%|████▋     | 13/28 [01:03<01:11,  4.76s/it]Infernece:  50%|█████     | 14/28 [01:08<01:05,  4.70s/it]Infernece:  54%|█████▎    | 15/28 [01:12<01:01,  4.72s/it]Infernece:  57%|█████▋    | 16/28 [01:17<00:55,  4.65s/it]Infernece:  61%|██████    | 17/28 [01:22<00:52,  4.74s/it]Infernece:  64%|██████▍   | 18/28 [01:27<00:48,  4.81s/it]Infernece:  68%|██████▊   | 19/28 [01:32<00:44,  4.91s/it]Infernece:  71%|███████▏  | 20/28 [01:37<00:40,  5.10s/it]Infernece:  75%|███████▌  | 21/28 [01:43<00:36,  5.20s/it]Infernece:  79%|███████▊  | 22/28 [01:48<00:30,  5.17s/it]Infernece:  82%|████████▏ | 23/28 [01:52<00:24,  4.99s/it]Infernece:  86%|████████▌ | 24/28 [01:57<00:19,  4.94s/it]Infernece:  89%|████████▉ | 25/28 [02:02<00:14,  4.89s/it]Infernece:  93%|█████████▎| 26/28 [02:07<00:09,  4.91s/it]Infernece:  96%|█████████▋| 27/28 [02:12<00:04,  4.98s/it]Infernece: 100%|██████████| 28/28 [02:13<00:00,  3.84s/it]Infernece: 100%|██████████| 28/28 [02:13<00:00,  4.78s/it]
08/16/2021 13:40:35 - INFO - __main__ - Starting inference ... Done
