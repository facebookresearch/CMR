11/09/2021 19:01:46 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=3, output_dir='out/mrqa_squad_bart-base_1029_upstream_model/', predict_batch_size=64, predict_checkpoint='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', prefix='', quiet=False, seed=42, train_file='')
11/09/2021 19:01:46 - INFO - __main__ - dataset_size=6400, num_shards=8, local_shard_id=2
11/09/2021 19:01:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
11/09/2021 19:01:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
11/09/2021 19:01:47 - INFO - __main__ - Start tokenizing ... 800 instances
11/09/2021 19:01:47 - INFO - __main__ - Printing 3 examples
11/09/2021 19:01:47 - INFO - __main__ - Premise: The 2017–18 Puebla season is the 70th professional season of Mexico's top-flight football league. The season is split into two tournaments—the Torneo Apertura and the Torneo Clausura—each with identical formats and each contested by the same eighteen teams.The Club will also play Copa MX.Rafael García Torres was named the club head coach on June 5, 2017, taking over for sacked coach José Cardozo. </s> Hypothesis: The 2017–18 Puebla season does not have two tournaments that have different formats.
11/09/2021 19:01:47 - INFO - __main__ - ['entailment']
11/09/2021 19:01:47 - INFO - __main__ - Premise: Genevieve LaCaze (born 4 August 1989) is an Australian athletics competitor who specialises in the 3000 metre steeplechase. She held an athletics scholarship at the University of Florida. She was selected to represent Australia at the 2012 Summer Olympics in London and Athletics at the 2016 Summer Olympics in Rio de Janeiro. LaCaze is of French, Italian and Spanish descent. </s> Hypothesis: Genevieve LaCaze completed her medical degree from the University of Florida while on an athletics scholarship. 
11/09/2021 19:01:47 - INFO - __main__ - ['neutral']
11/09/2021 19:01:47 - INFO - __main__ - Premise: EMP Merchandising also known as EMP Merchandising Handelsgesellschaft mbH, Large Popmerchandising, and Sweden Rock Shop is a German-based music mail order and merchandising store. The company distributes a quarterly catalog to customers. In a 2003 report the Osnabrück Chamber of Commerce considered the company to be the largest mail order business for Heavy Metal and Hard Rock music in Germany. </s> Hypothesis: EMP Merchandising starts with an A.
11/09/2021 19:01:47 - INFO - __main__ - ['contradiction']
11/09/2021 19:01:47 - INFO - __main__ - Tokenizing Input ...
11/09/2021 19:01:48 - INFO - __main__ - Tokenizing Input ... Done!
11/09/2021 19:01:48 - INFO - __main__ - Tokenizing Output ...
11/09/2021 19:01:48 - INFO - __main__ - Tokenizing Output ... Done!
11/09/2021 19:01:48 - INFO - __main__ - Loaded 800 examples from dev data
11/09/2021 19:01:48 - INFO - __main__ - Loading checkpoint from out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt ....
11/09/2021 19:01:49 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
11/09/2021 19:01:49 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

11/09/2021 19:01:49 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
11/09/2021 19:01:56 - INFO - __main__ - Loading checkpoint from out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt .... Done!
11/09/2021 19:02:02 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/13 [00:00<?, ?it/s]Infernece:   8%|▊         | 1/13 [00:03<00:43,  3.65s/it]Infernece:  15%|█▌        | 2/13 [00:07<00:40,  3.70s/it]Infernece:  23%|██▎       | 3/13 [00:12<00:40,  4.06s/it]Infernece:  31%|███       | 4/13 [00:16<00:35,  3.96s/it]Infernece:  38%|███▊      | 5/13 [00:19<00:31,  3.94s/it]Infernece:  46%|████▌     | 6/13 [00:24<00:29,  4.23s/it]Infernece:  54%|█████▍    | 7/13 [00:28<00:23,  3.97s/it]Infernece:  62%|██████▏   | 8/13 [00:30<00:17,  3.52s/it]Infernece:  69%|██████▉   | 9/13 [00:33<00:12,  3.17s/it]Infernece:  77%|███████▋  | 10/13 [00:35<00:08,  2.93s/it]Infernece:  85%|████████▍ | 11/13 [00:38<00:05,  2.89s/it]Infernece:  92%|█████████▏| 12/13 [00:40<00:02,  2.58s/it]Infernece: 100%|██████████| 13/13 [00:41<00:00,  2.15s/it]Infernece: 100%|██████████| 13/13 [00:41<00:00,  3.17s/it]
11/09/2021 19:02:43 - INFO - __main__ - Starting inference ... Done
