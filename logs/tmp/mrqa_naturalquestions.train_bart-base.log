06/17/2021 16:30:27 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=True, checkpoint=None, dataset='mrqa_naturalquestions', debug=False, dev_file='data/mrqa_naturalquestions/mrqa_naturalquestions_dev.mini.jsonl', do_lowercase=False, do_predict=False, do_train=True, eval_period=500, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=3, num_train_epochs=10.0, output_dir='out/mrqa_naturalquestions_bart-_0617', predict_batch_size=64, predict_checkpoint='best-model.pt', prefix='', quiet=False, seed=42, test_file='data/mrqa_naturalquestions/mrqa_naturalquestions_dev.jsonl', total_steps=-1, train_batch_size=32, train_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', wait_step=10, warmup_steps=300, weight_decay=0.01)
06/17/2021 16:30:27 - INFO - __main__ - out/mrqa_naturalquestions_bart-_0617
06/17/2021 16:30:27 - INFO - __main__ - Using 4 gpus
06/17/2021 16:30:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
06/17/2021 16:30:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
06/17/2021 16:30:29 - INFO - __main__ - preprocessed_path=data/mrqa_naturalquestions/mrqa_naturalquestions_train-preproBartTokenized.json
06/17/2021 16:30:29 - INFO - __main__ - Start tokenizing ... 88251 instances
06/17/2021 16:30:29 - INFO - __main__ - Printing 3 examples
06/17/2021 16:30:29 - INFO - __main__ - Context: CorelDraw ( styled CorelDRAW ) is a vector graphics editor developed and marketed by Corel Corporation . It is also the name of Corel 's Graphics Suite , which bundles CorelDraw with bitmap - image editor Corel Photo - Paint as well as other graphics - related programs ( see below ) . The latest version is marketed as Graphics Suite 2017 ( equivalent to version 19 ) , and was released in April 2017 . CorelDraw is designed to edit two - dimensional images such as logos and posters . | Question: which is the latest version of corel draw ?
06/17/2021 16:30:29 - INFO - __main__ - ['April 2017']
06/17/2021 16:30:29 - INFO - __main__ - Context: `` Fore ! '' , originally an Australian interjection , is used to warn anyone standing or moving in the flight of a golf ball . The mention of the term in an 1881 Australian Golf Museum indicates that the term was in use at least as early as that period . | Question: what does the word fore mean in golf ?
06/17/2021 16:30:29 - INFO - __main__ - ['to warn anyone standing or moving in the flight of a golf ball']
06/17/2021 16:30:29 - INFO - __main__ - Context: Home Town is an American television series starring husband and wife team Ben and Erin Napier that premiered on March 21 , 2017 on HGTV . The married couple restores Southern homes in Laurel , Mississippi . | Question: where is the home town show on hgtv filmed ?
06/17/2021 16:30:29 - INFO - __main__ - ['Laurel , Mississippi']
06/17/2021 16:30:29 - INFO - __main__ - Tokenizing Input ...
06/17/2021 16:31:43 - INFO - __main__ - Tokenizing Input ... Done!
06/17/2021 16:31:43 - INFO - __main__ - Tokenizing Output ...
06/17/2021 16:31:57 - INFO - __main__ - Tokenizing Output ... Done!
06/17/2021 16:31:57 - INFO - __main__ - Save preprocessed data ...
06/17/2021 16:34:22 - INFO - __main__ - Save preprocessed data ... Done!
06/17/2021 16:34:25 - INFO - __main__ - Loaded 88251 examples from train data
06/17/2021 16:34:26 - INFO - __main__ - preprocessed_path=data/mrqa_naturalquestions/mrqa_naturalquestions_dev.mini-preproBartTokenized.json
06/17/2021 16:34:26 - INFO - __main__ - Start tokenizing ... 1000 instances
06/17/2021 16:34:26 - INFO - __main__ - Printing 3 examples
06/17/2021 16:34:26 - INFO - __main__ - Context: Frankie is finally willing to arrange a title fight . He secures Maggie a $1 million match in Las Vegas , Nevada against the WBA women 's welterweight champion , Billie `` The Blue Bear '' , a German ex-prostitute who has a reputation as a dirty fighter . Overcoming a shaky start , Maggie begins to dominate the fight , but after a round has ended , Billie knocks her out with an illegal sucker punch from behind after the bell has sounded to indicate the end of the round . Before Frankie can pull the corner stool out of the way which was inappropriately placed on its side by Frankie 's assistant , Maggie lands hard on it , breaking her neck and leaving her a ventilator - dependent quadriplegic . | Question: who won the last fight in million dollar baby ?
06/17/2021 16:34:26 - INFO - __main__ - ["Billie `` The Blue Bear ''"]
06/17/2021 16:34:26 - INFO - __main__ - Context: The Eagles and the Patriots met again in Super Bowl LII , following the 2017 season , with the Eagles taking their revenge 41 -- 33 . | Question: when did the philadelphia eagles play in the super bowl last ?
06/17/2021 16:34:26 - INFO - __main__ - ['Super Bowl LII']
06/17/2021 16:34:26 - INFO - __main__ - Context: The pulmonary circulation is the portion of the circulatory system which carries deoxygenated blood away from the right ventricle of the heart , to the lungs , and returns oxygenated blood to the left atrium and ventricle of the heart . The term pulmonary circulation is readily paired and contrasted with the systemic circulation . The vessels of the pulmonary circulation are the pulmonary arteries and the pulmonary veins . | Question: how oxygenated blood returns to the heart from the lungs ?
06/17/2021 16:34:26 - INFO - __main__ - ['pulmonary circulation']
06/17/2021 16:34:26 - INFO - __main__ - Tokenizing Input ...
06/17/2021 16:34:27 - INFO - __main__ - Tokenizing Input ... Done!
06/17/2021 16:34:27 - INFO - __main__ - Tokenizing Output ...
06/17/2021 16:34:27 - INFO - __main__ - Tokenizing Output ... Done!
06/17/2021 16:34:27 - INFO - __main__ - Save preprocessed data ...
06/17/2021 16:34:29 - INFO - __main__ - Save preprocessed data ... Done!
06/17/2021 16:34:29 - INFO - __main__ - Loaded 1000 examples from dev data
06/17/2021 16:34:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
06/17/2021 16:34:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}06/17/2021 16:34:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
06/17/2021 16:34:42 - INFO - __main__ - args.total_steps = 27580.0
06/17/2021 16:34:42 - INFO - __main__ - Starting training!/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  
06/17/2021 16:37:43 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 16:39:04 - INFO - __main__ - Starting inference ... Done
06/17/2021 16:39:04 - INFO - __main__ - Step 500 Train loss 185.85 EM|QA-F1 {'EM': 0.399, 'QA-F1': 0.5427395594815752} on epoch=0
06/17/2021 16:39:04 - INFO - __main__ - New best perfromance EM|QA-F1: None -> {'EM': 0.399, 'QA-F1': 0.5427395594815752} on epoch=0, global_step=500
06/17/2021 16:39:04 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 16:41:53 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 16:43:25 - INFO - __main__ - Starting inference ... Done
06/17/2021 16:43:26 - INFO - __main__ - Step 1000 Train loss 136.58 EM|QA-F1 {'EM': 0.44, 'QA-F1': 0.6040064209356728} on epoch=0
06/17/2021 16:43:26 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.399, 'QA-F1': 0.5427395594815752} -> {'EM': 0.44, 'QA-F1': 0.6040064209356728} on epoch=0, global_step=1000
06/17/2021 16:43:26 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
 
  
06/17/2021 16:46:18 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 16:47:38 - INFO - __main__ - Starting inference ... Done
06/17/2021 16:47:38 - INFO - __main__ - Step 1500 Train loss 130.92 EM|QA-F1 {'EM': 0.479, 'QA-F1': 0.6353472471006109} on epoch=0
06/17/2021 16:47:38 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.44, 'QA-F1': 0.6040064209356728} -> {'EM': 0.479, 'QA-F1': 0.6353472471006109} on epoch=0, global_step=1500
06/17/2021 16:47:38 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 16:50:29 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 16:51:51 - INFO - __main__ - Starting inference ... Done
06/17/2021 16:51:51 - INFO - __main__ - Step 2000 Train loss 127.54 EM|QA-F1 {'EM': 0.476, 'QA-F1': 0.6446308189313142} on epoch=0
06/17/2021 16:51:52 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.479, 'QA-F1': 0.6353472471006109} -> {'EM': 0.476, 'QA-F1': 0.6446308189313142} on epoch=0, global_step=2000
06/17/2021 16:51:52 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 16:54:39 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 16:55:59 - INFO - __main__ - Starting inference ... Done
06/17/2021 16:56:00 - INFO - __main__ - Step 2500 Train loss 127.43 EM|QA-F1 {'EM': 0.496, 'QA-F1': 0.6587095233951826} on epoch=0
06/17/2021 16:56:00 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.476, 'QA-F1': 0.6446308189313142} -> {'EM': 0.496, 'QA-F1': 0.6587095233951826} on epoch=0, global_step=2500
06/17/2021 16:56:00 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt  06/17/2021 16:58:50 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:00:09 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:00:10 - INFO - __main__ - Step 3000 Train loss 124.50 EM|QA-F1 {'EM': 0.501, 'QA-F1': 0.6677006048697827} on epoch=1
06/17/2021 17:00:10 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.496, 'QA-F1': 0.6587095233951826} -> {'EM': 0.501, 'QA-F1': 0.6677006048697827} on epoch=1, global_step=3000
06/17/2021 17:00:10 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 17:03:01 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:04:20 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:04:20 - INFO - __main__ - Step 3500 Train loss 123.66 EM|QA-F1 {'EM': 0.503, 'QA-F1': 0.6608265259351236} on epoch=1
06/17/2021 17:04:20 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.501, 'QA-F1': 0.6677006048697827} -> {'EM': 0.503, 'QA-F1': 0.6608265259351236} on epoch=1, global_step=3500
06/17/2021 17:04:20 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
 
  
06/17/2021 17:07:10 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:08:30 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:08:30 - INFO - __main__ - Step 4000 Train loss 121.63 EM|QA-F1 {'EM': 0.51, 'QA-F1': 0.6742228445153096} on epoch=1
06/17/2021 17:08:31 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.503, 'QA-F1': 0.6608265259351236} -> {'EM': 0.51, 'QA-F1': 0.6742228445153096} on epoch=1, global_step=4000
06/17/2021 17:08:31 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
   06/17/2021 17:11:22 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:12:46 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:12:46 - INFO - __main__ - Step 4500 Train loss 123.03 EM|QA-F1 {'EM': 0.523, 'QA-F1': 0.6855379579204021} on epoch=1
06/17/2021 17:12:47 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.51, 'QA-F1': 0.6742228445153096} -> {'EM': 0.523, 'QA-F1': 0.6855379579204021} on epoch=1, global_step=4500
06/17/2021 17:12:47 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt  
06/17/2021 17:15:37 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:16:58 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:16:58 - INFO - __main__ - Step 5000 Train loss 121.88 EM|QA-F1 {'EM': 0.512, 'QA-F1': 0.6815651344313308} on epoch=1  
06/17/2021 17:19:47 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:21:07 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:21:07 - INFO - __main__ - Step 5500 Train loss 120.70 EM|QA-F1 {'EM': 0.518, 'QA-F1': 0.6844174010292053} on epoch=106/17/2021 17:23:57 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:25:28 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:25:28 - INFO - __main__ - Step 6000 Train loss 120.62 EM|QA-F1 {'EM': 0.529, 'QA-F1': 0.6925548638607958} on epoch=2
06/17/2021 17:25:28 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.523, 'QA-F1': 0.6855379579204021} -> {'EM': 0.529, 'QA-F1': 0.6925548638607958} on epoch=2, global_step=6000
06/17/2021 17:25:28 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 17:28:20 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:29:51 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:29:51 - INFO - __main__ - Step 6500 Train loss 119.13 EM|QA-F1 {'EM': 0.53, 'QA-F1': 0.6909654726005704} on epoch=2
06/17/2021 17:29:51 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.529, 'QA-F1': 0.6925548638607958} -> {'EM': 0.53, 'QA-F1': 0.6909654726005704} on epoch=2, global_step=6500
06/17/2021 17:29:51 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
 
  
06/17/2021 17:32:42 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:33:59 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:33:59 - INFO - __main__ - Step 7000 Train loss 119.28 EM|QA-F1 {'EM': 0.532, 'QA-F1': 0.6924931624059304} on epoch=2
06/17/2021 17:34:00 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.53, 'QA-F1': 0.6909654726005704} -> {'EM': 0.532, 'QA-F1': 0.6924931624059304} on epoch=2, global_step=7000
06/17/2021 17:34:00 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 17:36:49 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:38:13 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:38:13 - INFO - __main__ - Step 7500 Train loss 119.08 EM|QA-F1 {'EM': 0.529, 'QA-F1': 0.6941785098412836} on epoch=2
06/17/2021 17:38:13 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.532, 'QA-F1': 0.6924931624059304} -> {'EM': 0.529, 'QA-F1': 0.6941785098412836} on epoch=2, global_step=7500
06/17/2021 17:38:13 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 17:41:05 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:42:25 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:42:25 - INFO - __main__ - Step 8000 Train loss 118.31 EM|QA-F1 {'EM': 0.522, 'QA-F1': 0.6922304274914615} on epoch=2  06/17/2021 17:45:14 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:46:33 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:46:33 - INFO - __main__ - Step 8500 Train loss 117.43 EM|QA-F1 {'EM': 0.539, 'QA-F1': 0.7111543500409974} on epoch=3
06/17/2021 17:46:33 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.529, 'QA-F1': 0.6941785098412836} -> {'EM': 0.539, 'QA-F1': 0.7111543500409974} on epoch=3, global_step=8500
06/17/2021 17:46:33 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 17:49:24 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:50:51 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:50:51 - INFO - __main__ - Step 9000 Train loss 116.02 EM|QA-F1 {'EM': 0.523, 'QA-F1': 0.692620743815393} on epoch=3 
  06/17/2021 17:53:40 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:55:03 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:55:03 - INFO - __main__ - Step 9500 Train loss 118.25 EM|QA-F1 {'EM': 0.528, 'QA-F1': 0.7044935246738774} on epoch=3
 
  
06/17/2021 17:57:52 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 17:59:22 - INFO - __main__ - Starting inference ... Done
06/17/2021 17:59:22 - INFO - __main__ - Step 10000 Train loss 117.21 EM|QA-F1 {'EM': 0.528, 'QA-F1': 0.7013291533098384} on epoch=3
  06/17/2021 18:02:11 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:03:31 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:03:31 - INFO - __main__ - Step 10500 Train loss 115.46 EM|QA-F1 {'EM': 0.55, 'QA-F1': 0.7095549080050002} on epoch=3
06/17/2021 18:03:32 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.539, 'QA-F1': 0.7111543500409974} -> {'EM': 0.55, 'QA-F1': 0.7095549080050002} on epoch=3, global_step=10500
06/17/2021 18:03:32 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt  
06/17/2021 18:06:24 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:07:44 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:07:44 - INFO - __main__ - Step 11000 Train loss 117.63 EM|QA-F1 {'EM': 0.547, 'QA-F1': 0.71673796312434} on epoch=3
06/17/2021 18:07:44 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.55, 'QA-F1': 0.7095549080050002} -> {'EM': 0.547, 'QA-F1': 0.71673796312434} on epoch=3, global_step=11000
06/17/2021 18:07:44 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt06/17/2021 18:10:36 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:11:55 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:11:55 - INFO - __main__ - Step 11500 Train loss 115.69 EM|QA-F1 {'EM': 0.552, 'QA-F1': 0.7152492893920194} on epoch=4
06/17/2021 18:11:56 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.547, 'QA-F1': 0.71673796312434} -> {'EM': 0.552, 'QA-F1': 0.7152492893920194} on epoch=4, global_step=11500
06/17/2021 18:11:56 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 18:14:47 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:16:06 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:16:06 - INFO - __main__ - Step 12000 Train loss 115.28 EM|QA-F1 {'EM': 0.555, 'QA-F1': 0.7213320657892445} on epoch=4
06/17/2021 18:16:06 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.552, 'QA-F1': 0.7152492893920194} -> {'EM': 0.555, 'QA-F1': 0.7213320657892445} on epoch=4, global_step=12000
06/17/2021 18:16:06 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
 
  
06/17/2021 18:18:57 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:20:16 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:20:16 - INFO - __main__ - Step 12500 Train loss 115.26 EM|QA-F1 {'EM': 0.558, 'QA-F1': 0.7168809420241211} on epoch=4
06/17/2021 18:20:16 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.555, 'QA-F1': 0.7213320657892445} -> {'EM': 0.558, 'QA-F1': 0.7168809420241211} on epoch=4, global_step=12500
06/17/2021 18:20:16 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 18:23:09 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:24:28 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:24:28 - INFO - __main__ - Step 13000 Train loss 116.03 EM|QA-F1 {'EM': 0.564, 'QA-F1': 0.7232180074914532} on epoch=4
06/17/2021 18:24:28 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.558, 'QA-F1': 0.7168809420241211} -> {'EM': 0.564, 'QA-F1': 0.7232180074914532} on epoch=4, global_step=13000
06/17/2021 18:24:28 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 18:27:21 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:28:44 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:28:45 - INFO - __main__ - Step 13500 Train loss 115.26 EM|QA-F1 {'EM': 0.556, 'QA-F1': 0.7209863537332706} on epoch=4
  
06/17/2021 18:31:32 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:32:52 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:32:52 - INFO - __main__ - Step 14000 Train loss 114.64 EM|QA-F1 {'EM': 0.55, 'QA-F1': 0.7156935396631884} on epoch=5 
  06/17/2021 18:35:40 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:37:00 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:37:00 - INFO - __main__ - Step 14500 Train loss 114.79 EM|QA-F1 {'EM': 0.543, 'QA-F1': 0.7087101106116188} on epoch=5
 
  
06/17/2021 18:39:50 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:41:09 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:41:09 - INFO - __main__ - Step 15000 Train loss 114.76 EM|QA-F1 {'EM': 0.56, 'QA-F1': 0.7236812389440039} on epoch=5
06/17/2021 18:41:09 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.564, 'QA-F1': 0.7232180074914532} -> {'EM': 0.56, 'QA-F1': 0.7236812389440039} on epoch=5, global_step=15000
06/17/2021 18:41:09 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
   06/17/2021 18:44:00 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:45:19 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:45:19 - INFO - __main__ - Step 15500 Train loss 113.54 EM|QA-F1 {'EM': 0.56, 'QA-F1': 0.7215252313545503} on epoch=5  
06/17/2021 18:48:09 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:49:28 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:49:28 - INFO - __main__ - Step 16000 Train loss 113.58 EM|QA-F1 {'EM': 0.564, 'QA-F1': 0.7236132474826068} on epoch=5
06/17/2021 18:49:29 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.56, 'QA-F1': 0.7236812389440039} -> {'EM': 0.564, 'QA-F1': 0.7236132474826068} on epoch=5, global_step=16000
06/17/2021 18:49:29 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt  
06/17/2021 18:52:20 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:53:38 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:53:38 - INFO - __main__ - Step 16500 Train loss 115.37 EM|QA-F1 {'EM': 0.567, 'QA-F1': 0.7275832359443928} on epoch=5
06/17/2021 18:53:38 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.564, 'QA-F1': 0.7236132474826068} -> {'EM': 0.567, 'QA-F1': 0.7275832359443928} on epoch=5, global_step=16500
06/17/2021 18:53:38 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt06/17/2021 18:56:30 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 18:57:49 - INFO - __main__ - Starting inference ... Done
06/17/2021 18:57:49 - INFO - __main__ - Step 17000 Train loss 113.97 EM|QA-F1 {'EM': 0.56, 'QA-F1': 0.725548026670673} on epoch=6 
  06/17/2021 19:00:39 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:01:58 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:01:58 - INFO - __main__ - Step 17500 Train loss 114.37 EM|QA-F1 {'EM': 0.572, 'QA-F1': 0.7351538024460865} on epoch=6
06/17/2021 19:01:59 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.567, 'QA-F1': 0.7275832359443928} -> {'EM': 0.572, 'QA-F1': 0.7351538024460865} on epoch=6, global_step=17500
06/17/2021 19:01:59 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
 
  
06/17/2021 19:04:49 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:06:09 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:06:09 - INFO - __main__ - Step 18000 Train loss 113.15 EM|QA-F1 {'EM': 0.557, 'QA-F1': 0.7268563023800744} on epoch=6
  06/17/2021 19:08:58 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:10:18 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:10:18 - INFO - __main__ - Step 18500 Train loss 113.22 EM|QA-F1 {'EM': 0.572, 'QA-F1': 0.7292290432129793} on epoch=6
  06/17/2021 19:13:07 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:14:27 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:14:27 - INFO - __main__ - Step 19000 Train loss 112.53 EM|QA-F1 {'EM': 0.576, 'QA-F1': 0.734795928661739} on epoch=6
06/17/2021 19:14:27 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.572, 'QA-F1': 0.7351538024460865} -> {'EM': 0.576, 'QA-F1': 0.734795928661739} on epoch=6, global_step=19000
06/17/2021 19:14:27 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  
06/17/2021 19:17:18 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:18:38 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:18:38 - INFO - __main__ - Step 19500 Train loss 113.81 EM|QA-F1 {'EM': 0.567, 'QA-F1': 0.731225179203326} on epoch=7 
  06/17/2021 19:21:26 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:22:45 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:22:45 - INFO - __main__ - Step 20000 Train loss 112.46 EM|QA-F1 {'EM': 0.577, 'QA-F1': 0.737425169111395} on epoch=7
06/17/2021 19:22:46 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.576, 'QA-F1': 0.734795928661739} -> {'EM': 0.577, 'QA-F1': 0.737425169111395} on epoch=7, global_step=20000
06/17/2021 19:22:46 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt   
06/17/2021 19:25:39 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:26:57 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:26:57 - INFO - __main__ - Step 20500 Train loss 113.98 EM|QA-F1 {'EM': 0.573, 'QA-F1': 0.7331217163503139} on epoch=7
 
  
06/17/2021 19:29:48 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:31:18 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:31:18 - INFO - __main__ - Step 21000 Train loss 113.67 EM|QA-F1 {'EM': 0.58, 'QA-F1': 0.7369986794976635} on epoch=7
06/17/2021 19:31:18 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.577, 'QA-F1': 0.737425169111395} -> {'EM': 0.58, 'QA-F1': 0.7369986794976635} on epoch=7, global_step=21000
06/17/2021 19:31:18 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 19:34:09 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:35:29 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:35:29 - INFO - __main__ - Step 21500 Train loss 112.32 EM|QA-F1 {'EM': 0.578, 'QA-F1': 0.7353862839800879} on epoch=7  
06/17/2021 19:38:20 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:39:40 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:39:40 - INFO - __main__ - Step 22000 Train loss 112.20 EM|QA-F1 {'EM': 0.573, 'QA-F1': 0.731877138477801} on epoch=706/17/2021 19:42:30 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:43:49 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:43:49 - INFO - __main__ - Step 22500 Train loss 112.87 EM|QA-F1 {'EM': 0.573, 'QA-F1': 0.7333515330627192} on epoch=8 
  06/17/2021 19:46:39 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:47:57 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:47:58 - INFO - __main__ - Step 23000 Train loss 112.65 EM|QA-F1 {'EM': 0.575, 'QA-F1': 0.7351336392227142} on epoch=8
 
  
06/17/2021 19:50:46 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:52:04 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:52:04 - INFO - __main__ - Step 23500 Train loss 111.64 EM|QA-F1 {'EM': 0.578, 'QA-F1': 0.7374708725530216} on epoch=8
06/17/2021 19:52:05 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.58, 'QA-F1': 0.7369986794976635} -> {'EM': 0.578, 'QA-F1': 0.7374708725530216} on epoch=8, global_step=23500
06/17/2021 19:52:05 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt
  06/17/2021 19:54:57 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 19:56:23 - INFO - __main__ - Starting inference ... Done
06/17/2021 19:56:23 - INFO - __main__ - Step 24000 Train loss 112.80 EM|QA-F1 {'EM': 0.578, 'QA-F1': 0.7379865379963959} on epoch=8
06/17/2021 19:56:24 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.578, 'QA-F1': 0.7374708725530216} -> {'EM': 0.578, 'QA-F1': 0.7379865379963959} on epoch=8, global_step=24000
06/17/2021 19:56:24 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt  
06/17/2021 19:59:17 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:00:39 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:00:39 - INFO - __main__ - Step 24500 Train loss 112.94 EM|QA-F1 {'EM': 0.573, 'QA-F1': 0.7338929194169962} on epoch=8
  
06/17/2021 20:03:28 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:04:48 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:04:48 - INFO - __main__ - Step 25000 Train loss 112.48 EM|QA-F1 {'EM': 0.583, 'QA-F1': 0.7401811035910221} on epoch=9
06/17/2021 20:04:48 - INFO - __main__ - New best perfromance EM|QA-F1: {'EM': 0.578, 'QA-F1': 0.7379865379963959} -> {'EM': 0.583, 'QA-F1': 0.7401811035910221} on epoch=9, global_step=25000
06/17/2021 20:04:48 - INFO - __main__ - Saving the new best model to out/mrqa_naturalquestions_bart-_0617/best-model.pt 
  06/17/2021 20:07:39 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:08:57 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:08:57 - INFO - __main__ - Step 25500 Train loss 112.34 EM|QA-F1 {'EM': 0.582, 'QA-F1': 0.7389737731412375} on epoch=9
 
  
06/17/2021 20:11:48 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:13:06 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:13:07 - INFO - __main__ - Step 26000 Train loss 112.07 EM|QA-F1 {'EM': 0.574, 'QA-F1': 0.7339598233711518} on epoch=9
   06/17/2021 20:15:58 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:17:17 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:17:18 - INFO - __main__ - Step 26500 Train loss 111.79 EM|QA-F1 {'EM': 0.58, 'QA-F1': 0.7359916590735758} on epoch=9  
06/17/2021 20:20:07 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:21:26 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:21:26 - INFO - __main__ - Step 27000 Train loss 112.03 EM|QA-F1 {'EM': 0.582, 'QA-F1': 0.7371044114571701} on epoch=9  
06/17/2021 20:24:15 - INFO - __main__ - Starting inference ...
Infernece on Dev:   0%|          | 0/16 [00:00<?, ?it/s]06/17/2021 20:25:33 - INFO - __main__ - Starting inference ... Done
06/17/2021 20:25:33 - INFO - __main__ - Step 27500 Train loss 111.51 EM|QA-F1 {'EM': 0.578, 'QA-F1': 0.7349553338080923} on epoch=9
