08/15/2021 15:48:16 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/15/2021 15:48:16 - INFO - __main__ - dataset_size=5901, num_shards=8, local_shard_id=2
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/15/2021 15:48:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/15/2021 15:48:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/15/2021 15:48:17 - INFO - __main__ - Start tokenizing ... 738 instances
08/15/2021 15:48:17 - INFO - __main__ - Printing 3 examples
08/15/2021 15:48:17 - INFO - __main__ - Context: Hamburg Mountains (New Jersey)  The Hamburg Mountains are a range of the New York-New Jersey Highlands region of the Appalachian Mountains.  The summit, reaching a height of 1473 ft , lies within Sussex County, New Jersey.   Appalachian Mountains  The Appalachian Mountains ( , French: "les Appalaches" ), often called the Appalachians, are a system of mountains in eastern North America.  The Appalachians first formed roughly 480 million years ago during the Ordovician Period.  It once reached elevations similar to those of the Alps and the Rocky Mountains before naturally occurring erosion.  The Appalachian chain is a barrier to east-west travel, as it forms a series of alternating ridgelines and valleys oriented in opposition to most roads running east or west. | Question: Which system of mountains in eastern North America is Hamburg Mountains a range region of ?
08/15/2021 15:48:17 - INFO - __main__ - ['The Appalachian Mountains']
08/15/2021 15:48:17 - INFO - __main__ - Context: Time Keeps On Slippin'  "Time Keeps On Slippin" is the fourteenth episode in season three of the animated television series "Futurama".  It originally aired on the Fox network in the United States on May 6, 2001.  The title is from a lyric in "Fly Like an Eagle" by Steve Miller Band.  Basketball and time-travel play a prominent role in this episode.   Futurama  Futurama is an American animated science fiction comedy series created by Matt Groening for the Fox Broadcasting Company.  The series follows the adventures of a late-20th-century New York City pizza delivery boy, Philip J. Fry, who, after being unwittingly cryogenically frozen for one thousand years, finds employment at Planet Express, an interplanetary delivery company in the retro-futuristic 31st century.  The series was envisioned by Groening in the mid-1990s while working on "The Simpsons"; he later brought David X. Cohen aboard to develop storylines and characters to pitch the show to Fox. | Question: Who is the creator of the animated television series that its fourteenth episode of season three's title is "Time Keeps on Slippin"?
08/15/2021 15:48:17 - INFO - __main__ - ['Matt Groening']
08/15/2021 15:48:17 - INFO - __main__ - Context: Octopussy  Octopussy (1983) is the thirteenth entry in the Eon Productions "James Bond" film series, and the sixth to star Roger Moore as the fictional MI6 agent James Bond.   James Bond filmography  Commander James Bond RN—code number 007—is a fictional character created by the British journalist and novelist Ian Fleming in 1952.  The character appeared in a series of twelve novels and two short story collections written by Fleming and a number of continuation novels and spin-off works after Fleming's death in 1964.  There have been twenty-six films in total, produced between 1962 and 2015. | Question: Which fictional MI6 agent is a fictional character created by the British journalist and novelist Ian Fleming in 1952?
08/15/2021 15:48:17 - INFO - __main__ - ['Commander James Bond RN']
08/15/2021 15:48:17 - INFO - __main__ - Tokenizing Input ...
08/15/2021 15:48:20 - INFO - __main__ - Tokenizing Input ... Done!
08/15/2021 15:48:20 - INFO - __main__ - Tokenizing Output ...
08/15/2021 15:48:20 - INFO - __main__ - Tokenizing Output ... Done!
08/15/2021 15:48:20 - INFO - __main__ - Loaded 738 examples from dev data
08/15/2021 15:48:20 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/15/2021 15:48:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/15/2021 15:48:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/15/2021 15:48:21 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/15/2021 15:48:28 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/15/2021 15:48:34 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/12 [00:00<?, ?it/s]Infernece:   8%|▊         | 1/12 [00:06<01:16,  6.99s/it]Infernece:  17%|█▋        | 2/12 [00:13<01:08,  6.85s/it]Infernece:  25%|██▌       | 3/12 [00:20<01:02,  6.93s/it]Infernece:  33%|███▎      | 4/12 [00:28<00:57,  7.18s/it]Infernece:  42%|████▏     | 5/12 [00:35<00:50,  7.14s/it]Infernece:  50%|█████     | 6/12 [00:42<00:42,  7.15s/it]Infernece:  58%|█████▊    | 7/12 [00:50<00:36,  7.27s/it]Infernece:  67%|██████▋   | 8/12 [00:57<00:29,  7.27s/it]Infernece:  75%|███████▌  | 9/12 [01:04<00:21,  7.19s/it]Infernece:  83%|████████▎ | 10/12 [01:09<00:13,  6.51s/it]Infernece:  92%|█████████▏| 11/12 [01:14<00:06,  6.24s/it]Infernece: 100%|██████████| 12/12 [01:17<00:00,  5.00s/it]Infernece: 100%|██████████| 12/12 [01:17<00:00,  6.43s/it]
08/15/2021 15:49:51 - INFO - __main__ - Starting inference ... Done
