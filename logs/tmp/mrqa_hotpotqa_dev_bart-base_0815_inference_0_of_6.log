08/16/2021 13:36:17 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
08/16/2021 13:36:18 - INFO - __main__ - dataset_size=5901, num_shards=6, local_shard_id=0
/private/home/yuchenlin/.conda/envs/bartqa/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
08/16/2021 13:36:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
08/16/2021 13:36:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/16/2021 13:36:18 - INFO - __main__ - Start tokenizing ... 984 instances
08/16/2021 13:36:18 - INFO - __main__ - Printing 3 examples
08/16/2021 13:36:18 - INFO - __main__ - Context: Kiss and Tell (1945 film)  Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.  In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.  The parents' bickering about which girl is the worse influence causes more problems than it solves.   Shirley Temple  Shirley Temple Black (April 23, 1928 – February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood's number one box-office draw as a child actress from 1935 to 1938.  As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.   Shirley Temple  Shirley Temple Black (April 23, 1928 – February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood's number one box-office draw as a child actress from 1935 to 1938.  As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States. | Question: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?
08/16/2021 13:36:18 - INFO - __main__ - ['Chief of Protocol']
08/16/2021 13:36:18 - INFO - __main__ - Context: Big Stone Gap (film)  Big Stone Gap is a 2014 American drama romantic comedy film written and directed by Adriana Trigiani and produced by Donna Gigliotti for Altar Identity Studios, a subsidiary of Media Society.  Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s.  The film had its world premiere at the Virginia Film Festival on November 6, 2014.   Adriana Trigiani  Adriana Trigiani is an Italian American best-selling author of sixteen books, television writer, film director, and entrepreneur based in Greenwich Village, New York City.  Trigiani has published a novel a year since 2000. | Question: The director of the romantic comedy "Big Stone Gap" is based in what New York city?
08/16/2021 13:36:18 - INFO - __main__ - ['Greenwich Village, New York City']
08/16/2021 13:36:18 - INFO - __main__ - Context: 2014 S/S  2014 S/S is the debut album of South Korean group WINNER.  It was released on August 12, 2014 by the group's record label, YG Entertainment.  The members were credited for writing the lyrics and composing the majority of the album's songs.   Winner (band)  Winner (Hangul: 위너), often stylized as WINNER, is a South Korean boy group formed in 2013 by YG Entertainment and debuted in 2014.  It currently consists of four members, Jinwoo, Seunghoon, Mino and Seungyoon.  Originally a five-piece group with Taehyun, who later departed from the group in November 2016. | Question: 2014 S/S is the debut album of a South Korean boy group that was formed by who?
08/16/2021 13:36:18 - INFO - __main__ - ['YG Entertainment']
08/16/2021 13:36:18 - INFO - __main__ - Tokenizing Input ...
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Input ... Done!
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Output ...
08/16/2021 13:36:21 - INFO - __main__ - Tokenizing Output ... Done!
08/16/2021 13:36:21 - INFO - __main__ - Loaded 984 examples from dev data
08/16/2021 13:36:21 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
08/16/2021 13:36:22 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
08/16/2021 13:36:22 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

08/16/2021 13:36:22 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
08/16/2021 13:36:27 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
08/16/2021 13:36:31 - INFO - __main__ - Starting inference ...
Infernece:   0%|          | 0/16 [00:00<?, ?it/s]Infernece:   6%|▋         | 1/16 [00:06<01:41,  6.75s/it]Infernece:  12%|█▎        | 2/16 [00:12<01:29,  6.40s/it]Infernece:  19%|█▉        | 3/16 [00:18<01:21,  6.25s/it]Infernece:  25%|██▌       | 4/16 [00:22<01:08,  5.70s/it]Infernece:  31%|███▏      | 5/16 [00:27<01:01,  5.59s/it]Infernece:  38%|███▊      | 6/16 [00:34<00:58,  5.82s/it]Infernece:  44%|████▍     | 7/16 [00:39<00:50,  5.66s/it]Infernece:  50%|█████     | 8/16 [00:44<00:42,  5.31s/it]Infernece:  56%|█████▋    | 9/16 [00:49<00:38,  5.46s/it]Infernece:  62%|██████▎   | 10/16 [00:56<00:34,  5.80s/it]Infernece:  69%|██████▉   | 11/16 [01:03<00:30,  6.01s/it]Infernece:  75%|███████▌  | 12/16 [01:08<00:23,  5.90s/it]Infernece:  81%|████████▏ | 13/16 [01:15<00:18,  6.05s/it]Infernece:  88%|████████▊ | 14/16 [01:21<00:12,  6.10s/it]Infernece:  94%|█████████▍| 15/16 [01:27<00:06,  6.18s/it]Infernece: 100%|██████████| 16/16 [01:29<00:00,  4.99s/it]Infernece: 100%|██████████| 16/16 [01:29<00:00,  5.61s/it]
08/16/2021 13:38:01 - INFO - __main__ - Starting inference ... Done
