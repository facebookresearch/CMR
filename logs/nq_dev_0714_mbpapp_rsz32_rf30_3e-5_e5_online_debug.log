07/15/2021 01:24:02 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=None, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=None, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=0, num_train_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=30, replay_size=32, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=1, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True, weight_decay=0.01)
07/15/2021 01:24:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:24:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:24:07 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
07/15/2021 01:24:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:24:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:24:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:24:13 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
07/15/2021 01:24:16 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:24:16 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:24:16 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=30, replay_size=32, save_all_ckpts=1, total_steps=10000, use_sampled_upstream=True, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:24:16 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:24:16 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:24:16 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:24:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:24:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:24:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:24:23 - INFO - __main__ - Finished.
07/15/2021 01:25:24 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=None, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=None, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=0, num_train_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=30, replay_size=32, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=1, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True, weight_decay=0.01)
07/15/2021 01:25:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:25:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:25:29 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
07/15/2021 01:25:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:25:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:25:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:25:35 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
07/15/2021 01:25:38 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:25:38 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:25:38 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=30, replay_size=32, save_all_ckpts=1, total_steps=10000, use_sampled_upstream=True, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:25:38 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:25:38 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:25:38 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:25:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:25:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:25:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:25:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:25:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:25:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:25:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:25:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:25:45 - INFO - __main__ - Finished.
07/15/2021 01:25:45 - INFO - __main__ - Warning: bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl doesn't exist.
07/15/2021 01:25:45 - INFO - __main__ - Start Online Debugging
07/15/2021 01:25:45 - INFO - __main__ - Number of Batches of Bugs: 50
07/15/2021 01:25:45 - INFO - __main__ - Bug Batch Size: 20
07/15/2021 01:25:45 - INFO - __main__ - Replay Size: 32
07/15/2021 01:25:45 - INFO - __main__ - Replay Frequency: 30
07/15/2021 01:25:47 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt.
07/15/2021 01:25:47 - INFO - __main__ - Start bug-fixing .... Timecode: 0
07/15/2021 01:25:53 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:25:54 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_001.pt.
07/15/2021 01:25:54 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:25:55 - INFO - __main__ - Finished.
07/15/2021 01:25:55 - INFO - __main__ - Start bug-fixing .... Timecode: 1
07/15/2021 01:25:58 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:00 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_002.pt.
07/15/2021 01:26:00 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:00 - INFO - __main__ - Finished.
07/15/2021 01:26:00 - INFO - __main__ - Start bug-fixing .... Timecode: 2
07/15/2021 01:26:03 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:05 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_003.pt.
07/15/2021 01:26:05 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:05 - INFO - __main__ - Finished.
07/15/2021 01:26:05 - INFO - __main__ - Start bug-fixing .... Timecode: 3
07/15/2021 01:26:07 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:09 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt.
07/15/2021 01:26:09 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:10 - INFO - __main__ - Finished.
07/15/2021 01:26:10 - INFO - __main__ - Start bug-fixing .... Timecode: 4
07/15/2021 01:26:12 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:14 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_005.pt.
07/15/2021 01:26:14 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:14 - INFO - __main__ - Finished.
07/15/2021 01:26:14 - INFO - __main__ - Start bug-fixing .... Timecode: 5
07/15/2021 01:26:17 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:18 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_006.pt.
07/15/2021 01:26:18 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:19 - INFO - __main__ - Finished.
07/15/2021 01:26:19 - INFO - __main__ - Start bug-fixing .... Timecode: 6
07/15/2021 01:26:21 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:23 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_007.pt.
07/15/2021 01:26:23 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:23 - INFO - __main__ - Finished.
07/15/2021 01:26:23 - INFO - __main__ - Start bug-fixing .... Timecode: 7
07/15/2021 01:26:26 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:28 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt.
07/15/2021 01:26:28 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:28 - INFO - __main__ - Finished.
07/15/2021 01:26:28 - INFO - __main__ - Start bug-fixing .... Timecode: 8
07/15/2021 01:26:31 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:32 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_009.pt.
07/15/2021 01:26:32 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:33 - INFO - __main__ - Finished.
07/15/2021 01:26:33 - INFO - __main__ - Start bug-fixing .... Timecode: 9
07/15/2021 01:26:35 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:37 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_010.pt.
07/15/2021 01:26:37 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:37 - INFO - __main__ - Finished.
07/15/2021 01:26:37 - INFO - __main__ - Start bug-fixing .... Timecode: 10
07/15/2021 01:26:40 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:42 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_011.pt.
07/15/2021 01:26:42 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:42 - INFO - __main__ - Finished.
07/15/2021 01:26:42 - INFO - __main__ - Start bug-fixing .... Timecode: 11
07/15/2021 01:26:45 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:47 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt.
07/15/2021 01:26:47 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:47 - INFO - __main__ - Finished.
07/15/2021 01:26:47 - INFO - __main__ - Start bug-fixing .... Timecode: 12
07/15/2021 01:26:50 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:51 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_013.pt.
07/15/2021 01:26:51 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:52 - INFO - __main__ - Finished.
07/15/2021 01:26:52 - INFO - __main__ - Start bug-fixing .... Timecode: 13
07/15/2021 01:26:54 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:26:56 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_014.pt.
07/15/2021 01:26:56 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:26:56 - INFO - __main__ - Finished.
07/15/2021 01:26:56 - INFO - __main__ - Start bug-fixing .... Timecode: 14
07/15/2021 01:26:59 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:00 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt.
07/15/2021 01:27:00 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:01 - INFO - __main__ - Finished.
07/15/2021 01:27:01 - INFO - __main__ - Start bug-fixing .... Timecode: 15
07/15/2021 01:27:03 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:05 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_016.pt.
07/15/2021 01:27:05 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:06 - INFO - __main__ - Finished.
07/15/2021 01:27:06 - INFO - __main__ - Start bug-fixing .... Timecode: 16
07/15/2021 01:27:08 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:10 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_017.pt.
07/15/2021 01:27:10 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:11 - INFO - __main__ - Finished.
07/15/2021 01:27:11 - INFO - __main__ - Start bug-fixing .... Timecode: 17
07/15/2021 01:27:13 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:15 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt.
07/15/2021 01:27:15 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:15 - INFO - __main__ - Finished.
07/15/2021 01:27:15 - INFO - __main__ - Start bug-fixing .... Timecode: 18
07/15/2021 01:27:18 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:20 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_019.pt.
07/15/2021 01:27:20 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:20 - INFO - __main__ - Finished.
07/15/2021 01:27:20 - INFO - __main__ - Start bug-fixing .... Timecode: 19
07/15/2021 01:27:23 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:24 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_020.pt.
07/15/2021 01:27:24 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:25 - INFO - __main__ - Finished.
07/15/2021 01:27:25 - INFO - __main__ - Start bug-fixing .... Timecode: 20
07/15/2021 01:27:27 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:29 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt.
07/15/2021 01:27:29 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:29 - INFO - __main__ - Finished.
07/15/2021 01:27:29 - INFO - __main__ - Start bug-fixing .... Timecode: 21
07/15/2021 01:27:32 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:33 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_022.pt.
07/15/2021 01:27:33 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:34 - INFO - __main__ - Finished.
07/15/2021 01:27:34 - INFO - __main__ - Start bug-fixing .... Timecode: 22
07/15/2021 01:27:36 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:38 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_023.pt.
07/15/2021 01:27:38 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:38 - INFO - __main__ - Finished.
07/15/2021 01:27:38 - INFO - __main__ - Start bug-fixing .... Timecode: 23
07/15/2021 01:27:41 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:43 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt.
07/15/2021 01:27:43 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:43 - INFO - __main__ - Finished.
07/15/2021 01:27:43 - INFO - __main__ - Start bug-fixing .... Timecode: 24
07/15/2021 01:27:45 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:47 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_025.pt.
07/15/2021 01:27:47 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:47 - INFO - __main__ - Finished.
07/15/2021 01:27:47 - INFO - __main__ - Start bug-fixing .... Timecode: 25
07/15/2021 01:27:50 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:52 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_026.pt.
07/15/2021 01:27:52 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:52 - INFO - __main__ - Finished.
07/15/2021 01:27:52 - INFO - __main__ - Start bug-fixing .... Timecode: 26
07/15/2021 01:27:55 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:27:57 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt.
07/15/2021 01:27:57 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:27:57 - INFO - __main__ - Finished.
07/15/2021 01:27:57 - INFO - __main__ - Start bug-fixing .... Timecode: 27
07/15/2021 01:28:00 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:01 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_028.pt.
07/15/2021 01:28:01 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:02 - INFO - __main__ - Finished.
07/15/2021 01:28:02 - INFO - __main__ - Start bug-fixing .... Timecode: 28
07/15/2021 01:28:04 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:06 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_029.pt.
07/15/2021 01:28:06 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:06 - INFO - __main__ - Finished.
07/15/2021 01:28:06 - INFO - __main__ - Start bug-fixing .... Timecode: 29
07/15/2021 01:28:09 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:11 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt.
07/15/2021 01:28:11 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:12 - INFO - __main__ - Finished.
07/15/2021 01:28:12 - INFO - __main__ - Start bug-fixing .... Timecode: 30
07/15/2021 01:28:14 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:16 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_031.pt.
07/15/2021 01:28:16 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:16 - INFO - __main__ - Finished.
07/15/2021 01:28:16 - INFO - __main__ - Start bug-fixing .... Timecode: 31
07/15/2021 01:28:19 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:20 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_032.pt.
07/15/2021 01:28:20 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:21 - INFO - __main__ - Finished.
07/15/2021 01:28:21 - INFO - __main__ - Start bug-fixing .... Timecode: 32
07/15/2021 01:28:23 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:25 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt.
07/15/2021 01:28:25 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:25 - INFO - __main__ - Finished.
07/15/2021 01:28:25 - INFO - __main__ - Start bug-fixing .... Timecode: 33
07/15/2021 01:28:28 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:30 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_034.pt.
07/15/2021 01:28:30 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:30 - INFO - __main__ - Finished.
07/15/2021 01:28:30 - INFO - __main__ - Start bug-fixing .... Timecode: 34
07/15/2021 01:28:33 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:34 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_035.pt.
07/15/2021 01:28:34 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:35 - INFO - __main__ - Finished.
07/15/2021 01:28:35 - INFO - __main__ - Start bug-fixing .... Timecode: 35
07/15/2021 01:28:37 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:39 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt.
07/15/2021 01:28:39 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:39 - INFO - __main__ - Finished.
07/15/2021 01:28:39 - INFO - __main__ - Start bug-fixing .... Timecode: 36
07/15/2021 01:28:42 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:44 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_037.pt.
07/15/2021 01:28:44 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:44 - INFO - __main__ - Finished.
07/15/2021 01:28:44 - INFO - __main__ - Start bug-fixing .... Timecode: 37
07/15/2021 01:28:47 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:49 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_038.pt.
07/15/2021 01:28:49 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:49 - INFO - __main__ - Finished.
07/15/2021 01:28:49 - INFO - __main__ - Start bug-fixing .... Timecode: 38
07/15/2021 01:28:52 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:53 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt.
07/15/2021 01:28:53 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:54 - INFO - __main__ - Finished.
07/15/2021 01:28:54 - INFO - __main__ - Start bug-fixing .... Timecode: 39
07/15/2021 01:28:56 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:28:58 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_040.pt.
07/15/2021 01:28:58 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:28:59 - INFO - __main__ - Finished.
07/15/2021 01:28:59 - INFO - __main__ - Start bug-fixing .... Timecode: 40
07/15/2021 01:29:01 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_041.pt.
07/15/2021 01:29:03 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:03 - INFO - __main__ - Finished.
07/15/2021 01:29:03 - INFO - __main__ - Start bug-fixing .... Timecode: 41
07/15/2021 01:29:06 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:08 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt.
07/15/2021 01:29:08 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:08 - INFO - __main__ - Finished.
07/15/2021 01:29:08 - INFO - __main__ - Start bug-fixing .... Timecode: 42
07/15/2021 01:29:11 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:12 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_043.pt.
07/15/2021 01:29:12 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:13 - INFO - __main__ - Finished.
07/15/2021 01:29:13 - INFO - __main__ - Start bug-fixing .... Timecode: 43
07/15/2021 01:29:16 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:17 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_044.pt.
07/15/2021 01:29:18 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:18 - INFO - __main__ - Finished.
07/15/2021 01:29:18 - INFO - __main__ - Start bug-fixing .... Timecode: 44
07/15/2021 01:29:20 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:22 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt.
07/15/2021 01:29:22 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:23 - INFO - __main__ - Finished.
07/15/2021 01:29:23 - INFO - __main__ - Start bug-fixing .... Timecode: 45
07/15/2021 01:29:25 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:27 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_046.pt.
07/15/2021 01:29:27 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:27 - INFO - __main__ - Finished.
07/15/2021 01:29:27 - INFO - __main__ - Start bug-fixing .... Timecode: 46
07/15/2021 01:29:30 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:31 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_047.pt.
07/15/2021 01:29:31 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:32 - INFO - __main__ - Finished.
07/15/2021 01:29:32 - INFO - __main__ - Start bug-fixing .... Timecode: 47
07/15/2021 01:29:34 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:36 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt.
07/15/2021 01:29:36 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:36 - INFO - __main__ - Finished.
07/15/2021 01:29:36 - INFO - __main__ - Start bug-fixing .... Timecode: 48
07/15/2021 01:29:39 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:41 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_049.pt.
07/15/2021 01:29:41 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:41 - INFO - __main__ - Finished.
07/15/2021 01:29:41 - INFO - __main__ - Start bug-fixing .... Timecode: 49
07/15/2021 01:29:44 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 01:29:46 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_050.pt.
07/15/2021 01:29:46 - INFO - __main__ - Saving examples to the memory.
07/15/2021 01:29:46 - INFO - __main__ - Finished.
07/15/2021 01:29:46 - INFO - __main__ - Saving the memory to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:29:46 - INFO - __main__ - Finished. Results saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=6, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_6_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=1, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_1_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=2, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_2_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=5, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_5_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=7, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_7_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=3, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_3_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=4, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_4_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 01:31:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:09 - INFO - __main__ - Starting the offline evaluation of 7
07/15/2021 01:31:09 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_007.pt for facebook/bart-base .....
07/15/2021 01:31:09 - INFO - __main__ - Starting the offline evaluation of 21
07/15/2021 01:31:09 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/15/2021 01:31:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:12 - INFO - __main__ - Starting the offline evaluation of 33
07/15/2021 01:31:12 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/15/2021 01:31:12 - INFO - __main__ - Starting the offline evaluation of 45
07/15/2021 01:31:12 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/15/2021 01:31:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:12 - INFO - __main__ - Starting the offline evaluation of 14
07/15/2021 01:31:12 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_014.pt for facebook/bart-base .....
07/15/2021 01:31:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:12 - INFO - __main__ - Starting the offline evaluation of 27
07/15/2021 01:31:12 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/15/2021 01:31:13 - INFO - __main__ - Starting the offline evaluation of 39
07/15/2021 01:31:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/15/2021 01:31:13 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 01:31:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 01:31:15 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:15 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_007.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:22 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:24 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:24 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:24 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:24 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:24 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:24 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_014.pt for facebook/bart-base ..... Done!
07/15/2021 01:31:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:29 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:29 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:29 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:29 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:29 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:29 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:30 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:30 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:30 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:30 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:30 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:30 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:30 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:30 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:30 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:30 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:30 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:31 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:31 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:31 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:31 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:31 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:31 - INFO - __main__ - Finished.
07/15/2021 01:31:31 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:31 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:31 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:31 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:31 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:31 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:31 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:34 - INFO - __main__ - Moving to the GPUs.
07/15/2021 01:31:34 - INFO - __main__ - Debugger Setup ......
07/15/2021 01:31:34 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 01:31:34 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 01:31:34 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 01:31:34 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 01:31:34 - INFO - __main__ - Finished.
07/15/2021 01:31:34 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:34 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 01:31:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 01:31:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 01:31:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 01:31:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 01:31:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 01:31:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 01:31:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 01:31:42 - INFO - __main__ - Finished.
07/15/2021 01:31:42 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:42 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:42 - INFO - __main__ - Finished.
07/15/2021 01:31:42 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:42 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:46 - INFO - __main__ - Finished.
07/15/2021 01:31:46 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:46 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:46 - INFO - __main__ - Finished.
07/15/2021 01:31:46 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:46 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:47 - INFO - __main__ - Finished.
07/15/2021 01:31:47 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:47 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 01:31:51 - INFO - __main__ - Finished.
07/15/2021 01:31:51 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 01:31:51 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 13:13:34 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=None, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=None, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=0, num_train_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=30, replay_size=32, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=1, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True, weight_decay=0.01)
07/15/2021 13:13:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 13:13:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 13:13:41 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
07/15/2021 13:13:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 13:13:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 13:13:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 13:13:49 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
07/15/2021 13:13:55 - INFO - __main__ - Moving to the GPUs.
07/15/2021 13:13:55 - INFO - __main__ - Debugger Setup ......
07/15/2021 13:13:55 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=30, replay_size=32, save_all_ckpts=1, total_steps=10000, use_sampled_upstream=True, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 13:13:55 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 13:13:55 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 13:13:55 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 13:13:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 13:13:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 13:13:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 13:13:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 13:13:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 13:13:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 13:13:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 13:13:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 13:14:04 - INFO - __main__ - Finished.
07/15/2021 13:14:04 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 13:14:04 - INFO - __main__ - Start Online Debugging
07/15/2021 13:14:04 - INFO - __main__ - Number of Batches of Bugs: 50
07/15/2021 13:14:04 - INFO - __main__ - Bug Batch Size: 20
07/15/2021 13:14:04 - INFO - __main__ - Replay Size: 32
07/15/2021 13:14:04 - INFO - __main__ - Replay Frequency: 30
07/15/2021 13:14:06 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt.
07/15/2021 13:14:06 - INFO - __main__ - Start bug-fixing .... Timecode: 0
07/15/2021 13:14:13 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:14:16 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_001.pt.
07/15/2021 13:14:16 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:14:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=None, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=None, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=0, num_train_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=30, replay_size=32, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=1, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True, weight_decay=0.01)
07/15/2021 13:14:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 13:14:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 13:15:01 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
07/15/2021 13:15:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 13:15:02 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 13:15:02 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 13:15:07 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
07/15/2021 13:15:11 - INFO - __main__ - Moving to the GPUs.
07/15/2021 13:15:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 13:15:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=30, replay_size=32, save_all_ckpts=1, total_steps=10000, use_sampled_upstream=True, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 13:15:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 13:15:11 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 13:15:11 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 13:15:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 13:15:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 13:15:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 13:15:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 13:15:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 13:15:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 13:15:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 13:15:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 13:15:18 - INFO - __main__ - Finished.
07/15/2021 13:15:18 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 13:15:18 - INFO - __main__ - Start Online Debugging
07/15/2021 13:15:18 - INFO - __main__ - Number of Batches of Bugs: 50
07/15/2021 13:15:18 - INFO - __main__ - Bug Batch Size: 20
07/15/2021 13:15:18 - INFO - __main__ - Replay Size: 32
07/15/2021 13:15:18 - INFO - __main__ - Replay Frequency: 30
07/15/2021 13:15:21 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt.
07/15/2021 13:15:21 - INFO - __main__ - Start bug-fixing .... Timecode: 0
07/15/2021 13:15:28 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:15:30 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_001.pt.
07/15/2021 13:15:30 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:15:31 - INFO - __main__ - Finished.
07/15/2021 13:15:31 - INFO - __main__ - Start bug-fixing .... Timecode: 1
07/15/2021 13:15:35 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:15:37 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_002.pt.
07/15/2021 13:15:37 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:15:37 - INFO - __main__ - Finished.
07/15/2021 13:15:37 - INFO - __main__ - Start bug-fixing .... Timecode: 2
07/15/2021 13:15:40 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:15:42 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_003.pt.
07/15/2021 13:15:42 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:15:43 - INFO - __main__ - Finished.
07/15/2021 13:15:43 - INFO - __main__ - Start bug-fixing .... Timecode: 3
07/15/2021 13:15:46 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:15:48 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt.
07/15/2021 13:15:48 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:15:49 - INFO - __main__ - Finished.
07/15/2021 13:15:49 - INFO - __main__ - Start bug-fixing .... Timecode: 4
07/15/2021 13:15:52 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:15:54 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_005.pt.
07/15/2021 13:15:54 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:15:54 - INFO - __main__ - Finished.
07/15/2021 13:15:54 - INFO - __main__ - Start bug-fixing .... Timecode: 5
07/15/2021 13:15:57 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:00 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_006.pt.
07/15/2021 13:16:00 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:00 - INFO - __main__ - Finished.
07/15/2021 13:16:00 - INFO - __main__ - Start bug-fixing .... Timecode: 6
07/15/2021 13:16:03 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:05 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_007.pt.
07/15/2021 13:16:05 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:05 - INFO - __main__ - Finished.
07/15/2021 13:16:05 - INFO - __main__ - Start bug-fixing .... Timecode: 7
07/15/2021 13:16:09 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:11 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt.
07/15/2021 13:16:11 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:11 - INFO - __main__ - Finished.
07/15/2021 13:16:11 - INFO - __main__ - Start bug-fixing .... Timecode: 8
07/15/2021 13:16:14 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:17 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_009.pt.
07/15/2021 13:16:17 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:17 - INFO - __main__ - Finished.
07/15/2021 13:16:17 - INFO - __main__ - Start bug-fixing .... Timecode: 9
07/15/2021 13:16:20 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:22 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_010.pt.
07/15/2021 13:16:22 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:23 - INFO - __main__ - Finished.
07/15/2021 13:16:23 - INFO - __main__ - Start bug-fixing .... Timecode: 10
07/15/2021 13:16:26 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:28 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_011.pt.
07/15/2021 13:16:28 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:29 - INFO - __main__ - Finished.
07/15/2021 13:16:29 - INFO - __main__ - Start bug-fixing .... Timecode: 11
07/15/2021 13:16:32 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:34 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt.
07/15/2021 13:16:34 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:35 - INFO - __main__ - Finished.
07/15/2021 13:16:35 - INFO - __main__ - Start bug-fixing .... Timecode: 12
07/15/2021 13:16:38 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:40 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_013.pt.
07/15/2021 13:16:40 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:40 - INFO - __main__ - Finished.
07/15/2021 13:16:40 - INFO - __main__ - Start bug-fixing .... Timecode: 13
07/15/2021 13:16:44 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:46 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_014.pt.
07/15/2021 13:16:46 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:46 - INFO - __main__ - Finished.
07/15/2021 13:16:46 - INFO - __main__ - Start bug-fixing .... Timecode: 14
07/15/2021 13:16:49 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:51 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt.
07/15/2021 13:16:51 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:52 - INFO - __main__ - Finished.
07/15/2021 13:16:52 - INFO - __main__ - Start bug-fixing .... Timecode: 15
07/15/2021 13:16:55 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:16:57 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_016.pt.
07/15/2021 13:16:57 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:16:58 - INFO - __main__ - Finished.
07/15/2021 13:16:58 - INFO - __main__ - Start bug-fixing .... Timecode: 16
07/15/2021 13:17:01 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_017.pt.
07/15/2021 13:17:03 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:04 - INFO - __main__ - Finished.
07/15/2021 13:17:04 - INFO - __main__ - Start bug-fixing .... Timecode: 17
07/15/2021 13:17:07 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:09 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt.
07/15/2021 13:17:09 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:10 - INFO - __main__ - Finished.
07/15/2021 13:17:10 - INFO - __main__ - Start bug-fixing .... Timecode: 18
07/15/2021 13:17:13 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:15 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_019.pt.
07/15/2021 13:17:15 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:15 - INFO - __main__ - Finished.
07/15/2021 13:17:15 - INFO - __main__ - Start bug-fixing .... Timecode: 19
07/15/2021 13:17:19 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:21 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_020.pt.
07/15/2021 13:17:21 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:21 - INFO - __main__ - Finished.
07/15/2021 13:17:21 - INFO - __main__ - Start bug-fixing .... Timecode: 20
07/15/2021 13:17:25 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:26 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt.
07/15/2021 13:17:26 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:27 - INFO - __main__ - Finished.
07/15/2021 13:17:27 - INFO - __main__ - Start bug-fixing .... Timecode: 21
07/15/2021 13:17:30 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:32 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_022.pt.
07/15/2021 13:17:32 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:32 - INFO - __main__ - Finished.
07/15/2021 13:17:32 - INFO - __main__ - Start bug-fixing .... Timecode: 22
07/15/2021 13:17:36 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:38 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_023.pt.
07/15/2021 13:17:38 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:38 - INFO - __main__ - Finished.
07/15/2021 13:17:38 - INFO - __main__ - Start bug-fixing .... Timecode: 23
07/15/2021 13:17:42 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:44 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt.
07/15/2021 13:17:44 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:44 - INFO - __main__ - Finished.
07/15/2021 13:17:44 - INFO - __main__ - Start bug-fixing .... Timecode: 24
07/15/2021 13:17:47 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:50 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_025.pt.
07/15/2021 13:17:50 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:50 - INFO - __main__ - Finished.
07/15/2021 13:17:50 - INFO - __main__ - Start bug-fixing .... Timecode: 25
07/15/2021 13:17:53 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:17:55 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_026.pt.
07/15/2021 13:17:55 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:17:56 - INFO - __main__ - Finished.
07/15/2021 13:17:56 - INFO - __main__ - Start bug-fixing .... Timecode: 26
07/15/2021 13:17:59 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:01 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt.
07/15/2021 13:18:01 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:02 - INFO - __main__ - Finished.
07/15/2021 13:18:02 - INFO - __main__ - Start bug-fixing .... Timecode: 27
07/15/2021 13:18:05 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:07 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_028.pt.
07/15/2021 13:18:07 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:07 - INFO - __main__ - Finished.
07/15/2021 13:18:07 - INFO - __main__ - Start bug-fixing .... Timecode: 28
07/15/2021 13:18:11 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:13 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_029.pt.
07/15/2021 13:18:13 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:13 - INFO - __main__ - Finished.
07/15/2021 13:18:13 - INFO - __main__ - Start bug-fixing .... Timecode: 29
07/15/2021 13:18:17 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:19 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt.
07/15/2021 13:18:19 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:19 - INFO - __main__ - Finished.
07/15/2021 13:18:19 - INFO - __main__ - Start bug-fixing .... Timecode: 30
07/15/2021 13:18:23 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:25 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_031.pt.
07/15/2021 13:18:25 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:25 - INFO - __main__ - Finished.
07/15/2021 13:18:25 - INFO - __main__ - Start bug-fixing .... Timecode: 31
07/15/2021 13:18:28 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:30 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_032.pt.
07/15/2021 13:18:30 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:31 - INFO - __main__ - Finished.
07/15/2021 13:18:31 - INFO - __main__ - Start bug-fixing .... Timecode: 32
07/15/2021 13:18:34 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:36 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt.
07/15/2021 13:18:36 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:36 - INFO - __main__ - Finished.
07/15/2021 13:18:36 - INFO - __main__ - Start bug-fixing .... Timecode: 33
07/15/2021 13:18:40 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:42 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_034.pt.
07/15/2021 13:18:42 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:42 - INFO - __main__ - Finished.
07/15/2021 13:18:42 - INFO - __main__ - Start bug-fixing .... Timecode: 34
07/15/2021 13:18:46 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:48 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_035.pt.
07/15/2021 13:18:48 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:48 - INFO - __main__ - Finished.
07/15/2021 13:18:48 - INFO - __main__ - Start bug-fixing .... Timecode: 35
07/15/2021 13:18:51 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:18:53 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt.
07/15/2021 13:18:53 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:18:54 - INFO - __main__ - Finished.
07/15/2021 13:18:54 - INFO - __main__ - Start bug-fixing .... Timecode: 36
07/15/2021 13:18:57 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:00 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_037.pt.
07/15/2021 13:19:00 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:00 - INFO - __main__ - Finished.
07/15/2021 13:19:00 - INFO - __main__ - Start bug-fixing .... Timecode: 37
07/15/2021 13:19:03 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:05 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_038.pt.
07/15/2021 13:19:05 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:06 - INFO - __main__ - Finished.
07/15/2021 13:19:06 - INFO - __main__ - Start bug-fixing .... Timecode: 38
07/15/2021 13:19:09 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:11 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt.
07/15/2021 13:19:11 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:11 - INFO - __main__ - Finished.
07/15/2021 13:19:11 - INFO - __main__ - Start bug-fixing .... Timecode: 39
07/15/2021 13:19:15 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:17 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_040.pt.
07/15/2021 13:19:17 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:17 - INFO - __main__ - Finished.
07/15/2021 13:19:17 - INFO - __main__ - Start bug-fixing .... Timecode: 40
07/15/2021 13:19:21 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:23 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_041.pt.
07/15/2021 13:19:23 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:23 - INFO - __main__ - Finished.
07/15/2021 13:19:23 - INFO - __main__ - Start bug-fixing .... Timecode: 41
07/15/2021 13:19:27 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:29 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt.
07/15/2021 13:19:29 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:29 - INFO - __main__ - Finished.
07/15/2021 13:19:29 - INFO - __main__ - Start bug-fixing .... Timecode: 42
07/15/2021 13:19:32 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:34 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_043.pt.
07/15/2021 13:19:34 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:35 - INFO - __main__ - Finished.
07/15/2021 13:19:35 - INFO - __main__ - Start bug-fixing .... Timecode: 43
07/15/2021 13:19:38 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:41 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_044.pt.
07/15/2021 13:19:41 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:41 - INFO - __main__ - Finished.
07/15/2021 13:19:41 - INFO - __main__ - Start bug-fixing .... Timecode: 44
07/15/2021 13:19:44 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:46 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt.
07/15/2021 13:19:46 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:47 - INFO - __main__ - Finished.
07/15/2021 13:19:47 - INFO - __main__ - Start bug-fixing .... Timecode: 45
07/15/2021 13:19:50 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:52 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_046.pt.
07/15/2021 13:19:52 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:53 - INFO - __main__ - Finished.
07/15/2021 13:19:53 - INFO - __main__ - Start bug-fixing .... Timecode: 46
07/15/2021 13:19:56 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:19:58 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_047.pt.
07/15/2021 13:19:58 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:19:58 - INFO - __main__ - Finished.
07/15/2021 13:19:58 - INFO - __main__ - Start bug-fixing .... Timecode: 47
07/15/2021 13:20:01 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:20:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt.
07/15/2021 13:20:03 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:20:04 - INFO - __main__ - Finished.
07/15/2021 13:20:04 - INFO - __main__ - Start bug-fixing .... Timecode: 48
07/15/2021 13:20:07 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:20:09 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_049.pt.
07/15/2021 13:20:09 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:20:10 - INFO - __main__ - Finished.
07/15/2021 13:20:10 - INFO - __main__ - Start bug-fixing .... Timecode: 49
07/15/2021 13:20:13 - INFO - __main__ - Start bug-fixing .... Done!
07/15/2021 13:20:15 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_050.pt.
07/15/2021 13:20:15 - INFO - __main__ - Saving examples to the memory.
07/15/2021 13:20:15 - INFO - __main__ - Finished.
07/15/2021 13:20:15 - INFO - __main__ - Saving the memory to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 13:20:15 - INFO - __main__ - Finished. Results saved to bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json
07/15/2021 15:52:46 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 15:52:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:52:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:52:50 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 15:52:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 15:52:53 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:52:53 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:52:53 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:52:57 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 15:53:00 - INFO - __main__ - Moving to the GPUs.
07/15/2021 15:53:58 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 15:53:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:53:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:54:03 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 15:54:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 15:54:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:54:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:54:04 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:54:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 15:54:10 - INFO - __main__ - Moving to the GPUs.
07/15/2021 15:54:10 - INFO - __main__ - Debugger Setup ......
07/15/2021 15:54:10 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 15:54:10 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 15:54:10 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 15:54:10 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 15:54:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:54:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:54:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 15:54:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 15:54:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 15:54:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:54:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:54:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:54:15 - INFO - __main__ - Finished.
07/15/2021 15:54:15 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 15:54:16 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 15:54:50 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 15:54:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:54:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:54:54 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 15:54:54 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 15:54:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:54:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:54:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:54:59 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 15:55:02 - INFO - __main__ - Moving to the GPUs.
07/15/2021 15:55:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 15:55:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 15:55:02 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 15:55:02 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 15:55:02 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 15:55:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:55:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:55:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 15:55:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 15:55:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 15:55:04 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:55:04 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:55:04 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:55:07 - INFO - __main__ - Finished.
07/15/2021 15:55:07 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 15:55:07 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 15:57:02 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 15:57:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:57:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:57:06 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 15:57:06 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 15:57:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:57:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:57:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:57:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 15:57:14 - INFO - __main__ - Moving to the GPUs.
07/15/2021 15:57:14 - INFO - __main__ - Debugger Setup ......
07/15/2021 15:57:14 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 15:57:14 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 15:57:14 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 15:57:14 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 15:57:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:57:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:57:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 15:57:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 15:57:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 15:57:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:57:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:57:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:57:20 - INFO - __main__ - Finished.
07/15/2021 15:57:20 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 15:57:20 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 15:57:20 - INFO - __main__ - past_memory_keys: []
07/15/2021 15:58:15 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 15:58:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:58:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:58:19 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 15:58:19 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 15:58:20 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:58:20 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:58:20 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:58:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 15:58:27 - INFO - __main__ - Moving to the GPUs.
07/15/2021 15:58:27 - INFO - __main__ - Debugger Setup ......
07/15/2021 15:58:27 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 15:58:27 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 15:58:27 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 15:58:27 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 15:58:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 15:58:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 15:58:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 15:58:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 15:58:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 15:58:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 15:58:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 15:58:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 15:58:32 - INFO - __main__ - Finished.
07/15/2021 15:58:32 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 15:58:32 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 15:58:33 - INFO - __main__ - past_memory_keys: []
07/15/2021 16:01:19 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:01:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:01:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:01:23 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:01:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:01:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:01:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:01:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:01:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:01:31 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:01:31 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:01:31 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:01:31 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:01:31 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:01:31 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:01:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:01:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:01:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:01:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:01:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:01:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:01:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:01:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:01:36 - INFO - __main__ - Finished.
07/15/2021 16:01:36 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:01:36 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:01:37 - INFO - __main__ - past_memory_keys: []
07/15/2021 16:07:13 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:07:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:07:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:07:18 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:07:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:07:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:07:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:07:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:07:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:07:26 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:07:26 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:07:26 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:07:26 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:07:26 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:07:26 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:07:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:07:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:07:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:07:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:07:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:07:27 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:07:27 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:07:27 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:07:32 - INFO - __main__ - Finished.
07/15/2021 16:07:32 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:07:32 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:07:32 - INFO - __main__ - past_memory_keys: [b'a\x07$@\x9b\xf1/@ 21?\xb5Z\x01A\xef"\x99?F\x19\x06@\'\r\xa6\xbe\x06\x9a\xd8\xbf,#\xe6\xbe\x96\xc4\xa1=\xf3\x08\xca?\xa0\xb6\xa1?\xc4\xc0\xdb?X=\x9e?\xe2g\x9a\xbf\xee\xb7\x9e\xbf\xbc#M\xbf\x9a6(@G\xb4\x8b?\x97kB\xc0\xc0\xf9\x94\xbd\xe7\xdeg\xc0\x00C\xcd?\xf1\xa6\xd4?\xbc\x85\xd7?\xbegl\xc0\x9c\r%@\xdeE\x17\xc2`\xaa\x0b@\xa8\xbe\xe4\xbf5\x9f\xbe?\xc9\x96\x91\xbf\x08\xef\xed>\x8b\xc5\x8f\xbf\x9a\x8aQ\xc0\xaa\xda\xae?\n\x052?N?i\xbf \xb4\xeb?\xf2\xe4\xa5\xbf1\xd7\x14\xbfC]3\xc0\x9e\x82\n\xbf\x13\xfa\xdc\xbf\x03\x18\xee\xbf\x10U\'@G\x8a\x8b\xbe\xea\xfao\xbf\x7f^\x0c\xc0BM\x84>L\x14\x8e?\x1c\xcc\xd9>\x90\x87\x02\xc0\xd1r\x8d\xbf\xba\xcb`\xc0\x07\x9e\xb7>\xa0R\xcd?\xcc3\x90\xbf\x05&\xb0?\xff\x19\x86?\xd4\x0b\x88?\x9d\xf5\xe0?\x97I\xef?\xb5\xa8\xf2=B &\xc0\x18\x9fE\xbe9\xf3T\xc0\x12b\x88\xbf.\xfc\r>:\xf0\x08?\xd2.#?\tG\xe7>\xc6N\xa0?\x08r^\xbf\x1d\x89\x08\xc0V\x1en\xbe!\xf0\xd2?\xf9WQ\xbe\x99`\x18\xc0\x12u\x05?x\x1d\xc0\xbfJ\xc9(@\x8a(^\xc0\xda%\x8e\xbf\xcaOK?\xce\xee\x8f?e\xbbl@\x8fe7?\xe8}\x86\xbd\x8b\x9fI\xc0\xc45\xef\xbd\x1d\x8b\xac?\xe0s\xa5\xbe\xb3\xb0\xce\xbe\xb0\xaa\x92\xbeE\x0f\xeb>gZ\xc9\xbfC\xf9\xa7?\xc3~\x01\xc0J>\x89\xbf\x01\xf6\xab\xbf\xf7p;\xc0\xe967\xc0\xc2A\xdd\xbfU\xb8\x0b@\xf6\xfd\x88\xbe\x01\x8a\xb1?\xd8\xdcu\xbf\xcekC\xbf\xfa\xeb\xef\xbf\xa0\xb1\x16@8\n\xb2\xbf3\x94\xe6\xbet\xff\xe1\xbd1m\xb6\xbe\x80\xbc>\xbf\xe9\xd24A\xf0O^\xc0\x8c\xe5\xd4=\xfe0\x87\xbe\xf8e\xdf?Pyw<\xfei\xee>y:Y@J\xd4\xbb\xbe\xfe\xa4\xe1\xber\xa4"\xbf\x9a\xf2\xc5?q\xef\x8d\xbf\xc9\xbf\t\xbf\xd3B\xa8>J\xe7\xe8?\x98U\x10@*#\xfd?\x90\xb0\xcc\xbf`\xfbj\xbb\x8b@B\xbfZ0?@b\x0fh?\x03\xcaH\xbf\x1bK\x8b?\xf8`%\xbf\xcc\x0eu\xbd\x11\x04\xf2?\xf5E\xd9?\xeb\x18^> .\x81\xbb\xc9\x1f\xb0\xbf\xa0\xce&\xbf\xc0\x0c\xa1@\xdes\xdc="$\x87>s\xd0\xf5>\x9b\xff\x11@\x80\xeb#\xc0o\xbd\xdd?\xf5-\x9f\xbf\xbe)}\xbe\xb4\x9b\x1d>\xb0\t\x11\xbc(x\x91>To\xa7?\x92\xa6&?W\x8cb\xbf\xae\xc8\x98\xbe\xb5\xd9O\xbf\xa1\xf7\x1e\xc0\x15r*@B4\xba\xbe\x07\xa6\n@\xbf\xf1M\xc0U=\x90\xbf)\x7f\x16\xc0+\xb7Q@K\x16\x91?\x8e\x8f\xb5?\xe56?@\xb0\x11\xa4?\x84\xc0\x02\xc0\xd68B\xc0N\xe1y\xbf;V\xbe\xbe{\x13\x81\xbf\xcbH\xb9?-|~?iH%?\xf5j\xb9\xbf\xba\xb4\x94?)( @\xab"S\xbf\x85\x9f\xcc?t\xb7\xe7\xbd\xe4\xb5\xa4>\x1a\xd4/?\xf2K\xba\xbf\xa0Y\x91>\xc8\x7f\x04@2\x9e\x94\xbezB\xb2?8\x9ce\xbf\xb2\xb0\xe6?\xa4\xf7\xb2=_\xf4\x8d>\x193%@f\xcd\xe3\xbf\xe4\xebB\xc0V.\xc8\xbf\xd2\xd1\xdf?"b;@\xfa\xe7\x8c>\x88\x0b\xb9\xbd\x8f\xaf\x1a@\x81z\x1b@~(\x8e?(\x8b\xac\xbfZ\x85C\xbf\xcb\xe8\x01\xbe\xe7\xa7a?d\xb0\xd5\xbe\xda\xa8\x07>\x93N\xaa?w\x91\xaf\xbf\x89b\x8b?\xe9p\x03\xc0\x15\xd2\xfb?\xcf\xd2\xd7?g\xc9\x9d\xbf\x0f+\x19?\xa6\x97<\xbed\x96"\xc0\xbd\x95\xe5?w\xeaH?}\x05\xaf\xbf\t\x9c\x0f\xbf\xca\xe6\n@\x18\x8d\xf4?\xae\xf11\xbfH\xeam?\xd5\xe3\xce\xbf\xc8\x00\xe8\xbd\xbd\xd1q?\x91#\x84@x\xf2|@K\xca~?\xd59\xd8\xbf\xcb\xcc\x8e\xbf\x89!\xcd\xbf:\xc9\x03\xc0/%\x06?5\x1e\x8f?\x13\xa57\xc0\t\x05\xc8?\xed:\xc6\xbfY\xc95\xc0\x17S\x06@\xa7\x8c\n\xbe/\n(@\x1c\xda\xf6>fV\x98\xbf\xf8\xa9\x1c\xbc\xfe\xcc\x8c\xbf\xab\xc8H?Z\x03\xee>\x13\xc4q?P\xee\x9e>7\x8b\x82\xc0TU0>\xf1C\xc2?3\xff[\xbf\xbaKM\xc0\xbb\x16\x0e@2\x1d\xf0?h\xc70@]\xf2\x84>\xb3M\x88@[\xddJ\xbf\x8e\x98\x8b\xbd\xa5\xc92\xc0\xc8+\x0b@\xb0\xf7\x8d\xbc\xe4H)?i\x14\xdf?!\xd0\x19@K\x15\xf6\xbf4"&\xc0I(\x16\xbf\xf1\x9c3\xc0/\xa6\xa1=\xb2\xc2\x84>\x02\xae\x15@{0\xfd?\xab\x13X@\x86\xd5k\xbe\x07\x00\x9b?Bk\x1a\xbfsD\xe8>\xb5@\x82\xbf\xa7Z\xb0\xbe\x91\xca\x94\xbf+\x96\xf3\xbf\xec\xf0\x11\xc0\x1c:\xe6?\xc4V\x01?K\x80\x19@8\x16\xe7\xbep\xaa\xe3\xbe\xd03\x83;\x82vj\xc0u\xe0\xdb\xbe\x04o\xf7>\x96\xe95@\x91;\x07\xc0\x1bM/\xbfM\x03\x06\xc0\'+\xd5>\n\x86\xb9?\t:G?\x07i9\xbfP\xb1\x1d?\xc3\xc5j@y\xff8@\xcf\xc3M@\xfa\x05D\xbf\xd4\xa9)@\x80\x00\x8a?R \x04?\xa09\x96?\xff\xe1\xed>\x10\x08^<$q\xbb=\xfe\xd6\x8f\xbf\xe9\x16_?\xb4\xb6\xeb\xbe\xf3\x9a\xd5\xbf\xdf\x917\xc0[N\xcc=\xf7\x9b\x0c?hC\xe7\xbe\xfb\xf7\x1b\xbf5\xe5\\?\xe9\x8d\t\xbf\xe7\x9b\x99?s\xfdF\xc0\x9a\xd0\x93\xbdq/\x12@\xc1\x19Q@\xec\xd3\xca\xbe\xce\x862@B\x11P>\xa1r\xb9\xbf\xa4\xf7\xd5\xbd\x96_\x0e\xc0B\xe5!\xbfa\x11I?c\xe2\xf6>\x97r\xa6\xbfO:\xe5?\xa9(6\xbf\xac\xdc3\xbem\x83\x92?4v-\xc0(97\xbfV\x1c\xbd\xbf\xfb\xbe6?\x81p\x9b?}\x0b\xaa\xbe\x06\x19K?h\x97\xf1?mO\xa0>^V\xbe>\xea!2?\x96\x93\x87?rZ\xed\xbe\xd6\x1c\x80>\xb6\x95\r\xc0\xe4:\xd7\xbf\x10IU\xbf\xa8\xba\xc6\xbfV\x14\x82?\xda\xed\xaf\xbf-\xfa\xe3\xbf|\x7f\xdd=e\x95F\xbf$\xddl\xbf)\t\xaa>]\x8b\x99>x\xdf\x02\xc0\x87\xca\xa9\xbfU\xd5\x19\xc0>\xd6\xa2>\xf1-\xcc\xbfC\xd7!\xc0\x14\xdb\x16\xbf^\xd9\x1b\xc0L\x0b\x06\xc0\xfe\x1ec\xbd\x97U$?`\xbb\xb7\xbf\xad\x8a\x9d\xbf\xcc`z\xbf\xea\xf4W?J\x02B>\xe6\x9c\xf3?E\x14\xd2?5\x1b%?\xb4R\xbb?#\xda`>!\xa3\x93>\xb70\xcf?\xf6+\xd1?\xe8\x8b\x87\xbf\x966\x96\xbf@\xdb\xa0\xbf6\xc9\xfb?E\x1c\x9c\xbf\x93\xb5\xa8?\x02j6\xbf\xf2\xd6b\xbe\xea\x95\xd2?\x8e}\xca\xbf?\x8f\xb2\xbf\xe9\xfc\xef\xbe\xff/\x1b\xc0\\g[>=\xa0\x1d\xc0\xc3B\x17?\xd6\xe3\x9f\xbf\x05\'\xb2>d\xe8K\xbf\x83<\xb9>fy\xde\xbe5`6\xc0\xb2"\x87\xbf\x85\x9fU?(I\xb4\xbcm\xfe\xd8?\xd1\xc8\xef?\xfb6\xce\xc0\xc8r2<\xdb~\x97\xbf\xdce??\xaf\x8e\x80?\xcc4\xe5=P<\xf2\xbf\xf6\x8cM\xbf?r\x17\xc0\xac\xcb\t@P&\x1a\xbc6\xed\xd3\xbf;\xd6\xd7?`~\x81\xbfR`\xac>\xca\x99S\xc0]m\xde?"!#\xc0\xb6\xcf\xdf\xbf\xc4\x8a?\xbf\x14r\xf9>.\xac\xbd>\xc8\xae?\xbf\x90\x8d}\xbe\xa5F7?\xe7\xc4!\xbf\xe0\xcc\xff\xbe\x8a\x11\xc4\xbf4\xe3\x01\xc0t\xa9\xf0?\xb8\x82\xe3\xbf|k >J\xdb\x1f\xc0d\x0f\x0e?\xb9\xd9h@\xf4\xf7\x9b>\xcb\xd5\x8b<\xa1\xa2\x04?Y\xdc\x97?\xd5\xe9Y?\x87\xe6\xa1?\xcb\x0e\x04@\x9dG\x1a\xc0.\xc3\x1b?\xef\x14M>&\xe6\x10@~/u@\x07\xa0\x18\xbe\xac\xfeN?\x9c\x8b\x9c\xbe\x82\xd3\x93\xbfGL\xea>s\x8f\xd3?\xb3\x9d\xac?\xe2\xd5\xad\xbfj\xee8\xbf\xa1\xb8?\xbf\xec4\x9a?[\xbb\xc3\xbf\xa8\x1c4\xc0\x98w2@\xdf\x06u?n\x9d\xf1\xbf\x92o\x9d?\xc6f]?\xe5\x1f4?\x92[\x06>\xd6\'\x88>\xf8\x8b\xa7?\xc0\xc4\xf9\xbf\xf3\xc1*\xbf"\xaeJ\xbfL\xe5\xa9\xbf\xf4\xfa!\xc0m\x8c\x18?{un@\xcf\xcd\x0f>\xa3u\x95?z\'\xe9=8\xd7\xa9\xbf\xdc\xa7\x86?\xcdPn?\x1e\t\x0f\xc0\xc3\xfe\x9f>\xe0\x91F\xbf\xc6Y=\xc0^\xca\xd6\xbf\x11\x7f\x80\xbe\xe1\x9d\x15>,\x15]@_K\x14@\x17\xc0\x9a?\x1am\xb9?6\x90Y?\x96\x8d\xf3>\x1a\x00\xd6\xbe\x8d\xaf\x16@\x96:\xd3\xbe\xb1-\xb1?\xaa\x04\xc7>\xc5\xd40@=\xf7\x8d?E\x97N@\xd1t>\xc0\xceNS?%4P?\x8e\xbf\x08\xc0\x1a\xe3\x8e\xbf\x10\x1d\x16?"B\x93>\x19\t\x9c\xbfl\xfc\x8d<\xd1t\x14@4\xe9y\xbcr\xf5\xc5\xbd\x8f\x8f\x9c\xc0\x85\x1dV?:\xf7\xf0\xbf\xb8\x80\xa5\xbf\xc8\x9a\xc9?x\xdb"\xc0\xdb!-\xbfzpE@\x07\x03\xe7?\xc1\xa9\xb7?Y\x9a\xae?\x15\xec\xba>\x0c\xff\'=\xf8\xc2\x83?4\xfa\x9b?\xf8\xda0\xc0\x99\x91h\xbf*7\xd0>\x83\xee\xf5>\x14mW@K\xbd7?\t\xba \xbf2\x0c\xa4>\xf9\xf17\xbf\xe9\x18\xcb\xbf\xbe\xce\xe2\xbfbp\x80\xbfl!\xbf\xbeRw\x08\xc0(w\xb2?\x9e\xc8\x0b@\xa3\x9a\xf0\xbf\xe4~\x9f\xbeX\x1a\x89?k\x88\xe7?\x1b\x08\x1c\xc0\xd6\x9a\xa0\xbf\x12#.\xbd\xe3\x18\xcd?h\xfd\x06@\xa6\xa3f?\xe1\xa9G\xbf\xb6\xa0"@,\x15\xad\xbf7\xda\x9d\xbf\x8c\xc3\x85\xbfie\x0c@|L{\xbe\xc5W2\xbe8a\xc6\xbd8b\x94?&d\x87\xbf\x81\xc4\x1e?\xf6g\x1a=dR"?~\x08d\xbf\x11\\\xa7?:&\xde\xbe\xc6\xd7\xe0>\xfc\x05\x14?k}\xae\xbf\xf1"\x9d\xc0r0R\xbe\xb4U\xcb?\x13{\xfd=\xb0\xba\xf7>d\xa6=\xc0-\xf4K>\xc8\xaf\x99>-\xa5\x9f\xbf\x12\xa9:>\xbe\xc6\x19\xc0n\xb8\x9d>\x18\xe6\xf3??v\x9f\xbf2r\x9e?\x1e\xc8\x82?\xe05\xa6\xbd\xac\xc2b\xc0"\x93\x84?@\x03\xb9?\x89|\xaf\xbf07\x11@B\xc4f?\xde\x8a\x8e\xc0\xd9\xdc\xd6?Z\x87\xc9>a\x99F>\xfcA\xd3\xbf\xe0\xc1\xdd?8\xa5G\xbfe\xdd|?\xcc\x05\xfd\xbb\xa1\x16\xa0\xbe\x8b\xa6\xd0>\xb3\xbb"\xbe \xb3\xee\xbe\xd03\x0c>\x16\x01\xa3>R\xba[>\xf01!\xc0~\x98\x93@d,\xe7\xbdb\xfej@9i\x98\xbf\xfd\x8eX>\x9ba\x0e?\x97\\\xfe=Y\xea\x16\xbf&Pp?\xd2\xe3\xcf>s\xcfW\xbf\x7f\xb2\x8e?\xa4\x82\x04@\xaf\xfa\x0f@*\xc8\t@I5\xc0?\xa7\xffd?FZ\x83?\xb43\x93>\xa9j\xe5?\xce\x088?\xeb\x8b\xf3?\xd6\xd8\x07\xc0{\xd1i@H\x90\x99?\xd2\xf9\x17\xbeR\xf4\xe9<\x95\xfc\x8f\xbdKE\xb8\xbf\x7f\x8a\x12@$\x89\xb5\xbe\xa3\xc1\xe4\xbfr\xc6\xc8>r\x05\xb7\xbf}U\x8d?CG\'\xc0\x00\r\x93?\x17\x98\x94\xbf\xa4\x04\x06AM\x83\x1c\xc0\xb7\xf7%\xbf5\x839@\xa4\xff\xbf>\xa6\xc4\xae\xbe\x99m\\\xbfre\x9b>E\x10\x08\xc0\xfb\xb1\xda?\xb1k\xf5?\x11\x93\xcf>\x12\xd9\x1b\xc0\xae\x82\x17@\x07\x9a\xd7?Z^\xad\xbcI\x1eJ\xc0\xd1\x8e\xe2>{K\xe9="\xc4\xc7\xbfpuJ\xc0}\xabE\xc0\xa8b\xc1?Wz\xdd?\x95oB?\xf9\x9a\xf9\xbf\xfa;\x11\xbe7\x17\x13?\xf4Q\xbf\xbf\x8c\xae\xdb\xbe\x84l\xb1>(\xb4\xa7\xbe\xaf\xab\xaf@\xec7~?\x9d\xbb_?\xdd\x86\x80>n,\xc6\xbfV\xd6\x02?+J\x9f>Hl\xbe\xbf~\xa0\xd0>CZ\x04@\xb7`M@\xa1\x1d\xdc?6\x1dS\xbe\x04zm\xbf\xbe\xde\xf7?9F3?!L\xc5\xbf\x1et\x88?\'|\xa0?6+\x8a@\x95\xf18=\xdc\xf6\xb4>\xc3\x11\xaa>\x12\x05??b\xe1\x19?,\xb4\xfc\xbf\xb2\xd6\xfd\xbe\xb8y:\xbf\xee@\xad\xbf\xcd\x15\xdf?\xac\x97m\xbfv\x85\xb4\xbdW\xf0\xaa@\xce\x0c\xe4\xbeL\xed\xd7\xbe\xbc=\xef?v\xe2\xd1\xbe\xa9.\x1d?\xb2\xb7\x84?^\xa2U\xc0K\xa0\xa2\xbf\x08\xf6\xb5\xbf\xd5\'\xb1?2\x12\xaa\xbd3L9\xbf', b'\xa2\x80\r@\xb9\xfc<@U\x96\xa1?\x84c\xed@\xfcN\xa5?v\x03\x13@\xaf\r\xac\xbe<\x9e\xf4\xbf_\xaf\xb4\xbe\x83\xbdM>u\n\xe7?\x0b\x01\x96?\xbd\xfa\x9d?qi\xb4?\x01\xe7.\xbf\xe5\xdda\xbf\xaf\x13\x1e\xbf\xeb\xff$@}[!?\xd2\x90<\xc0\xbc=\x97=U\x18^\xc0\x85\xb8\xc6?,\xec\xb1?\xd3\xcc{?\xa1\xa5W\xc0\xb9\xa1\x1f@`?\x18\xc20\xfd\x1e@\xc7]\xe6\xbf\xe0\xfe\x83?"\x96X\xbf\xdf\xc9\x85?\x05\xdd\xa2\xbfA\xe16\xc0\xa8\xff\xbd?\xec\xc1\xb2>\x04\xd5\x15\xbfm\xfd\xeb?\x91s\x9d\xbf\x81\xf4T=\xdc\x8f\x12\xc0\xaeM3\xbf_i\xbd\xbf\xf7Z\xf7\xbf\xa5A#@\xe8)\x19\xbf,\xf1\xa4\xbf\x12\xa9\xec\xbf;\xbb\x85\xbe\n!\xaa?\xb9\xb5\x1f?#\xf3\x04\xc0\x1aSb\xbf\xa6\x0e\x82\xc0\xc4_R\xbdIp\xe8?\xd0\xcd\xa6\xbf\x01\xe6\x8a?4\xe9\x80?\x0e\xad\x9f>A\xee\xd6?\'\x88\xb8?H\xda\xd1\xbe\x97\xde2\xc0\xbb\xff\x0f\xbf\x14\xeaJ\xc0\x84 k\xbf\xe8*\x87>\x8c\xfd\xac>\x01\t\x15?8F\x16>\xd4\xc4\xd7?RtP\xbfd\x14\x1c\xc0`E\xd8\xbe\xec\x1a\xaa?\xea\x13\x00\xbf\x11\x81\x07\xc0\xe3\x03\xf0>l?U\xbf\xd5<%@\xd1\x9cW\xc0\x99\x9c\x8b\xbf\x96\xf8>?\xc1\x94\xbe?\x01_[@\xf8:\x83?\xf4\x9e\xcd>H\x9b/\xc0\x80\xa1\xda\xbe>\xaf\x82?\xca\x81|\xbfN\xdfF\xbf\xa7|\r\xbfF\x0e\x05?\x94\x89\xe4\xbfBN\xbf?\x1e~\x17\xc0\xa0\x08}\xbfp}9\xbf\r\x90K\xc0H%3\xc0\xb6o\n\xc0\x91\xd1\xd2?\x0f8h\xbd\xd1}\x93?4dG\xbf\xaa\x1b`\xbf\x11\x87\xd4\xbf_\xd3\x06@\x06^\xde\xbf\x947\x98\xbedp\xf9\xbd\x1eB\xcf\xbeqY\x85\xbf\xca\x05-A\xf1pS\xc0\x88\x06\x18\xbe:\xb3U\xbd\xc6b\x01@\xc6 \xee=\xe4\xa9\x15?\xf0[b@\x07\x95B\xbf4yP\xbf\x13\xff\xa8\xbe\xc9\xd9\xde?\xb6\xd4\xb3\xbfaI\x14\xbf\x00"\x88>/0\xde?x\x05\x05@\xc5\xaa\xd1?\xc6\x82\x8f\xbf\xfc#\xa6=\xc9\xdfV\xbf\xa1\xf2>@\xe4\xa8\x12?Q\xc3,\xbf\xee1\xa0?\x86\xe7U\xbfJ%\x04\xbe\x08Q\xf2?\xab\x93\xec?\xe7(J?Ls\xb6\xbeo\x91b\xbf\xe7I\x8d\xbe\xa1<\xa5@\xf0\xc5\xf2\xbd\x11:0=\xfe\xa7\xeb>\x89k\xf8?bQ8\xc0n\x02\xd0?\x1b\xaf\xb4\xbf@\xe4\xe3\xbeL\xd6\xa2>O\xdf\x19>6\x97\x08> 7\xa9?yN ?\x94F_\xbf\x13\xa5\t\xbfe\x1d3\xbf\x8c\x7f"\xc0^\xcb\x16@\xd7<q\xbf\xd3\t\x00@\x89\xec;\xc0\x8c\x84P\xbf\xda\xc2\x14\xc0b\x95_@\xf6\xdec?\xf3\xd2j?I\xaa6@\xac"\xbb?\x95\x95\x15\xc03{U\xc0\x98\xb1v\xbfD^\xb3\xbe\xe4f\x1b\xbfio\xa6?c\xb5\x14?u\x8f9?\xfa\x13\xaf\xbf\x12\xbf\x96?a\x16\x1b@\xf1\xfeK\xbf\xda\xd0\xe7?\xb69\x17>\xf7\xad\x0e?6\x8d\r?.\x18\xa9\xbf\xb6=2?\xfaB\x15@\x80\xae\x95;\xc9\x9b\xa1?w\xc2\xca\xbfI\x01\xc5?\x94\xfc\xea\xbe\xb8r\xb0=\r\xa0H@z?\xf2\xbf\'\xcf#\xc0\xbd\xa0\xe6\xbfW5\xcb?\xba`$@j\xa7\x8b>p\'W<\x90\x1a"@\x80\xb7\x05@\xe0!\x9e?\x88\xfc\xb2\xbf<\x90\xaf\xbe(t*\xbd$D\x86?\xc4E\x99\xbe\x89\xd3\x0b\xbd\x7f\xa4\x8f?\xaa\xde\xb1\xbf\xb0\x1cm?S!\x13\xc0,\xc9\xd2?\x1e\x8f\x05@w\x12\xc2\xbf\x0b8\xa1>\xee"V\xbe*U\x02\xc0\xcdi\xd1?\xfcW\xfd>*\x8e\xaa\xbf:\xec@\xbf\x009\xf7?,5\xfd?\x1d\x9a\x84\xbf1\xf0d?\xc2\x8a\xb9\xbf\xbf\xa2V\xbea\xe4\x00?\x1c\x1a\x8d@5,\x85@X\x9b\x83?\xb4\xdd\xf9\xbf\xc9\x83$\xbfA\xf4\x07\xc0\xf3\xd2\x00\xc0\x9d4\x9b>\xb6\x88\x8f?\xa5\x0fP\xc0\xe6r\xc5?\xa3\xe2\xb7\xbf\xa1\x1aE\xc0\xa6\xbb\x01@\x04S\xab=L\x17?@P\x80\x99>\xc7eX\xbfT8\x13>\x10\x98\x95\xbf\xa7\x0bA?\xa9\x8e\x11\xbe4+\xc5?\x9e\xbe/>%\x00p\xc0@\xfc\x94\xba\xc7\xf8\xb7?{K\x8f\xbe\xd5\x822\xc0\x9d\xa8\x1b@LF\xde?\x00\xfaE@\xb5N\xc0>\x80AI@\x9d\x9cn\xbf%\xa9\x13\xbe]\xf6\x0c\xc0o\x95\x07@}\xabp=v\x8e\xad>\xb6\n\xe1?\x03!\x10@Z-\x1f\xc0\x96<)\xc0\x11\x19-\xbf\xe4\x01<\xc0\xbe\x8e\xa1>c\xd5(?<S"@9\x14\xeb?<\xf0J@\x86\xd8\xe2=0\xdcn?.\xc9\xb0\xbe\x10g\x13?sr\x8c\xbf\xace\x99=HUt\xbf\x80>\x17\xc0X\x80\x01\xc0]_\xe0?\x84\xecr?\xf7:*@\x83\xcf\x8e\xbeJ\x90\xf9\xbe\x14\x15A\xbe\x0c=b\xc0GO\x94\xbe7\x85O?\xaa\xdd\x18@\xcbJ\xd2\xbf\xd3\xa7 \xbe"\xa0\xeb\xbfL\xfe\x0b=\xefk\xc1?\xdd\xb1\x1f?\xbc@K\xbf\xff\xc8\x13?\x9b\xa7u@\xb8\x11K@\xb7\xabZ@\xd6\xdek\xbf\xe3|;@\x8b"w?\xbe\xfc(?\xa2\xeeA?\x15\xa9\x13?Z\x9e\x0f\xbfNI\xba>\x15\xf4T\xbf\x03=R?\x8a\x97)\xbe\x9c\xad\xf4\xbf)[/\xc0\'+x=\xa6\x91`?\xe2\xf52\xbfj@z\xbf8\xdf`?\x90\x9a\x16\xbeH:\xd0?!\x07d\xc0\xfel\xc8\xbe^\xce\x12@\xbf\xb5Z@X\xe1\xce\xbd\xd1{N@"F\xc4>\x84U\xc5\xbfS\x06\x9e\xbet\xc7\x0c\xc0\x0c\x9f\x13\xbf\xa1Fb?J\xec\x80>CK\xd6\xbf\x88\xdb\x81?\x9b#\x17\xbf\x1f\x18\x98\xbeV_\x98?\x13\xda\x17\xc0\x99\x00\x17\xbf\x85}\xdd\xbfX\xf4\x81?\xa7\x88\xec?:\x0cQ\xben\xac\xb2?\xd0\x90\xf5?\x9eow>\x15\xa8\x88>\xe4\x817?\x0e\x02\x97?\xb7\t\x97\xbe\x1b\x0b\x81?\xe1\xa6+\xc0\x1fm\xac\xbf\x99\x98\xb7\xbf\x1b\x18\xe2\xbf\xb0\xf9<?\\5\xb6\xbf\x05\x87\xe6\xbf\xe6\x07\x7f>:z\x04\xbf\x8a\xfdl\xbfD\x03T>>\x11\xbb>\xd3\x1e\xe7\xbf\xe1\xa7\xb3\xbf1\xfa\x0e\xc0\xd5\xff?\xbe\x9c\xea\r\xc0&\xca\x0f\xc0\xfa\xb4\xa4\xbe\xfa\xa8\r\xc0=\xb3\xcd\xbf\xf4$\xa2\xbc\x81\x9e)?l\x16\xab\xbf\x80\xab\xeb\xbf\xee\xdf\xb0\xbfPC\x17?\x0c\x9a9\xbea/\n@\x05\xb1\xdf?Q\x96]?\xec\xea\xa3?\x18\x83\xd6>K\x0f\xee>\xf4\xb4\xdc?\xad\xd6\xee?\t\xeda\xbf\xfer\x7f\xbfJ\x9e\xa1\xbf\xecN\x07@\xd4c\xce\xbf})\xc1?\xfc\\X\xbfN\x92\xf2\xbd\xf9\xcf\xa7?\xcaV\xb0\xbfg\x7f\xc8\xbf\xab\xc6\xbc\xbej\x86\x19\xc0%\x10\x1b\xbe\x16\xf2\x18\xc0\x99\x00\x94?!\xce\xa6\xbfu\xe2m>\xd4\xc3\xb8\xbf\x02\xd6\xf4>\x07\xfb1\xbf\xe6\x949\xc0\xdb\xcf\xa3\xbf\xc3\x0f)?<\xc8\xd0>\x9e5\xb0?\x99\x07\x01@w\xb0\xc6\xc0K&\x17\xbf\xc6\xd2\x84\xbf$\xd8\xdf>\x04/P?\xedy\x01?Mr\xb2\xbf\xff\xf1R\xbf\x9e\x01A\xc0s\x07\xf8?\x1e\x92\xf9\xbeu\x87\x98\xbf\xa3Y\xaa?.j\x8d\xbf\xb9\x98K?\x15\xaff\xc0\xd4\x83\xbb?\xfb\xcd\x1c\xc0W\x11\xc7\xbfq\x8a&\xbf\x01\'\x1d?\xea\x95\x89=\xa3\x9f%\xbf\xedK\xa2\xbe\xb3\x8b\\?\xb2bS\xbf\xe0xu\xbd\xdc\x11\x08\xc0\x04{\xf3\xbf\xe0K\x07@*Q\xe8\xbfW\x0c\xd5>\x90R.\xc0v\xdb\x0c?\'\xa4A@W\x1f\xc3>\xa0}\xb7=K\x81\\?<\x02\xab?\x87y\x1c?\x83m\xda?U\x8c\x14@\x12\x88\x1b\xc0\xda\xb0\x81?\xa0\'\x90<Gv"@\xee\xc1\x8b@\x06]\x9e>\xa5\xf28?\x02\xde\xd7\xbe5\xd4\xa9\xbf\x9c\xed(=\xe6=\xeb? \xca\x88?\xe7\x92\x8a\xbf\xc6g5\xbf\xca3\xa2\xbe\x860\x06@\xcb\x93\xac\xbfHf8\xc0\x1c\x835@\xa0\x1f\x90?\xa3x\n\xc0\xceLU?\x06\x8b]?\xa9;D?\x03\xb2\x8d\xber^\xb5=\t\x9a\x9a?\xa4x\xe3\xbf\xf8I\xf3\xbd\xbe\x1b\x95\xbf6\x9e\xa8\xbf]V\x1a\xc0\x05\xb9h?\xf8kc@\xba{=>W\xb58?\xec*<\xbeR\x17\x99\xbf\x93\xae\xe1>\xe6\xe3\xe7>/e\x14\xc0\xd9l\x9d=hl\r\xbf\x15|=\xc0i\xa3\xe5\xbf\x96Fr>\xa4\x1c!=\xef{O@\x97f+@\xd1>S?\xe7\x94#?\x91C\x0f?9\x80\x16?\x97N\x01\xbfq\xdc\xda?R\xe0X\xbfv\r\r@\x16\x8e\xed>\x1f\xc2"@\x10m/?\x17\xefC@zv-\xc0\xc1\x1bz?\xb2\xfdO?\xd6\x1d\xdc\xbf\x8f\x99I\xbf\xdf\xbd\xc1>\x05\x80\xc7>Sw;\xbf\xe8\xdd\xa6>\x9a\x15\n@\x82\xfc\x84\xbe\xe8A\x15=\xf2\xb7\x99\xc0>\x9a\x12?\xbd\xde\xee\xbf\xbe)\xb4\xbf\xb3\x8f\x85?v`#\xc0\xdb\xc0)\xbf\xdc\xddJ@%\x91\xd1?\xfb\xcf\xc4?\x9d\xcf\xe9?\xfdZ\x12>$\xea\x14>T\xe5\xb9?\xea\x16~?\xda\xee[\xc0\x92\xdbm\xbf\xe66\x88?\n\xa5\xd4=\x8c&S@Yd\xa1>\x995\x17\xbf\x04%\t?\x81a\x80\xbf\xf0V\xc8\xbfb\x05\xef\xbf\x95e\xb8\xbf\x8e\xcd\xea\xbe\xf4u\xd7\xbf/\xd8\xb3?\xef\x9b\x08@6\n\x12\xc0R\x8f\x16\xbe\xec\xb7\x82?\xab\xae\t@\x93\xb2-\xc0\xe4\xfd\x9e\xbf\x05\x02\x97\xbdc\xd5\xca?\x9f\x94\xe3?^\xb8p?\xed\x85_\xbf\r\xd3\x1f@\x0f}\xa9\xbf{\x80\x8f\xbfS\x1f\xd2\xbet\xa3\x15@\xb2\x9fY>\xcb,^>2\xa1\x1e?y\xdci?\x17>\x8c\xbf\xa3\x1b\xea>VSV>\xa3\xd8y?PAh\xbf\xda*\xe2?\xc2\xdc\xc4\xbec\x02\x83\xbe\xcb^\x85=\xdd\x0e\xa2\xbf\xfc>\x8c\xc0\xa41\x9b=\xd7\x1f\xb6?sG\xbf=\xb1.\x13?\xe9\x812\xc0r\x9e\xda>R\xe2\xe4>Z\xa7\xae\xbf$C\xa4><q\x06\xc0\x82P\xfe>\xe0\xa0\xd0?X\xe5z\xbf\xd9\xde\xd1?Q\x92Q?\xf8\xdd\x80\xbc\x9a\xb6r\xc0\xa1\xa6#?V\x9d\xb9?\x8e\xf0k\xbf\xeco$@W@J?\xcc\xbeo\xc0\x05\x87\xaa?\xfd\xde\x98>\x7f\x97\x01?\xe6\x82\xda\xbf9W\n@\x867\x80\xbf\xc9\xa50?9\xef\x06?\x12\xe7\xbe\xbd::\xa8=\'\x81\t\xbf\x15\x94%\xbf\xc8 \xb2\xbc\xa04\xac\xbd\xb8\xfd\xff>\xebv8\xc01Y\x90@\x0e"d>\x9f\xe9s@<Ky\xbf\xdbM\x14?\t\rD>v\xe4\xd2>/\xdf \xbf0\xa9??0?4?\x96\xd61\xbfS\xff\xb2?\xcc\xa4&@J(\x18@f]\xf1?\xad`\xc6?\xe06\xa8>\xc8\x83Q?\xfb\xa8@>\x1as\xea?R\x9e(?\xf1>\x89?\x08n\x18\xc0\x8a\xffc@\x8c\xc7\xa5?\xe4\xb0\xc5\xbca\xd1T\xbf\xea\xe4\xe6\xbd\xcb9\xd6\xbf-\x17$@\xa2N\xd4\xbe>\xf0\xbd\xbf\x88K\xc4>]\xdb\xd9\xbfN\x05f?\x8c\xee\x0f\xc0z1}?d6\xa5\xbf-\x99\x17A\xb2\x04(\xc0*\x18a\xbez\xa7?@\xb3\xc6N?f\xfcx\xbd&\xa8;\xbf\xb9\x7f\xd5>U\x95\xd3\xbfB\x11\xab?\x9c\xc6\xa3?\x90\xbd\x05?\xc2\xc3\x19\xc0?r\x10@XH\xca?a\x8b\x8f\xbeT\xf4=\xc0\x14\xd0\xe9>\x9eq\xf5>\xcf\xca\x85\xbfW\xcc>\xc0W\xfc5\xc0\xd2\xc6\xf7?Q\xb5\xe3?\xebwL?\x8e\x04\xe0\xbf\x08/@>\xf1\x15\x03?\xcd\xcf\xc3\xbf\xc6\x91\x1f>MC\xdc>\xba\xcd\x1f\xbeJ}\xa9@\xebY\x95?\x9dtc?\xacW\x07\xbdzn\x97\xbf29K?\xae\x952\xbe\xd3d\xd2\xbf\x0e\xfcY?\xb6\xad\x12@\xf8\xbd1@^\xbe\xfa?\xb4\x9b0\xbd\xfcT\xc1\xbf\x9e\x0f\xfe?3\xee\r?\xeb\x9d\xca\xbfJ\xd3\xab?\x86\x18\xb6?\xc9<\x84@U];>\xf0\x01\xa6=\xf4#\x00?\xe82\x1e?(1L?\xb7\xbe\xde\xbf\xf8\xeb.\xbf\xac\xa7/\xbf\x8f\xfa\x9b\xbfZ\x1c\xc2?\xe1\x8a]\xbf\x90>e\xbbV\x1f\x9e@\n\x81\x83\xbfD\xfb\n\xbf\xec\xc8\x02@\x90\xc4\xa6<\nuI?\x84e\xa8?s^]\xc0U$\xc3\xbfZ\xf6\xe4\xbf\xc4\xb0\xb8?<\x8d\x11>\xdc\x9a:\xbe', b'\xa0\x16\x15@\x1d\xbe:@\x13B\xaa?\x16\x02\xfa@\xbb\xa0\xa6?C\xa4\x02@\xf7\xef\x1a\xbf\x14b\xd4\xbfZgb\xbe\xcc\xb2\x96>\xc3\xa8\xf6?w\x12\xba?zP\xc6?M[\xc4?\xbd\xad\x19\xbfGO\xa7\xbf\xde\xf4-\xbf\x94g\x1f@\x18\xe4,?EH1\xc0\xa17\xf3>\xa8\x92M\xc0\xb18\xb8?(\x11\xb1?\xdc#\xd2?\x9b\nt\xc0*\x843@\xa2\x12\x1c\xc2\xf4\x99\x0e@\xf4?\x04\xc0M\x10\xc6?*\xc8|\xbf\xdbA\x86?k\x95\xcb\xbf!T\'\xc0@\x1d\x83?\x95\xe3\x8f>n;\xad\xbe\xd8\xdc\x05@_*\xab\xbf\xa4U\xdb\xbe\xea\xe66\xc0[|f\xbf\xc9\xe7\x91\xbfC\x8c\xc9\xbf\xbdA,@\x01\x1b\n\xbfM\x15\x84\xbf1\xb0\xdc\xbf\x9d?\x9c>\xed\xfe\xbe?\x04bp?F\xa5\xd7\xbfb,\x8e\xbf2\x1bn\xc0A\xd6(>\xf8\x1d\xbe?0\xe4\xc6\xbfo\xcd\x9f?\xd4\x1e\x83?\xafh.?\x14\xb3\xd5?g\x07\xae?\x14\x03K\xbf\x01R\x0b\xc0\xb7h\x11\xbeJ*W\xc0\xbe\xa8/\xbf j\xe0;\xfa\xe6\x86?\xe7\x9c3>\xb2\x7f\x83\xbeo\xae\xa9?\xf7\x1a\x00\xbf\x88(!\xc0i4\x84\xbd\x04`\xd6?\x9a\xd9\x0e\xbf\xcc\xb4\xf3\xbf\xf8\xa7\xfe>\x864o\xbf?\x97A@.\xfaL\xc0\xd5\xc5\x9c\xbf\xb8\x12\xab?\r\xec\xa0?\xd2\x99B@\xe4qd>\xe0\xc7\xd8=\xbdQ)\xc0\xcc\xac\x9e=\xa48\\?k\xd37\xbf\xb8O\xc2\xbe\x1fL\xa4\xbe\xbf\xc4\x9a>\xa5\x98\xb1\xbf\x07\x90\xcb?\xc8\xdf\xef\xbf\xc0\x08\x8a\xbf\x84\x85~\xbf\xca\xf1C\xc0\r~#\xc0\x03\xbd\xcc\xbf\x89\x0c\xf8?\xd3\xd1\x1e>\x97\xae\x8a?\xf2\xb1\x80\xbf\xbe\xb1r\xbf\x15 \n\xc0\xa6\xad6@\xae\x1a\xd3\xbfM\xee/\xbeI\x96\xa2>\x07\xce\x06\xbf4\xcbD\xbf\xd3\xd83A\x0f\x8f\\\xc04V\xde>\xcb\xa7f\xbf\xf9s\xed?\xfeB\xce=\xb7\x983>Ffr@,y]\xbdZ\xe3\x19\xbfg\x02\x14\xbf\x02v\xfc?G\xc7\xe0\xbf\xfc\xd9H\xbf.T\x10>\x87E\xab?i\x1e\n@\xb0{\xff?\xa0\x9d\xed\xbf\xc1\xea\xa1=8L\x92\xbfx\\N@\xf1\xbc<?\xe5\x9a\xb9\xbe \xbf\xb1?\xe2\xd5\x14\xbf4\x9d\xdb\xbe\xfd\xee\x0e@Fd\xde?"\xc5+?j\xaa\xc1\xbe3\x98f\xbf>\xea\x97\xbe\xaa\x00\x9a@Ae\xa4\xbe\x07\x98\x03\xbfj\x17\x88?.\xfd\xde?\xc4&*\xc0\x0e8\x00@\x8e\x01\xb3\xbf\x12\xbe9\xbe\xdc\xbe\x8d<\xc5!/\xbe\xb2j\x86>G\x9b\xa0?-\xac<?\x9b\x14V\xbf\x05Y\x80\xbe(\xce(\xbf:\x00\'\xc0\xb3.\'@\x05\xbc\x00\xbf\xa9\x9d\x00@\xc5\x12?\xc0\x03\xe0\x86\xbf\xc8\x15\x14\xc0\xbc#U@1\xea\r?\x9cVa?\xe8\x038@h\xd0\xb3?\x12d\x01\xc0\xaa\x84K\xc0\xc4{\x7f\xbf\x8e_#\xbfpb-\xbf\x02\x8e\x05@\'\xe6\x86?\xfc\x0eY?y\xa7\x86\xbf\xb2\x1d\x03?\xfe\xef\x01@\xc6\x8f\x92\xbe\x83\xad\xbe?@\xcf\x8f\xbd\xa0\x96]>\x17\x97\'?\xd2o\xad\xbf{\x93\xbc>w\xe7\x11@R\x9b\xa3=\xe5\xc3\x9c?\x82\x9b\x89\xbfMg\x06@(s\r>\xf4\xa4\x81>1\x91I@/\x8a\xdd\xbf\x98\xc9\xf6\xbf\x93\x00\xe6\xbfk\xaf\xc2?4\xc8B@\xa0\xbf3>\x8e\x9c{\xbe\xa2\x92\x19@\xcd\xf9\x08@^[R?\xe8\x97|\xbf\\\x013\xbf\xf7 ^>\x1e\x89\x88?\x08\xe7\xca\xbe\x1c\xef\x0f\xbe.\xa5\x85?h\xed\xb7\xbfRV\xa3?cC\x10\xc0|p\xfe?\xc1\xaa\xcc?\xd5E\xd0\xbfU\x16\xfc>pj\x99\xbcf\xe1\x0b\xc0t\xae\xcb?<\x00\x03="\x7fL\xbf#h\xb6\xbe\x94\xe2\r@qZ\xe5?9\x1c\x88\xbf\x0f\x0e%?\xf2\xc6\xd4\xbf\xc2Qm\xbe@Z\xfe>\x93\x02\x84@\xc5\xf1w@\xb6kj?\xa6\xe6\xf8\xbf\x9f\x18\x0f\xbf\xa8\xe3\xe9\xbf\x8a$\x08\xc0\x08W\x01?\xdbA ?\xb3W0\xc0=u\x99?\xf3\xa7\xa6\xbf_Z-\xc0\xb7\x10\xdd?\x9f\xa6\xd7=\x1d\xb7\x1e@\ti_>=\xca\xa7\xbf\x04\x07\xbd\xbd\xd5^A\xbf\xa2x\xa7>8\xdc\xd4>\xbc[+?1j\x12?\xaa\x11\x82\xc0<D\xb7\xbd\x99\xca\xd2?\x1a;\x00\xbf\xcc|8\xc0q\x0f1@J<\xd9?c\xe4<@\x9c\xbd\xff\xbc\xca[_@\xb4\xceT\xbfX+\x05<\xd3v\x01\xc06\xf3\xe6?\xb6\xf2k\xbe<p\x80>\x8b\x96\x08@\xa7!\xfb?\xe6\x10\x0e\xc0\xd7k\x1b\xc0 _\x1a\xbfy\xac7\xc0_e\x9e\xbe\xd3\x06\xd8>gY\x01@\x05\xd0\xe7?\xe2\x9e6@S\xf2\x91\xbe\xaf\xa6\x8b?&\xb3 >\xbe^\x92>\xfe\xcbH\xbf\xbf\xde\x9e=\xd5\x91\x83\xbf\xd8\xec\x03\xc0\x07\xeb\xd8\xbf>\x0f\xe8?\xfc\xfa\x11?\xe4Y\x19@\xf9\x0f!\xbf\xb2l\x12\xbf\x00\x03\x81:\x1d\x02e\xc0\xa0\x88:\xbfM\x96y?\x8f\x85\x08@j\xa5\xf1\xbfH\x18C\xbe\x9a!\xdf\xbfD\xf9\xab>5l\xbe?\x18\t\x96?`\xd6\x13\xbfh\xae4?tph@\xafzP@\x1e\xe3N@\xff\x8bp\xbf,J8@\xb3P_?Q2y>\xf2\x02\x0e?x\xedh>\xf0\xd9S=\xa8\x82d\xbe\xe3N\'\xbf\n\xad\xe2>\x90\xd8\x1d\xbe^q\xee\xbfE\x92\x17\xc0\xe4,0\xbe\xa8U4?\xa7\xe9\x13\xbf3*-\xbfkF\x82?\x82\x8c\x83\xbf,\xa5\xa9?V\xb5I\xc0\xf06@=\x0b\xd5\'@W\xe3j@dx\xe9\xbdu\xba9@\xe6\x16\x0e>k\xber\xbf4 \x1a\xbe\x01z\x1b\xc0\x08\x04\xac\xbe\xb9A)?\xf8\xac\x8b\xbd\x0e\xa5\xb6\xbf\t\xc6\xc3?\xfb\x0c$\xbfM\xd6d=*D\x84?\xf7\xf5\x10\xc0\x19\xb7\xa8\xbd\xffq\xda\xbf%\x1b\xb4>\xf2\x0b\xb3?\xc0A\xdc=\x08\x8fo?C\x12\xfc?b\x8a<>ng\x1a?\x99\xb1\x83>\\\x8b\xd4?kt\xc3\xbe\x82\x84\x08>\xc7<\x19\xc0\x97\xe1\xd3\xbf\xa4\\\x93\xbf\xd3\x04\xd1\xbfe\xd9\xb0>\xf8\x84\xbf\xbf9\xbb\xc7\xbf\x97t\x8c>LjR\xbf\x15F\x82\xbfH\x10\x9d\xbd\xd9\xf2\x11?\x8b\x03\xf5\xbf\xf4\xfd\xb8\xbfT\x95\x0c\xc0\x83\x179\xbe@\xd7\xfd\xbfQ2\x1d\xc0\xba\xeeN=\xfdN\xb4\xbfa\xe7\x14\xc0\x1e\xea\xdd\xbe\x15@\xdf>!_\xda\xbf\xde\xce\xd7\xbfh\x14\xaf\xbf/\xf4\x16?\x13<\xac\xbe\xc7\x0e\x13@\xb4\xe8\xe3?\xe5\xce\xf6>\x0fe\xb1?\xea,\x9d\xbe\x00\xb4\x13<\x19{\xd6?)\x8d\xd1?\x9d\xa7Y\xbfh8_\xbf9i\x99\xbf$\x0f#@\xa6\xbc\x9c\xbf\xf8\x94\x9a?\x10T\x98\xbfJ\x18\'\xbe\xffo\xbb?\x05\xe6\xec\xbf\x99\x11\xcc\xbfK\xb3\'\xbe\x99=\t\xc0X\xc6\x19>`\x1f\xf7\xbf\xa8\xbdC?\xc79\xc2\xbf\x02\xaa\xb6>\x88\x13o\xbf#\x17\x8b>\x14<-\xbf<\x0f4\xc0\xee\x1e\x97\xbf\xd6\xcb4?\x00J\xe6=\xc4\xcc\t@~\xe5\x07@s\xe6\xbe\xc0\xdc\x11\xa3>IC\xc3\xbfT\x05M>0L\xec>\x0f$h?\xc4g\xc5\xbf\xc2\xdam\xbfX5*\xc0\x81\x97\xea?\x9c\x89\xc5\xbe\xe5Y\xd6\xbf-"\xc6?\xe2\xfd{\xbfod\xc4>\x165Y\xc0I\x07\xcb?\xf1e2\xc0\xaa#\xc5\xbf_\x0c\x13\xbfP\xd9\xda>\xa5\x0c\xcc>v\xdfM\xbf\x88H\xa9\xbe8\x19\x1e?l@(\xbf\x0e\xd9{\xbeN\xf4\xca\xbf\x8c\xc1\x08\xc003\r@\x7f\t\xc0\xbfb2<?\'c\x0b\xc0f\x003?\xe8{u@\x85Nu>^\xbbv\xbe\xc2\x19\xc8>\xf6\xea\xa8?\xf8\x883?N\xcaZ?\xbd:\x03@\x8c\xc4\x05\xc0\x19I\x18?\x1fh\xfc>\xa3\xe1!@\xa1\xac\x81@\xe2\x92\xd4=~q\x81?{j"\xbf\'\x98\x89\xbf<\xd9\x0f?;\xc7\xf1?dO\x92?\xa0@e\xbf]\xceP\xbfpu\xb5\xbdU\xab\xad?D\x19\xab\xbf\xfd\x9d>\xc0p\\4@,1\xa0?R\xbf\x06\xc0(\x90(?\xe5l]?\xe8\x1d,?X\xb4c<\x15\xe3\xa5>\xb6\x83\xd4?\x8b\xd5\xe1\xbf\xb4\x1d]\xbe\xc6\xaa\x9d\xbf\x14\x8c\xa5\xbf\x96\xa7\x1f\xc0\xdc]6?:Lr@\x08Ca\xbe\x96\x9a\x84?\x80\xc1B=\xf3r\xd8\xbf\x90n\x05?\xd1_~?\xd1\xca\xee\xbf\x90\x0c\x86\xbd\xd1\xc5\x12\xbf\x8eI&\xc0\x9bm\x04\xc0 \x13G=\x01\x15\xa2>\x7f\xb2C@\'\xa4\x11@\x8b6\xba?\xcb\xc6s?e8\x08?\x06\\\x18?v`\xd0\xbe=\xed\xd8?\x9c\xc6,\xbe;\xe8\r@\x1ctI>\x04F @\x18\x00\x80?\x99;m@\xcb\x968\xc0#@\xa2?\xb9h\x0c?\xa6\x91\xfa\xbfYK\x06\xbf\x08|\xe9>\x12f\xa1>\xcc\x8d8\xbfa\xa4\xa6\xbe\xc1\xf1\x03@\xcb\xa5\x88\xbd\xaa\xbb(\xbe\rk\x92\xc0\xab;1?\xeen\x06\xc0\xe0e\x8d\xbf\x15\xec\x9e?f\xbf\x06\xc0\x8cCw\xbf\x94\xcfj@\xaf\x06\xc5?\xc6"\xd2?\xca\xc0\xb5?:%\xaa<\x11e\x03>\x95}\xab?\xce\xae\x90?\xed\xee4\xc0\x15u\x87\xbf\xf3F\x80?!<\xc7>\x1f\xdeK@\xb0Lq?\x97E[\xbeA\xea1>k{\x8e\xbf%\xb2\x80\xbf\xd9t\xb3\xbf\x16\nX\xbf\xe7k1\xbf\xf6\xf5\xdc\xbf{\xf6\xef?.Y\x03@\xfb\xdd\x03\xc0w\xa7\xae\xbe\xfa(\x8e?\xf4\xb1\xda?\xdc\x81#\xc0`\xa9\x98\xbf\xba\xce\x97\xbd\xd6\xb8\xff?\x14\x95\xb3?b(\xb5>`\xbc\x8a\xbf\x95+)@\xac\x03\xb4\xbf\t \xb3\xbfu\x92\x14\xbf\xe9\xe9\xf8?\x05\xcd\x96>\xd7\x1d\xff=\x19\x14\xd8=<\x93\x80?\xd2z\xdc\xbe\xbb\'\xaa>L~\xf9<\xa6\xcf\x87?\x97\x944\xbf\xe7\x89\xca?\xc4\xb5\xfd\xbd\x99\x9b\xbd>\xdc\xa5\xaa>\xe3j\xeb\xbf\xa3\xe2v\xc03#\xc0=\x9d\x0ei?d\x92\xdf>\xee\x1eq=or9\xc0A\x16\xb6=\x8a@\xed=l\xb6\x89\xbf \x80\x8b;+\x13\x08\xc0\x0c\xc7Y?\x9e?\xab?\xebz\x81\xbf\xba\xff\xa7?b\\\x80?\x84#\xe1\xbez\xf8p\xc0k\x9a\x9a?\xb10\x86?\x883\x8a\xbf\x01\xc6\x0c@\x87\x00=?\xd2\x10r\xc01\xf4\xca?\x96w\xef=\x0e\x89I?f\x11p\xbf4\x81\xda?Y\xeb[\xbfM\xd2\x14?\xa0\x9e/=\x9f\xd37\xbd\xae\x0f\xaa\xbe\xe0r\x07\xbfB\x9b\x18\xbf\xa4\xe3\x96\xbd\x00\xee\xd0:Z\xba\xff=\xf5\xf0\x03\xc0B\x0f\x84@\xc6e\x01?\x97\x97R@\x14\xc5M\xbf\xd7\x05"?\x8e\xb5\xde>\xf8\x0e>\xbd\xf1\xe3@\xbf\xa16\x06?\x1b\xdf\xe2>/\xd3\xea\xbe=\xde\x80?\xcdt\xda?}\xad\x16@\xeat\x07@/\xd8\x95?s\x01\x10?\xaea\x80>\x966\xea\xbeJ:\xc8?~?q?06\xfc?\x01\xa4\x18\xc02uS@\x90\xcb\xb3?\xeeE-?\x88\x05\x00\xbf\x11^Y>\x19\xd6\xcf\xbfd(\x12@W\x8b)\xbf\xe36\xc3\xbfJ\xeb\x8e=\xdc\xe2\xf7\xbf\xef5H?\xbd\xf1\x05\xc0ta\x9f?\xa4U\x83\xbf\xb9s\x0bA\xeb\x17\r\xc0\xb8,\xc4\xbeW\x8eL@\xb6)\r?\xb9\xe8\x88<*\xafj\xbf\x9b\xfd\xbf>g>\xe0\xbf<\xe0\x90?&\xb9\x87? z\x12\xbbs\xba\x02\xc0]\x96\x0e@TU\xca?\xb8\x9e6\xbe\x94\xa9K\xc0;\xfcL?_\xe3\xef>\x88<\xa2\xbf{uL\xc0\xdba=\xc0V\x92\xd3?\xdcn\xb9?Z{t?.\xc2\xd1\xbf\x92:\xd1\xbe[\x96T?!\xad\xda\xbfd\xf9\xdf<\xa4L\'?\xb4\x93\x9f\xbd \xb9\xa8@\r\xcc\xab?[A\x81?Ru\x9e\xbe\x11V\x89\xbf?_X?\xa4\x99\xc1=\xdd\xd1\xf9\xbf\xa7u\xf0>+y\xe4?kk\x1d@&P\x11@t\x01\xc8>\xb7\xb6B\xbf\xe8_\xc6?\xa0\xdb\x1f>b\xef\xc4\xbf\xdd\x9b\xa5?O\xc3\xa9?\xb4\x84w@C\xdc\x8d>fv\xbf>\x19\\\x94>\x0fb\xe8>Z\xb3[?O\x02\x97\xbfL1e\xbf\x8b\xb2\xcd\xbe6[\xa1\xbf\x1e\xea\xaa?\x80\xa3\x99\xbf04\xbe\xbb`4\x95@\xa9\xa22\xbf\xa0u\xfe\xbd\x12\xe6\x08@\xb4\xd8\xff\xbd\x0b\xda\x93>\x87\x16j?;\xad7\xc0Y\xcd\xb2\xbf\x8fj\xa3\xbf\xb7k\xbf?\x96\xb7\xcf>}\xcc\x0f\xbf', b'/\xff\x08@\xef;<@rC\x8a?\x12M\x07A\xeb\x99\xc9?\x9cB\x1a@J\xd7\x8f\xbe\xb8\xa7\xd5\xbf\x18m\x1a\xbf`\xcfZ=\x0b\xda\xfd?\xc9\xc7\x84?\xc8\xee\xa2?\xb56\xa0?\xac@z\xbf\xc89\x9f\xbfB\x7f0\xbf\xd7`9@,ZR?fRQ\xc0^\xff\x92=[\xac]\xc0 \xe7\xc4?\xdd-\xf7?Y=\xb4?\xf1\x94a\xc0\x0e\xfc\x1c@\xa1l\x1b\xc2=\xd4\x17@:\xb7\x00\xc0L\x8f\xb4?w(y\xbf\x87u#?"\xa9\xa2\xbfZZ&\xc0\x10\xb5|?|"\x07>\xdb\xb5\x80\xbe\x89f\xfd?\xc2\xbec\xbf\xbd\x8eR\xbf\xef\xa5&\xc0[\x01\x0b\xbf3\xd9\xab\xbf\x93\xd5\x9c\xbf!Y\x1d@\xfd3\x11\xbfgE\xa0\xbfY\xee\xc0\xbf\x89\xf2\xc8=&T\xa5?\xca!\xb2>\xd7\x0f\r\xc0\x80\x14u\xbfrue\xc0nb\x97>\x18\xe2\xcd?\x94\x8e\xa6\xbf\x9e\x83\x08?\xfe2\xa2?OU\xf4>~]\x0e@\xd8\x08\xaf?`r\n>\x87\xd8\n\xc0<\xeaI\xbebwW\xc0\xc0~\x10\xbf\xda\x0c\xfb>\xbf\xfa!?8\x19\xcf>lc\xb3>$\x01\x86?\xd0\x93A\xbf\xcaR-\xc0|+\xef\xbc\xf5\xbe\xe5?\xa2\x82\x81\xbf\nF\xfc\xbf\xb5e\xcf>U\x1c\x8c\xbf\xcb\xd5&@#@@\xc0\x08\x81u\xbf\xc8\xdc\x8d?\x07t\x86?\xecNH@_\xfa4?\x00{N<\xa1\xfe,\xc0\x0cem\xbel\x93P?\xef\xa9\x06\xbf\xe9\xdc\x8b\xbe;\xed\x0e\xbf\xce\xb9-?\xc8\xca\xd8\xbf\x07C\xa2?/z\xd6\xbf\xd1s)\xbf"\xf3j\xbfj\xb5J\xc0/\x80,\xc0Ua\xbb\xbfU\xcf\xf3?\x96\x08t>\xb9\r\x8b?\' \x87\xbf\x9c\xb8g\xbfB\xe0\xfd\xbfuO\x13@\x05\x84\xa3\xbf\x94\xa0[\xbc\x9c\x17\x96\xbdN$K\xbf\x94K\x98\xbf\xa8N2Au&=\xc0\x1c\xad\x0f?\xe8\xbc\x8d\xbdG\xd4\x03@>\x86}\xbe\xf68\x16?\xe8{j@S\xde,\xbf-\xc6z\xbfXn5\xbf\xef.\xc0?f\xbe\xd7\xbf\x1e\xb9\x88\xbf\xfc\x85l\xbd\x80`\xf6?\xf4\xdb\xc9?\x83u-@\x8b]\xf0\xbfx\xc6(>\xa9\xff\x00\xbf\xd1PG@\xf4\xda\x17?\xb5\x12\x1f\xbf\xdfcU?\xb2\x94\x08\xbf\'\xe5\x1e\xbf\xdb\'\x0b@t(\xd9?\x7fQl?\x90\xb3.\xbe\x1cI\x13\xbfGH\x86>\xa8\xc1\x9c@,\xb8\xb6\xbd\x8f\xeb\xd2\xbe\x10s:?\x97{\x1a@\xbe\xc7\x0e\xc0\xe6|\xff?F,\x94\xbf:\xb7D\xbeX~n\xbe)\xa2\x19\xbeN\x10\x80>C;\x9c??\xb0_\xbdWV\x14\xbf\xd1b\xfb\xbe\xe35\'\xbfs\x05#\xc0S\x12/@2\x17n\xbe\x1b\xe7\xe7?Y\x02\x19\xc0\xea\x01~\xbfC3\x1b\xc0L\xf5R@\xef6\xff>\xfd\xf7\x9e?\xc5\xd8f@\xfe\x03\xb1? \x80\x11\xc0\xc8\xf0F\xc0\xf0k\xab\xbf\x80\xc33\xbf0dk\xbfP\xe2\xac?\xf7\xdf\xc1>\xc9\x8a\'?\xda\x8a\xe4\xbe\x83Zo?\x9e\x8d\n@\x0bl\x0e\xbf%m\xe7?d\xde\xbb>\x8b\xebI>\x82"\xe6>\xca\xbc\xcb\xbf\xe5\x8eF>r}\x08@v\xaa\xb0>RS\xae?f\xb5\xb7\xbft\x18\xfa?\x0c\xf6\x9e\xbd\xa8\xe8K\xbc\xde\x111@\x9b\xc2\xf2\xbf,\xdc8\xc0:V\xbb\xbfp\x88\xc6?<\xceL@\xfdKd>4c\xa4=\x02}\x14@\x90\xc4\xf9?\xc0^\x84?\xb9\x87\x8e\xbf\x02\xa11\xbf\x8d\xcb\xb1>&\xdd\x92?;\x8e\x12\xbfl\xbd\xa1=9\xf0\x91?\xf1\xc8\xf1\xbf\x17\xd3Y?\x9c\xf0\x06\xc0T\xb6\xe3?H\xeb\xd8?\xd0\xacz\xbf\\\xad\n?x\xd77\xbd\xe2\xe0\x04\xc0\x1a\x15\xa0?\x04\x7f\x12>\xe4\xd2\xd4\xbfJ]U\xbf\xd3r\x1a@J\xe2\xc5?\xe4\x8b\x10\xbf\x99\xd8*?\x18j\xb1\xbf\x81m(\xbf\xdb\xfbD=\xdeqd@Q(\x89@qH\xbf?\\S\xd5\xbf\x05\xf9;\xbf\xceO\x00\xc0@\x15\x11\xc0\x01\xf7\xbb>\xd8\x8ex?\x18\x13+\xc0\xf6\'\xb6?}\x02\xd7\xbf\xc7\x0e3\xc0\xa5I\x8b?\x1c\x12\x14\xbe\x7fJ:@\x19\x1d\xca>\xee\xf6\xed\xbe\x16Ff>Zo\xc3\xbeh\xd3\x17?\xbc\x89\xdd>\xe5\x00P?\xc3@\x18?,E\x8f\xc0(.-<:f\xef?\xa0\xddq\xbf8a3\xc0\x06\xc2D@\xce\xe8\xf6?\xe4H*@\x90\x8a\x80\xbe\x0ekr@\x07\x9e\xdc\xbe\xfe\xaf \xbeE\xf3\xd5\xbfL\t\xfe?w\xb4\x88\xbe\xb8vY=+\x99\x0c@\xf3\x0e\x15@\xd6\xdd\xfa\xbfh\x95\x13\xc0\xb0\xc0\xc4\xbe\xc2\xd3#\xc0\\\x1d\x00\xbe\xbd\x96\xad>\xef\xfd\x1c@\x10\xcd\xed?\xe8\x04F@\xb2\x8c\xef\xbe\x17\xfb\xcc?6\xdd\x9c\xbd\xd8_\x94\xbe\xfa\xc7\x02\xbf\xf6r\x16\xbeZ\xa1\xcf\xbf\x85\xcb\xc3\xbfd}\xf4\xbf\x9e\xf9\xce?\xb0\xc5\x9f?\x8a\x05\x1f@{\x96\x94\xbeb\xd3\x06\xbf\xd6JJ\xbe\xf46W\xc0NV\x1d\xbf\x06\xf6y?\xd7\x1a\x0c@%\x01\x0c\xc0\xe3\x0e\x9d\xbe\x9b\x14\xe6\xbf\xd7h\r\xbe\xc92\xd7?{\xadJ?q\x03\'\xbf\x1d\xde\x85?\x883\x89@\x9a\xdeZ@\xd0\xd0.@k<:\xbf]\xd5\x1f@\x96\xec\x92?\x10\x9c\xbb=mQ\x9b?D \xcb>:4\x1f?\xf0St\xbe\xb0\x87q\xbf\xf8\xbf\x81?\x9a\xc5\xc7\xbe\xfd\t\xd3\xbf\xf2\xbe3\xc0\xa2\xa9\xb7\xbe\x1e7t?V\xc5\xa2\xbdz%w\xbf\x84:\x99?\xf4\xe4\xa1\xbf\xe2\xe2\x88?\xc7w6\xc0\x14\xe4q>E14@5\nZ@N\x9cL\xbf\xab80@\x1c\xc7\xee=&6s\xbf\xd0V\x8d\xbe\xb6\x0b+\xc0\x8d \x18\xbf.\xaa\x04?\xd8H4<\xca%\xc3\xbf9E\xa3?B\x1f&\xbfp\xd8\xe1\xbeZb\xb2?\x1a\xdf!\xc0\xe8\xd2\xb9\xbe\xa8\x81\xe7\xbf\x04\x8e\x0e?\xa8\xc0\xcc?M\x19&\xbez\x7f\xb3?p\x0c\xf8?\xc1\x9d\x89>\xb2m\x9f>\xbb\xd6\x03?\xbc\xe3\xe1?\x9c\x84>\xbe\xdbF\x07?v\xd6\x0e\xc0K\xd3\xb8\xbf\xac.F\xbf\x88\xec\xc4\xbf\x0e\x948?\xec\x9f\xd9\xbf\xda\x0e\xbd\xbf\x7fnO>\x01tJ\xbf\xdc\xaa\x9e\xbf\x94a\xa3\xbe\xbe\x0f\xa5\xbd\xae\x97\xc3\xbf\xe9\x9b`\xbf\xa5\xe4$\xc0\x1c]\xaa\xbe+\n\xed\xbf\x03\xc84\xc0\xee[\xd7\xbe\xd8\xf7\xe2\xbf\xd4b\x1c\xc0t\xe5\xa4\xbed3(?:_\xef\xbf-\x8c\xbf\xbf\xddC\xbd\xbfOJ\x84?\x88&\'>]\x9b\xe8?KV\n@\xaf\xd3D?\xa5\xe5\xde>\xe9\x9f\xac>\x01\x93\xb1\xbe~\x7f\xde?:\xa3\xf9?\xa6iN\xbfA\xa1\x9f\xbf}_\x92\xbfU\xfd)@\x98Il\xbf$>\xc5?\x98\x94\xae\xbf\xeb\xef\xc8\xbe\xcdu\xc8?\x8eP\xba\xbfA\x8a\xaf\xbf\xed\x9a\xaf\xbd\xd5\xe7\x07\xc0\xccQ\xec>x8\xd6\xbf\x8cu(?\xbc\xc0\xc0\xbf\xe0\x13\x02>Y-\x8c\xbf\xaa\x13s?\xac\xda\x1b\xbf\x00\x1d6\xc0\x9e\xc0\xaa\xbf\x08\xf79?\x8b\xeb\x02\xbf\xcb\xc6\x01@\xb2\xa7\xf5?\x0b\x9b\xcb\xc0\x1a\x98\xdb=\x8b\x8a\x84\xbf\xb2\xdd8>\xf8\x1e9?\xc0\x80\xc9;6\x7f\x11\xbf\xf4/\xd6\xbf\xca68\xc0\xdb8\xcf?(\r\xda\xbe\xf7\x8b\xda\xbf\xc2m\xc8?A[V\xbf\xe63\x16?\xd3\xa9D\xc0\xbb\xb1\xe2?J&+\xc0\xd6\xbb\xe1\xbf\x88\xf0/\xbf\xf5;q?:\xe2\n?\xa2\xd1,\xbf\\\x13\xd8\xbd\x02\xb7h>\xce\xb3\xde\xbe\x9c\x14`\xbf\xa5b\xdb\xbf\x1b\xff\x19\xc0\xf5\xf7!@U\xdc\xad\xbf\x8e\xecc?J# \xc0\x82\xd1\x86=V/|@\x89\xe8\xb3>U\x91\xbc>\x8548?\xc6J\xe7>^\xb0\x92?\xfdSV?\x99W\x08@\x94\x9a\xf6\xbfPG\x04?\x1b\xbas>\xcc\x8e\x07@l\xe0[@\xce\x1e\x8d\xbd\xae\x0b\x91>/r>\xbf\xa0\xcd\xaa\xbfj\x85{>\xcf\xd6\xd4?\xc7\xf5\xb9?\xe5%.\xbf\x11\x07%\xbfJ\xb0j\xbfu\xa6\xa7?\xddh\xbf\xbf\xc7l!\xc0\x02\xb3\xf1?\xaf@\x85?me\xe9\xbf[\xeen?\x11\xfar?Po\x1a?\xde\xb2&\xbe\xe2\x1c6>Ie\xdf?7\x06\x9d\xbf%\x8b\x9d\xbe\xa03l\xbf#\xfe\x9a\xbf\x1a\xf7+\xc0\xf9\x9f\xb2>$\xcbu@\xc2\x1c\x8f\xbe\xea\xcb\x83?\xe0\xec\x04<\xbb~\xcb\xbfuj6?\x8bP\x89?qD\xe7\xbf\x84\xec_\xbd\xed6\x15\xbf\x82V3\xc0\xc4\x96\xc9\xbf\xd3\xfb\x0c?\xec[\x96>`\xa7a@\x12\xf3\x1e@{\x1dL?Yy\x92?\xb0\xe4K?\xb04\xe3>\xc4\xa4\xe1\xbe\xf4\xb4\xd3?\x08\r\\\xbd\xe1k\xdf?\x1c\x9a\x18?j\x9c(@|\xc0i?&\xd5i@$\xed3\xc0\xbdJ\xa2?Q\x12I?.\'\xe5\xbf\x83\xf8\x13\xbf\x1f\x08\xcc>\xf2\xffi=\x98\xbb\xa3\xbfh\x1f&>B\x98\x1d@,dE=1Z\x9b\xbe\x0b6|\xc0\xc4Q\x00?\xd32\xd7\xbf\x1b\x12\x95\xbf\xbf$\xaf?X\xf2\x04\xc0$~\xb9\xbe\x159I@\x1fW\xe6?X\xa8\x9a?[\x8e\xc7?;\x93(>\x06\xf9\x8a>\x9dH\x85?\xe6,q?\xd3\x89-\xc0=3\xc5\xbf\xd2/\x94?\xea\\\'>\xae6]@\xda\xd9\x0f?0\xb6@\xbf8\x9eo\xbe\xc9j\xa0\xbf\r\x1a\xaf\xbf\xdc\xc2\t\xc0)\xdc<\xbe\xa0\xceQ\xbdO\xa6\xed\xbf\xc9K\x0f@\xd2))@ \x01\t\xc0\xd2\x99\xb2\xbe\x15z\xb7?\xa0\xdd\xf8?\x10o^\xc0\x1c~\xe3\xbe(\xfe\x12\xbe\x16^\xbb?\x9b\xc2\xb9?Z\xadp?\xd8a\x91\xbf\x10M+@8:_\xbf\xc9\x92\xc8\xbf|\xd7K\xbf\xac\x19\xed?\xd9\xc4I>\xcb\xaaf>R/\x90>\x8f\x04\x93?\x10\x8a"\xbflV\x97<\xfc\xad\x93<*\xd7d?X\xb9\x0c\xbf\xb4\xe3\xaa?\xa0u\x89=B\xf2`>\x8c\xc7x\xbdX\xfd\xf9\xbf\xab\x82\x80\xc0\xb2w8\xbe\xb6\xbe\xd7?\xe3\xed\x8e>\x9d\t\x13?\xdf\x81\'\xc0\xcf\xbc\xfd=\x06\x05\xa7>\x9f(\x94\xbf\x1c\xc2\xbf\xbd!\x9d\x05\xc0\x16:\'?\xd7\x0e\xa8?M\xfeF\xbf\x1ef\x91?\xc0\x1cS?\xa0\xa5\xa2\xbe\x15Ns\xc0\xc9n\x1a?\xda\xe0\xd9?j\xcd[\xbfY\r\x14@\xc2{M?+\x04\x90\xc0]h\xe2?\x9d\xc6\xd9=\xe6\x9c\xc0=\x87o$\xbf\xd0R\xd1?\xb7\x07\xb1\xbf\xe4\x8f\x89?\x85\xc8\x86>7\xa5\x0e\xbf\x18\x02\xae\xbdp\xeb)\xbc\xad\x1b\x99\xbe\x8d\xb6\x85>\xc0\xb9\xaf<`\x95I<c\xe1\xed\xbf4\xb3\x89@\xe4\x0c\xfc>\xaa`V@\xae\xd7\xb8\xbe\xd9\xae\x19?\xc7D\xde>\xb1$\x86>\x8bK?\xbf\xa6 s?~95?u\xf3"\xbeN\xb1/?=\x1f\xaa?f\xc2\x01@^\xe9\x03@\xae\x9d\x8e?\xf9\x8fw?\'\x0fE>\r\xb2\xf4\xbe\x8f\x03\xcc?&\xb8\xa2?\xd4\x0f\xa8?Q)\'\xc04\xebK@\x9bn\xab?xG[>J\x7f\xb9\xbeB\x8du=\rN\x8f\xbf\x8f\x03\x05@)\x89Q\xbf\xed\xad\xd8\xbf\xc1\xc8\xad>\xe4J\xef\xbf$\xa1t?[M\x08\xc0\xa9\xfc\x96?+%\x92\xbf*\x01\rA\xab\x84\x19\xc0\xd74\n\xbf<\xacI@\x8c*\x9d>\xcc"\x98>e\xc0Z\xbf"\t\xd6>\xcb\xb2\xce\xbfb\x11\x8a?\xab\xae\x9a?\xaa\xedY>M7\x07\xc0P/ @@T\x91?1 \xe1>E\xc9-\xc0D\x0e~?*S\xd7=\xef)\xcd\xbf\x08\x08K\xc0TVR\xc05\x1b\x87?T\x10\xde?U\xb4\x95?\xe6D\xad\xbf#~\xb3\xbe\xd6@h?c\x1d\xd4\xbf+\xd4\xce\xbe\x13\xf15?\xc0\xf8\xaa\xbd=<\x9a@\xc8\x92\x97?\r\xfc\x89?\x08\xc2\xc7\xbe-\x0e\xb7\xbf\x98Vx?\xa0J\xd9\xbeJ\xa8\xdf\xbf\xfd\x97\x0e?\'\xef\x05@%\x0e\x1d@X\xbc\xd0?\xe6)c\xbeI\xfb\x96\xbf\xacS\xe4?\xe8\xc3\x17?\xces\x86\xbfV\xb5\x9a?2\x93\x9b?\xf6\xbb^@\x03c\xcc>\x91\x9e\xf4>\x04n\x0b?\x9b\x12\xf7>\x06\xbb\xbd\xbdY\'\xe7\xbf\xd8\x1c\xab\xbfci)\xbf\x06\xc5\xae\xbf\xa7\x0b\xd2?`\x82\'\xbf\xf1]E=\x17\xff\x98@\x88\xa1\x96\xbf\x9cK3\xbf\xb4\x81\x1f@\xe4\xc8/\xbf\x90\xe1\xd9\xbc-f\x83?U\xe0G\xc0\x94D\x92\xbf\x86\xcb\xd8\xbf\xe6\xee\xd2?\x94\xa7\xc4=\xeb0%\xbf', b'\x039"@\xac\x9a-@Q\xce\xe9?\xe1\xe6\x07A4\xc0J?n\xed\xa4?k\x99\x86\xbe\x10\\\x9e\xbf\xd2\xffT\xbf\x9f\x1e\x9b\xbe\xdc\x88\xbb?\xcb\xb4\x02@\xbb\x08a?\xf4\x99\xbc?\x9c\xccG\xbe\x88:9\xbft\xd8?\xbf\xf9\x1a\xf8?\x192d?A\xba?\xc0\'\xf1\x8c>p\xb1D\xc0] \x9f?\xa7\xca\xd4?\xc2\xeb\xb8?"HY\xc0\xc2*\xfb?:k\x1d\xc2\xc6i\x14@\xda\x12\x0c\xc0\xc8\x8d\x98?L\xe51\xbft\x02q?1\x1b\xad\xbfN\x978\xc0\\\xaaR?\x88\xc2\x14\xbe\xc0J\xd9\xbe\xa6\x9f\x16@\xc6\x7f\xa5\xbf/\x1e\xb6\xbe\xca\xe3=\xc0\xe40\x19\xbf\x12W\x80\xbf\xb7\x15\xbc\xbf\x10\xef\x1d@X\x95\x94\xbe\xe0+i\xbf\xda\xde\xde\xbf\xa0!\xb1;\x86L\xaf?0%\x98>\xae\xe8\xa8\xbf\xe0\x160\xbf\xad\xfeI\xc0\\\x1d\x0b>\x82P\xd3?\xcd\x8f\xc6\xbfk_\xb5?w\xe8\xb8?\xf0\x8b,?\x03\x0cj?M\xfc\xce?*\xa6\xad\xbe\x0e\xd4\x15\xc0*\x12M\xbfu\x10Q\xc0N[\xfa\xbe\xa3W\x0f?\x95I\\?\xba\x96]?\xb5\x9b\xa3\xbd\x0f\x18\xdf?vM\xa4\xbe\xee\r\x1a\xc0\xaa\xe9Z\xbe|Z\xc6?t+\x03\xbf:\xab\xf8\xbf\xad\xa4R>\x01~\xaa\xbf\xd3N8@\xa1\xe7\x16\xc0c\x1e\xdf\xbf\xc6\xe8\x9e>\x11`v?\xc4\x1az@"\x85\xb8>[\xe6A>\x02_A\xc0H02>~\xcbo?\xf9\xb5\x03\xbfu\xc5\x93>\xcf\xe9\xc5\xbe\xc5P\xb2>\xaa\x90\x04\xc0\xaaG\xd3?\xc1^#\xc0\xc5\xee\xc1\xbf.:J\xbf\xd4\x1aH\xc0\x92\x12\x0f\xc0\x176\xcf\xbf>\x03\xa6?\xa8I\xa6>\'8R?\xa4hq\xbf\xbc\xd2}\xbf\x8bD\xe5\xbf.\x871@\x0e\x84\xdb\xbfV\xa4O\xbf\xf3\x86\xf9=+\xcb,\xbfn*\x00\xbf\xa4\x10/A\x1b\xe0O\xc0\xba\x1d\xcd>B\xa1\xbf\xbes\x06\xb7?\x02\xfdT\xbei\xf3??\xb4pI@\xff\xed\x16\xbfd\xabY\xbe\xd0\xfeS\xbf\xbb\xcf\x91?\x8a\xd9x\xbf\xf08\xd6\xbf\xad\x99\xc7>n\xa9\xe0?\xe3\x00\xe7?0\xe4\x0c@mZ\xd9\xbfYf\xa8=C\xfa\xcf\xbe\xa3\x98C@\xb6SB?~\x97\x0f\xbf\x0f5n?\xab\x19\x12\xbft)\xe7\xbdt\x12!@|\xa6\xec?$\xe0\xa7\xbdp_\x10=\x17\x8f\xb1\xbf\xe5-\t\xbe\xe0\xcf\x9d@X\xbb\xca<\xe0Y\xd5\xbd\x90\xceI>M\xda\x15@<g#\xc0*\x80\xaf?\x00\x02\xb6\xbfN*\xa1\xbe\x9f\xf7\xc7>\xd8\x86\xe5\xbb\xb8\x1a\x8a>0\x126?\xdaJ\xca>\xa6mO\xbf\rPI\xbf:\x8c(\xbfXk\xfa\xbf\x89*%@\xd5K\x1e\xbf{\xe7\x10@R\xdbA\xc0\x9a\x84@\xbf\xec\xd4\x0f\xc0\xb7\xf1?@U\x8e\xc2?\xb2sF?\xe3\x95+@\xf2m\x86?\xb4\xd4\xec\xbf\x9b\x90H\xc02/\xb7\xbe\xd0\xe7\xd0\xbe9\xf7\x1b\xbf]\xab\x92?\x80\x05\x00?1\xce\x94>9\x10\xac\xbf \xad >C\xf7\x11@\xdb%[\xbf\xa1\xe8\xf7?{\x8b\x02=\x18v\xf2>~1\x0e?(\xad\xa1\xbf\xc8\x89+?\xc7\x0c\x0e@\x84\xd2\x8e>\xd6d\x92?\x97\xb7\xc0\xbf+\t=?\x0b\x951\xbf@\x94\x15?\xfb\x1f)@\x17x\x0c\xc0\xd4g\xf5\xbfd+\xb0\xbf\r5\x00@?\x81Q@e\xf7\xea>8,\x96\xbc\xc9\x04 @\xbf\xfc\x04@\xf9\x1e\x83?\xee\xd4m\xbf\x80\x85K\xbf\xd1\x87 \xbeK\x023?\x82}\x9e\xbeJ\xfc9\xbe\xa0\x18\x9b?\x1a\x10\x8f\xbf\xf8v\xaa?\xf6\xb92\xc03\xd0\x04@\xec\x10\xa7?L\x0f\xa6\xbf%\xdd\'?\xc8\xfc\x17>\x0eG\xf9\xbf\xd2\xca\xf1?\xf0\xc5\xbd>~\xb5\x81\xbfQ\t\xfc\xbeG\x19\x9a?6O\x01@DU\x9b\xbe\xd2\xc9t?{s8\xbfD,\x0c\xbfP\xa7\x81>\xe3\xde\x84@\x8b\x97P@:}\x8a?\xe3\xce\xb2\xbf8s\x01\xbfJ\xab\x93\xbf\xd4\xae\xe3\xbfBO\xf1>i\xeeo?d\xa89\xc0\xa7\xdc\xcb?\x15>\xa2\xbf\xd6\xf8\x18\xc0D\xc3\xea?\xf4k\x19?H\x86$@\xbd\x83??0E\x89\xbff\xef?\xbe\xa4O@\xbe\xa4%F?-\x98 ?\xf7(\x98?\x82\xf0\x8b>\x06a{\xc0N)\xca>\xed\xe7\xe4?\xa7Id\xbf\x10\x0c.\xc0[\xe8/@`\xef\xbb?J\xa6\x14@\x07\x84\xb4\xbeAae@\xa7= \xbf\x80g\x9b>\xd2;\xe1\xbf\xe5\xc1\x15@\xae\xa4F>\xc0\x95\x92=\x86x\n@\x1f\x9e\x0e@\xd7X\x06\xc0Hj\xe3\xbfH\x94d\xbe\x82?P\xc0\xbc\xea\xb7\xbd*\x9b[?\xa0`\x18@\x13O\x0c@\x82#T@j{\x92>}\x0c\x8d?\xefx\x94\xbe\x90\x14"\xbc9\xbc\xab\xbfL-\x06\xbf6\xdb\xae\xbf\x1a\x1e\xa7\xbf\xe4~\x03\xc0$w\xf2?\xb5ju?_F(@F\xd0\x01\xbfP\xeez\xbd\xfc\xda\xa7=\x8d\xdb^\xc0\xda,\x07\xbf\xdc\x03d?\xf7?\x00@\xf4\x9d\n\xc0\xab\t\xd3\xbey\xf2\x0c\xc0\xd7\x00>\xbd\xb9\x8f\xa2?\x04\x99k?\x7f\xf9?\xbf\xbc?\xe8>\x0bcg@\xfb\xc5W@\x9b{:@IB<\xbfP\x862@F#\r?\xd3\xb9\x96>l80?\x98V\xfd>`\xcc\xa6\xbe\xab\xcd\x12>\xd2\xac\x12\xbf~\xf1\xf5>\x8eN\xb7\xbe8%\xae\xbf;\xe1)\xc0\xf6\x0f\xea\xbdQ\xf7\xf5>\x85\xad\xbf\xbe\xac\xb2\x1e\xbfv\xc1\xb0?:\xa4\xbb\xbeW_\xa5?3\xed\\\xc0\xf6\xfa!\xbf\xb2\x15\x19@EoR@\xd2\xd6\xdd<\x95n!@\xd3)\t\xbe\xdf_\xb3\xbf\xa9\xcd\x85\xbeaZ\x11\xc0\\\x18y\xbeP\x0b_>\x87\xa6\xa1\xbeK)?\xbfT\xd0\x98?\x92\xb1\xf7\xbdF8v<\'\xa2_?\x92\xa4\xfd\xbf\xd4|\x8c;\xb2Ok\xbfC\xed\x1b?\x17d]?\xfc2#\xbf\xbb(\x94?^\x12\xd7?\x88$\x86>\xae\xa7\x9b>\x1a5\x0f?5\xea\x97?[\x04\n\xbfF\xfe2?\x06(\x17\xc0\x8e\xbc\xa7\xbf\x16\xb0\xa1\xbf\'\xc1\xc5\xbf\xdeu:?\x9d\xd1\xa2\xbfl3\xe0\xbf\xc6b9?\xa8\x9b\xb8\xbe\xe5N\xce\xbf\x9aM1\xbfP\x1a\x19>h\xbf\xbf\xbfP\x8c\x85\xbf\x9d\xe3\x14\xc02\xe0$>A\x9d\xdb\xbf\x13\xd9H\xc0\t\xc2O\xbf]\'\xec\xbf\xd7*\x02\xc0\x81n\xcd\xben(\xb7>\xfa\x00\xd6\xbf0x\xad\xbf\x13\xba\x8c\xbf\xdc\x1dd?u\x1c \xbfM\xc0\n@\xf1\xfa\xeb?\xdd\xd0N>Q\xda\xc4?\x9a\x11P> \xe3\xd2=\x00\xcf\xaa?\xb0\xa6\xd0?\x06\r\xa3\xbf\xb0\x16\x85\xbf\x99L\x9e\xbfk\xadC@\xf1T\x97\xbfdD\x84?\xe5\xe6\xcb\xbf\xb7\xe6m=\x1b:\xde?<\x1f\xe3\xbf\xd4Hy\xbf\xfcB\x13>=\xbb\x08\xc0>1\xf2>\x7f\xf5\x0b\xc0\xd42\x8f>\xde\xbe\x88\xbf\x91JY>}\xa3\xab\xbf\xa2QI?A\xeb\x94\xbe\xe0\xc7\xe7\xbfF\xb3\xc3\xbf\xf2Y\x02?\x12Yd>Je\xa2?bT\xf8?OT\xaf\xc0\x08l\xba\xbbv\xa4=\xbf@\x87\x98\xbb\xef\x806?\x14\x18\x12>\xc9\x03\xe1\xbf\x143\xb1\xbf\xcb\xe5\x12\xc0I\xab\xf0?\xb0p\xa6\xbe\x96\xbc\xc2\xbf\x19P\xf6?3\x02\x95\xbf\x9e\x88x?#+X\xc0\x06\x85\xfa?\xd7\xc6\x18\xc0?V\xa5\xbf\xbc\xe2\xd0\xbe\x1e\xdd\x87?\x98\xda\x98\xbe,M\x86\xbfY\xa5\xdb\xbe-\x16"?\xfa\xcd\x04\xbfk\xdeF\xbf\x19\x91\t\xc0\x04\xd3\xe0\xbfJ7\xfc?=\xea\x8a\xbfxrJ>\xc8.2\xc0Y\xbf\xc7>!SN@\\\xdd\\\xbd\xa2M\xee>R\x8f\xc0?\xd4o\x9a?\xc0\xe8t?\xc5\x9a\x91?\xabO\xeb?\xc7E\x0c\xc0\xb6c\xe2>\xd9ST>\xb0K\x0e@\xa9\xeb\x84@\xf2\x1b\xfb\xbe(\xe1\r?\xab\xef*\xbf\xda\xb4Y\xbfM#1?Ha\xc6?\xec\x99\xb0?\xf2\xc9\x7f\xbf\xf8\'\x1f\xbf\x00n\x85\xbf/\x05\xe5?\x0cW\xb5\xbf\xa1z\x1c\xc0]\x86N@\xea\xe0\xd3?\x0e!\xc3\xbfr\xc2d?9l.?\x8b\x99o?\x91b\x8d=\t\x84\xb6>D\xb6\xab?\xe5\xa5\x90\xbfh\xb1N\xbeV\xa5z\xbf\x87A\x8f\xbf;\xd7\x05\xc0\t^\x04\xbe\x168f@\x84|\xd5>\xc8\x00\xb1?1\x02\xd9>lX\xd2\xbf\xac\\X?IfU?8`\xf9\xbf\xcbo\x8f=\xa3~\x8a\xbf\xcdz\x16\xc0\xb0W\xc1\xbf\xaf\x99,\xbd\x9e2\x99\xbe\xb1\xd1@@\x8d\x1e\x07@\x11K\xc6?9BF?\x15o\x81?$\xfcZ?\x019\x9c\xbe\x1c\x14\r@\x8c\x8b\xf6\xbe\xf6x\xab?*\xd3\x9b>{=?@J\xb5\x96?d\xde[@\xb3\xdc8\xc0\xfd\xe1M?\xc4Ld?TU\xe8\xbf\xddN@\xbf\xa5\'5?\x95\x8f\x13>}f\x8f\xbf>M#>p\x9b\xec?\x95\x11\xe6\xbd@\x8bC< "\xb3\xc0\x10g\xfe>ZD\xf3\xbf\x11\xc2\x04\xbe\xf8\xe7\xa7?)\xec\xb8\xbf\xbaiR\xbf\xc8FC@E~\xc5?\x9d~\xe9?\xa6,\xac?\xe0\x8e0?\x0cXp\xbe\x89\xa5\xc0?cYH?m\xcd>\xc0\xe4\x03\x86\xbf\xc8e\n?\xe2\n\x02?\x96\x008@rWA?\xde;\xe2\xbd\xd0H\xea\xbe\x12\xb45\xbfR{\xbb\xbf\xbdx\xdb\xbf7\x9a\x7f\xbf\xd8\x80\xf4\xbe3\xe53\xbfc\x17\xf8?\xd2\xc5\x1a@\xd9w\n\xc0\xe8\x87\xa6\xbd^y\xe9?}}\xe0?"\n\x1f\xc0\x9bw\xbc\xbf\xe8\x9c\x92\xbe?v\xf7?\x17\xb7\xcd?\xb2D\x97?\x98\x89\xac\xbf\xf5r\xed?(\xef\x95\xbf\xed\x02\x9f\xbf\'J7\xbf\x7fK\xf4?\x80l\x9d>\x15\xb61>\n\xd1T?2\x14\x87?\x7f\x95\x87\xbf\xb7\x96D>\xc8HS>\x9a\x82V?\xbd\x86\xcc\xbe\x87\x9e\xa9?\xc7\xec\x07\xbe\x16\x8a\xda>qD\x06>W\xb1\xb5\xbf\x16f\x97\xc0"bd\xbf\xae\xee\xa5?\xed\xbdz>z\xc8\x08?u\x12T\xc0$/\xb6>\x0c\xfe?\xbd\xb0\xf76\xbfhf\x9e=\n\xbf\x03\xc0\xa0e:>:\xee\xfb?z|&\xbf,\x1f\xbe?A\x15m?\x98\xed\xa0\xbd8\x86o\xc0r\xf1\x89?\xdd)\xe7?p\xbd`\xbfJ~\xf6?\xcf\xde\xb6>L~\x88\xc0\x7f\xb2|?\x02\xf1a>\xb4$\x0b>U\xbe[\xbf\xfd\x85\xfe?[\xfd\xf0\xbe\xfc \x1f\xbe2\x1a\xf9>\xd8\xa8\x14?\xb2}\x95>\xb0q\xda\xbc\xae\x0fT\xbf\x89\xbc\xbe=1\x9d\x08\xbf7\xfa#?\xda\xae0\xc0\xd4U\x8a@Q\xc2\xd2>`\'L@\x07}:\xbf\r$\x02?\x0eO:>$\x12&>\x8a\xb7\x01\xbf\xa8\x80\xc0>.\x98\xc4>\x08Q\x81\xbe\x9es\x8e?\x96\x05\xdf?\n#\xe9?.\x84\x0e@\xb3\xcf\x88?\xd5\x82\xa5>\x1eq\xf3>\r\xf7h\xbe\xa1\xc9\xd2?\xb4!J??l\xa4?x\x1b\x1b\xc0)\x9eI@\xcf\x94\xbd?j\xa3\x93\xbd\xcd\x17\xd1\xbe3\xe32=aG\xb4\xbf\xd6\xeb\x1b@\xb4\x19J\xbfY\xc1\xe4\xbf\xa6\x0e\x19>\x9d\x84\xc3\xbf\xb9T\x15?\x83\x7f\x0e\xc0\xc3\xe4\x8a?4\xa7\x8c\xbfq\x1c\xfe@\xe9\x8d\t\xc04V\xeb\xbe1\x1dF@X\xf7\x1f>\xae\xbc\xc7\xbd\x9e\xfa;\xbf#\xc3`?N\x9c\xe8\xbf\xfeVa>\x9d-\xb1?\xf8\xeb\xca>\xc0,\'\xc01\x81T@<Q\xc8?\xb42S>\xc1\x8f,\xc0\xaa\xf6+>2\x9c\n\xbe\xfb!\x9b\xbf\xf0\xf7z\xc0lL2\xc0\xdb3\xaf?\xf1\n\xb9?9\x04\xe2>\x9c|\xb9\xbf\x92~\xa4\xbd\xf2\xaa\x89?!W\xbd\xbf\ry\t\xbf\x00\xfd)?\xb3\xed\x86\xbei\xfe\xaa@\x1f\xa4\xcb?\x9b9\x86?\xc0\xdau\xbe\xb72\xd5\xbf\xcf\x95\xc5?\xe5\t\xc2>\xb5+\x05\xc0\t-\xa5>\xbf\xf5\x1f@a\xc40@+\x9a\xf3?\xd6\x1aO?\xafz>\xbf\x9f\x91\xf7?b\xd0\xb1>q\xcd\xd3\xbfK\x17\xa3?\xed#j?\x97\xb5X@5\x04\x8f>\xeet\'\xbe\xf4\xd1$\xbd\x1c\x87\xc6>\x12\x7f\x00?\xbb\xb3\xe0\xbf\xe4\xd3\x7f\xbf\xf8]|\xbf\xd2\x9a\xc4\xbf;w\xc5?\x82\xf1*\xbf\xf1\xd8"\xbf\x14\xc3\x9e@ \x03\x92\xbf\xf8\x15\x12\xbfX\xab\xd9?v !\xbd\xc6\xe1\x03>\xd4\xf0\x9b?\x9b\xe6K\xc0\xb8\x01\xe6\xbf@Z\xe9\xbfC&\xdd?\xb0\x02"<p\xb4\x03\xbf', b'1\xb9\x15@\xb8\x05.@\xa76\x9f?F\x07\x00A\xf8\xef\x9a?\xc5\xe6\x15@-N\xcd\xbe\xae6\xe6\xbfy\xae\x1f\xbfE\xbd\xbb=I\xab\xb9?\xe2\xa8\xd3?nY\xa4?d\r\x95?&\xbab\xbf0+\x9f\xbf@\xbdd\xbf\x00a*@\xa9\x1f\xd9>\xc1L=\xc0\x1a\x9cr>\xc3\xb2]\xc0f\x85\xd5?5\xcb\xd1?G\xbc\xbe?\x87\xb3j\xc0\xdd`\'@O\xe7\x17\xc2\xd23\x16@\xdc\x9b\xe7\xbf\xb4\xcd\xc1?5\x13\x8e\xbf~\xafc?hq\x9b\xbf\xa1\xe64\xc0y\xe1\xad?b\x0f`>\xb9\x90\x1c\xbfi\xb7\x03@\x96%\xa2\xbf\xc2)\x19\xbf\x0b\xb5M\xc0"3J\xbf\xadj\xc5\xbf\xf4\x0f\xf9\xbf|\x80\x1f@\xf6\xb3\xe4\xbed\xe8S\xbf\x90\x95\xf4\xbf\xee\xd2\x01?\x95\x04\xcb?tf\xf7>\x0c\xf2\xf3\xbf)(\x0f\xbfR\xday\xc0W\xa3K<\xc2\x07\xba?\x9e\x12\x9b\xbfB\x05\x99?`,r?\x14D6?\x9e\xb7\xf3?\x94\xaf\xea?Y~\xe6\xbew\xc5)\xc0@ J\xbe\xaa\xa7V\xc0"d{\xbf\xfas\xdb>\x1d\x83(?\xca\xbf\x11?\xdf5\xe5=\xa6z\xd0?\x14Y\x14\xbfyh\x1d\xc0\xecK\xd1\xbe<\x8a\xdd?\xf9 \xbe\xbe\x9a\x8f\x14\xc0W\xde\xfa>x\xa9\x86\xbf\xf8\x12<@\xd4\xabJ\xc0\xad\x89\xaa\xbf{\xdf\xbd?<w\x06?\x0c\xceT@\xdbH\xc3>\x80\xd6^;\xb5p*\xc0t\x19\x9d>0?\xa4?l;\x0c\xbe\x9a~3\xbfP\xea\xa9\xbe\xb4\x8bM?\x90\xb8\xe2\xbf#\xa8\xe2?\xd1\xdb\x10\xc0\x94x\x90\xbf\xee\xdb/\xbf\xf7\xf2G\xc0/\xc5+\xc0\xbeG\xda\xbf\xe7r\n@J\xf7\xe3\xbe\xe9\'\x8a?\xef\xe5\x97\xbf\xd2\x8f5\xbf\xa5\x97\xfa\xbf\x81\x13$@\xce\x8b/\xbf,\xfa\xe8\xbew\x8e\xbc=w{X\xbf\x11\xa5A\xbf\x04#1AJ\xa2V\xc0X\xde$\xbe\xb71\x0e\xbe\xf5\xb1\xdb?\xd0\x88d>\xf5\n:>\xb4\xfa[@ \xabM;\xc2\x12\xf8\xbe\xb6~\x0b\xbf\x929\xb0?\tI\xd3\xbfq\x16E\xbf\xe9\xebK=\xff\x83\xd3?\xa1\xd7\xfb?\xba\x19\x0e@A\x0c\xca\xbf\x98\xfd\xb6\xbc\xd9R\x1c\xbfv\x94A@\xd4\x08\x9f?\x99\xf3\x1a\xbf;M\xaa?vY5\xbf6Q"\xbe\xf7b\x03@\xaf\x8b\xe9?\t2g?\x94A\xc5\xbe\xf3\xeb\x8b\xbf\xfc;R\xbdO\xff\xaa@`\xd4\t=\xaa\x85\x03\xbe\t\xeb\xef>\x83\xf7\xe4?jWA\xc0%3\xc7?\xf8\xc7\xac\xbf\x84\xc4\xc1\xbe\x80\x1e0>\x15\xff6>H\x1b\xa8>\xe1\xe1\xc1?&.\xbd>\x1e\xebM\xbf\x0f\xa4\xcc\xbd\x99\x93f\xbfHS\x1e\xc0\xad\xa63@\x0b\xa8&\xbf\xa8\x1b\x16@\xe0w:\xc0{\xa78\xbf\x86\x96\x0f\xc0]\xc0^@\x8a\x12\x83?\xb2\x85\xa1?g\x7f;@\x82V\x9a?]\xc5\r\xc0j_:\xc0\xb8\x1bZ\xbf\xb0\xa4\xf3\xbe\xe0>V\xbf\x12\xe4\xf9?\xbc\x08:?o\x06\x14?\x00\x95<\xbf\x18\x8a\x8d?\xa8\xff\x08@l\x9b\t\xbf\xd3\x18\xb5?\x9a\x19\xc8<\x89+\x88=\x16`"?\x83\x81\xe3\xbf\x0e\xfa\xe0=\xfc5\x0c@\x8aB\xb1>k\x03\xa4?bc\x9a\xbfD\xc4\xee?v\xf6\x1d\xbe\x82\xc4\x81=-\xd7L@\xa8)\xce\xbf\xee[\x10\xc0\xb2\x15\x16\xc0\xcd\xcd\xf2?\xc6\xd77@\xeb\x8c\xcf=\xac\xd0\xdf\xbe\xe2Z\x15@\x9aJ\x16@\x1f*A?<\xe6\x89\xbfJ\xf2H\xbf\x99U%>\x16\xe8L?v\xb7\x83\xbe\xfb7}\xbe\xe2?\x86?\xb5\xb7\xb8\xbf\xd3$\x93?\xd1\x02\x18\xc0:\xa0\xf1?\xcf\x07\xdd?"\\\xc1\xbf\xe1\x86\xa0>\xe4\x86|>-\x960\xc0\xdbp\xce?\xb9\xd6\x06>\x1b>\x96\xbf\xc3\x95\xe4\xbe\x18p\x0f@\xc8\x14\xe9?H\x1a\x0f\xbf\x1e\xc1C?wi\xb4\xbfz`\x9a\xbe\xef\x1f\x1a?\xd6\xad\x7f@B\xb6v@\xb9Bl?\x9c\xf9\xe3\xbf\x0c\xb7q\xbfO\xc1\xe2\xbf\xa4\xcb\xfa\xbf\xb9\xb1\x01?\xd4\xec@?)\xce)\xc0\xe6\xe6\xac?\xba\xff\xb7\xbf\xd6G.\xc0\xcc\xa0\xf8?\xaf\x96\xe3<C\xff\x14@g\xad\x0b=\xbaSx\xbf\xc6\xbd\xd7=\xce\xb8x\xbf\xc1e\x1e?\n\x88\xd1>}A\x8f?h\xc8\x8f>\xfeu\x84\xc0\x868\xe5=9\x9b\xbb?WL\xe4\xbe\xfa\xb3H\xc0\xf5\xcf"@\x03\xbf\xe4?\xc0C8@\xec\xe4^\xbeO\xdf[@\xb6Z\x8f\xbf`;T\xbe\x1f\xda \xc0\xd5@\xfe?\x94\xba0\xbe\x0b8\xe6>\xbb\x1d\xee?0\xa7\x05@\xe4z!\xc0P\x1c\x1d\xc0 \x7f\xac\xbe\x07W2\xc0T[k\xbd\x82X1?\x1a\xe7\x1b@)\xdc\xe8?\x9f\xb6M@\x0c\x1c8\xbf\xb4\xc0}?0\xc9$\xbd\xd7=?>\xccBV\xbf\x18\x13\x02\xbf\xac\xd6\xad\xbf}`\x0f\xc0\x9b\x83\xea\xbf}K\xcb?\xf7\xa5f?sq2@j\x81V\xbf*\xb2$\xbfx=\x16=\x90\xf2]\xc0\x84\x9d\xf3\xbeY\xbb%?\x0ct @\xbf\xc6\x02\xc0\\{\xde\xbd\xa5p\n\xc0\x80\xa0\x07\xbe\x02\x82\xcc?\xca\xeb\x84?\x19dV\xbf\n\xf4\t?\xb1\xfdc@?\x84F@R@V@<*\x81\xbff\x0f-@\x94M\x87?j.\xdc>\\\xe5~?\x04\xa1R?\x0c:\xb5\xbe\xe8C\x7f>[\x9da\xbf=#)?(\x8fr\xbd)\xe3\x08\xc0\xd3\xf7-\xc0r\x94\xd7=LGZ?tDZ\xbe0T\x07\xbf\x8e\xdc\xc0?\x0c\x03~\xbf\xe2.|?\xe0"g\xc0\xea\xa6j\xbe\xc1\xa2 @>r\\@\x04\xb1c\xbe\xbd-K@~\xfe[\xbd\x7f\xd3\xc2\xbfp w\xbe\xff\x90\x02\xc0B\x06\xa2\xbe\\Cj?f\xe9\xa8>\xff\xc1\x92\xbfhU\xac?\xb7\xee\xbb\xbe\x8c\x8bQ\xbe\xc7!\xc6?\xdd\xa7\'\xc0\xb8e\x1b\xbf1\x07\xbe\xbf\xfca6?\xf1u\xb7?x\xf6\r<lJ\x9b?\xecL\x08@Je\x95=}\x10\n?f6\xc6>:\x9a\x7f?\xadT\xb9\xbe\xb9`\r>\xcbA\n\xc0\xc2\xf9\xd3\xbf\x91t\x84\xbftB\xc1\xbf\x97\xbc\xa1>!x\xd2\xbf\xb0\x88\xfe\xbfC\xa0C>w\x12Q\xbf\x13\xef\xae\xbf\xe1u\xbf>\xd4\x1e\xb5>:\xaf\xe7\xbf\xc8\x96\x8b\xbf\x97\x7f\x17\xc0\xfb\x83/\xbe65\xea\xbf\xa5(1\xc0\x8bWP\xbf\x87\xa4\xf8\xbf\xc2\xeb\xff\xbf\xfb\xdf!\xbe\x9a\x81{?\xec\x88\xe6\xbf\x1a\xc1\xd8\xbf\xbe\xd4\xcc\xbf\xa2\xb8\xfa>6\xa3\x8f=Dk\xf5?v\\\xd5?(\x12\t?\x0f\xa8\xb0?V\xc6M>y\xa0\x9a>Ba\xda?g\x99\x01@\xba(q\xbfm\x08\x9d\xbf\xc56\x8d\xbf\xe3\xc2\x02@\x9d\x9a\x9c\xbf\xf0~\x8d?\xdf\x8b\x95\xbf\xb13\x88>\xf3\xb7\xa9?\xe1\xa3\xe9\xbfY\xd8\xe8\xbf~\x06\xd1\xbe]\xb7!\xc0\xa73>\xbe\xb0X\x15\xc0\xd7\x8eZ?\xca\x1a\xb3\xbf\xfaX\x8d>t\xc9\x97\xbfF\xb3\xde>|\xd2\xa3\xbe\xb6\x03A\xc0\xe1\xc9\x8e\xbfm\xc1l?\xca\xde\xcf=\xe0\xd4\x02@\x88\x1d\xf3?\xcaM\xba\xc0\x82\x179>\xed\xbdM\xbf[p\x18>\xb1\x14\x9e>8\xe46?\xe9\x8a\x96\xbf\xf6\xac\x9e\xbfr6=\xc0\xb4\x8e\x17@\x1e\xc9Z\xbe^x\xc4\xbf\x87\x86\xb5?F\xe0W\xbf\xac\x87\xd8>\xf9\'U\xc0\xcf9\xbb?\x92E1\xc0\xd3\x11\xe8\xbfz\xe7N\xbf$/\xff>\x03\xc2=>\x1c\xf63\xbfh\x04\xd2\xbeD\x0cL?&\xd6\xd5\xbeF\xb9\xce\xbe\x1f\n\xd9\xbf\x84\x90\xff\xbfJ\xa1\r@a\xa0\xe7\xbf\xb7\xec\x06?\x88\x08 \xc0\xac\x00\x85>8\x92g@\xa8\x0fn>\xcf<U>An\\?{4\xa2?D2\x19?\x9bD\xa8?\x8b\x88\x0c@\x94i\x16\xc0K\xd2\x0c?D\x03\x96>mf\x1d@\x8a/\x81@\xc4\x95\xf9<\xb57b?\x16%\x1c\xbf!\xdb\xa1\xbf\xf2o\x9a=#\xd1\xec?\n\x96\x8a?Z\x9bf\xbf\x88,\x1f\xbf\xf2nG\xbf\x0e\'\x94?\xe0\xdd\x99\xbfz\xf0J\xc0\x88ui@B\x9e\xb6?M\xe5\x07\xc0\x95\xdc\x8f?\xa3\xa9]?\x10\xfc\t?\xd2\xbd >\'n\xa3>j\x9a\xaf?q\\\xe6\xbf\xd4\xc3O\xbeh\'\x82\xbf\xd9\x1a\xc9\xbfi\xc1.\xc0/\x860?\x0f\x08o@\x04\x0fv\xbe\xd2\xfe\x84?(\xd3\x88>L\xf1\xbd\xbfO \xe7>\x97 2? \xd9\r\xc0\x7f{\x0b>\x92\x9e\xc4\xbe!\xc25\xc0\xf1\xb6\xce\xbf\xda\x89\xbf<T\xb9h=\xe6\nW@F\xe8\x0e@\x037\x93?\xb2\x08\xa2?\xe8\x86=?\xcc\xdfM?\x90\x02\xef\xbeXt\xc2?b\xd6\x01\xbf\x8a\xbf\x03@\xe2\x9b\xd8\xbdKH8@\xdd:\x80?@\x8bU@\xc8\xdd3\xc0\x1b#z?\x98\x90W?\xeb\xe8\x05\xc0\x1c\xa9\x82\xbfn}\x1b?\xe0o\x0b?s\x1az\xbf\xa4\x82`\xbe\xf5\xca\x06@n\x81\xb7>* \x8e\xbe\xc0\x19\x9c\xc0%\xe1\x04?\xdd\x1a\xe9\xbf\x7fg\x94\xbf\x1d\x0c\xc9?V[6\xc00\xb9*\xbf#\x19Y@\xcf\x04\xf1?\xe7b\xd1?=\xac\xae?\xf4c\xfc=x\xbeO\xbeG\xf6\xc7?\xe0/\x9b?\xf7`5\xc0\xe4QD\xbf[\x86T?\xe8\xf2\x85>\xd8\xc7@@\xb0W\xa2>gS\xd4\xbe\x86\xbc\x05?\x11\xa1r\xbf\x00\xd8\xd5\xbf\xb0\xca\xc7\xbf\xb2\xffn\xbf\\\xab\xf5\xbe>\n\r\xc0\xd3C\xcb?`\xc0\x11@D\x7f\xe0\xbf\x9c2\x8b\xbe\xfa\xb4\x89?\x8eD\x08@\x1dM\x1c\xc0\x0c\xa2\xb6\xbfT\x1f\x17=A\xd6\xc4?{l\xf9?Z\xef[?\xe2A@\xbfn\xf2\x1b@\x8a\xe9\xaa\xbf\xd3\xad\x8f\xbf\xa6\x8f@\xbf\xb37\xd7?\xb5\xc7\t\xbfVH\xb0>\xa0\x1e\x83>\xd2\xee\x85?\xd5\xc8/\xbf\xf8\xd7,?m\xb8\x07=p\xbbc?8\xa2\x8a\xbf\xf4(\xaa?o\xa6\x03\xbf\x85V\xe6>\xdaA\xdb>}6\xb1\xbf\xb1\xc7\x86\xc0\x0c\xb9 \xbe\x8fo\xa9?\xfeL+=x\xd3\r?\xe3\xc1>\xc0\xa6\xb3\xd7>:\xcf\xb3>9\\\xaa\xbf\xfea]>-\x15\x06\xc0P\xda\x87?\xc7i\xe0?\x16Xl\xbf\x17\x0f\xa7?\xa6\x16r?\xceN\xc0\xbe%6i\xc0s\x06\x8c?\x9a\xb0\xb0?\xb2\xe0~\xbf#0\x19@q\xbd\xfd>|e\x7f\xc0Np\xd5?G\xd7\xd5>+o)?\x18Z\xb8\xbf\xed\xea\xf1?;\xf4\xaa\xbff}\xf6>\xe0\x0b\xbd=}\xd3\xa2=\xb9\xac\n>\x13\xaa\x89\xbel\xd7\xf7\xbe\x05i-?\xa8\xa5\xa4\xbc\xb8@\x89>x\xfd!\xc05\xe5\x8d@/\xa2\x9e=\xb1Zv@\xd0\x98\xa0\xbf\xcd\x83.?\xcf\x17\xdd>`\x05\xcb>\x19kQ\xbf\xa7\\E?e\x02!?g^_\xbeJ\n\x95?ES\xed?h1\x16@=\xa5\x1d@\xe1\x1d\x8c?o\xa5{?,\x91\x0f?>!\xf0\xbe\xd3\x18\x0e@xB\x89?em\xb9?\xe5\x8d\x1a\xc0(\xac\x80@\xef\xb8\xa9?B\x04\xc9>\xd4\xed\xc0\xbeu0\r\xbe2\x10\xe1\xbf\x1f\x19\x19@\xe7\xc6\x15\xbf\xf6\x04\xc2\xbf\x02q\x1f?u\xbe\xce\xbf\xe1\xe1\x88?S\x9b\x1f\xc0\xa5\xcd\xa9?,pP\xbf\xab\xbc\xf6@\x7f\xbb\x0e\xc0\xfd_\x85\xbe\xf0\xd2J@\xd09\xba>\x85<\xd8\xbd\xc2\xce\x81\xbf\xdeOW>\xbb\x08\xd5\xbf\xb0\xf6\x8f?\xfb\xc0\xc7?\xa89\xb0\xbb\xe0\xdf\x11\xc0\xd0\xb0\x16@\xf9\x8d\xc6?2)\xdc\xbe\xc3\xd5:\xc0,\xa7\x0f?l\x9b\xfb>\xf8b\xd0\xbf\x06\x80P\xc0\xf6\x98C\xc0\xe1\\\xb8?B\xf9\xb7?\xb6I6?\xe3u\xd5\xbf\x9c\xaa\x9d\xbdp\xf26?\x1bu\xd9\xbfs\x00\t\xbe\n\xaf\xe0>\xa8\x05\xb3\xbd\xbe\xba\xbb@^\xb1\x9f?\x98\x9f_?\xd8,\xbc\xbc\xc1\x01\xbd\xbf1wx?\n\xfd\x80\xbd\xf0(\xf7\xbf\x0f2\x11?\x8a7\x13@\x7f\xe66@>\xdf\x00@\xb4\xd0\xe0\xbd\x04O\xa0\xbf\x8c)\xd5?u\x82\x12?\x0fT\xdc\xbf\x1d~\x9c?\x9c\x90\x99?\x9e;s@\xb54U>\x88\x19\x0e>t\xf7\xba>\x8bHz?\xaaAk?r[\xd9\xbf\x08\x1d\x0c\xbfR\x8dT\xbf\x0fU\x8b\xbf\xe2\x8c\xd2?Bp3\xbf\x98u\xc0\xbe6\x0f\x9e@2I\xe8\xbe\x0b$\x81\xbe\xfcy\xe7?\x0f(s\xbe\xc9\xf9\x98>\xc9\x08\x93?\x02\xc7U\xc0\xa7\x1d\xa8\xbf\xdaO\xde\xbf\xd5\xc4\xb0?\x10\xaa\xd2<\x91/\xbb\xbe', b'jo\x11@\xf1\xa4"@?\xf3f?E^\xfa@\xd1\xfeI?\xc8\xe8\xe7?\xd3\xc5\xb6\xbe\xf3\x8e\xdc\xbf\xbb\xa9\x0e\xbfN{\xa2\xbe\x14\x9b\xa8?n\xae\xec?\xc1\x98\xa2?\xefx\x9c?3\xea\x8a\xbf[\xac\x85\xbf\xe2\xb2\xc5\xbe\x82\xd2\x1a@Y )?\xad\x0f1\xc0\x83\xa7\xf5>J\xad`\xc0\xc2\x7f\xbd?\xb5\xf4\xd1?\xa6\xe6\x92?$\xe0c\xc0XI)@\xc88\x18\xc2\xac\xfb\x07@\x85\x0b\t\xc0]0;?\xce\xae~\xbeL\x8cK?\x8d\xc4\x96\xbf\x86\t>\xc0\xa3\x80\x7f?\xba\xaei=;\x03\x1c\xbf\x1b\xef\x12@\xb2cx\xbfc\x16\xaa\xbe\xc5\xc8L\xc0O\xcbV\xbf\x8b\x04\x8d\xbf\x0ek\xd3\xbf\x99\xdb7@\xca\x97\xc4\xbec\x9c\xc4\xbeQG/\xc0\xb8zp<Z\xea\x94?\xecf\xbe\xbd\x91\xf1\xd3\xbf\xcc\xc7\xb2\xbe\xe4ok\xc0J\x01S>\x0e\xc4\xcc?\x18\xd9\xc8\xbf^\x00\x00@\xcf\xdbN?\x9c\xef-?Pl\xed?"-\xbb?t\x17\x83=\x8d\x99\n\xc0I\t\x18\xbfbrD\xc0\xad\xc5#\xbf`\x1cJ?\xeed7>\xbfdW?J\x81\xe7;\xed\xc5\xe9?S\xd7\x94\xbfe)\xea\xbf%wW\xbf:\x90\xd8?\xdf\x82#\xbf\\Y\xf8\xbf\x98\xc9@>\xa9B\xc6\xbf\xa9L?@\xf6\xf7P\xc0+\xe1\xe2\xbf\x80\xa6\xab?\x0co\x16?\x95\xc3h@\x83\x96\xd2>M\xf4\xf6>\xe0z&\xc0\x95\x9f\xc6\xbe2\xda\x9a?\xfb\xe0\x17\xbf\xbd\xa5L\xbf\xfe\x1b1\xbf\x0c~\x07?\xce\x92\xf7\xbfz\x13\xf8?+\xa3\r\xc0\xbdvl\xbf\x99kq\xbf\xd2\xaaB\xc0\x1c\xec\xfc\xbf\x7f\xf8\x83\xbf\xcaN\xf0?\x92>3\xbea\xfc\xb2?\xd6o\x95\xbf\x00\xdeT\xbf\xd6K\xe2\xbf\x95\xc9\x1f@\xc0\xc6\x07\xbf[\x91o\xbf\xfd\x90\xc3>\x0f+\xa3\xbe\xb3\r0\xbf0\x820A\xa2TO\xc0 c\xf4<\xf8\xaf\xfe\xbd\xc4Y\xf5?\x0c\x88\xa1>\x10\xe8\x85>\xea\'U@\xdf\x1c\xd1\xbe\x08\x01\xff\xbdR~\xc1\xbe\x99C??@\xa5\xa7\xbfR\x061\xbf\x95g\x8d>\x86\x0e\x92?\x1a-\x14@\xaeB\x1f@\x16\xda\xee\xbf\x05\xf3\xce\xbe\x08Q\x8b\xbenEN@\x0c\xacH?\x17\xb0r\xbf\xeej\xb2?4\x8a;\xbfI\xe7l>\xb2\\\xe1?U\x00\xb3?\x1b1D?\xac\xfa\xf5\xbd\xae\x87a\xbfZ\x80A=w\x15\xaa@\x0e\xeax>\x1f\xeb\x87\xbeP\x19\x17?z\x01\x05@U95\xc0\xfa\xb7\xc9?Q\xday\xbf\t\x80*\xbfj\x01?>N\xfd"\xbew\xdb\xb3>55\x8d?\xe3\xd1Y?a\x84]\xbf\xfaY\x0b\xbf\xe0\xb4\x86\xbf\x9c%\x0f\xc0n\x07%@\xb1\xe8\x04\xbf\xde"\x1a@\x86,?\xc0WB\x03\xbfW\xee\x04\xc0\xaa\xf6_@N2\xc7?\xf8\xbf\xac?:\x06=@\x19\x1c\x81?\xef\x17\n\xc0\xcd\xe3@\xc0\xbcN\xb3\xbe=\x00\x1a\xbf\x1c%\r\xbf\xc0i\xd2?\x9e\x8a#?\x0e\xa0\xc8>\xe1\x8aM\xbf\x897\x93?\x02\x06\r@\xff 0\xbf\xe82\xc8?\xd2~\xa8<N\x0e\x1c?\x02\x0f\x0e?\x8d\xc7\xc8\xbf\xd2\x9b\x00\xbc"B\x17@<?\xff>\x1e\xeay?\x99\r\x9d\xbf\xe4\x95\xd1?Vl\xc2\xbe\xc9|8?\x8e5<@\xde>\t\xc0\xcc\xc0\xb9\xbf\x9c\xd2)\xc0\xd2\x88\x03@2e<@\x98#\xd5\xbd\xc5s\x99\xbe\x85?0@v\xce\xfd?\xa7\xe2\x82?\x97\xd3\x9b\xbfDXu\xbe\xca\xfcN\xbdG\xe4\xa5>2\x85\xe4\xbe\xbcu\x8b\xbe=\x83\x88?\xf8\xcd\xd7\xbf\xa4~t?0Y"\xc0C\xf9\xf5?\xcc\xd9\xa1?\xfb\x88\xb9\xbf\x99r(?\rtL>\xa3a.\xc0{\x02\xc6?\x1co+>K\xc5\xa1\xbf\n\xc0&\xbe\xba=\xee?\xc6\xcf\x04@\xbbF\x02\xbf\x19\xdcP?=L\xed\xbf\xc0\xe5\x14\xbej\xdf\x0f?\x19D\x85@\x1eCY@]\xa8\xa7?\x1e;\xdd\xbf\x922.\xbf\xfa\'\xeb\xbf\xb8\xe1\x08\xc0$/\x82>\n\x0em?\xd0?\x0b\xc0\xf4\x01\x9a?\xd9\x83\xc3\xbf0 ;\xc0\x87\xf0\xf7?m\'\x9c\xbe\x1f\x19\x16@\xd6\xa3\xec\xbc\xaf,N\xbfFU\xb3\xbe\nMf\xbf\x9dJ\x17?cx\x1c?\xebb\x96?\x8b\x01\xdf>X\x8d\x85\xc0\xbb1k>\xbe\xc8\xc7?y\x96\x83\xbe\xc7o]\xc0d~\x14@\xfc\xe6\xaa?\xc3\xa3\xfa??\x86\x96\xbe\x9b-R@v\xe4L\xbfc\\\xf0\xbe\xf0\x15\x04\xc0\x87\x8a\xf9?\x04\x91\x0b>\xa9\xce\xd2>P\x82\xf6?\x81\xca\x17@\x98\xf5!\xc0\xe5\xcf3\xc0p\x7f*\xbe\x9a}6\xc091\x08\xbeu+_?\xcfi,@\xcca\xdd?\xce08@\xc6M\xda\xbe*\xf0K?\x93Z\x82=\x1e\x0bk>&ap\xbf^\xd8~\xbe\xe1\xe1\xa6\xbf2\x04\xc2\xbf\xe7\xa5\xf8\xbf\xb6B\xde?\xb9\x9bS?.\x95"@\xc8V\x05\xbf\xd2\xd9\x9d\xbe\x84\x9b\xbd>\xda\xd5H\xc0\xcc\xee\xb0\xbew\xea\x80?&\x93\x0b@\x06\x9a\x07\xc0\x88\x07A\xbd\xc2q\xe7\xbfW\xc8\x9a=O\x0c\xb5?\xe0\xb2\x89?\xd6\xad\xe9\xbe\x82\xdeD?\xf7re@\xf6\xd7[@\'\xa59@\x18\xabV\xbf\xbb\x89!@\xf5\xe61?\x8eq+?\x87\xd9\x94?\x18\x82\x0f?\x14yF\xbe\xc45b>arn\xbf\xd2z\xf1>l\xcb\xcf\xbd^1\xf1\xbfEN;\xc0\x1bw\xc9>\xbe\xfdb?\xac\x86\x05>\xf2X\xe6\xbe\xdb\x97\x9b?+\xa5:\xbf5P6?t3e\xc00\xa0c=\xcf`4@|iz@q\xc5\xae\xbe\xe1\xf7;@lj\x02\xbf5\xe1\xa9\xbfs\xdf\xa4\xbe\xfe7!\xc0\xfb3\n\xbff\xdai>\x00 k>\xd2Z\x9c\xbf\x7f_y?\xccB\xf2\xbe\x8a\xb4\xa7>s\x10\xac?~\xe22\xc0F\x95\x02\xbf\xb7\xf3\xdc\xbf&\xb8\xe1>\xbf\xac\x82?W\xbb^=\xe3\xd8\xb6?,m\x1b@;i#\xbda\x0c\xbf>\xc0\xf5\x10>\xf2\xc8\'?\xa6\xe6\x95\xbe\xf6\x18A?o;\x18\xc0\xb3\xe8\xbb\xbfq\xa5\x92\xbfq\x10\x8f\xbf\xc5D\xc2>\x88\x86\xb3\xbf\x0c)\xfc\xbfob\t=\x8dl-\xbf\x99\xab\x82\xbf\xba\xb9\x08\xbf8=\x08?\xd7\xda\x00\xc0\xb8\xbf\x1b\xbf\xb6)\r\xc0\x9eTE>RJ\xc8\xbf\xe2\x11S\xc0{\x0bQ\xbfL\x9e\t\xc0e\xb8\xd8\xbf\xc1\xfb+\xbfc\x89\x9c>\xf8C\x00\xc0\xf9.\xee\xbf\xc4D\x94\xbf\xffB\xa1>\xa2\xf1\x02\xbf]M\x02@,t\xc1?*/\x16?YI\x91?,^F=\xbar\xf8=\x8aK\xcd?KC\xd0?\x98\x17\x10\xbf\x0f\x18\xc0\xbf#\xe6\x81\xbf\x1a\xf6 @\xd2=j\xbfn\x84\xf7?\xe7\xfb\xb3\xbf\x86\xcb\xce<L\xc6\xa5?Y\xaa\xef\xbf\x08\xdcg\xbf|\'/\xbf\xc7\xe3\x01\xc0\xf8\x97\xef\xbc,Q\x10\xc0\xaa\x0f\xf2>\xf4\xc6x\xbfIi >r\x91\xbf\xbf\x8ei=?\xec\xe8\xf9\xbe\xecN9\xc0F\t\x9f\xbfm\xf7y?L\xe4\x08?\xbc\x90\xf0?\x1dY\x11@\x16\xc7\xc8\xc0@\x83\x06>n\x04\x86\xbf\xc7y;>B\xad\x97?VV\x18>\xc7\xb4\xd1\xbf\xc2\xb0Z\xbf\xb8I \xc0\xba\x1d\x10@\x81\xe5{>Zk\x8a\xbfEs\x85?\xf0\xf6a\xbf\xd7\x1a\xdd>\x11U\\\xc0G\x01\xcd>\xe6\xd7\n\xc0\x87l\xb9\xbf\xf4r:\xbf\xac\x85\xe1>E1\xb2\xbe\xc4#\x96\xbf%\xc5\xe1\xbe\xb4\x06\x87?\x12\x8b\x84\xbet:\xf4\xbd<\xc7\xc9\xbf$\xdb\x05\xc0\x05\x99\xe2?\x9a\xdf\xe3\xbf\xea-\x1a?;\xbb\x1f\xc0\xae\xce+?)\xf4[@m\xcb\x9a>\x87\xc9\x8a>\xa2\x81\xa0?m\xe1\xc7?\xcc"\x84?\xa8~\xcc?\xfcT\n@X\xa4,\xc0a\xd6,?\xd4\x9f\xe7>0\'\x08@\xc9\x96\x8b@J\x9eB\xbeq\x92L?&<\x85\xbex\xed\x9a\xbfY\xea\xc7>\xea\x94\xbf?\x18\x8a\x9c?\x11\x983\xbf\xba\xd9\xcf\xbeB9_\xbf)M\x92?zTn\xbf\xbf\xf4R\xc0\xc2\xf0m@\xc0\x0f\xd4?\x1e\xb1\xc2\xbf~\xad\x98?*/\x1b?A"(?6`@?H\xc4\x10?\xf8\xc0\x99?v\x8b\xbd\xbfP\x1c\xfa\xbc\xa8=D\xbf<\x99\xba\xbf\x05\x0b\x19\xc0r\xbc\xe7>^\xaa\x8b@\x85\xf5\xfd\xbe\xc6\x03\x87?\x0f\x03\x07>\x0c\xc1\x9d\xbf\x1c\x8d2?\xd6\xac\xcb>g0\x00\xc0\xb7:\xdc=\x1e\xfb\xaf\xbe\xac\x00&\xc0s\x81\x8d\xbf\xea\xcds>\xf4\xd41=\xbb\xe6G@\xaa\xe9\x06@]\xbb\x9c?\x9d\xa4F?\xe2\xca\x83?\x1e\xeb\x97>3\x7f\x1f\xbf4\xce\xde?3\x87<\xbf\xd8\xe5\r@I\xf0\x8f\xbe\x9c@-@\x8a\xdau>_\xd0F@\xff\x00\x19\xc0c\xdb\x9b?\x82\\<?\xf2Y\xc5\xbf\xf5\xc9x\xbf\xfd\xab\xc0>\xe2\xa4\xcd>\xa8\xc9\x96\xbf\x88r\x1d\xbd\x05\xea\xfc?\x10m\x0e\xbb\xa7t/>o\xa1\xa5\xc0&)Q?\x1dT\xc6\xbf\x18zf\xbf\xca@\xc1?\xca\xc1\x07\xc0AD\x1e\xbf!\xf7J@H[\xda?{\xb0\xe9?i\xa8\xbc?V\xd1??\xcd\xc7\xbc\xbe\x98\xea\xbb?luR?\xbb-/\xc0\\=\x9b\xbf\xaaE(?\x7f\x00\xe5>a\x81;@s\x19O?\x04\xba\x11\xbfl\x7fc>\xf0-*\xbfGs\x19\xc0%\xa5\xeb\xbf\xbb\xb7|\xbfD\xde\xf4\xbe[\xce\xcc\xbf\xadx\xbf?\xbc{8@\xadY\xee\xbf`\x8c\xbf\xbb\xc7\x0b\xa4?`/\x02@\x07\xdd\xe5\xbf\x9e\xaf\xa6\xbf\xecl}\xbe]x\xf9?\x86\xc1\x06@j@U?\xe4}r\xbf$\x91\x16@n\x01\xe1\xbf0.\x9c\xbfW\xe2\xa3\xbeFW\xbc?\x80\xa7\xbb\xbb(\x18/?\xef^\x15?\xa5\xb6\xb0?\x95\x7f\x88\xbfD\x15^?\x9d\x07F\xbe`\xeb\x89?FK\x9d\xbf\xb3J\xd7? \xe2\x15\xbf\xcf\xb1\x02?\xb9_\x84>\x0b\xeb\xa4\xbfk\xaa\xb4\xc0\xd0w\xdf\xbe\xbb\x00\xb2?\x9b\xc7\xc9>\xaap\x16?\xf5^B\xc0\xf4\x86\xda>\xc4\x81\x84\xbd\xe8*\x95\xbf\x07\xa4\xfa>5Q\x0e\xc0\xdb\x05L?\xbfT\xe4?\x15A\x8d\xbfG\xf2\xcb?\x15\xa6\x7f?\xb0O2\xbe \xdb^\xc0\xd6\xd0\x86?\xd69\xa9?\xc9L\x84\xbf\x90,%@\tt\x13?\xc0\x13\x83\xc0>\x17w?\xec\xfa\x13?\x10\x07\x02?\xa4f\xc7\xbf\x91R\xea?s \xee\xbe\xfbQ}>*8\xcb=%"M<\xec^n>\x16\xd4l\xbe\x8f\xbeg\xbfF>\xe6>tZ\xf1\xbd\xe7\xc4\\?q\xb7%\xc0q\xc4y@\xba6\xfc>]\x1fM@J\x86\x12\xbfl\xa2\xc8>\x8c\x9eV?\x0e\xec\xaa=\x14\x9f\x9c\xbe\x12M\x17?\xb8\xa1E?|\xc9\x99>\xccC\x9b?F9\xb3?\x05\xc2\x0f@\xa6\x16\x0b@D\xcc\x96?\xfb\x07T?&7Z?\x92\xa9\x13\xbe\xe9\x03\xe4?#\x95\x1b?\x96U\xb7?c\xf1\x13\xc0\xd7\x15S@\xeas~?\xbdu\x03?\xdf\xac\x04\xbf\x14\xab\x1f>:\xc4\xf3\xbf\xe0\xcf\xf9?V\x8f\xdd\xbeF\xb6\xc3\xbf~\xa1\x8c>\\\x93\xb7\xbf\x8c\x18\x1a?\xef\x9e\x14\xc0\x82?|?\x986\x90\xbf\x8f\xe5\xdf@\xd1i"\xc0\x8ct\x8c\xbeM(L@\x10T\xf8>&\x82\x1e\xbfo\tz\xbf\x81\xc7\x1f?3\xbb\xd9\xbf\xfe\xb7)?\xdd\xab\x90?%\xfa;?\x7f\x01\x1f\xc0\xf2;\'@\xabZ\n@\x03[+\xbf\xcbmG\xc0Fz\x08?\xdaZ\x08?\xbf}\xf3\xbf\x19\xbbb\xc0BOE\xc0\x16\xdd\xb1?hx\xc1?D\x8c\xbb>h\x82\xd2\xbf\x10\xd0\x93\xbe\xfe\xe56?%\xfc\x00\xc0*\x8d4\xbe\xaf.\x8d>\x9a\xd3\xa0\xbe\xe5\xfa\xbb@\xc0T\x9a?\x8e\xb9<?8tn\xbe\x04\x83\x95\xbf>\x04\x81?\xa7x-?rS\x06\xc0Q\xc3X?C\xe7\x03@!\xfaA@\xac\xed\xd1?"\xf2\x14>\xbb*\x9a\xbf\xf7\x0b\xf8?49\x8b>\xf5k\xb7\xbf\x1a~p?\x14\x9b9?\x97\xb4z@\xa3\x87\x9d>\x87\x91\xaa=\xb7\xff\x80>9\x8d]?V\xb7d?|H\xb0\xbf\x1d\xf9\x0f\xbfl\x9a\\\xbf\xd9t\xb4\xbfc`\x95?B\x94\xe3\xbeV\x0e\x9e\xbe_D\x8d@\xec1=\xbf\x11\x90\x99\xbe\t\x9e\x1a@(\x8a\x0b\xbe\xc1\x8a@>\x1bf\xd5?\xe7\xfbF\xc0\x7f\xcc\xe1\xbf,\x0c\xfd\xbf\ro\xb8?\xd8H\x04>q\x95<\xbf', b'\x84\x05\x17@\x1b\x05/@\x85I\x85?\xc1\n\x08A\x8cJ\x98?\x1a\xf6\x1b@K\xf2n\xbe\x0f\t\xe4\xbf\xae\x19D\xbe\x80\xc9\xa7\xbb\xd6\xfc\xea?\xcb\xceu?4i\xdd?\xbe#\x87?\xcb\x1cn\xbf\x03r\xa3\xbf\xbd[\xdc\xbe4\xa7\r@\\\x00[?\xc6\xa8J\xc02\xf0>?\xf0\xffQ\xc0\x80\xf6\x00@\x94\x8a\xab?\x83j\x9f?\xa1rZ\xc0\xe9\x14$@M\x18\x1c\xc2;\x1b\t@\xe2n\xef\xbf\x92R\x9d?\x98\xcf^\xbf\x12qO?\xe9z\xe6\xbfr\x84+\xc0\x03\x08A?\tHm?\xac8\xdf\xbc\x06\x19\x10@2\xcb\xa9\xbf\x9a\xad\xba\xbe\xddw*\xc0n\xb04\xbf\x9a\x13\xa8\xbf\xc7\xd7\xa4\xbf\xce\x92-@\xe9\x02(\xbf\xcfp<\xbf\x847\r\xc0_P\x11?~^\x93?w>\xce>8e\x15\xc0\xedB\xbf\xbeIVb\xc0\t\x06\xc7\xbdo\xa4\xe1?\x15s\xe2\xbf\x8es\x89? \xb5\x93?\xa2\xa3??\xd0\xa8\xf0?\xd9\x83\xc1?\x04\xe5\x00\xbf\x07\xe8\x16\xc0[X7\xbfL9Z\xc0a\x17\xac\xbf\xe8D;>T\x92\x1e?\xb3\xf1w?I\xf0\xda\xbe$\x92\x8e?\x024\x89\xbf.\xbd\x19\xc0\xbe\xd6\xfc\xbd4\xf0\xc0?\x95MN\xbf\xc3u\'\xc0q\xa8\x08?\x9a\xa3F\xbf\x95Y\x16@\x02\x178\xc0xL\xc7\xbf\xc7\x13d?M\xdee?,\xb3V@h\xcc\xb3>$\x02w=\xae\x9cC\xc0\xd96\xa5\xbe,6n?\xae\xe4\xfe\xbe\xdeD&\xbf\xc9\xa2o\xbf\xc4A\x91>\x06\x82\xbc\xbf\xe5\xb9\xae?%\xeb\t\xc0|\xb7W\xbf\x83\xbb*\xbf\xf6\xfa#\xc0H{1\xc0\xd6\x15\xae\xbfp\x89\xbd?x\xdb\xe9=\xcb\x1c\xc5?\x96\xa5`\xbf\xd95\x00\xbf\xac`\xf5\xbf]\xb1-@\xef=\x16\xc0PL\xec\xbe\xbe\xcd\xa1\xbdHe\x82\xbe\x0c\x7fL\xbfl\x0f+A)7D\xc0\xf61\x10?\xaa\x96\xbb\xbd\x136\xd9?\x03\xd7D>i\xe6\x85?\xb4\xcfN@\xa0\xf9l\xbe$$;\xbf[\x164\xbfwq\xc0?\xe1\xa3\xc3\xbf\x86~/\xbf=\xc8X>\xd7&\xce?\x7f\xb5\xcc?t\xdb\xfc?s\xd3\xfe\xbf\x967/>L\xe4I\xbf\xed+:@\xe5\xeb\r?>H<\xbdz:O?\xc6\xeb%\xbf\x0c\x8c\xbf\xbe\xc2Q\x14@bx\xda?\x7fQ`?\xa0D\x02\xbe\xa68\x8a\xbf\xe3\xb2\xc4\xbe\xe0\xdd\xab@\xe8Q\x1f\xbf\xc2\xae\xd5\xbd\xeb\xdc ?\xd7\x1f\x01@b%\x1f\xc0\xb8\xdb\xf5?\xa4\xbe\xc1\xbf8\xda0\xbe\xc4\xf75\xbe\xf3\xce\xb1= \xca\xc2\xbe\xdf\x0c\x85?\xc4cU?\xe0\xc7E\xbf\x999\xf5\xbe\xe5r\x1e\xbf\xb3\xbe1\xc0\x1c\xe5\'@\x13\xc2\n\xbf\\\x92\xf1?\x16"]\xc0\xeb\x0b\xd8\xbe\x97\x10,\xc0\xec\xe3P@\xc2XB?"\xa6\xb1?\xb4~V@\x0f\xa2\xb0?2\xb0\x16\xc0\xc7\xc2F\xc0\x1b4\xa0\xbf\xc8\xba\xaf\xbe\xd1b@\xbf]v\xe0?\xea\xa8K?k\xaa3?:0\xb5\xbfxU\xed>\xb6x\x07@\xe8\xfd\xf1\xbeG!\x9c?\xa0Q\xb3\xbc\x8c\xc8R?\xb5\x04\xcc>\xce`\xf4\xbf\xdet\x0c?z\x07\x1e@\xb2%\xf8>\xce\xf4\x92?K\x86\x85\xbf/\xec\x03@\xa6=\xbb\xbe\x0f[\xcd>G\xf71@\xd9\xae\xca\xbf\x08\x87\x01\xc0F?\xfa\xbf\xbd\xeb\xa7?WV\x1c@\x00DM\xbe\x8c\x04\xf4\xbd\xf97=@g\xb6\xff?\x8a%\x84?}\xc6\xcf\xbf\xc0\xe4L\xbf&\xdd\x94>\xc5Fk?\xb0\x7f-\xbf\x03\x82\x8e\xbd\xe3\xfc\x9e?Y\xcd\x90\xbf\xdb\x01\xb4?\x98z\x12\xc0\xb2&\xf4?[i\xdf?2l\xb9\xbfL\xc1B?&(\x02\xbfX\xc3\x12\xc08O\x00@\xe2\xa2\xfc=J\xa9\x8f\xbf%`\x10\xbf;\x07\xe8?\x99y\x05@{\xe0\x08\xbfv&\xb6>\xa5\xb4\x8f\xbf\xfc\xdc\x02\xbfLs;?\xc7\xbc\x85@P\x03\x84@\x81j\x9d?\xdf\x0b\xe8\xbfi\x8d\xaf\xbfR0\xd7\xbf\xf5\xde\xe3\xbf@x\xa8>S\xe0\xb6?b\xe2 \xc0\xd3G\xb4?U\xd6\xb8\xbf6\xd1L\xc0\x94l\xc2?:\xc8`\xbe\xd0N,@\x81\x80E>\x97\x17u\xbf}\x97\x82\xbe\xc0\x86\x1f\xbf\xde\xdc#?\xc6\xde;?\x85\xc8/?\xdd\xf8\x9e>\xc6\xf5\x9a\xc0\x08W\xa4\xbc\xd5\xa4\xed?\x82k8\xbf\x8f"3\xc02D;@\x17\xdd\xbd?)T!@\xa4\xbd\xa0;\xad\xfcQ@\xafk\x1a\xbf\xc6z\xa1\xbe\x05\x92\x02\xc0\x0c\xb4$@\x1c\xd1\x85\xbde\xb71>/\xb7\n@\x935\xfe?\xdf\x0c\x1e\xc0\x1e\x9e\x1c\xc0\xa4\xd7\x17\xbfn;*\xc0\xca\xda*\xbe\xcc\xb5\xac>;\x01)@\x0b\xed\xc6?m\x14Z@\xb9\x0b\x18\xbfG\xe3\xab?\x9a2\xe1\xbd\xd2.\x9d>i\xdc\x91\xbf\x92\x13\xbd\xbe[\xa4\x9f\xbfPu\xb0\xbf\xfb\xd7\xec\xbf7\xfd\x08@\xe6z\xde>\x1c\x04 @\xc8c\xc6\xbe\xb0\xc2K\xbf\xb0o\xd1\xbb4x`\xc0\'y\xef\xbe\xb8\x19\x9f?\x80\xf8\xea?\x13P\x0c\xc0\xe9\x82&\xbe\xa6\xa0\xe7\xbf\x96\xb4\xa5=\x99\x97\xe1?E\x00y?\xbc\xd8\x8b\xbf\x92\xde\x95?\x84_U@\x8d#K@"21@\xed\xaa\xcb\xbe\xf6\xc24@#*\xc0?\xe2\xed<>~\xcb\x99?\xde\xbe\x04?=\x18\x97>\xc2!\x86>m\x9e\xdf\xbe\xc2\xe7\x17?\xbe\xd6\r\xbe\xc0\r\xdd\xbf\x01\xf3%\xc0aN\n\xbe\xceya?c\x82\xaa\xbe\x90\x17\xf1\xbcHj_?8\xa9\x83\xbf\x16\x8d\xb2?\xa5c9\xc0&\x80.=\xa8\xe3\x1f@\x17A[@Di\xb9\xbeHF)@\xe4\xa5\r?\xfa\xbd\xbc\xbf*\xc7\xe7\xbd"\x80\x11\xc0P\xac\xd5\xbd\xea\xc4=?;Y\xa3>@\xad\xfa\xbf\xf3\xc6\x8e?\x9br\xd3\xbe\xc1\xf48\xbe\xeb\x89\x91?\x08\xb3\x14\xc0\x85|2\xbe\xde\xd5\xce\xbf^j\x19?\xf1\xf4\xb5?\x92H\xf0\xbdB\xb8\x81?&F\x08@\xfdx\xb0>\xbc\xe3@>w\xc3-?q:\xa2?\x12\xb7\xee\xbe"\x9b\x1f\xbe\xb1\xa4\x19\xc0\xc4\x04\xa9\xbf\x1e\xd4Y\xbfl\x9e\xf8\xbf\x84k\x00?\x13\xa4\xa8\xbf\xadb\xae\xbfB}\x16?o^Z\xbf-\x8f\x80\xbf\xf1B\xc9>\xf0i\xaf\xbec\xbf\x18\xc0\xfa\xe0\x82\xbf\x8a\xdb\x04\xc0\xf2\x84\xec\xbe\xb9\x9f\xc4\xbf\xf2\xd1\x1a\xc0\xad2I\xbe^T\xee\xbf\xb5\x1b\x16\xc0\xbe\x803>\x873\x00?U\xac\xee\xbf8\r\x8a\xbf~>}\xbf\x1e\x96:=\x0cn\xfc\xbc\xf4\xdc\x03@\x91\x88\xcc?o\x9bi?\x7f\x83\xe7?&h\xe3=\x1bw\xbb>X\xef\xf8?D\xe2\xf3?\x0f\xfd\xa5\xbf\xdf\xa4\xa5\xbf,\x80\xc4\xbe\xe1\xa2\x14@\x8e=o\xbfV\x88\xac?\xac\x97\x89\xbf\xfd\x1e$?\xf4\x15\xa4?\x87\x03\x07\xc0T\xc3\x92\xbf?\xf5\xbb\xbd\xc7T#\xc0\xea9p=\x1a\x02\x12\xc0\xdd*9?\xa0\x9e\xb7\xbf\x14\x0c\x19?\x02(\xa4\xbf\xbe\xfb\x93?\xacQ\x14\xbf_\x98&\xc0H\xa5>\xbfa\x180?J\xe1\xad=j\xd6\xb9?\xbc\x04\xf6?q\x1a\xc6\xc0\x84\xb6\xa0\xbdz\xb6c\xbfw+\x80?\x83rE>\xe0\xf2\xd0\xbe\x9e\xa8\xb4\xbf\xe0\xed`\xbf\x06\xcf$\xc0 \xb8\xee?m\x82\xb9=X\xc6\xad\xbf\xe4\x98\xc0?\xd3\xe7\xa7\xbf\xe9L\xac>\xbfJr\xc0\x93\xb8\xb5?,\x98(\xc0Sj\xcf\xbf\xf1z\x0e\xbf\xde\xa8q>v\xe8\xa1>\xa0@\x82\xbf\x05\xbb\xe0\xbeo)\x90>W\x9e+\xbf;\x9a"\xbf:\xa0\xfe\xbf.o\x05\xc0\xf9\x9d\xf0?H3\x9e\xbf\xdc\xe6Y>=d\x18\xc0\xf0\x06\xc2>O\x81A@b\xc5\x00?\r\xff\xaf\xbe\xc8\x11<?\x10*\xb5?y J?wa\x11?%\x82\x03@\xe4\x99\x05\xc0\xef\xa38?\xe0$m\xbe\x90\xed\x06@\xea]w@Z\xe7\xae>Wf(?\xb4\xb8\xaa\xbe@\x9f\x92\xbfA2\r?\xe6^\x01@\xc2(\xa9?\xa5\xe7\x04\xbf\xa7\xddC\xbff\x0e\xfa\xbe\xdbD\xc9?`{\xc9\xbfk\xa9A\xc0\xf0\xe4!@\xe4(\xad?\xb8d\xf8\xbf\xd0b_?\x10\x00y?O\xac\xa6>\x98\xf2h<\xe3LA>\x9a\xd6\x81?o\x97\xb1\xbf\xf3\x1b6\xbf\x07\x15\x1f\xbf7\xb2\xb0\xbf\x80\x13$\xc0+O\xb3>\x1b\x99\x82@\xc1\xda\xd6>;\xbc\x97?1\xd6\x82>y\x06\xdc\xbf\x0f\x14\x1b?c.u?\xa2\xf1\x08\xc0\xde\xe7\x93>+:q\xbf\x1e\xd10\xc0\xeeY\xd3\xbf\xa4\xdb:>\x1c\xc8\x03?KPb@\xba\xc7$@\xaf,\x9c?\xc5\xb6\xa2?<\xb05?\x82\xc6$?\xa0!\xee\xbeJ\x8e\xdf?\nP\x06\xbf\xbd\x15\xb0?\x84\xa5\xa3>\xa8\x86\x1c@\xc1:\xb3?I\xe0d@:\xe16\xc0\x1d\x1e\xa7?\x8e\xcd^?\x1e\xc3\xeb\xbf\x8b\x16\x07\xbf\xfc*\x82?\x02\xd0\xf9\xbd\xe9\xa4\x97\xbfh\xc5\x10\xbd\xa0\x18\x02@\xdf?%>\xdd\x11\r\xbf\xd9\x94\x8c\xc0\n\xa1\x01?Y\x1f\r\xc0\xeck\xb7\xbf\x18\x83\xae?\xf5\xfb\x01\xc0\xa4qH\xbfu\xe7O@\xf3\xee\xf5?Q\xbd\xbf?\xb8\x10\x88?-,\xf2=\xf2\xf8p>\x08\xed\xb1?\x1c\xa4\xa6?\xd4\x08R\xc0]\xe1\x94\xbfgmV?\xd3\xf3=?Q\'3@\x05\xa8\x15?\x9aN=\xbf\x1ca\xb1\xbd!Hm\xbf\xc8\xa8\xad\xbf\x8a\'\xdf\xbf\xa0Dv\xbf\xf4T\xf6\xbd3\xbb\xe9\xbf\xfa\x07\xe7?\xe5\x19\xd4?!\xc4\xcd\xbf\x08\x18L>\xb28\x91?\xdbq\xcd?\xde\\9\xc0h\xd3?\xbf\xda;\r?\x08\xe9\xbf?+\xae\xe7?\xc7\xaa\x84?y\x00\xb0\xbf\x17E\x11@\xb2\x98\x94\xbf\x8c\r\xa0\xbfs\xb5?\xbf,\x81\xfc?\xd5\xaa\x18\xbey\x1b\x94\xbd\x9028\xbep \x92?\x8ay\x07\xbf\x88(\x05?\xa2hi>"cX?/o<\xbe\xb4\x98q?\x94\xe0\x04\xbf"\xbd\x18?\x8e\x95\xaf>\xee\xc1\xb9\xbf\x01\xe3\x8c\xc0\xa8q\x83\xbc\x89B\xeb?7\xef3?\x03\xcc>>o~;\xc0\xc4\xd8\xd7>"=*\xbe\xcf\xb8r\xbf(\xa9>\xbeP\xa3\x14\xc0\xe0\xc4%?\xe7L\xbc?:Xv\xbf\xa6\xfaA?\xf389?B\x9bA>\xfe\x19s\xc0k\xcfT?\n\xf0\xa6?\xcc\r\x88\xbf\x97\x07\x0e@\xff\xba6?i\xde\x85\xc0\xd1\x10\xdc?\xf7\xb5\xcc\xbd0\xcd\xbe>\xfc\xe6\x9c\xbf\xb7\x84\x06@4\xfe\xa8\xbf\x86\x93\x06?\xf8\xe8\x90>\x90G\xae=\x0b\x18{>\'\xf4\x0c\xbf*\x06\xdc\xbe\r\x8d*?r\xe2\xe1\xbe\x1as\x0c?\xec\xcd\x1e\xc0\xca\xce\x85@\x86K\x18?\xb6\xddf@\xaeGl\xbfx\xad\xca>^\xc0\xce>\x13-\x13>p\x1d\xb2\xbe\xf3\x87\x9a?%\x1f$?\xc8\xe9\xd5\xbc\xd0\x01\xbb?%\x11\t@\xb6\xba\x11@\xd0\x82\n@\x8e\x99\xac?\x95\xf94?\x98\xc0\xe7>\xd3\xc7\xb6\xbe_\xbc\xb9?\x95\xf1$?]\xc0\xcb?\xa2\x0e\x15\xc0`\x18W@DP\x9d?\\\x81\xf8>\xc8\xc1#\xbfD\x92\xac\xbe\x81\x16\xa0\xbf\xe8C\x1a@\x1e{4\xbfl\'\xaf\xbf\xa4\x08\xee>R\x1b\xf6\xbf\xbaR\xb9?u\x15\xf6\xbf\xf0\xdfI?\x01\x99e\xbf\x94q\x1eA4h \xc0\xa0\x0b\xa5\xbfMYD@\x854o?\xc8\x9dS=&{W\xbf+\xc1T?\x11\xc3\xdf\xbf\xa0f\x89?\xdc\x8e\x86?nw`>\xe7\xa7\x07\xc0\xb9\xbc\x13@\x99\xdf\xd1?f\xae\xef=\x1a\x828\xc0`\xb3\x0f\xbc\xff\xd2\xe3>\x1c\xf5\xad\xbf9OW\xc0\xcfTF\xc0W\xf0\xc2?\xedR\xd1?\x90\x88V?\xcfD\xa7\xbfh\xf8\xd1\xbd\x82S+>\xc2\xbe\xeb\xbf~\xf9\xa5>\xf4\xdf\xb1>\x08\x91\x16>X/\xa4@\xc4\x9b\xa1?\x9b*\xad?\x06&\x88\xbet\x0e\xce\xbfq\x87\x93?\xa8\xc6)=\\e\xb2\xbf\xdb\xb0,?\x83U\x11@)G\x1b@\xae\x8e\xb4?\xc2\xae\x8d>\xacs\xaf\xbf\xd9\x05\xef?\x9d\xa1\xe6>7\xeb\xd3\xbf\xa3<\xac?\x8d\xee\x9e?\xd8\x90\x83@\xef\xd4\xfb>\x83\xaa\x96>\xe8S\xb5;\xf6\xc8\x1b?@\xf1B?#\x92\xf1\xbf,\xe7\xaf\xbeL\x15>\xbf\xa7C\x90\xbf*\x1f\xdc?\x0ce\xab\xbf\x92S\xfa\xbe\xacX\x94@\x92\xbf\x98\xbf\xe9\xcf\x1a\xbfz~\x0e@6\xd9)\xbfF\x9b\xaf>b3\x83?7\xafZ\xc07w\xa0\xbf}\x0b\xe6\xbf\xf51\xc1?\xae\x99_\xbd\xcao\xf2\xbe', b'vS\x17@x\x905@C\x0f\xa3?\xe2\xe7\xf7@\xd9\xd0\x9f?\xb1\xef\xe8?\xd6Nc\xbe\x00\xf8\x07\xc0$\xc6\x9d\xbe\xc2\x8b\xee=\xd3d\xed?JP\xd1?[+\xc5?6\xe5\xba?\xb0\xc62\xbf\x83\x8a\x9a\xbf\xcf\x8d_\xbf\x9a\xc7\x0b@\xe031?\xa6\xa3:\xc01\x8e|>o\xf4Y\xc02\x91\xcc?\x08\x85\xc6?!\x0f\x99?\xbd\x82e\xc04H\x15@\xa0\x87\x1c\xc2\xa8\r\x05@\xb0^\xe3\xbf\x11A\x9b?\x97\x99\x84\xbf:>v?\xa3P\xce\xbf\xe8|!\xc01\xf0\x81?\xe6\x80}>\x96\xc3-\xbfw\x16\x1d@\xc9\xbc\x9c\xbfQ\xa4\x18\xbe\x1a\xf1\x1e\xc0\x9aHO\xbf\x04\x92\xb5\xbf\x8a\xd8\xff\xbf)O#@\x93k!\xbf\xd4%}\xbf\x95\x9b\xd4\xbf\xdaF~\xbe\xef\xd6\xc1?\x9a\x0b\x82>iY\xb5\xbf$\xc8\x97\xbf\x1e$Z\xc0X\xe5}=<\xe7\xbe?\xbbD\x12\xc0\x9b\xa9\x94?\x99\x07_?\x7fNc?\xa12\x97?\xb3R\xcb?\xf0\xeb\xa5\xbec\xa2+\xc0\xf9G\xcc\xbeC0Z\xc0\x94\xa7i\xbf\x12L@>\xa8m\x8a?T\xf7\x97>g\x9b\xb3>z\xf1\xa7?D\x1cY\xbf\x1f\xa0\x1f\xc0f@|\xbeb\x1a\xbe?{D!\xbf\xc3\xc7\xe8\xbfk=\xae>\x86/\x8b\xbf\xee;!@\x85\xf9S\xc0\xd4\xac\x7f\xbf\xf5\xe9~?\xa8\xfc]?\x8b\xbbP@\x1e\xfa\xc0>\xd6a\xc4=?\x91@\xc0\xa5{\x06?\xad\x97\x95?t\x10\t\xbf\xda\xffW\xbe\x87\x82\xd2\xbe\xd997?K\xdc\xbf\xbf&\xd1\xd2?$E\x04\xc0\xc6T\x85\xbf\xd2F\x1d\xbf\xcaW[\xc0\xdb;2\xc02O\xf0\xbf3?\x0c@\xc2z\x07>\x9b\xe3\x8e?%Gi\xbf{\xa4\x81\xbf\x1f\xb6\xdc\xbf\x97\\$@\xcfc\xdd\xbf\x96)\xaa\xbd\x08\xbf(?\x9e\x06\x1d\xbf\x96\xfe\x04\xbf\x13\xae-A\xcf\x97Y\xc0\xacN}>\xe4K\xd4\xbe\x16E\xda?\x98\xf6\x1e=\xb8\xc3\xc3>\x07)d@\xca5\x9b\xbe\xd8\xd1\x15\xbf\x95\x08\xac\xbem\xbc\xe4?\xd8\xbe\xa2\xbf\xe0\x19{\xbf\xf4\xe9\xc3=\x13\xd1\xdb?L\xe8\x0c@m&\n@1\xbb\xb8\xbf c\x1e>\xbb\xdb:\xbfpC?@\x9f\x17\x17?\xeeP\xe8\xbe\x1a\xd2\x8c?y\xc8\x1a\xbf\xe0\xe2\xdc\xbd\xb7`\x07@L&\xf5?\xdc\x93\xf2>r\x17\x07\xbe\x1f\xb2\xab\xbf\xd5\xbe\xc4\xbe\x05\x82\xa6@\xe8\x9bg\xbe\xac\x8b6\xbfh:P>z\xfd\x06@b\xb2/\xc0\xae\xe4\xf9?\x0c\xfd\xbc\xbf\x8e0b\xbeE\xdd\x17>s\x81/>\xa0\x10\x96\xbd\xe0\xd0\x91?\xd9\x8a7?\xca!-\xbf\x06\xe7\x94\xbe\x91\x92\xcc\xbe\x8ec\x11\xc06A"@n\x04\xf9\xbe.\xcf\x04@\xd3\x04I\xc0\x03\xdf/\xbf\xa1\xdc\x1b\xc0@TZ@\x1f&\x88?\x0f|\xb4?l\xa4@@F\xc3\xc8?W8#\xc0\xbc\x99.\xc0\x14\xe7H\xbf\xc2\x86;\xbfR\xda_\xbf\xce\x1c\xc6?F\x04O?\xfbi\x1b?x:{\xbf\xce\xd07?W\x1c\x07@\x1c\x812\xbf\x8a`\xd8?f\x8a\x07><AJ>\xc4d\xca>L\xb9\xed\xbf\x18\xdez>\x1d\x00#@v\xda\xf2=\x9d+k?\xa2\xe4\xd6\xbf\x84\xc4\xf9?|\x08#\xbeDES>\xd6\xc71@F[\xf4\xbf\xfa\xa3+\xc0=\xf0\xf5\xbf\xa2\xb7\xdd?\xf2:,@~]\x10?`\x0c~\xbd\x03\xdf\x1a@ZI\x15@\xdd\xcaB?\xf8\xa9\xaa\xbf\xbc\xa7x\xbf\xe5\x1cT\xbe\x85SU?<@\x9c\xbe\x89u\xba>y\xf0\x82?4\x9e\xa6\xbf\nux?\xf0^\x00\xc0\xd1\xc7\x02@\x82!\xea?\xe2\xfb\xb3\xbf\x1e\xfc<?\x00al;\xce\xe5!\xc0\x14\xee\xe7?\xa8\xf2\xc8>\xea\\\x97\xbf.\x80D\xbf\xe8Z\xf6?\xd9@\x01@<\x1d%\xbf\x9a\x12\x12?\x89&\xe1\xbfX\xb8k\xbe\x1e\x14??%\x15\x84@3\x98y@\xa5p{?\xa9\x10\xd2\xbf\x90m\xad\xbe:\xc4\xb4\xbf\xedi\xdc\xbf\x9d\x0fG>\xa5&\x8c?_\xde-\xc0\x8d_\xb2?\x83\xc1\xd8\xbf-\xfbI\xc0\x9f\xcb\xf9?\xdd\xd6\xc1\xbe%\xae%@&\xc1*><\xcf\x80\xbf\xe0\\\x0b\xbeNU<\xbf \x976?\xb0\x9c\xa4\xbe5Z\x81?\xff(A>\xdao\x80\xc0\xd0\xc1\xda=\xe5\t\xe1?\x17\xb0\xde\xbeS{>\xc0\xd1\x16.@\xc3\xc7\xf5?\x84\xae4@\x89\xaa\x01>\x15\xe6\x84@A\xb9M\xbf\xc0\x9f\xb5\xbb\xe3\x87\x16\xc0&\n\x08@R\xf5\x8c> \xad\xe5>\xf8g\x00@Nq\n@\t\xd8\xf8\xbfu"7\xc0\x85\x11\xca\xbeD\x83.\xc0\xackC>v\xff\xeb>\x08\xe3\x1c@\x04\x04\xff?\xd4EA@\x0e\x0b.\xbeE\x19w?vtw\xbe\xa4\x07\xd6>\xdc9]\xbf\x8d!V\xbe\xd3F\xb4\xbf\x12\xd9\xf7\xbffC\xfb\xbf\xb2#\x02@\xd2\x8a\x08?\xc0E/@\xf8\x1e$\xbfF\x91\xdf\xbe\xa0W\xbb\xbe\xc5)|\xc0;\xab\xb2\xbea\xbcI?&S\x01@\xcf\xae\x03\xc0~\xb0\x10\xbd\xe5\xda\x0b\xc0\xa7J)>y[\xbf?[\xcaz?\xf0\xb1#\xbf\xb4{\xa3>V\xbd\x81@\x8cjF@\xf4\x10=@\x96\n5\xbf\xdc\xf8)@\x05\xc2\x96?\xceN\xab=+)V?B\x15\x10?\xf0\x1d\x02\xbd\x90q\xfb;\x7f)\x8a\xbf\xdc\xd0\x05?\xd4\x87M\xbe\xec\xfc\xe6\xbf\x14\x96-\xc0\xe0\x1b\x14=g\x80Y?\xbc\xf9D\xbf&\xcd\xf4\xbev\x0cl?7\x88@\xbf0\x13\xa0?w\x1a=\xc0\x04Ul\xbe\xdf\x15 @\xdc\x1eT@\xa3\xeb\x89\xbe\xceJ\x1f@\x06\x16\xd9=\x08Z\xb3\xbf\x0c[+\xbe\x1ad\x17\xc00c*\xbf\x9cp\xa2?\xfe\xec\x9f\xbd\xa9\xeb\xb5\xbf@\xe3\xe6?FN\xf3\xbe\x94mt\xbe+\xb2\xa2?\x860\x05\xc0K\x81\xb9\xbe\xff\xe2\xb3\xbf\xc2\x18;?\x8e\xa7x?z|\x12>\xb1\xbas?\x9c\xd7\xe2?2R\x10\xbe\x106\r?d\xb0\xff>\x90\x02\x90?\x0e\xe6\x1f\xbd\xd4\xfbD>\xd4 \x0b\xc0\xf6\xd4\xdf\xbf\x88\xf3`\xbf\x18`\xd5\xbf\xc63\'?\x8b\x94\xcc\xbf\x81y\xef\xbf\xa2\xe3\x96>@I\x1e\xbfN!\x9a\xbf\xe4\xf3V=\xc9n\x16\xbe\x9d\x94\xe5\xbf\x04\xafz\xbff\x8f\x1d\xc0v\x80\xd6=\xd0\xbe\xf0\xbf\x87\x9a@\xc0i\x1f\x10\xbe\xf1\xf6\xe5\xbf\x9d\x03\x00\xc0I\r\xe9=\x98\xa81?c\xb3\xd9\xbf\x823\xd0\xbf\xb5Y\x86\xbf )\x87?\xd8\xfd\xf9\xbe\x18/\x06@1\\\xdd?}q3?\xd5\xbe\xb5?@2\x96\xbc\x1f\x99\xfe>W\xe0\xe8?\x0e\xdb\xe0?\xc7[\xa8\xbf\x1e\\\x7f\xbf\x96\x9d_\xbf\xe5\x03\x1f@\xfe\x08p\xbf\xdd\x97\x91??a\xc3\xbfq4\x82\xbd\xca\xf7\xc9?\xd0\xe1\xf3\xbfR\xd6\x95\xbf3a\xd4\xbe.\x93\xfb\xbf\xd0Z\xb5;\x84F\x0f\xc04\xe4[?\xe9|\xb0\xbf\xd6\xbe\x18>.h`\xbf\xc8\x9e\x08?TF\x96\xbc\x07\x81-\xc0a\x96\x88\xbf\xff\xd2\xf9>\xa4&+\xbe\x7fx\xe7?#\xa6\xe4?\xb9\x86\xcc\xc0\x9e\xb8\xbc\xbdT\x13\x91\xbf\x82b\xb6>&\xc5!?wx\xa3>on\xb3\xbf\x11\x8b\x98\xbf\xf3\xf0H\xc0}\xaa\xfc?\x98\x83\xb3\xbea\xeb\xee\xbf\x02\xc5\xf8?\x82\xe4\xac\xbf\xe3\x8d\x02?*\x97a\xc0\xe0\xf5\xd2?\xcd1)\xc0\x16\xeb\xab\xbf\xf2\xbe\xe1\xbe\n\xbb\xa5>\x1c\x87\x9d>U\x19\x9a\xbfF\xc1\xb5\xbe\xf7\xda"?\x9ck\xec\xbe\x0c\xcbF\xbfs\x1f\xb5\xbf%\xc8\xea\xbf\xaf\xec\r@\xc4b\xaf\xbf\x0b\x11\x10?\x88\xf2=\xc0,\xe1\x00?G\xc6b@\xa9\x7f\xf5;&\xd7\x98=\x87\x96A?f\xb6b?\x16\xfcX?\xda\xddf?\xc5\x9a\x08@\x12\xd4\x19\xc0\xec!+?\xef\xaa\x94>\x07{\x17@\x99l\x81@\xf2\x99C\xbefy\x14?\xd8\xb8\xe9\xbe\xb8\xceV\xbfSfm?\xf4<\xd9?\xad/\xa8?\x16\xb4i\xbf6\xca}\xbf\xe5\xb5\x10\xbf\x04\xd7\xd6?\xb6\n\xa5\xbf\xfc\x16 \xc0\xd2v\'@ \xc0\x8d?\xba\xd1\xed\xbf\xa1\x16-?\xb88\x12?B.D?=\x99\x9b\xbe\xb8\x10T>\x90\xab\xb1?^\xf6\xf9\xbf\x1e\xff\x9b\xbe\xbez|\xbf\xc3\xde\x90\xbf\xd5\x91\x08\xc06\xc6x?\xc0\x81\\@\x98s\x8e\xbd\x90\x1d\x8a?^\x96R>A\xdc\xdd\xbf\xc0\xd5<?iT\x95?\xe4\xf1\x0b\xc0\xfd\x89\xc9>q\xa8<\xbf\x14\xdd-\xc0\xc0\xe8\xdf\xbf1\xcb\xc0\xbd.,\xd9>\xa1:A@\x9f\x93!@\xb78i?&\xb6\x9e?\xea\xde\xf0>\xa8@\x1e?\xe6\x9a\x94\xbe5\x14\t@0\xd2\xf7\xbc\xd2\xbb\x04@\x1a\xbe;=\xbe1\x1f@\x91)\x87?+lV@E\xbaF\xc0Xh\x9f?PU\x87?\xb2{\xf5\xbf\xe0\x91\x1a\xbf\xd3U\xd8>6\xfc\xe4<\x9ad\x8f\xbf\n\x95\x0b=\xe2\x1b\xeb?\x9e\x03`>\xc6\xe5\x8a\xbe\xe0\xe7\xa4\xc0!\xc14?}B\x0c\xc0\x98\xea\xa8\xbfD\xcb\x93?\xe6]\xfb\xbf\xc6\xdba\xbf\x94%i@~@\x02@\xa80\xe1?\xc8\x8a\xae?!a\x02=,\xdd+<0\x18\x99?\xe1A\x8c?\xb9u?\xc0\xe3\x9d\x8f\xbf\x03J^?"\xc3\x0c?\xa8\xd1L@\x92(l?\xe0^\x17\xbf\x01h\x88>\x0bu\xa8\xbf|P\x98\xbf\xfe\xc5\xcb\xbf\xb1\x02x\xbf\xd7\x8f\xa4\xbe\x03L\xea\xbf\xe0u\x07@\xea\x7f"@c\xbc\xf8\xbf\xa4\xaf\xd7\xbeUH\x93?\xb4w\x00@\xfc\xa1-\xc0\xce\xf4\x80\xbfx\xc4\r\xbc\xc7q\xd2?\xcfB\xd3?\xd6^\x07?_\xba\x85\xbff4\x10@\xf2>\x92\xbf\xdca\xb5\xbf\xef\xe7O\xbf\x82`\x02@>\xcf*>J\xd4\x19=\xbe\x91\xc6>\xacM\xa5?p\xb1\x0f\xbfG\xc3\x9e>\x18HV>&\xbf>?\x07\xf1;\xbf\x83Z\xb0?|\xf1\xe3\xbe\xa8\xe0->\x00\xb2\x00<\xc4)\xcc\xbfl\x0f\x93\xc0\xa0\xa7\xea\xbd\x9f\x1f\x9a?\xcd)\x9f>[\x92\xc0>\'\x16C\xc0\x00[\xd5=R\xae:\xbe\xa1\xc1\x96\xbfG\xfa\x81>\xe4\x8b\xff\xbf\x15\xc0\xc8>]D\xdc?l\xeeA\xbfE^\xa1?\xeb>n?`\xa9\x04\xbeh\x18n\xc0%\x90\x91?0\x11\x9b?\x9b\xc3\x9f\xbf\xd3\xaf9@\xac\x8f(?\x96\xe1\x80\xc0PP\x9f?\xb0\x8d2>t\xb4H?5\xb5\x89\xbfk\x01\xc6?O)=\xbf*\xca2?\x08\xed\x05>pT\xa2=\x92Z>=\xec)\xe6\xbeTP\x00\xbf4\\\x04>\x91\t\xd7=\x9a~=>^\xb10\xc0\x90\xed\x89@\x1c\xe0c>\x1c\xc4T@p\xc2^\xbf"\xef\xf3>\x8f\xec-?\xebFN>\xe7\x98Q\xbf\xf2N\x83?-\x951?\xda\xda\xeb\xbe*\x93\x94?:\xb3\xd3?\x0e?\n@\xfew\xff?%\x1f\xbd?\x82\xe9<?\x12`\x1f?\xc2\xf4I\xbe\xca\x19\xd6?\xd7\xc3\x88?]9\xe4?\xeb\xa0\x0b\xc0\xa4Ma@kb\xc5?\xa8\xe2\xae=\x834B\xbe\xb6\x04\x8f\xbd\xb3\xa9\xb2\xbf=\xad\'@\x92\xb2\x11\xbf\xda\x15\xc3\xbf\xfa\x89)>1\xb5\xc2\xbf\x9c\xb1 ?\x02\xc8\x0f\xc0\x85\x13\xc7?\xee\xeeE\xbf\xd7\xa0\x11As).\xc0\xa4\xeb\xf5\xbe0\xe6L@\x9c\xa6\x05?\x1d\xf4\x8c\xbd\x1a&4\xbf\xc4q\xf4>\xe2\x07\xf6\xbf\xcd\xba\xaf?\xc7l\xc2?\x04@\x9f>\xcb\x8d\x0c\xc0\xb9\n4@\xcd\x17\xdf?}\xdb\x86=b\xff:\xc0\xa8.\\?\x80\xff\xab>\x9c\xbb\xb7\xbf9\x94V\xc0\xeb4O\xc0\xbf\x0e\xd7?X\x18\xd8?x6\x81?\x8el\xd5\xbf\x8bi\x9c\xbet\xf7\xff>\xf9\xcc\xd5\xbf@\xde\xcc\xbe\xb1\x05G?0\xed\xa6\xbd\xcf-\xb5@S\xd3\x84?\x02\x12P?;J\x03\xbf\xfe\x91\xc3\xbf\x9a\x96\x8f?z\tU>\xdb\xa7\xc3\xbfqg\x15?7[\x1c@tD,@B\x03\xed?>\x9d\xaa>\xc6\x9b\x1a\xbf`\xf2\xde?\xb0\xf4\x05?(\xb7\xdb\xbfy\x96\x9a?\xda\x9e\x94?\xbe\x98p@v[\x93>\x0e\xadK\xbe\xdc\x17h>7\x8bG?\xe2\x81\'?\xa4\x19\xff\xbf\x82\xcf\xfe\xbe\x8e\x8a9\xbfU6\xb0\xbf1\x02\xe0?9\xf2\x98\xbf\xf6 J\xbe\x18l\x95@\xf3\x13,\xbf|^\xbc\xbe\xdb\xfd\x02@q\xb9\xc0\xbe\x89X\xd5\xbc\xd0\xe8\x87?\x070@\xc0Y\xda\xab\xbfS3\xc5\xbf-U\xd0?\x80\xdc\x9c:$K\t\xbf', b'\xc6$\x08@\xb5^7@\x86\x8a\x89?\xee\xb1\xff@\x8e\xce\xaa??\x9d\x1d@\x91\xe8\x17\xbf\x17\xb7\xd6\xbf67\xa2\xbe\x0cy\xe3\xbd\x9b7\xc6?\xfeL\xad?\xc5\t\xb1?\x0c\xd8\x9f?Q\xc4\x1d\xbf\xc0\x02\x8a\xbf\xcf^;\xbf^\xf1\x1d@\xb7\xf6e?+\x13F\xc0\x81.\x99=o\xb8\\\xc0/O\xe6?\xca\xa6\xd6?\x8f\xda~?XED\xc0D\xa3\x03@\x7f\xba\x1b\xc2\xd0K\x17@\x0e]\xe0\xbf\xea\xf8\x80?\xf7\xa2k\xbf\x86\x05\x97?`o\x96\xbf\xc9E;\xc0\xd9\xf5J?|\x14\x07>}\xd5\xd2\xbel\x19\r@\x07q\x92\xbfD\xf8\xcf\xbd\xd5@0\xc0\xf2\xb6\x95\xbe\xf3\x98\xc7\xbf(\xc5\xc7\xbf@\xdb8@\xfe<`\xbe\x83#\x91\xbf>\xa2\xfe\xbf\x84\xfeD>\xaf}\xa2?\x02Z\xba>$g\x01\xc0\xe8\x1et\xbf*(X\xc0\x96\x11\x9f>G\x06\xa5?\x16\xee\xc2\xbf\x8b\xc9\x83?8\x95\x99?\xf30J?\x134\xe0?T\x15\x04@L\x19G>l\x91-\xc0\xa4\xf6\x88\xbeH\xe7N\xc0"\x142\xbf\xd8\xda\xf2<\x10L\xd6>m\xa2^?\xa9J\x85\xbd\x04\xcb\xba?\xb6*b\xbf\xe36(\xc0\xc4\x8fW\xbe!$\xec?R\xe9\x85\xbfZ\xcb0\xc0\xd2\x81;>*\xd9\x8e\xbfD^8@\x04\xfcB\xc0p\x8aj\xbf\xce\xf8\xbb?\x9f\xe6\x81?\xf6Y\\@\xd7\x1d\xa9>\x96\xfb\xc5\xbe\xbb\xd5:\xc0\xdeza\xbeJ\xc8\xb3?\x10\x98%\xbf(xJ\xbe3\xc5\x87\xbe0\xa6H?\xafq\xdd\xbf\xe37\xd2?m\x19\x01\xc0\xd4\xc4\x8b\xbf\x06\xd4j\xbf2\xa51\xc0\xd0j0\xc0o\xcd\xbe\xbf\x10"\x05@\xed\x0b\x01>,\xdd\xa4?\xd3zb\xbfl\xc2~\xbf\xec\xd8\xfc\xbf0V\x17@J\xca\xa3\xbf\xd8\x06\xd0=@\xaf\xb7>\xa0\xb6\xb4\xbe\xc0\xc7\x17\xbf$u-A\x0c\xc2Y\xc0\xd2Y\xa3><7\n\xbfw\xe8\x02@\xb6\xc8\xcc>\x0b\x19\xa4>7\xa1o@\xaeG\xb6\xbd\xe7\xc9.\xbf\xe5!M\xbf!P\xd8?\xfc\xe5\xc1\xbf\xb8\xeb\x19\xbf\xa8#/=a\x07\xe0?\xb1\xf9\xee?\xe5j\xea?,\xb0\xcf\xbf>\xd5\x8c\xbd\xad\xbf\xe9\xbe\x10\x904@\xa2\xa0@?v\xe0\xef\xbe\x83N\xae?ORj\xbfE\xaa\x17\xbe9\xe3\xf7?\xb0\xc8\xf5?X\xceG?\xf4S\x03\xbe\x01a\xb7\xbf\xaa\x93\x0c\xbf%\x82\x94@x2\x14\xbd\xbb\xf8\x9a\xbe%\xc7\xdc>\x9a/\n@\xe9H"\xc0z\x16\xfc?\xb7\x05\xbd\xbf\x98}$\xbdp\x04\x05>\x005\n>?K\xa9>\xe5\x0f\xa5?\xcc6s>\xf9Sh\xbf\xc8v\x08\xbf\xf2\xf8\x8a\xbe\xfb\xd6)\xc04]\x16@$\\U\xbf%\xe3\n@\xea\xc0<\xc0\x00\xc7\x86\xbf\x8f\xa0\x19\xc0<\xa5F@A\xc5K?\x8f\'\xaa?\xf67=@)\xa2\xdb?\x18R\x1e\xc0\xf6d-\xc0\x10\xb0|\xbfQS\xaf\xbe\xf2\xba\x80\xbf\xbb\x10\xca?\x0b\x90\'?\xc6\xfd\x02?m\xe0\x83\xbf3;U?;\xa5-@\xedl\x19\xbf\x1c\xa5\xc0?!\x1a\x8a>\xc4\x1b@=^\x96#?\xa1\x84\xd8\xbf\xff9\xd1>\xb8N\t@\x101\xc6<\xfe\x7f\x89?\xe8\x96\x95\xbf\xe6k\xeb?\xe8\xe5\xab\xbe#\xa8`>\x93\x0c6@\xf3`\x04\xc0\xf1\xfcA\xc0u\xc5\xd9\xbfb[\xe4?\xf7\'>@\x90\x18\x1f>\xf4_#\xbe\xcd9\x06@\x1b\x0e\xf7?\xd7\x85\x88?\x99\xab\x96\xbf\xec\x97\x83\xbf\x82#:\xbd\x11A*?"y\xc4\xbe\x80\x15\x9a=2>\x98?\x08\xf0\xaf\xbf[\xa9d?\xe8p\x17\xc0\xa4\xa3\r@\xe2W\xdf?\x92T\xb3\xbf\x90J\x14?\xda\xe3?\xbe\x81\t!\xc0\xd6\xc5\xca?\x99\xc4\x12?\x86%\xa7\xbf!\xd1\x0c\xbft2\xb7?j+\xd4?t\xc2\xfc\xbe\xe5L\x1f?\xb1\x07\x84\xbf\x84O\x17\xbf\xc5\x04\x14?\x95ht@"1~@hn\x91?l]\xe7\xbf\xa7h?\xbf9w\xd5\xbf|\x1e\x00\xc0\x146\x8d<c\xef\x89?\xe9\xb4?\xc0\xc3\x87\xc9?\x0f\xec\xb8\xbf\x83\x00<\xc0}\xe4\xd5?\xd7\xfd\xc3>\x98\x8e\x1b@M\x11*>\xa6\xb1\x88\xbfF\xda5>\xff\xdbg\xbf4u??<\xbbT>\xf2:\x9c?\xfdl\xc2>\xf7k\x82\xc0\xd6\x1dE>E\xc7\xd5?IZO\xbf\x90\xa4?\xc0\x9b\x96>@&\x06\xc2?\xc5e<@Iy\x86=\xc9\x01v@\xc3 H\xbf\x00\x87\x94\xba\xf3\x82\x1d\xc0~\x7f\x12@\x88\xc9:>S\xa8g>&\xe5\x05@\x00p\xf9?\x11\x9b\x06\xc0\xae\x80!\xc0qZJ\xbf\xee\xf54\xc0L\xd3b\xbdy&5?\xb5U9@\xf6\x83\x0e@\x9d\xdeP@:<\xf1\xbex\xc8\x96?2\xdc0\xbe\x0e~\x13?L<\x9b\xbfPF]\xbeJ\x18\xb2\xbf\xbc\x9e\x02\xc0\xe8,\xe3\xbfO\xd3\xcf?\x15G\x14?\x8fr-@<\x8a\xff\xbe\x96\x1c\xbf\xbe,|\x1a\xbec\xfa~\xc0q\x8b\xe3\xbe\xd0{/?;s\n@T\xef\xf8\xbfw=\x05=\xad;\xf6\xbf\xce\x14\x0c\xbf\x0b{\xe4?\xba\x9ao?\xc2\x02+\xbf\xa04\x13?\xd5\x07s@\xb1\xc0S@\x9b%L@\xe2\xb5\x89\xbfT\xdd0@\xe0\xe0\x86?Q\x03\xb0>\x7fs\xa0?\xe3\xa0\xf9>\xb2\xd0\x8f\xbe\x05\xd0\xc4=\x81\xa2\x98\xbf\xb0\x8e\xf7>\xf4\x8e#\xbe\xe3M\xca\xbfuV-\xc0\n\x1b\x05=\x86\x0cd?\xc4\x15\x1e\xbf\xcf\x13\x13\xbf\xcb\xd0\xaf?~_\xf6\xbe\x91\xec\x84?d\'a\xc02\xc8`\xbe5\x0f\x15@\xb4w^@P\x8f\x9c\xbd\xac\xd44@\x02\xf9\x8f\xbdB0\x82\xbf\xe0^\xe0\xbe\x96i\x15\xc0h7c\xbf&\xdf\xb8>Y\x13[>\x9e\x94\xb4\xbfE(\x85?\xf4f.\xbf\x00%\x9c=\x96#\x9c?\xf0\\\x15\xc0\xb6\x12\x81\xbev\xb0\xb7\xbf\x1b\xd9l?XT\xb1?\xdeC\x1e>\xf3\xfc\x92?\x897\xf8?P`\x81>\x91\x06\x1e?3\xc4\xab>X@\xb1?\xb21->\x18\xe8_>\xd1B\x02\xc0Sf\xce\xbfEA\x80\xbfR\xf4\x95\xbf\xdeV\x07?\x85-\xa0\xbf\x9a\x8a\xfb\xbfT"[\xbdM\xfb\xf1\xbe4e@\xbf\x0b\x99|\xbe\x98\xfb\x85\xbem\x14\x0e\xc0\xba\xa75\xbfo`\r\xc0t\xc7\xc6\xbd\x86X\xf7\xbfN\xaf\x1c\xc04\x1c\xfc\xbe\x8e\xd2\x0f\xc0\xa4\x97\xfe\xbf\xbei\x16>\xb5\x89\x1f?\x14\xdf\xb8\xbfI^\xb9\xbfS\xcc\xa7\xbf\xdb[ ?\xb6T\xd7\xbdT%\xfe?\x15\xec\x99?\xa9\x84w?\x99G\xe8?;\xd1n>Y\t\xa6>\x0c0\x01@\xa4\xf5\x04@.P\xa7\xbf\xb1\xac\xad\xbf>\xf4q\xbf6\xa6\x1d@\x08"W\xbf`;\xa7?\xfb$\x8c\xbf4\xf6P\xbdZ\x1b\xb4?\xbf=\xea\xbfO"\xd0\xbf\x8c\xec\x84\xbe\xb6\xa8\xf0\xbf\xdc\xff\x1e>\x9d\xca\x11\xc0\xaf\x1e<?+\xe1\xe2\xbf\x9c\xe5\xda>\x00\x16\x97\xbf\x05\xd1\x14?\xdb?\xcd\xbeV\xb0 \xc07\x0e\xad\xbf\x06\xffY?{}(>c\xb1\x02@\xb7\x94\x14@c\xe5\xcd\xc0\xd0O\xdf;\xe3J\x9f\xbf\xabO\x81?>\xbf\x1b?>H\xdb>hm\xcd\xbf\x9c\r\x8c\xbf\xc71%\xc0Y\x93\xff?\xdfO\x9c\xbe\xe9et\xbfRd\xb7?Wo\xa4\xbf\x8f\x12=?\xb5\x1fs\xc0\xea\x12\xc0?\x98v\x1a\xc0\xb0\xcf\xc5\xbf\xf6aC\xbf\x08R??\xf2d\xab>\xdd\x18|\xbf\xabk\xc4\xbe\r[\x01?\x18\xae\x1d\xbf\xd2\xc3\x92\xbf\xf16\xfd\xbf|\x13\x1f\xc0\xf7\xef\x1b@\xfc\xfb\xcb\xbf\xa1X\x01>"\xdd.\xc0N\x9a\xb8>\xe3\x8eX@\xda\xccN>X\xa0\x0b>\xc4\xb6*?\x85\xa0\x83?Ytp?x\xcf\x95?\x16\x82\x04@\xb3)\x17\xc09`7?Ty\xb6=\x06\xad\x17@r\xd8\x8c@\xad^|>\xc9=\x19?\xd9\x15\xe5\xbe\xb6\x97\xb3\xbfV\x8f\x19?\x02\xd0\xdd?<\xe5\x92?0\xa1o\xbf>0w\xbf\r\xe75\xbf{\xc2\xbf?\xfb\xe4\xd9\xbf\xa0\x8c?\xc07n%@#\x07\x80?8\xb1\x05\xc0\x81_q?\x16\xc5S?&i\x12?\xdc\xdeq\xbe\xbd\x8e\xa0>Nh\xbd?\xc0\x03\xd6\xbf\x00\xf9.\xbfT\x01\xb2\xbf\xed\x0c\xe2\xbfB\x93\r\xc0\x1e \x81?]\x01v@_(|\xbe\xd1\xf6\xae?2IW=\x1e\x00\xdc\xbf\xa5\x02[?jyA?O\x00\x13\xc0\x8e\x1a\x17?85C\xbf\xb4\x85@\xc0\xf5\n\xab\xbf|?\x81=\x1d@\xe4>\r\xf1H@$\xa2.@\xfc\xe0Y?\xd3:L?\xfa\xba\xd5>\xaa-^?\xe0\x99s\xbe\xf6\xdc\x00@\xd6\x00k\xbe\x87\xe8\xd5?\x0eQ7>\xc2\x0c#@\xd5\xfay?,\x80V@fJ;\xc0\xb2ND?\xf3\xcf\x85?\xfc\xef\xf6\xbf\x06\xd5\x8b\xbf\xa0b@?\xc2xl=\x9bpY\xbf\xfc\xb4\x1b>C\x94\x0b@\xdc\xb5\x07\xbe{8\xb3=\xcf\xeb\x8f\xc04K}?\xc4o\xcf\xbf\xe3\xb1\xb1\xbf\\+\xa4?$\x16\x00\xc0\xf5\xb7l\xbf\xc7\xddI@\x95\xcd\xc8?\xd4\x08\x05@\xc9c\xaf?\x83\xfcD>A$\x85> O\x8a?\xd7\xc2\x80?\xae`<\xc0l\xd5\xb0\xbf\x13~U?m\x81\xe8>ZX"@\xf5\xc2\x1a?_;\x02\xbf\xdd\xe7\x85=\xae\xcc\x85\xbf|\xb1\xc2\xbf6\xea\xec\xbf\xd5\xd7d\xbfe\xf0\xca\xbe\x7f\xcf\xf5\xbfA\x8c\x01@\x84A\x13@t\xd5\xf5\xbf\xf5\xfa{>Uq\xa6?\xdb+\xf8?\xbb\x81\x17\xc0\x8b}\x8a\xbf\x0c\xden=\x8b\xb4\xae?\xcf\xcf\xf8?vvQ?~\xb8\x83\xbf\x8a8%@Q\xa7\x80\xbf\xeb\xe4\xb4\xbf2\xdb\x14\xbf\x8a\xcf\xeb?\xe86}\xbd\xdch\xc4>\xde\x18s>L\x13o?:\xfc~\xbf\xa6E\xe0>\xe1\x8c\x0e?K\x03T?\x7f\x08E\xbf8]\x93?\xc6\xd5\xf8\xbey\xfb\x81>\x8c%\x1a?\xe1\x00\xab\xbf\xbd\xdd\x90\xc0\x984R\xbd\x193\xa7?,(v>J\xae\x19?\xdd_F\xc0b\xf9\x18?\x05\x1b\x86>#]\x8c\xbf\x98d-?\xa0\xf9\xed\xbf\xfd\x0b\x01?>\x9f\xe4?\xda\xf1q\xbf\xd4\x8c\xb9?\xd0\x19\x8a?\xcf\xe8\x84\xbe\x13X~\xc0\x13XH?*\xfa\xbc?\xaa1\x95\xbfN\xc8\x19@\xdd~\xd1>\x93K\x89\xc0\xb54\xb4?\xb7\x98\x06?\x02\x00\x08?\x9b\xea\x95\xbf\xa5\xcc\xd7?\xff\xb7\x87\xbf\xc4\xb2A?\xb3\xcd\xc9>\x84\xea\xd2\xbd\xda\x14\xdd\xbd\x12\xcf|\xbd\xc3e\x82\xbe\xbd\x959>\xa4u\xcf\xbe\xc0\xf1\xc2;X_)\xc0r\x06\x86@\xe4!r>\xc9\x89R@\xee\xf5\xa7\xbf\xdc`\xe0>\xacw\xf2=\xdb\xd5g>\xd6\xe4)\xbf\x13Dr?\xd8U\x04?R\xb1\xf4\xbe\x05\x91\xb2?\xe6j\xcc?5\x88\x14@\x8c\xde\x02@\x93f\xc0?&\xcb\x1f?\x9ca\x03?&4\xe4\xbe\\\xa2\xf6?\xd4\x0f\x9e?b`\xf7?\xe6d6\xc0A(U@\xae\x96\x90?\xce\x80\xd3<\x18\x81\xbc\xbe\xe0\xa5\x00\xbew$\xcc\xbf*5\xfa?\\z\xca\xbe\x14*\xe4\xbfB\x10\xcc>\xa1c\xc5\xbf\x9c\xca9?\x97i\x13\xc0\xdf7\xb4?O\xb0f\xbf\x88\xfe\x0fA\x0bl&\xc0\xf1\xd0\x0c\xbe]\xe7?@\x1ev\xe6>R\x9a\xee<\x05?\x13\xbf\x03\xa1#?\x91]\x11\xc0\xc3\xfe\xb3?%1\xa8?f\xde\x8c>\xb1.\t\xc0\x10\xe3\x16@2s\xf8?\xd3\\\x0b\xbe\x96\xafN\xc06D\xf0>v\x1d\n?\xed\x85\xbb\xbf\xd9\xb8W\xc0\xf1\x93T\xc0\xa4\xc9\x85?\x0c\xc9\xbe?\xdbq\x83?\xb0\x80|\xbf\x97\xee\x83\xbeZ$\xee>\x0b:\xd5\xbf\xbd\xab\x18>5\x82.?f]7\xbe\xe4\x06\xb4@\xb0\xd8z?\xa4\xdfn?J_*\xbeN\x9d\xd6\xbf\x98\x1aj?4\xa9\xc6<\xf2\xec\xda\xbf\xfd=6?\xaf\xe2\x1a@\xd5\x9d@@\xe3\xe4\xe6?\x18\xd50\xbez\x1au\xbf$Y\xe6?T\x82\x0c?\r\x07\xa9\xbfD\xa8\xa5?LI\x94?\xc4\xffx@$B\xfa>j\xaa\x9f\xbc\xe6\x99\x0c>\xe2\xea2?\xec\x11\xfe>-\xf8\xe7\xbf\x02\xf5\xf9\xbe\xbf\xfb"\xbf\xf9b\xbf\xbf\t\xcd\xae?A[*\xbf.7\x99\xbd,\xd8\x93@,>t\xbf\xfcab\xbe\x9a\xc0\xaf?\xe1\x90>\xbf\xb91\x18?\xe2%\x95?\x1bcS\xc0\x82\xa5\xcf\xbf(t\xc4\xbf\xf3\xd9\xbe?\xfe\x7f\xba\xbd\xbc\x8f\x9c\xbe', b'\xa4O\x0b@\xf5\x03\x1f@mo\x8f?\xd4\x7f\x05A\x84\xd7\xdd?\xe4\xde\x10@ \x97\x85\xbed\xe4\xa3\xbfS-+\xbf\xd0\x1f\x04=e8\xf5?\x80\xdc\xea?\x89\x13\xbf>\xad\x00\xa5?e\x04\x03\xbfY;$\xbf\x15|8\xbf\xb1\xb1\x07@7v\xb1?\x80\x18D\xc0u\xe2u=\x88\xecO\xc0\xfe\xb5\xe7?\xc2\xd8\xa5?FA\x85?\x8acb\xc0\xfb\x84+@\xe3\xa7\x1a\xc2\xd5U\x10@d\xe5\xfd\xbf\x88M\x8d?\x97\x0e\x02\xbeB\x15\x94?\x08\xd5\xac\xbf\x17\xa25\xc0\xefg\x92?Q\x1f\x8e\xbe\x14B\x06\xbf\x04\xbb\xf8?2\xe6s\xbf\xe7d>\xbe\xda\'2\xc0;\x1e@\xbf\x82\xff\x86\xbfr\xaf\xd4\xbf\xba0\x04@\xe1\xbc\xa3\xbeKs\x97\xbfgo\xe0\xbf\x80\x80\x84>\xea\xe2\xa4?0\x1d\x83?\x13\x9c\xe4\xbf\x92\xd7W\xbf\xb9\x81p\xc0Ve\xd8>\x93\x1b\x80?\xf7\xa8\xa6\xbf&\x06e?\xc2\xfa\x05@q\xdf\x94?\x89\x9e\xc1?\xf6\x8b\xad?\xc6\\\xa9\xbe)t,\xc0\xb1\x1cH\xbf\xb3\\=\xc0^\x84\xb3\xbf\x07\xa7\x1a>!\x0bc?\x16\xd6\xa7=\x9e\xa0\xf9\xbd\tL\xe8>\x97\xc4\x07\xbf,\xd9\x1a\xc0\x0em\xde=\xd2\x13\xd3?F\x05\xd4\xbe\xf3\x04\xe0\xbf\xbc\xe3\xfa>t\x02\x05\xbf\x9e\xb9&@\xec^/\xc0Q\xc6\xa2\xbf\xb3\xe1\x85?G-.?\xeb\nU@\xce-\xe5>\xcc\xf6\xec\xbe\xc1\xb1\\\xc0\x82U\x05\xbfw\xf7\x9a?\xd4\xd7\xd8\xbe\x90\xd2\xb9\xbd\xdd\x02H\xbfj \xa5?\xbf\x1d\xa7\xbf\x88v\xc8?uP\xef\xbf\xab\xf2\x1e\xbfi\xeb\xa0\xbe\xfe?]\xc0,X5\xc0\x98D\xda\xbfMT\x04@\n\xcfM=<\xef\x88?\xc8\x9a{\xbf\xb7\xe3H\xbfyH\xf9\xbf\x93\x18%@\x069\xb2\xbf\x81>*\xbf\xe0\xaa*?<De\xbf\x8b\x88\x1b\xbf2\xeb5A\xc01\x81\xc0\xff\xba\x1d?yE\x90\xbet\xb9\xe0?H\x9b(?\xac\xaf ?\x815c@0I\xf3\xbep-\xf7\xbe\xae\x99\x82\xbf\xd3#\xc8?\x96r\x9e\xbf0Hk\xbf\x1a\xa9\xb5>\xeeo\x04@\xd5K\xaa?\x88\x00\xbd?\xd6X\x04\xc0\xc2\xc1k=\xa4\x84\xdb\xbe\xa8\x9a%@0\x87\x9e>H\xa6\x06=\xedF\x89?\xfd\x9e\x8e\xbcx\x010\xbf\xfc\xbd\t@k,\xb1?\xe1[R?P\xd2\xbb\xbe0\xda\x97\xbf~0\x12=R \xb2@d\xb4\x0f\xbf<\x10\x9b=f\x15\xf9>\xf1\xba\x1b@CS2\xc0,R\x16@\xe5\x1a\x8c\xbf\xae\xc1\x96\xbdd\xa2\x13\xbe\xec\xeb\xe2\xbbP\xee\x0b\xbe\x85\xbd\xaa?C\xbc\x99>\xaa*\x07\xbfGWp\xbe\xea!\x17\xbeG\xab\x11\xc0s#!@V\xb8\x06\xbf\x96T\xd5?\x0c\xd8.\xc0=\xb8O\xbf\xb3n+\xc0T\xdc\x1c@\xc4\xa7\xa8?\x0b\xe5w?\xb5\xfb<@\xd6\xca\x95?\xfa\xeb\x12\xc0b1V\xc0\x15\xf7\x1a\xbfT2\x85\xbe\xca\xf5t\xbf\xd2\x0bT?\xe7H\xbd?\xa9\xd3\x0b>\xc9\xa9S\xbf\xf0\xe8j>\x80\xc2\x11@\x88\xe24\xbf\xaa\xfe\xea?l\x13\xa3>\x11\xc5\x00?s\xf25?0N\xb7\xbf]\xacL>\xf8\xd2\x00@\x98\xfbz=\xc0_\x87?\x08\xb9\x88\xbf\x1bV\x92?A\x86\x99\xbf\x1aHE>\x1e\x05c@\xbd<\xcd\xbf\x88y"\xc0$1\xf1\xbfX\xfc\xae?\x826B@t\xfd\x01\xbe\x80\xc3\xe7\xbekr\t@\xe1V\x08@\xe9Qi?\xf2[\xb5\xbf\x13}\x8b\xbf\x9e\xec\xd1\xbd\xd2\x10$?\xddS\r\xbf\x7f\xe9\xc4\xbe\x17\xb5I?U\xda\xb1\xbfm,l?\xa2\x84\x17\xc0\x00\xa9\xe1?\x08_\xcf?\x0fe\x8b\xbf\xa2\x13j?\xb6\xe8\xc2\xbe\xd2)\xfb\xbfw\xe8\xdd?\x1e*c>\xf33Y\xbfY\xe0\xdb\xbe8\xcd\xea?9\xaci?I\x8cA\xbf\x13p\xc3>t\x9d\xae\xbfFu\xf5\xbe\x18\xde\xd8>\xec\xb4\x85@(s\x8c@\xf4Y\xae?\xc3\x9d\xe2\xbf\xe3\xb7.\xbf\x91+\x8b\xbf\xba\xe5\xf7\xbf\x0e\xdb\xda\xbe7\x07S?"HR\xc0g\x85\x8e?@\xf1\x1e\xbfi\xe4,\xc0\x98|\xa4?T\x05\x00?\x1a?!@\xce3\xe9>\xef\x7f>\xbf\xe0Jf=\xd6\xbd}\xbf\xbe\x06\x06?\xc6\x0f\x9d\xbd\xa73\x89?-\xd18?\x97\xc8\x84\xc0\x81\x7f\xa7\xbe\xcd\x8b\xf3?\xac\xae\x92\xbf\x08z*\xc0y\xc8*@\x9c\xc0\xaa?\xf1,)@\xbd\xc5\xbb\xbe(\xabc@<f?\xbf\x1c\x0e\r\xbe\x8dc"\xc0[W\x05@\xb6\r\x92\xbe*\x0c\x93\xbe\x86S\x19@z\x9a\t@Y\xa2\x19\xc0/t\x10\xc0\xe5\xf9#\xbe\x1f[#\xc0\x8e\x16\xa4>k\x17\xd0=W\xac\x0b@\x9b\x85\x0e@\xad\xc3D@\xc6\x1dR\xbfC\xf4\x8c?P\xd8\n>\x0e%\x80>Z\xa4\x88\xbf\xa9\xf1\x90\xbe\x86!n\xbfg\xc9\xdd\xbf\xd7]\xf1\xbf\x05.\xc7?CL1?\xfd\xe0\x0b@?wX\xbfV\xcd\xfd\xbeL\x19\xd5\xbd\xff\x8dx\xc0\x0c/\xf6\xbeZ;D?)\x9d\xbd?\x0b\xbd\xf4\xbfmj\xd6\xbeA\x13\xdd\xbf6b\xea>\x9d\xa5\xe0?\xf3Qu?\xf2]\x8f\xbf\xbc\xc4E=\x94M\x88@\xd4\x05\x1d@L\xa6>@\xc0\t:\xbf\xc8\xe2\x17@f\xa8\x80?\xcd\xa7\xd2>w\xcd1>(\x9f\xa7><\x8a\x17>\xc8C\x04>\xd8u\xea\xbe\xaaX0?44\xa9\xbe\xa1\xdf\x03\xc0\xde\xc0E\xc0\x9a\xc7)??U\xe1>}0\xca\xbe|B]\xbf\x1e\x89\x84?\x9a\xe7\xf7\xbe\xd2\xd9\x85?\xc9\x06&\xc0\xe0\x14\xf1\xbc\xb3\x9e\x19@\xb2\xbap@L\n\xb7=\x15\x14:@34\x01\xbf\xc2E\x89\xbf\xd8t\x96\xbc\xb7_\r\xc06\x98\xa9\xbeVc\xb7?\x1a3\xe5>(\xe0\xb6\xbfA\xff\xb5?\xaa\xf7\xa5\xbe~l#\xbe\xcf\xbd~?\x80\xb3\xdc\xbf_f\'\xbe\xbb\xf1\xe5\xbf\x18~\xbe>\xd1\x8d\xa9?\x07\x88\x1f?:+\x91?"A\xe6?C\xe4(?H\xc7\xd9>\x11\'\x85>\xcb\xdc\x99?\xe6F\x02\xbf\xd0\xf3\x04\xbf\x83[\xf5\xbf8\xad\xb2\xbfNEe\xbf\nn\xcc\xbf\x18o\x0c?@\xc4\xe2\xbf\x96j\x13\xc0%a\x96>\x96\x10j\xbfa\x91\x93\xbf\xd1\xc1\x07\xbeh\xd0\xed\xbebo\xb9\xbf\xc3!\x9d\xbf\x98\xbfH\xc0h\x8aW\xbeN\xf7\x10\xc0,\x02\x1f\xc0\xf17o\xbft6\n\xc0;/\xf2\xbf\x10\x8d\xfe\xbe;\x85\xff>\xf1O\xd5\xbf\xf6\xf4}\xbf>\xfb\xb3\xbf\xd9\x93\xd7>\xf5l\x80\xbe\xaa\xc1\xc5?\xc2\x0e\xdd?\x8e\xf8\xd9=,\xd5\xd6?\x01H\xba>E\x8f\xd9>\x83|\x0f@\xf4\xc1\x03@WZ\xb7\xbff\xf1t\xbf\xe3r\x8f\xbf\x82\xa9\x10@R\xa2W\xbf]\x8f\xe9?\x15\x16\xc8\xbf\xe8\x8cX\xbe^\x99\x83?\x94\xa2\xdf\xbf\xdc\xe2\xab\xbf\x89f\xc4\xbe\xa0\xee\'\xc0\xbc\xdc\xf5\xbe\xcf\xd1\x1a\xc0\x91\xddg?Q~\x92\xbfPvV?Z}\x99\xbfj\xfb\x0b?\x9a\xf4\xfc\xbe\x83+\x1b\xc0\xb5\x89\xc5\xbf\xb4\xffq?m\x1b \xbf\xde\xe3\xdf?\x97\xbd\xd0?\xfc\x1d\xcd\xc0\xe0\xd4\x99;f\xbe\xa7\xbf\xfb\xec\xd7=\xb7n\x9c\xbe\xc7+`>i\xc2\xb4\xbfM\xd7\x8d\xbfK\xc4\x0b\xc0i\x7f\xe6?7K\x8d\xbe\xd9\xd5\xcc\xbf\x0f\xfc\xa0?=\x0b#\xbf{84>j\\F\xc0)\xe1\xd9?3\x8b\x19\xc0\xb3\xc4\xa3\xbf\xf1\x06\x00\xbf\x1dQ]?F\xac+\xbe\xbc*\x02\xbf\xc97)\xbf\xe1\xe1\xc8>.\xdc7\xbf\x7fF+\xbfk\x15\xe6\xbf\x9e\xa3%\xc0R\xd4\x1e@\xa1\xc7\xaa\xbf>\x80.?&\xa9\x07\xc0sQ\xc3>?\xf2V@U\x03,?\xa1\x8d\xad=$\xfc\x99>\x18\xa0\x88?\xe49\xc1?\xc2ny>!o\x05@\xab{\x19\xc0>I?>\xcde\xc4>\x12\xd2$@"\xbdr@>)\x15\xbe\x88\x89\x9e?\xa9\x03\xb3\xbe\xe90\x0e\xbf\x9a\x01%>\xd1\xc8\xbc?\xb5\x8f\x99?\xe1JO\xbf\x81f\x93\xbf\x90j\xef\xbe\xbd\xc5\xc9?\xb2\x91\xd3\xbfzH\x19\xc0\x18\xfd\x1f@\xb2P\xe2?\x94"\t\xc0\x16p@?\xbc\xfa#?\x95o??\xa6\x88H\xbe#\xd6\x1a?3\xd9\xac?\xcc\xe8\xb7\xbf\x86S\xef\xbe\x92\x84u\xbf\x9cFO\xbf>\xcb\x0c\xc0\x8e\xcd4?\xbclg@\xb1@5>\xc2d\x97?\xbf!\xc0>j\xc5\xcb\xbf\xda\x05*?\xeb)w?\x1f]\xcc\xbf\xc6\xa4I?\xe5)\x1e\xbfYSB\xc0\xeb\x0e\xde\xbf\xeeL<?\xe23\x13?\xed-J@C\x9e&@\xe4\x1e\x91?\x7f\xee\x9b?\xbd\x95g?\xb9\x00v?\x18\x88\xa5=\x8c\xdc\xfa?\xc6\xfd\x80\xbe\xf0H\xc1?\x8e6\x83>z`"@\xd2\xa2)?\x03\x0cx@\xce\x93;\xc0\r\x03L?\xcf\xfd4?Qe\xca\xbfr\xfb\xc3=3\\A?\x94\xdf=?\xd4\x81;\xbf\xd6\xb80>\xe3\xea\xfc?p\x85\x92=T\xcb\x08\xbf\xab\xeco\xc0\x0eL\x87?\x14\xbf\xff\xbf\xbe\x9b\xb5\xbfN\x07v?\xf0$\x04\xc0\xeb\x1bo\xbf50S@\xf6\xb5\xf1?*\xfd\x02@\x9fq\x9d?\xc5\xb1A>\r74\xbek\x92\xfc?\xcdR\x8f?\xbcy?\xc0\xbc,x\xbfpW\x9e?\x8ex\xb9=\xa9\x0bX@\xb6\xcd\x04?q\xc2$\xbe\xe9\xe1\x9d\xbe\xde\xa9\xa2\xbfn\xe1\x82\xbfK\xe6\xcf\xbf\xd6\x07\xfe\xbe\x84o\x04\xbf\xbbwX\xc0\xc7\xa0\xcb?0\x02\r@[\xa4*\xc0x~\xa4\xbd\x1c\x88\xc4?\xfd*\xc9?\x99\xe44\xc0\x84\xf9<\xbf\x16\xca\xce\xbd\xa60\xc0?+\xf5\xc5?\xd4\xda\x10?\xf6c\xca\xbf\xcc\xba(@\x93\xd6G\xbfd=\xa6\xbf\x04P\xc2=\xcac\xc1?n\xb6\xe8>\r\xd2>>\xc09^?\xc0\xce\x84?\x14\xf31\xbf\xd0z\xb4>\x8f+\x11>\x8cw\x9f>^7%\xbf\xdb\xc1\x9e? \xdbF\xbe\x87\x90D=D\x14\x8b\xbd\x12\xd8\xd4\xbf\x08\nm\xc0\xd8\xac\x7f\xbe\xf8J\xa3?\xeb\xcd\xad=\xf0\xc8\x8c>\x825O\xc0\xc8\x18\xcd>\n\xc8\xa8=\x05\xe8f\xbf@\x1f\x18;\x03\xab\xe2\xbflX\x91>&\xef\xbb?\x9f\xc1\x9a\xbf31\x8e?a\xfd\x05?\x06\x11\x98\xbe\xd8\xbbf\xc0\x1c\xa7\xee>i\xb4\xbb?\xd7\xcd&\xbf\xbc;\x1b@\xe8\xc9M?\xab\x92y\xc0\x8ey\xe6?a\xee\n>\x08\x9e\x89>nr4\xbf\x11\xe4\xb3?\xd8\x1f\xa2\xbf\x12t1?1\xca\x81=:\x96\x95\xbe+0\x08?\x82\x88\x10\xbeA+\xcb\xbeB\xe65\xbe\xfe$\xb5\xbe(\xc7\x93\xbdy\xee\x03\xc0CR\x7f@\x8e\xe2J>\x04\xde\x88@"\xcb9\xbe\x86 \xe3>\xb69.=8\x9d\x0e=-\x9e\xf8\xbe[^\xfa>Uc\xe4>\xf6\x88k\xbc\xedo\x96?\xd4\xc3\xdd?Z\x9a\x00@\xe7U\xe5?\xce\xd6P?\x8f\x93\xa0?W\xcd\xb3=~LK>f\xaa\x94?\xdctm?\x89\xdc\xbd?@\xf1"\xc0\xe9\xd4z@\xe06\x01@\x96\x1a\x15?\xa7\xdeD\xbf\xa4\x94\x86>\xb5T\xaa\xbey\xfc\x14@\x8ar"\xbe\xf1S\xc7\xbf\xa6\x0eP?\xfe\x96\xc4\xbfJ\xb0K?>I\xfb\xbf\x85\x9a\xa6?V\xce4\xbf\x15\xdd\x14A?\x1d(\xc0\xf012\xbf$-5@D\xacL=\xe8\x10\x95>\xe4\x873\xbf\xa1\x91F?\x86\x14\x1f\xc0gH\xae?\xdb\x85\xab?\xfa\x10X>FP\xf8\xbfa\xcb\x14@\xa9\xb6\x99?k\xdb\xee>\xb5\x9dF\xc0\x8e9\xe6>wK\x11?\tZ\xca\xbf\x02]z\xc0!\xa5*\xc0l\x88\x0b@\x8d.\xd0?P\xf4\x8b?>\xf3\xc2\xbfT*\x88>\x1c\x03W?H\x7f\x91\xbf(:l\xbd\xcf\'\r?\xf0\xf0\x00\xbe\x11\x96\xb4@\xa0+7?\xc9\xec`?\xc8\xa3A\xbfw\xdf\xa1\xbf\xf5\xde\x9c?4s\xd5\xbe\xfdQ\xb5\xbf(O1>\xfb\x8a\xe8?\x9eg\x17@\x14\xd4\xac?M\x02\x18\xbf\xef\xffJ\xbf\xf6\x85\t@S>j?{\xb9\x0b\xc0-\x9a\xdd?\x94\xd6\xdc?\xd7\x82\x9d@W\x90`?<\x03 >N\x81\xf8>\xf9\x8cR?@J\x0f?\x06 \x06\xc0\x18\xe4$\xbdA\xca\x98\xbf\xc4\x99\xb5\xbfO\xcf\x04@\xe2tx\xbf\t\x9f@\xbeZ\x9b\xaa@\xf4\xfaD\xbf8\xb3\xbd\xbe\xa8"\xb0?\xb6c\x8f\xbd\x0c\x1b\r=|3\x85?\xc2-/\xc0g\xa0,\xbf\x0c#\xd4\xbfr\x08\xb6?\x01\xe19?"\x1d\xfd\xbe', b'\x08\x0c\x0c@3\xc1\x1e@\x7f\n\xae?\x8cz\x00A\xde\xa4\xca?"|\xeb?KN(\xbe>\x8e\xc8\xbf\\\x7f=\xbf\x14I\xb1\xbe\x84\x8d\xc1?\xbb\xe8\xcf?\\G"?\xec(\xa5?\xbb\\y\xbf\xc5\xfe\xa9\xbf\xe5\xed\xcd\xbe\xa44 @Y\x1b\x98?8?A\xc0\xfe&\xf1\xbd\x9c\xdfV\xc0`9\xa7?;J\xb5?\xc7\xea\xb6?M\xb6w\xc0\x0c\x17\x0b@\x952\x1b\xc2\xeb-\x1f@\x95?\xf0\xbfb\x11\xa6?p}`\xbf6\x14\xd3?0\x95\xd9\xbe\x11\xf3\x1c\xc0\xca)K?\xa3Z\x8a>*\x8f\xb4\xbe\xbaN(@m\x1d-\xbf\\e/\xbf!2(\xc0\xc4\xde%\xbfy\x16\xa1\xbf\xf6\xb2\xd2\xbfv\xca1@\x02P\x89\xbeAm\xa0\xbfM\xd6\x00\xc0\x0c\x9d\xfe>\x85\x13\xa1?\x06\x1b\xc1>\x815\xd8\xbf\xfd\x16\x97\xbfl\x10K\xc0\xe7b\xeb=.CW?\xa1\xdd\xd1\xbf\x1a\xcb\x7f?\xb7\x8e\x8f?\xd4\xd9$?\xec\x16\xa5?\x84\x00\xc2?@"#>\xber+\xc0\xf8\xeab\xbd\xdc\x88I\xc0\xb8ce\xbf6\xd8\xf4>\xf8\x02\x87?RN{>\x8ct\xf2>\xd8\xa7\x11? :\xd5\xbe\xef-@\xc0\x85\x0c\xc1\xbe\x19\xc5\xb4?\xe1\xf9u\xbf\xd56\xef\xbf\xd8\xe5\x13\xbe\xaa\xdf8\xbf\xb0\xca+@\xfb\x845\xc0\x00]\xce\xbff\xc4\xb8?\x98\xe4W?\xee+L@O\x05\xc6>\x0c\x7f\x8b=\xde\xeaI\xc0\x0e(\xac>\xb2\xf6\xbb?\xbc\xbc\x83\xbf0\xf2\xe4\xbb\x8d\x9f\xf4\xbe\xc5\x96\x0b>,\xdf\xf9\xbf.l\xd1?\xfd\xc4\x16\xc0q\xc3\x95\xbfT\xe1\x17\xbf\xbfc(\xc0\x01\xfc/\xc0\xd7K\xc7\xbfTx\x01@\xdaa\xc0=jU\x90??\xb9\x07\xbf\xaa\xa87\xbf2\xa0\x07\xc0J\x98\x1f@\x0f:\xbd\xbf\xec\xcc\xad\xbe*\xf65>\xa6\xc0\'\xbf\x88\xd0\xc7\xbe0\xc85AJ\x18{\xc0\xd8\xcd\r?\x0cb\xcd\xbe[\xa1\x07@\xb4&:>\xd5t\xc0>\x85<]@%\x02\xc9\xbe\xcaT8\xbf\x058#\xbf\x1f\x9a\xea?<\x0c\x8e\xbf\xda\xd4\x89\xbep\x12i\xbb\xa9x\xd6?\x8fH\xea?\t\x0f\xe5?\x03 \r\xc0E\xb2d>\x9ft\x84\xbf\xcd0;@\xf3\t\x03?\xd0B\xd2\xbe>Ms?\x04\x93;\xbe,\x10\xb0\xbd\x9e\x80\x05@ak\xd9?\x8c2y?\x92|\x01\xbetF\x8d\xbfl9\xac\xbem\x0c\xb0@\xac\xd5\xce\xbd\xa5\x05\xd5\xbeS\x03\xed>\x84v\x0e@\xa1\xe5&\xc0\xaf \xf9?\xd0\xa8\xbd\xbf\x1a\xbc\xf6\xbe\x01\xaa\xd4>.\xaa\x1b\xbf\x1c(<\xbd\xd4\xfc\xc5?\xb6\xe7\xe8=#\xc4*\xbfs_\xd6=:\x16\xde\xbe\xa4\xf8\x1b\xc0L\x0b+@\xce=\xb5\xbe\xb4\xd4\x14@}\xffI\xc0\xb7\xa6\\\xbf\x1eF#\xc0{L<@2\xed\x8a?y\xee_?LcU@\xae\x96\xa1?\x02-\x0b\xc0Z\xbdI\xc0\xa3\xb3\x9d\xbf\x95\x86Y\xbfP\x8e\x9b;\xd8\x9b\xb7?\xe3Z"?{\xc8r>\xc3-b\xbf\xd04\x91?\x9fj\x15@h\x92\t\xbf%\x91\x07@P*\xad\xbe\x06pt>e\xea\x1a?\xb5M\xdc\xbf!\xd4\xae>iT\xf0?L\xcc\xd6\xbeF\x0c\xa7?\xa9\x15\x86\xbf\x94\x96\xa8?\xc03\xfb\xbe\xd7\xda\x0c=\xa4\x07`@P\xa6\x04\xc0\x9f\x01\xed\xbf\xae\xd3\xe9\xbf\x92\xe7\xe5?\x19=(@\xb4K\xa5>\xe0\xee\x81<i$#@S\xae\xf3?P\x9f>?\xf4\x9ed\xbf0$\x8a\xbf\x1bk\xc2\xbe+\xef\x8c?\x986\x18\xbf\x10\x92\xec\xbeY8\x85?\xce\xea\xc0\xbf+\xcc\x12?\x97\xef\x19\xc0\xba}\xec?\xaa\xba\xd3?s/\xa0\xbf\xa8"+?\xca0\xf8\xbe\x8d\x01\x17\xc0r\xcc\xc6?\xca\xb6\x89>t\xd0|\xbf\xb8\xeb/\xbf\t\x80\xe0?\x17;\xc2?\x88\xd0\x86\xbf\xa8\x9b\x8e?\xe8\x19\x9b\xbf\xc1C\xd8\xbe>p+?\xb0:z@G"j@\x93\xce\xab?\x07\xf3\x04\xc0Z$a\xbf\x8b\xfe\xd7\xbf\xec\x82\x0c\xc0\x9d+S>\xa5h\xec>S\xb1`\xc0{\x86\x91?\xbf\xf3\xdf\xbf\x94\xf2`\xc0C\xa0\xc9?G\xc1\x8b=\xb3\xe0\x1b@q\x9b\xc6>w\x84\x97\xbf\xe8o;\xbe\x0f}\x17\xbf\x00\xc6O?I@\xae>,\xc6\xa7?\x81f%?\\\xfa\x86\xc0\x8e\x08X\xbdZw\xd0?\xab\xc7F\xbfi</\xc0\xab\xbcN@\xffW\xaa?\xfe\xfe,@\xec\xf0\r\xbeImz@\x0eL\xce\xbe\x0bb\xd3\xbe\xbcA\xf9\xbf\x90\x94\xe8?4\x98\xa3\xbe\x10\x82\x1b\xbd\xc3\x1c\x13@\x9b\x18\x0f@\x84\xe2\xfd\xbf\xbdm\xb9\xbfU%\x85\xbe\x8a\n%\xc0\xa9\x930>\x90$\x18<\xa36\x03@Ds\xfd?a\xabf@b\x06\x1b\xbfr\x13\xb5?\xea\x9a\x99>\xcf3\xc4=\xab\xfdN\xbf\x1a\x9a\xdb\xbe\x83\xe5\xd2\xbf\xddm\xb5\xbf\x8c&\xa9\xbf\x93\x86\xd8?\x16G\xb9>o\x1a\x17@p\x1a\x0e\xbfp\x89\x0b<\xfa\t\xe7\xbe\x96\xb0b\xc05\x12\xda\xbe\xd2\x14\x9b?\x8c\t\xbc?u8\n\xc0\xf3h\n\xbf\x94\xa1\xef\xbf\xf8\x13\xd0\xbe<\r\xcb?\xe0\xb0"?\xa7\x88[\xbf\x96Z\x9e>\xc2\xcbz@\x98\x8cE@\xdd\xe5T@#\x03-\xbf(h3@\xd0\xbb\x97?v\xabJ\xbe!k0?H\x0e\x14?V\xba\x1f\xbeN\xdb\x9d>8\xee\x94\xbf0\xbf!?\x9a9\x92\xbe\xaf\x89\x04\xc0Hg@\xc0\r\xf9\x0c\xbeJ\xa8\xdb>K\xe7:\xbe4(\xcb\xbe\xfa\xfc\xa0?\x08\xa5\xf1\xbe\xae\xd0\x96?\xc3$A\xc0U\r\xad\xbe\xd4\xae\x1b@*\xabR@\xdfM\xfc=]\x87\x10@$\xb4\x8c>\xe5\x15\x15\xbf\xe81\xeb\xbdja\x1f\xc0U\x10&\xbf\xdb\xe39?t\x010\xbd\x16Y\xaf\xbf\xc8\xff\x95?\xba%\x96\xbd\x80\xe9o\xbe\x1ey\xaf?\xc5\xee\x1a\xc0gq\xa1\xbe\x19\xa9\x8e\xbf\xc94\xb1>\x02T\x93?:S\xe8\xbd\xa7K\x96?\x8b\xca\xde?>\xf8K\xbe\x9f\xc3\x87>Ns\x8c\xbb|\xff\x9f?^d\xd6\xbe\xdc\xed\x02\xbe_2\x06\xc0\xfc\xf9\x9e\xbf\xba\x8a\x9e\xbfA-\xbf\xbf\x94\x93\t?\x8ff\xb1\xbf\x86\xf4\xaf\xbf\x00\xd7\xc6>\x0f\xf73\xbf\x1a\xd2\xa3\xbf\x1aJ\n\xbe\xd4\x0c\x0c>\x8aF\x9e\xbf\xfc\xc3\x98\xbfn\xaa\x1f\xc0\xd4\xdd\xea=|!\x14\xc0\x07m(\xc0\x9c\xfa\n\xbf\x1f\xba\xe0\xbf\x13|\xcc\xbf\xb0f\xf6=\x8e0\x87>?\xf8\xe2\xbf#^\xd6\xbf\xadl8\xbfP\x97B?}L\xe3\xbe!\xbf\xec?(#\x04@[1`?\xfdq\xdb?\xc6\xc6\x88>\x81g7>wT\xdd?\xb4:#@\xe2\xf2\xc0\xbf\xd4\x82S\xbf\xab\xe7\xad\xbf 5@@\xdc%\x87\xbf;\xc6\xc8?g\xdf\x92\xbf\xeer\r=Hr\x81?\nH\x19\xc0\x88\xfb\x99\xbf\xc0!\xf7<\x87\r2\xc0\x18\x16R=\xabe.\xc0\xa0S^?I\x8e\xa4\xbfe\xf7\x8d>\x1a\xe4s\xbfT\xee+?/d5\xbf\xb4\xefM\xc0\x01in\xbf&\x0bV?8\xb5\x85<\xa6{\xe6?\x99Q\xe0?\xa0\xcb\xd2\xc0\xa0"\xb3>\x90\x0bQ\xbf\xb9\xcc\xf8>\x0e\x96\x1a>\xf0.<=\xbbG\xe6\xbf3^\x80\xbfuF-\xc0\xef;\xb8?\x9c\xa7\xfe\xbe\xd3\x83\xe1\xbf\x19%\xcf?|i\x83\xbf\xccUI?&oP\xc0\xf4J\xba?\xd4\xdb%\xc0\xda\x85\xcc\xbf\x13\x7f;\xbf\xebg\x04?~\x0e\x06?\r\x05\x8b\xbe\x1a\x9ft\xbe\xf3\xfe\x06?\x80\x19O\xbe\x83f\xab\xbf\x1dg\xb2\xbf\x8c\x81\x12\xc0\xb1)\x06@\xcb\xb6\xd7\xbf\xc8\xcb\xaf=X\xc8\x1f\xc0\x12|\x1d>\xb2\xa0X@\x07\xb1`?\xe5\x8c\x8c>_ f?`N\x9d?\x82O\x9e?\xcf\x1a\x1d?\x81;\x01@h\xc2"\xc0\xa6u\x18?\xa6\x80\x99>\x12\xf02@\x06\xb1p@\x04\xe6\xb9\xbeB\xbaa?\x00L\xbb\xbe\x83\xc9f\xbf\xbe\x1a\x91>\x1e\xbfs?B_\xd6?\x8b/S\xbf\xd1Z4\xbf<}\xb4\xbc\x02\x96\xcb?\xbe\x9c\x96\xbf\xf3/\x16\xc0\x80!M@[u\t@d\xde\xcc\xbf\xe0\xbb\xbb?\xc75/?\xad\xd5\n?\xf8\xfd\x87\xbe\x83\xab\x11\xbf\xa0\x8e\xd0?\x0cp\xa4\xbf\xb0U>\xbc\xbd=\xb1\xbf\x07\xe5b\xbf\x0cG\x17\xc0\x9c\xbbS?\x1egu@[\xda\x10\xbd\x11\xaf\x91?\x82\x8e\xf5>S.\xdf\xbfWp\x83?\xdcw\x90?\x1f\x9f\xc0\xbf\xf56Q?"N7\xbfv\x945\xc0,\x9d\x9d\xbfF\xae\x8e>\xfc\xff\xeb>\x99\x01X@\x8a\xf3\x1f@I\xd7\x98?\xb6\xc4~?\xb8\x9b\xef>\xbf\x9e\x13?x)\xdf\xbe\xbf\xd8\x11@\xd8\xa0\x00\xbf\xf86\x85?\xaa\xe8\x93>(\xbb?@\x11`@?\x97`l@\xdeS0\xc0_\xdd\x8a?\x15Y\xa6?\xfe\xb0\xf5\xbf\xdd\x80x\xbf\xf0\xbf\xe7>\xaes\xe4>\xbc\xd9e\xbf\xbb\x04\xb4>r7\n@\xcd\xd0\x96>\xdcD_\xbfe\'\x89\xc0|\x8e\x0f?\xe7\r\xd2\xbf"\xfe\xb6\xbf\x81\xa7\xc5?Qt\xc9\xbf\x98{\xfd\xbe\xd5\xa9V@\x06t\xb9?\xfa+\xe6?1\xdb\xc8?\t\x85\xab>\xb0\x95\xe7\xbd\xda\xeb\xc9?$\x9e\xab?\xca\xc5E\xc0h\x01\xba\xbfb\xd0\x8c?\x9d<\x18?\xc6\x193@;\x0b\x0c?\xf8\xe9\x82=\xcd\x17\x81\xbe\x1aD\xad\xbf\x99\xdb\xb4\xbf\x06\xfd\xf4\xbf\x16\xb4n\xbf\x1a}\x0b\xbfT]$\xc0\xdaN\xb5?o9\xf1?\xf8\x7f\xfe\xbf\xbb\xc5\x82\xbe!\xccF?;\xc8\xf1?\xad\xf1\x0c\xc0\xeb\x86Q\xbfL\x9e\xa4\xbe \'\xac?\xc3\xe0\xc9?\x11\xcd0?{\xd6\x9d\xbf\x15\xf9\x1f@\xd8\x82\x1e\xbf\xf4c\xb1\xbfg\n\xbe\xbe(q\xfa?\xabol>\xdf{\x9f>R\xef\xe1=Rz\xbe?o\xcb\x9c\xbe\xd8\x9c\x95<D\xc5\xd3=E!a?*#\xd4\xbe\xe9\xad\x82?\x05\xfa\x1a\xbf|\xff\xe4=4Y\xef<\xda\x86\x00\xc0\xb4\xd9{\xc0)\xd1\x19>\x86\x15\xb5?\xa5\xc3H?4N\x01?\xe5aq\xc0d=\xe2\xbd\xb8\x85\t?n-\x98\xbf#\xdb7?G\x8f\x07\xc0 _\x87>\xa0\xbe\xbe?N\x92U\xbf\x05\xa8\x96?o\x06Z?\xa4\x7f\xe9\xbdqKn\xc06\xe9\xa3?\xd4S\xbd?\x84\xcf\xc0\xbeS\x89-@\x00a<?z\x1f~\xc0,\x11\xd4?,e\xe0>b\xef\xf5>>KF\xbf\xce\x1c\x9b?\x9d\x8e}\xbf\xa9\xd00?y\xc0\xf5\xbb\xfe\xfc\x88\xbeD\x97\x08\xbd\xb1\xfb,\xbe\xef\xae\t\xbey\x97Y>|\x96\x82\xbe%\x98\r?j\xc6\x12\xc0,\xf9n@\xb5\xae\xd0\xbeT\x9fR@\xb2E\x84\xbf\xe8m\x19?V\x03q>\xe3\xc5\x1c>\xed\r0\xbf\xa6\t\x16?\xe8\xbcN=WK\'\xbf\xca\x82\xb0?94\xb0?\xa7\xf2\xbc?fD&@\xcb\x98O?\x18\xeaV?\x00z\x86>\xf7D\xce\xbe\x8f\x8a\xa5?\x90\xfe\x90?R\xa2\x05@\re*\xc0M\xf3,@\xd4\xbe\x85?\xd4$\xdb\xbd\xc3\x0f=\xbf-\xa5\xc7>t\x8c\x9c\xbf\xe4\x9d\x06@\xb2\xc5\xdd\xbdu\x8d\xc2\xbf.\xb8%?\xa0\xc6\xa5\xbf1\\D?n\xb6\xfd\xbf(P\x9d?,\x88\'\xbf\xfd\xef\x13Ay\x12\x1d\xc0/s\x08\xbe\xe9\xe96@Hq\xb6\xbc\x98\xd4\xc6\xbd\xa3\xca\xa6\xbf.\xee\x0e?\x16\x03\x13\xc0\xa1\xee~?\x86\xfc\xc2?\xec\xdc\x85\xbc\x1e/\x0b\xc09\x18,@\rD\xf7?\x93\xd4^>6{:\xc0H\xca-?"1\x1b?\xd1Z\x9c\xbf1\xb8\x83\xc0\xc8FE\xc0\xec4\x06@;2\x9b?\xe3\xf7\xc3?\xbb\xd1\t\xc0F\xda\xff\xbe\x81\x7f\x92?6\xd0\xcf\xbf\x15j2>\x08\xb7\x1c>\xfb\xd6>>\x98\xe9\xaa@\tuy?\xd5,\x81?\x96J\xfb\xbeI\xc6.\xbf\x1c\xd1v?\xf6O\xd8=\xb6|\x84\xbf\x86\x00\x8d>\xc1\x8a\x0e@\xc6<1@2\x15\n@JU(\xbf\x92\x83\xe4\xbfT+\xf7?Js\x13?\xf1\xf8\xbe\xbf&\xf8\xa0?<\x06\xd4?\x84\x8b\x89@2\xd5$?o\xef->l\xb8\xd2<\xc4\x0f\x92=?\xa7[?\xf88\xd0\xbf\xd4\xfd\xe0\xbe\x86~\xc4\xbe\xcf,\xcc\xbf:\x85\xd0?\xe6\x08\x00\xbf\xd0\xc9F\xbe\\\x98\xa6@\xc8\xd8{\xbf@\xed\xea\xbe-^\xde?Z\xa8\x03\xbf\xa2\x9e*\xbf\xb1\xab\x93?\xcc\x08T\xc0\xc78\x81\xbf\x92\xfa\x9d\xbf\x0cG\xdc?na5>\xefV\xcf\xbe', b'\x91\x0b\x12@f\x88\x1e@m\xc3\xa8?gm\x0bA\xce\x8b\x8b?\t\xfb\x01@Z\x10\xc4\xbd\xcb\x8d\xd4\xbf\x00\xb9\xce\xbe\xafs\x9a=\xf7*\xef?j\x8d\x93?\x12\x95\x87?gX\x93?\xdf\xbdN\xbf\x00\x8d\xbe\xbf\x07ei\xbf\xee\xd9\x1c@\x84a\x92?\xa4\xd6@\xc0\xaf\x0c=\xbe\x98\xd9T\xc09\x90\xb9?R\xa0\xa7?3m\x99?\x8e[`\xc0\xe0&\x06@b\x17\x1c\xc2\'\xfd\x1f@8+\xf8\xbfd\xafo?\x85\x9f\x0b\xbf\xf5\xb7\xa7?\xc9\x84\xae\xbf\xdb\x108\xc0\xd6^\x06?j\x08\x0b>Dg\xf1\xbe\xe4\xe9\x05@\xcc3V\xbf\xf4\xdf\xe3=\x16\xe9J\xc0\x9b#L\xbf\x01\xec\x9a\xbf\x18\x87\xec\xbf\x17W\x0b@T\\\xb8\xbe\xf6\x93p\xbf\x0c\xe0"\xc0|\x11\x8c>\x84V\x80?d\xbf\xc2>\x14x\xfa\xbf\x1f\x98\xa9\xbe\xae\x8bm\xc0ru/\xbd\xfc\x84\x97?>\xbd\xad\xbf\x10-\x88?F\xa1s?\x06\xc2-?N\x0f\xbf?T\xd0\xcb?\xf0\x8c\x87\xbd\xaeI@\xc0\xa1\xaf\x8c\xbe\x0e\x0eP\xc0I\xe8=\xbfK"\x95>\n\x87+?)L\xc5>zrc?\x16h\x98?\xe0\x19b\xbf\xc2\x10\x11\xc0\xeb\x06\xd4<\x9d\x8d\xe1?\xc8j\x16\xbf\xf8\x8c\xf8\xbf\xfb\xf9\x04?\x9a\xda\x9d\xbf\x0c\xf3(@a\x9fX\xc0\xc7W\x9e\xbf|B\xb5?\xae\x11+?\x96\x10P@\xfc\x00\t?\xdco\xa4\xbd\r`9\xc0?i\x1d>\x9e\x93\x86?Ce\xb3\xbe\xfa}\t\xbf\xc5\x06\x1a\xbf\xeb\xbc\x9d?h\xed\xc0\xbfo\xa2\xb1?\x9e\xdb\x05\xc0\x16\xbc\xfa\xbe\x1b\xaaC\xbfS\x105\xc0\xdd*J\xc0v\xad\xd4\xbf\x9a\xf7\xe4?\xf6\x1d\xe5=EZ\x8b?\n\x00X\xbf\x98\x87w\xbf2i\x19\xc0\x12L>@\x9e\xbb\xb3\xbfU\x9bt\xbf\xb1\xbfd>\xf23\xdf\xbe\xf5\xafK\xbf!=+A\xa0EW\xc0\xa0g\xb2>\x1c\x0e\xdf\xbdL\xfd\xf1?8\x9c\xa6<j\x17\xe9>\xa5\xe9J@\xf8L^\xbfZ\x0cK\xbf\x92\x95\x8a\xbfq\x12\xce?\xb9\xf2\xca\xbf}\xfc=\xbf`\x85\x98=\xa15\xe3?\x9c$\xe1?A\xd0\x17@\x1e\xbf\xd4\xbf\xae\xaa\x8a>\x98\x11O\xbf\xacs@@\x88\xfdY?\x92\x90\x1b\xbf"\x03\xa1?0jE\xbf\xbd\xf5\xa6\xbe\xd7/\xf5?c\xc7\xe1?\xdb\x89<?@\x8e\xc2\xbd\x97j\xa4\xbf\xe2\xb4\x0b\xbe^X\x91@\xd2\x0c(\xbe\x05|)\xbe?\xc8\x15?9\x00\xf1?\xfa\x8c4\xc0\x8c\x1b\xa5?\xe3)\x9e\xbf\xb2@\x85\xbe\xfb\xbfx>\x04E\x0b<\x9b\xcc\x8c=\xccF\x82?\xa7\xd9\x0c?$L\xa7\xbe\x89\xcb\x95\xbd{\x8fY\xbf\xc6|(\xc0\xc2\xb60@\xdaI+\xbf.\xa4\xe0?\xc4\n1\xc00\xaf\x00\xbd\xa4Q%\xc0x0n@A\xe25?`UQ?\xeb\xfdO@\xbb"\x9d?\xe3\xe2\x02\xc07\xe0<\xc0wg3\xbf<A\xaf\xbe\x9d/\x85\xbfm\x87\xdf?8pE?\xd0!\x98>\rs^\xbf\x03\x8b\x97>\xd1\x18\xeb?\xe8\xdd\x9b\xbf\x04\x8f\x83?R\xc3\xf6>t\'\x17?\xe30\x1d?L\x1a\xff\xbf\x1cf\xa3<\xe9\xd8\x14@\x8a\xad}>\x8c$\xb8?\x17r\x80\xbfH]\xf0?\xc4\xba\xd8\xbe\x10\xa3\x96>K\xde:@\xee\xeb\xd6\xbf\x9c\x1a\x05\xc0k\x99\xdb\xbf\xe1k\xe2?\xa4\x047@\x10\x0c\x98\xbcF\x08&\xbe\x17X*@P\xc0\x04@p\x95\xc8>b\xdd\x94\xbfR\xa3\x81\xbf67x>\xc2mK?\xeb\x01\x01\xbf\xfc\x90^\xbe-\x90o?\xe7>\xbe\xbf\x8bD0?\xbf\xa4\x1a\xc0f\x86\xf9?P0\xad?\x7f\xd5\xe3\xbf\xe0\xd5\x12?\xeer\xd9\xbe\x9f\xe2\x1c\xc0\x14\xd0\x03@\xe1\x05\x86=\xe2\xad\xb1\xbf\xf2\x15)\xbf \xe4\xd5?\xdc\x9b\xb9?\x82X\x80\xbf\x8b\x92*?\xa6N\xb1\xbf\xf1\xdc6\xbe\x9a\x12 ?\xb2(\x82@\xb8\x87\x86@[\x97\xc2?r\xc6\xdf\xbf\x8dZ\x82\xbf\xaf\x16\xb9\xbf3\xc9\x05\xc0\x8b\xd2i>\x93\n\x91?\x87\xac.\xc0!\xe7w?c\xaa\x94\xbf\xe9\x168\xc0c\xdc\xc6?\xe4o]\xbe\xe8?%@\xc7 \xd5>\xd9~*\xbfx\x14\xb4=#\x0f\xe0\xbe\x8b\xc8|?\xc5\xb02?\x9c\xc2H?\x06U\x8f>\x17A\x87\xc0\xb9i\x94>$\xd7\xeb?\x19\xb4\x07\xbf\xfe\xed"\xc0\xe3\xa1-@\x8f\x9c\xb6?\xbcL%@\x83B\x1d\xbfiG\\@\x18\xa6/\xbf\xb4n\x82=Jw\x04\xc0h\xb7\xef?\xca\x00G\xbe\x90\xa4\xfc\xbc1\xa9\x15@A"\xec?\xcf\xc2\r\xc0\xfe\xb3\xe6\xbf\xa2\xd6\x01\xbf\x9fR\xf5\xbf\xc8\xb4\\\xbd\x16\xfd9?\xc7$2@\x12i\xea?\xb7\xa5^@c\xc5\xc3\xbe\x99-\xad?\xbe\xbf\xc6\xbe\x12\xe8\x04>\x17\xfc\xb0\xbf\\\xef\xa4:y\r\xab\xbf\x109\xdb\xbfz\xfc\xe2\xbf\xba\xad\xc3?\xa8\xa1\xf6>\x8a\x19+@\xf2\nr\xbd\x03UC\xbf\xa4\xd0\x0e=56i\xc0=N\x01\xbf<1\x9d?\xdb\xa6\x04@\xa2\x02\x08\xc0\x14D)\xbe\x97L\x14\xc05L\x17\xbfhN\xdd?\x93mn?E\xd3\x12\xbf_,\x03?m5\x83@"qA@\xc8\x11C@5;y\xbf\x9aC>@V\xbd\xc2?\xdey\x96=nbz?>\xf2\x06?p\xfd\xb5<\x08\x07I\xbd\x15/5\xbf\xb0O.?\x9a\xa5\x88\xben\xce\xe0\xbf!\x8f\'\xc0\xe61\xdd\xbe2\xa5\x87?\xd0\xa9\xa0\xbe\xf9\xd6\x97\xbe\x87\xd3\x99?\\)\xc4\xbeG\x15\x93?2\x92-\xc0\xba\nK=\x11C(@\xc30Y@\x18Ml\xbcW\xbe)@\x01\xc7\xe3=(u\xa5\xbf\xfce\xd7<:\xbf\x11\xc0v6\x10\xbf\x8aJo?\xac\x87\x96>\x00z\xb9\xbf\xc5\xc5\xda?x\'[\xbd\xf4\xbft\xbc\xd4\x14\xa3?\xea4\x06\xc0>\x9b\xb2\xbe\xa5`\xbb\xbf\xe9\xc5y?\xdd\xb5\xb3?~"\x17\xbf\x1f\x86\xa9?\xce\x8b(@\xd4G\x93\xbe>y\xc8>\x82|c?\xfa\x08\x91?l\xa8K\xbe\x16\xa5u>\n\xb9\xe4\xbf\xf8B\xa6\xbf\x07\xcb\x16\xbf\xc9\xe4\x95\xbf\xb6\x15\xce>6\xed\xac\xbf\xb0g\xd9\xbf\'\x1a\x1a?\xd4\x1c\x0e\xbfY@\x8c\xbf\xbf\xf7\x15\xbeD&\xfd\xbeED\x02\xc0q\x9b\x87\xbf\xf3G\x0e\xc0\x97\xd2\x92\xbe\x90\x1d\xff\xbf\xe4]+\xc0\xe4\xa4\x08\xbf\xb2\x0e\xeb\xbfqg\x0e\xc0`\x96\x17;\x0eeu?\x16\xf9\xed\xbf(\xd6\xba\xbf\x15\x06\x91\xbf\x1a\x15e?\xa5y\x92=\x05\xc6\x03@\x01!\xd9?\xe2\x14\x0b?\xc0Z\x9f?2\xdc\xe2>\xd6c\xcc>\x96A\t@\xa0{\x00@\xd0\xc9\x8c\xbfGL\x81\xbfS\x9a\x02\xbfSG\x1c@\xb6\xb5\xef\xbe\xd0=\x80?\xf7:\xd7\xbf!~@\xbe=\xe1\xa9?\x01\x9f\xbf\xbf9\x8d\x9b\xbf\x80\xd7\xe6<x\xcd\x1d\xc00tU=uY\x0b\xc02\x12\x00?\xadQ_\xbf\xb5\xcf\xea>((\xc8\xbfY08?\xe2\xb3-\xbe\xca)\x14\xc0\t\x03\xa6\xbf%Y\x91?\x8a\xa6\xb8\xbdV\x95\x05@*J\xd8?A\x11\xdb\xc0~\xda\x15=\xdc\xb7\x89\xbf\xf8E\x03?\x18\xf67?f_\xa2=\x97\xd9\xe5\xbf\x18\x85\x9a\xbfI\x87;\xc0G\xcd\xbb?\t\xbf\xf6=\x05\xa2\xce\xbf\xe92\xf8?\xefR\x83\xbfQ\x1a\x97>\xef3f\xc0\xa5\xe5\x97?Q\xd3\x10\xc0\xa4N\xb0\xbf\xc0\xde,\xbf\xa0\xe5\xa0>|<\x1d?\x19n\xaa\xbez\x06-\xbe\'\xb4(>K&\x15\xbf.G\xf9\xbe\x92\x93\xdf\xbf\xdb\x87\x03\xc0\xf3\xee>@}\x92\x8a\xbfUs\x17?\xb2\xf36\xc0\x98\x10`=\xec\xccT@\n\x9f\x06>\xb7>\x8e\xbe\x0f\x84\xaa?\x1dFt?\xde\xa1[?\xbeIZ?\x89\xcd\r@\xbd\x8c\xaf\xbf^P\xda\xbd\xfe\xc2\x96=\x0e\xf4\t@\xaf\xdfx@\x81\xeb\x98\xbe@\xac=?6\x80\x92\xbe\xcaI\x8a\xbf\xffot>\x08A\xe8?\xdf\xd9\xb6?\x9c\x045\xbf\xba\x90P\xbf\xd4\x90.\xbf\xea\xda\xd6?\xe4s\xbd\xbf\xeb\x13C\xc0\xb57\x0e@\xfd \xa4?\x06Y\xfb\xbf\x1b0.?\xa0t>?\nez>/x\'=\r\x9d\x18\xbeTY\xb6?\xb6c\xc1\xbf\xb9\xea\x8c\xbe3\xe3\x83\xbfR\xcd\xb6\xbfB\x11\x18\xc0\xd4\xe1\x16?Ynz@Y\xf9\xde\xbc\xd9\xaa\x8c?p\x8f\xeb=\xe73\xf0\xbf`\x842?jD\xac?\xcc2\xf6\xbf\x1cib\xbe\xe8\xda)\xbfO=\'\xc0\x01\xbd\xc4\xbf\x95\xae0\xbe3=\x05>\xb0\xb7S@\xcfS?@\x16 j?\x96L\x8c?\x94|\xa0>\xbb\x9bg?H\x84\x10\xbe\x88Y\n@D\xb0\xf1\xbd[\x85\xb8?$\x89\xdc\xbc+\xb4\r@\x14\xd7\x17?\x02&X@\xc9\x8c6\xc0\xe6O\x9e?\x07p\x1e?0\xaa\xe0\xbfz\xa4\xf2\xbeO\t\x90?}\x9d\xb7>\xd0\xd7\x90\xbf\xe9\xfe\x12\xbeM\xf4\xf3?,\x18\xc9\xbb\xd8*Y\xbf\xe2\xfc\x9c\xc0\xfd8\x18?B\x81\xeb\xbf\xaf\x0f\x89\xbfS8t?\x07\xa8\xe8\xbf\xeb\xf3K\xbf\x1e\xffP@\xe6\xc5\xf8?\x80\xca\x00@(\xe0\xb7?\xfe\x97\x19<gp\x10>\xe0<\xa5?\xb9\xa3\x92?\x9a\x85,\xc0*\xbe\x8e\xbf\xb1Gz?\xb8\x8f\xa5>\x89\x85E@\x88>;?\x82\xf9\x81\xbfs\x10\x8a\xbe\xcf}O\xbf\x00\x03\xa2\xbf\x0cv\xe8\xbfY\xaa\xad\xbf\x97\x9f\xb0\xbe*i\xe6\xbfvk\xee?\xa6\x1f\x01@6?\xcf\xbf\xfe\x11\xfd=\xff\xa6\xa3?\xa3\x86\x00@3{1\xc0\xeb\x12u\xbf\xd6\x8a\x8d\xbd\xf9\xd9\xa5?L\x8d\xe5?\xe8\x93K?q\x02\xb6\xbf\xcex\x19@\x1f\x94\x8c\xbf\xff&\xab\xbf#in\xbff\xf1\xe8?\xde\xc5O=\xf6\xae\xcb\xbd/4\n=\xa6K\xbf?x$%\xbf\x0f4;?\xd0\xae\x97>N8!?y=\xdd\xbe\x1b\xd2\xa5?\xec\xe9\xf3\xbeQp\xf3=\n\x94\xbe>\xc5\xc1\xc7\xbf\xc6\xfc\x8b\xc0H\x8d\xcc\xbe|5\xa5?\xfa\xf9\x18?\x0cm\x02?\xe7\xfb>\xc0\xde\xd3\x90>nUx=\x05h\x81\xbf\xff\xea\xd9>y\x13\x1c\xc0\xab\x1b\x86>\xb9\xd4\xb9?\x91\r\xa3\xbf\xd5\xb2\x91?2H\xa0?V\xa7\xe0\xbe!\x97m\xc0X\xe8n?\xd0\xfd\xbe?\xa4J[\xbf\xb6e#@\x12A\xdf>Y\xfc\x83\xc0?\xd4\x94?\x9e\x89\n>s_\r>j\xed\xad\xbf\xc7\xe8\xe1?\xb5g\xa8\xbf\xde\x11\x13?#\xd8\x19=\xe4q\xc1>\xd81\x86>\xe2\x1e\xfe\xbe\x9c\x82\xc8\xbeN\xe4\n>"\xe2\xc4\xbe?\xf7h>3\xb1\t\xc0]\'\x89@o)\x02?\x8b\xfeU@\\\x05X\xbf\xd7\x05q?\xa4=\xe6>\x0eh\x95>\xb5\n$\xbf-\x1e1?\xe8\x16)?\xc6\x9f\xb2\xbe\x1a\xc5O?\x92 \xdb?\xb8\xcb\x05@\x86,\xf5?\xc3\xd6}?\xdc\xb3j?\x16w\xd1=\x1b\x9b9>)2\xa3?l\x9e\x84?\xe8#\xe7?D\xae\x1d\xc0N\x9fa@8(\x93?\x82 \xd3>,\xf5\xc3\xbe\x95\xf3\x11\xbe\x93+\xec\xbf\xcd\xe1\x1a@\x0e, \xbe\x02\x85\xe7\xbf\xd0???\x9f\xab\xc0\xbfkQ\xa8?\x06d\r\xc0\x98\xba\x91?\x83kN\xbf\xf7\xc1\x02AY;"\xc0C\xde-\xbe\xf2\xd5I@\xc2S4?\x86\x82\\=\x84\xc5\x8e\xbfi\x1a\xe7>z\x1c\xee\xbf\xe4=\xab?L\xb6\xd6?s[\xff\xbd\xebS\x05\xc0\xce\xdb\x1c@[\xa4\xf3?\xafrR>-FD\xc0\x80\x94{:\xc6\xbf]>\xda\xa5\xcc\xbf\xd3]b\xc0\xe8\xd3]\xc0`&\x00@\x12\xb9\xea?`\xf2L?\xcb7\x8c\xbff\x08j\xbe\xce\x98#?\xc3K\xbc\xbf&\x18\x8f=\xa7\xf0\x80>J\xa9\'\xbePZ\x8f@\x03\xda\xa6?\xaa\x9ei?\xe8I\x18>$U\xd7\xbf\xb6x\x91?\x90\xc1\xee\xbb%y\xd5\xbf<\x99\x00?\xd7\xdd6@\xa8J.@\xfcH\xf8?:7\x05?@g\xcd\xbf\xf1\x18\xe9?\xd9\xcb\x17?\xda\x8a\xf1\xbf1\xff\x87?\xee\x89\x9f?\xd0/\x85@\x17\xb4\n?\xe8 \x8d>\x9ewm=\x19\xfa3?\xeco\x96?K\x07\xa1\xbf\x04\xbc"\xbf\xbd\xb0\r\xbf\x02\xd1\xc0\xbfm\x84\xba?\xeaa\xb3\xbf-@\x88\xbfl\xe3\xad@0\xd1_\xbf\xcbv\x03\xbf5\xc8\x1a@\xcd\x93\'\xbeC\xbch\xbd\x93\x9f\x8c?\xb9\x9aP\xc0\xcd\xd6_\xbfI\xec\xb0\xbf\x81\xc1\xea?@\xcd4>\xfct\xf6\xbe', b'\xe0\x86\x1f@}\xd9/@\xb0\x1f\xaf?\xb6\xe1\x03A\xad\xa4\x87?\x8f\x1d\x17@g\x1d\xc1\xbe\x1b7\xcf\xbf\xeaf\x88\xbd\xca\xaf#\xbe\xda;\xbb?\xb5\xa4\xba?8\x14\x9c?t&\x85?,\xac\xe3\xbe\xa4k\x89\xbf\xfa\xb2\x06\xbfq\xe1\x15@mRn?\xf2fC\xc0{j\xd0>\xc5\xe1T\xc0\xe3"\x04@\xd8\x1a\xd0?P\x19\x8a?\xb0wZ\xc0;6\x0e@AJ\x1c\xc2\xfb\xee\x19@\xfep\xd5\xbf\xd9\xd0Z?\x0e\x8bO\xbfV\x06\x81?,\xc3\x84\xbf_\xf0:\xc0?\xe9~?Y\xd4N>\xa6\xc8\x9d\xbejf\x04@\xdcB\x99\xbf2\xe4i\xbe\xbfi;\xc07\xe5 \xbf\xa9o\x90\xbf\\\x12\xda\xbf\xcd\x8a\x19@.\xd3\x17\xbe\xb2$%\xbf\xc0\x01\xe7\xbf*\x8a\xec>W/\xba??\xc4\xc7=\xba1\xf2\xbfP\xa6P\xbf\x9e\xbfG\xc0l\xbb\x1f>\x99)\xb7?\xe9\xc6\x85\xbfR\x16\x97?\xc6\xe9\xb5?K">?\xc1\xed\xc3?\xe9=\xcc?\x04U\xd1\xbd4\xb8<\xc0\x9e\xd3\x11\xbf)\xddI\xc0\xb6pv\xbf\xa9f\xaa=\xff\xedp?B\x03a?\x9d\x0f$>\xd0\x95\x97?z:>\xbf\xdd\x01+\xc0*\xb5#\xbdL\x87\xce?&1r\xbfi\x93\x19\xc0\xc7`\xa4=;L\x91\xbf\xe5\x8f5@\xf3@H\xc0\x9c\xb9\x85\xbf\xf2\n\x8b?\x85FI?\xd9\xaal@\xa6\xec\x04?\xcdC\x96\xbe\xbd1H\xc0BE\x0f\xbeL\x1d\x80?;\xe9\xb0=\x06\xbaV\xbe@\xee\x07\xbf\xdf\xadV?\xc2\r\xe6\xbfa\x07\xd5?\xe7s\xde\xbfJ\x12p\xbf\x17\xb9\x86\xbf\xce\xccE\xc0\xa5IK\xc0\x04.\xf5\xbf\xbe\xe9\x00@\x93\xfe\x89\xbdy\xc1\xa8?\x9a\x9ft\xbfIZ\xa2\xbf\xc6\xee\xfb\xbf\xc6v(@\x98\x02\xa4\xbf\x8b\xcc\xb5\xbe4\xdd\x83>\x1dg\x0e\xbfA\xa7\x1a\xbfUA7A\xe5\x9fW\xc0\xb4ae>d\xb1\xbf\xbe\xd4\xa0\xc6?F\x92\x02?\x89\x16 ?P[i@\xec\x8d\xb7\xbe\xb6\xd0.\xbf\xed\x11\x11\xbf\x0es\xe1?\xbf\x89\xd5\xbf\x0bh;\xbf\xce\xf3=\xbe\'\x92\xfa?8\xce\x04@\xee\xbd\x00@\xaeQ\xf0\xbf\xc0\xd9P>q\x90v\xbe3\x93)@8\x97\x0f?\xfd\x19\xd7\xbe\xc1y\xa0?\x0f\xe4A\xbf\x8a\xa1\xee\xbd\x90\xf1\xde?\xbd4\xd0?\x131N?\xc3YX>_\xefA\xbf\x8cWb\xbe\xdb\xc2\x8d@\xfa$m=*\xba\x81<l\xee$?&\xb1\x11@\xce33\xc0\x18\x90\xe9?\x92\x8d\x8e\xbf3[\xac\xbe,\x8f\xd0<\x9c\x99&\xbeoY\xe0>+\xe8\x93?\xa3R\xe3>a\x17\x0e\xbf(\x1e#\xbfz$g\xbfI\xc5$\xc0\xb8V.@*H"\xbf\x05\xc4\x16@W\xbfF\xc0\x9bq\x07\xbf\x18\xc8\x12\xc0\xaf\xe4R@\xde\xa1\x8e??\xd0d?:EK@\xc5\xbe\xda?\\\x94\x1b\xc0\xbf\xdf!\xc0J\xf9r\xbf\x1a4\x9a\xbesZS\xbftn\xca?6\xccE?\x1c#\x01?\xeeuk\xbf\xb8f\x80?\x1e\xf5\x16@\xebs%\xbf\x0ek\xde?\xb4\xb0\x96>\x1a\x0f\x9c>\xc0a;?\x9e\x9b\xe6\xbf\x03\xfc\xaa>WW\t@\x80d\xe4\xbb\x88$\x8f?\x9a\xc0\xa6\xbfY\xe1\xd4?\xae\xf9\xca\xbeNQ\x16>\xc1\x89 @#t\xe2\xbf\xd6c/\xc0\x10\xbf\xea\xbf\x16\x90\xd0?\xa2\xd08@s\x9b2?\xfa\xa88=\xc5A\x06@\x03`\x0b@\xb2\x0c\x84?\x8d*\xba\xbf\x89\x85\x81\xbf\xa6\xf3\x1b>v\x19V?@\x94\xa1\xbe\x07\x00Q\xbe\x13\xd5$?0\x7f\x99\xbfT}\x82?+\x919\xc0\x92F\xea?N\xeb\xe5?\xb4\xef\xd4\xbf\x1e\xcb\xff>\x92\xb5\xb1="4"\xc0\xbb\xfd\xc3?\x9e(\t?\xa9\x88\xc3\xbf\xce3\x1d\xbfkZ\xc7?\xd4\x94\xef?\xdc\xaf\xf1\xbe\xdf\xc0r?jm\xab\xbf\x9e\xb4\x9e\xbcl)6?~\xbf\x7f@\x98zy@\xdd\xb3\xa9?\xca\xc3\xf0\xbf\xf2\xbe?\xbf\x14\xdd\xff\xbf\xa8|\xfc\xbf\x1f\xf4\xa4>\xf5Ru?\x86wF\xc0\xa8F\xb6?x\xf0\x92\xbf\xb8\xabB\xc0\xf61\xbe?:\x06)\xbd+\x02\x1f@\xfa\x12\xb0>\xe7\x80\x93\xbf\xcc|\xed>Q/5\xbf\x96\xcd#?n\xbe$>\x93RN?\x80=7>\xa1B\x86\xc0\xaa\x19\xfb\xbd(Y\xd3?;c\x1a\xbf\xd8\x85J\xc0\xba\x1cB@C\xa8\xc8?\xb1\x16C@:\xef\xac\xbebBu@[#J\xbf\x08\x85\xc4<#s\x1d\xc0\x1a~\x03@\x84\xfe\xb1>\x9a6\xbe>\xd3\xf1\x0b@\xfeo\xe5?l\x8b\x0f\xc0\x9dU\x06\xc0\xe3\xd4c\xbfK{\n\xc0:\xb6\x12\xbe$\xe5\xf8>\xe2\x021@/\\\xbe?.\xce:@3_\xba\xbe\x074\x8c?:k]\xbeQH\xb1>\xdf\xb7\x97\xbf\x91\xc1\x07\xbf\xea\xc2\xda\xbf>T\xe1\xbf\xa1\xeb\xf5\xbf\xd29\xf5?E\xbb"?h".@l\x9fK\xbf\xe20\xd3\xbet\xca\x92\xbcM\x16v\xc0\xde:\xf8\xbeu0\xea>\xcc\x9a\x1c@\x82%\xf9\xbf\x07j\x1c>\xf2y\xf3\xbf\xeb9\xbf\xbe\xd7\xc5\xcd?u\xb0\x00?c1"\xbf\xaai\xfa>\x8ac\x83@w\x14U@\x96\xf2=@\xfb\n\x88\xbf\x1e\xbe(@\x03\xe9\xab?\xd9\n\xaf>\xe5]j?\xfa\xd0\xdc>vA\x95\xbe\xc0\x98\xe4\xbc`\xe3s\xbfB\x8b??U\x028>+\x9a\xc7\xbfw\xd72\xc0x\xb5\x07=\xfd\xf8/??\xd1Q\xbeD\xd9\x1a\xbf\xd9\x84\xc3?e*\x16\xbf\xf9\x01\xb5?\xea\xdcC\xc06\xb0w= \x84!@\x96\x81P@v)\xbd\xbd3\xa5 @\xfc\xcbO>\xa4\xac\xaa\xbf8\xb2\x06\xbe\x98\x92\x16\xc0\xfb\xf1\x85\xbf2O\xea>\xaf"9>&\x8e\x8a\xbf\xbb\xc3\xaf?\xf7\x88\xb9\xbe\xc8<}\xbb\x9f,\x99?\x87Z\x05\xc0r-\x00\xbf\xe8v\x99\xbf\xe7.\xfc>\xd5\xd5\xbb?\xa2\x0c\xb2\xbd\xcf\t\xa8?e\xb1\x14@ \x9c\x90=J\xaf\xbd>\x0b\x8d\x9c>\xdf^\xbd?V\x10\x87\xbdD\xb9~>\xaa\xa3\x08\xc0\x88\xb6\xd2\xbf\x08\xeex\xbf:\xd2\xab\xbf\x1e\x8f^?\xa8\x88\x92\xbf\x1a\x88\xf7\xbf\x9a\xfc\xf9=\x12\xdbD\xbf:P@\xbf\x8a}\x81\xbe\xb8G\xdb\xbe\xd5\x92\x15\xc0\x8c\x89o\xbf\x8f\xad\x1b\xc0(8P\xbe\xeb\x03\xf0\xbf\xd5N&\xc0\xfa39\xbf\xca\x9f\t\xc0\xbc\x8b\x06\xc0\xf9\xee\xa9\xbee\xb1\xca>Z[\xb4\xbfd\xff\xcd\xbf\x1fH\xac\xbf\x9b\xfd\xa3?>\x1b\xc1\xbd\x04^\xf4?\xfb\xd5\xc4?\xca\xd3\xad?\xb5\x06\xb6?\xf2%\xae>$\x15\x02>3T\x03@\xcbw\x11@Ht\xa6\xbf\xa6D\x96\xbftk\x80\xbf\xf7\x8a%@.\xd8\x9d\xbf\x87(\xa1?\xc4}\xb7\xbf\x92Yj\xbe?\xea\xae?\xf1\x19\xf6\xbfS\xdd\xae\xbf3\xa4\xdb\xbe)\xd8\x11\xc0\xc9\xc2d>m\xe8\x03\xc0\x00U!?,\xd8\xbc\xbf!\xba\xf6>\xd2\xbfl\xbf\xdd\xd6\x13?\x0b\xe8\x05\xbfbtL\xc0\xc2\xe4\x95\xbf\xc7\xdeA?\xa0/&<\xc9\x96\xff?k6\x03@\xf6\xc6\xd4\xc0ic\n\xbeM\xba\x82\xbf\x04\xc0\x04?uU\x1a?\xfdWJ?\x0c\xd9\xf7\xbf(\xbc\x94\xbf&7.\xc0>\x85\xe5?\x18\xa1\xd0\xbeG1\xb4\xbf\xbcq\xc5?\xbc\xfa\x8c\xbf\xc2\xe5!?\xc8\x9bw\xc0\x8e$\xcc?\x92<\x13\xc08\x17\xe2\xbfi\x1f\r\xbfq5r?\xb6`"?\x87\x0cS\xbf\xca\xaa\x1b\xbf7\xd1\t?\xd6\xfc\x08\xbf\x10d\xb9\xbe\xa7\x95\xbd\xbf\xae\xc3\x12\xc0\rL&@\xfe<\xd0\xbf\xae\xba\x02?2\xd64\xc0!G\xa1=1>U@\xda\xc5\xa1>h\x14#\xbd\x7fD@?XJX?\x95\xae%?\x83\x99\xb3?&\x1d\xfc?=W\t\xc0f\xe5\xe6>\xee\xa5+?\xfaH\x10@\x11\x82\x88@@x\xc9\xbc\xbfK-?\xd0\xa0\xae\xbe4\xd4\x8d\xbf\xc7YY=\xef\x94\xe4?Q\x9b\x99?\x07a\x9e\xbf\xce\nT\xbf\x03\xc2\x05\xbf\xcc\xbe\xc0?\x8b\xff\xc6\xbf\x86\x1c0\xc0\xdf\xc0\x0e@r:\x8a?\xaf\xc3\x04\xc0#\x02\x9b?;\xd3??\xbdj\xd9>G\xe6\xb4>\x11\xe7R>\xd9\x9b\xae?\x835\xd4\xbfvF^\xbf\x86m~\xbf\x13\x90\xc1\xbf|\xb8)\xc0\x0boU?a\xf8Z@]\xd0*>\xd2p\xd7?\xed\xa3\x9e>\xcd\xef\xcc\xbf:{}?\xe8~\x01?B\xc3\x00\xc0\x82\xab\xd7>\xe54\n\xbf[\x96>\xc0\xd9\x0b\xa2\xbf8</<\xe0\xaa\x08?\x0bVC@\xa3:(@\x0e\xd55?i\x06F?{b\xa0>@\xe83?\xe8\x15X\xbe\xf5\xac\xf4?\x06\rC\xbe\x97#\xea?\x1c\xf5\xce=l\x8a-@\x92\xb16?\xa6\xc5k@P\x902\xc0W\xf42?\xc5\xd5e?\xf6\xbb\x02\xc0\x1aNk\xbf\xd9\xefG?<?\x82>K\xdbP\xbf\x8cX\xea>\xf7o\x12@\x04\x07\'\xbe\xb8\xba~\xbe3\xc2\x99\xc0)\xdc\x9d?1\x94\xc9\xbf\x1b9\xbb\xbf\\k\xd1?<@\x02\xc0_\xe94\xbf\x8fG=@\x8cx\xd8?\xe5\x86\x0f@/u\x9c?\x1d1\xea>=\n\xdb>w\xf5\xb9?\x13ra?;q+\xc0\xc8\x88\xb5\xbf[td?\xfdc\xa5>\xc5)C@\xfc\xe0!?A\xb9!\xbfD\x1d^\xbd30\x88\xbfL\x92\xc7\xbfc\x06\xe4\xbf\x15\xc8L\xbf\xa1\xc8G\xbf\x11\xb5\x1e\xc0\xad1\xfa?&\xb4\xf6?O\xf3\xf8\xbf\xc0F\x90\xbc U\xa1?\x1es\xf9?LW4\xc0h\x06\x98\xbf\xce\x1eh\xbe[o\xcd?`\xa2\xf4?::S?\xeb\x89\x84\xbf\xabC\x14@\xba{y\xbf\xcc>\x8c\xbf*\x10L\xbf\xbf%\x00@\xa8\xb8\x9f\xbc\x14\x1a\x02?b\x03\x92>\x861\x95?\xf1\xbd\x1c\xbfn\x983?\xaaw\xb7>\xf6m\x01?\xf7\x9c%\xbf\xbc\x9dt?3\xdb\xaf\xbe\xb2\x0b:>\xae^\xe3>Y.\xb5\xbf\xcdm\x9d\xc0jS]\xbe\x10\x95\xb9?n\xf2\x86>\xc4*\xea>\xdb\xf0K\xc0\x88\x87\xbf>\x00t\x93\xbd\x17\xf4\x9b\xbf\x9c{\x18?\x8e\xf5\xee\xbfKRb>\xa9\xdf\xb7?{E\x94\xbfG\x06\xc2?^\xa0\xb0?"\xe7\x01\xbf\x13h\x84\xc0_\x06\x12?\xb6\x90\xac?\x96^V\xbf_\x87\x1f@\xf3x\xdc>vF\x8a\xc0\xa8\x12\xba?[L\x16? ~\xa7>Z\xcb\x97\xbf\x8f\xb7\xe3?\xe0\xc2\x9b\xbf.@\xa0>F\x98\x95>x|\\\xbe"4\xe1\xbd\xd2j\xb1\xbe\x08S\xc4\xbe\x10\x03A\xbd\xee\xf8\xc5\xbe\x14[\xc1\xbd\x06S-\xc0#8\x86@\xe7y\x1b>4\xd0_@\xc6\xf1\xa3\xbfs\xf0U?\xa9\xee\xf6=\xe9\x89\r?;\x9d\x94\xbf\xb3\x17]?n\xaak?_\xdbM\xbf\x82\xc2{?:)\xd6?\xc9,\x13@{\x1d\xfb?a\x8b\xaa?\xa7\xd5\x18?<\x1f\x91>W\xe6.\xbe\xe4\x13\xfd?\xde\xffq?\x92D\xed?<\x85\'\xc0\xc1\xd2]@1\xb4\x95?\x0e+\x01\xbd\xf2\xb0\x1d\xbf!\xa5\xd5=\x1f\xa6\xf0\xbfsQ\t@\xd0/\xdd\xbe\xf0\xe7\xcb\xbf\xe0\x06\xd8>\xfe<\xe6\xbf\xc5\xf3W?\r\xa7\x06\xc0\x9b\x97\xc8?\xeaax\xbf3(\x0fA$w\x08\xc0\xc4mZ\xbe\x863A@\xa7\x1fA>\xd9\x95m=\xfa=W\xbf\x1e\xe9\xd6>\xbd\xc0\x08\xc0-\'\xb3?wR\xd6?L\xf7\xff<\xf9\xdc\xd9\xbf\x19\x1c\'@/\x1e\xe1?\x99\xdc\xbb\xbe\xce9T\xc0\xf5\x0b\xac>H\x0b\xe1>\xa3\x9f\xf8\xbf\xfe\x94S\xc0\xa9\x9b@\xc0\x19\xde\xcc?\x82\xec\xc2?6\xa1Y?D\xf5\x95\xbfNZ~=W6\x06?{\xcd\xc9\xbf\xa6\x95!>\xd7\x08\xf2>\\\xf2~\xbe6\xc5\xa8@jP\x98?_\xfc\\?\x9d\xe1\t\xbf\x15\xe3\xc9\xbf\xee\xca\x88?\xdew\x7f>\xe5\t\xe9\xbf@\x83<?\x99y\x10@a\xac@@x\xc3\xcb?"\xa0\x17>\xd3\x9c\xa9\xbf\xb6\x94\xbc?\x95\x86&?\xb0\xef\xcf\xbf@t\x98?\xcfHI?\x94\\p@\xf6\xb0\xaa>\xfcd\xd5\xbcN\x98\xb9>^l\x85?\xf1,#?\xe7\x86\xc8\xbf\xfc\xf4\xf3\xbe\x95q\x10\xbf\x8f\x15\xcc\xbf\xa0\xcc\xd4?\x1e\x93+\xbf\xee\x86\xde\xbe}\x85\xab@b9\xe5\xbez=\xbd\xbe\xd9\xf3\xe9?u&x\xbf\xd80\xa4>P\x82\x85?\xa0\xd0>\xc0\xce:\x8e\xbf\xcf \xd0\xbfy\xf4\xc9? \xc4\xd6\xbb\x97\xb6\xb9\xbe', b'DB\x1b@\x92-\x16@\xcf\x99\xb1?\x1b\x17\xf2@\x96\x97i?\xbc\r\xeb?\xf1\x0c\xf3\xbez\x18\xa3\xbfx\xfa\x7f\xbf< \xb6\xbeV%\x98?0o\xf0?\n\xce\x9d?&\xc3\xab?f\x1eI\xbf:\x8f.\xbf(\xe8\xae\xbe\xd3}\x00@\xc5\x85_?\xfc\xd86\xc0\xaa\'\x83<\x00\xc5g\xc0\x88\xf9\xe3?\xdf7\xdc?6y\x83?a\x1f]\xc0\x80\xe5\x13@\x0c\x04\x19\xc2\xce\xde\xd2?Wh\xfe\xbfN\xd6\x19?\xe7H!=m\xe0\x91?\xcc\xef3\xbf\x94\x14?\xc0\x94\x99\xe8>Z\n\xe8=u\xb9#\xbf\xf7\xa6\x15@Q\xb6\xab\xbf\x1a\xeb_\xbf\x93\xf2$\xc0\x10\xd1"\xbf\xc4\x83\xac\xbf \xec\xc6\xbf\xd3\xf6\\@\xaf2 \xbf\xd1M\x8d\xbf6\xc1\x10\xc0b\xcc\xe8\xbe\x00\xdf\xb5?\xd4\x82\x8e\xbey`\x19\xc04\x15Z\xbf\xa2Q`\xc0BK\xb2>q}\xba?\xff\xa2\xd0\xbf\xdfC\x93?\x01cl?\x15\xb3\xb3>\x17o\xad?o\xfc\xd8?\x7f8\x97\xbe\n\xf3\x1f\xc0\x80\t\x1f\xbfwfJ\xc0\xea22\xbf\xf2\x12\x90>\xa0\x9a\x0b?\x92Y\x94?\xc3\x16@>%\xd2\xd9?C\x8b\x08\xbfP]\x02\xc0\xe3\xf6\x0c\xbe\x1b!\x91?s&\x8d\xbfW\x84\xc1\xbf\xf7\xb2\x92>\x06\xa3\x98\xbf\xd2>/@\x8e-T\xc0\x97(\x9e\xbf\xa1\x01J?\xfe\xda;?\xa4wk@\x1f\xb3<?\x8d7\xd6=\xc8\xb5V\xc0q\xd7_=\x1e\xb2M?a\x06\x85\xbe\xc7\xe7\xc1\xbe\xd1\xb0\x13\xbf"\x00N?\xdd\x1b\x0b\xc0R\xf4j?\x89\x16\x03\xc0\x93\x10U\xbf\x93\x890\xbf\x87\xcdL\xc0\xd0\x1e9\xc0\x8e\x14\xa0\xbf\xba\xd8\xdb?M]\x9c>\xff2\xa2?\x0c`^\xbfYf&\xbfO\xe3\xe1\xbfT\x84\x1a@Ut\xc0\xbf\x94=f\xbf\x14u\x8b>\xfdR\x9b\xbe\xbeGn\xbe\xe8~2A\xbe\'m\xc0u\x9a\xbe=\x120\xcb=\x83}\xff?\xf8\xb6\xf4>\x1e\xfa\xa5>i\xbeT@\xe1\xc1\x03\xbfe\xe3\xa0\xbe\xbfA8\xbfK\xc6\xbf?b\xd1q\xbfJ\x92q\xbf\x88\xd8\x18>\x1f|\xa5?\x89c\xee?\xd4`\xf7?\xfc\xc5\xd6\xbfB\xfd}>\xb0\xae\xa4\xbd\xbe\xa0M@\x8f\xe2F?OG\x13\xbf\xeec\xb4?\'X\x81\xbf\xa0_w>\x14\x8c\xc7?\xf9G\xc2?|\xaeH?\x00\xc4\xa0>\x8a\xe7\x8a\xbf\xd6\xaa\xc1\xbe\xd6\xd3\x98@v\xd5a>v\x0e2\xbd-\xea\xf0>\xb7\xd9\x14@\x0f\xba"\xc0.\xf5\xea?\xffn\xb8\xbf\xda39\xbe(Ih<Fmf\xbd\xc5\x88\x18?%\xae\xa7?\xc7\x17e?\x81`\x18\xbf\xda)\x8c\xbe.\x9f]\xbf\x90\x0c1\xc0\x9dL.@\xa0\x84c\xbelZ\xf9?RX>\xc0\xf9AB\xbf\xbe\xc8\x1b\xc0\xd5XT@\x0f7\x8f?\x99\x14w?g\xc4$@\xfe\xac\x94?\x18\x99\x02\xc0\xdb\x944\xc0d\x8e\xb5\xbe\x04\xdc@\xbd\x82\xfb\x84\xbf\xef\x81\x92?\xb2=\x1e?6m\x08?\xe9\n9\xbf\x15\x05\x88?\xda\xd0\x02@\x18\'8\xbf"\x85\xf9?F\x03_\xbe\xa2\xc0\xb8=\x9c\xee\x8f?^\xa8\xe4\xbf\x8d\xce\x82?r\xb2\x02@\xb8D\xa5=P\xf1;?\x9a;\xb2\xbf\xce\x12\xf6?\xbe\xfc>\xbf\xb0\xef\xba=\xae(,@\xde\x1c\xc2\xbf\x1e\x1c\xfb\xbf\xff\xc7\x16\xc0v\x82\x00@q4F@\x83\xee\x99>*l\x89=\xfcJ\x1e@Mt\x16@T\x10\x80?UoI\xbf5\xf7a\xbf\xf3\n\xa5>\xd6\xb0\x82>L\x004\xbf\xd5\xcc6;F\xfa\x81?W\xaa\xd5\xbf\xf8\nU?\xef^\'\xc0\xea\xe7\xea?\xc2\x03\xb7?]K\xdf\xbf\xe8|\x83?\xd6\xb7&>nW)\xc02h\x03@M\xd0\xd7>\xdc\x8b\xcd\xbf\xb5\xb2\r\xbf\xa7\xe6\xb6?\xbc\x0b\xdc?\x0c\xce8\xbf;\xb9t?-\x9f\xba\xbf%\xfc\xce\xbexE\r?\xe84\x87@\x1bD|@\xb9wp?\xb0n\xcf\xbf\xce\xe5\x1c\xbf\xb1\xeb\xb1\xbf\xfb\xac\x13\xc0\xee\xb7w>\x9e\xa8\x95?A\x9b7\xc0FS\x86?rb\xf5\xbf6\x120\xc0\x1c\x81\xca?\xb8\xfd\x17\xbf\x1eF\x16@\xe0<\xaa>\'\x83`\xbf0\xa0\xe5=\xf6hP\xbfE4C?\x80hl>\x07\x00\xb0?\x9b\x9d\x07?&\x93~\xc0X\xcb\x99>S\xe4\xb2?H\r\xb2\xbewaD\xc0\xc6\xb20@\x86\xd9\xd5?s\xbb%@\xbe\x8b]>:\x03y@\x80\'\x0f\xbfl\xd9\x8d\xbcA\xdf\r\xc0\x00\xe7#@$\x88\xbb\xbdKP\xd2>\xa6\xe5\x08@\r.\xda?\xd1\xc0\x07\xc0/d \xc0Q\xc5\x8c\xbe\x90H=\xc0\xd7\x87B>\xa9_1??\x839@8\x01\xdb?2\xeb>@h*\\\xbd\xae-t?\xf4\x8f\xb0\xbe\xb0\xe0j\xbc\xef\xe6\x1c\xbf\xd0\x93\r\xbf.~\xb3\xbf\xd1~\xb4\xbf\x989\n\xc0;\x80\xcf?\xe0;e?\xd5\x93\x04@\xc8W\x10\xbf\x94\xbe\t\xbf\x1f\xae\x94>\xf0\x88R\xc0,\x911\xbeO\xef\xa6?/\x1b @\xf3\x06\xe9\xbf\x10\'\xe6\xbd^/\xe9\xbf\x06\xb4\x86\xbe\xb2n\xe5?\x8e\xdb\xab?\xc8\x7f\xad\xbe\x8a;Y?+?y@\r\x86O@2\xceR@J\xea\x80\xbf_\xd1B@\xc0\xe2\x9c?\xf8\xff0=\xba\xe7\x8e?88\x0b?\x84Z\xc5\xbe\xd8m\xb8>\xe5\xc7Y\xbf\xe2\xdb-?p\x83Y\xbd\xf5/\xde\xbf\xf9e2\xc0\x02\xb7w\xbe\xab%p?~\xcf\x1c=\xb6\xd1&\xbf\x90\xad\xc0?\xf0*\x8f\xbf<R\x99?S\xb3n\xc0"\xb66\xbe\xec\x9c$@\xb9Kk@\x88\xd61\xbf.\x1c%@$\x1a"=*\x03w\xbf\xf3\x93\x07\xbfTl$\xc0\xf3\xf3\x98\xbf\nF\xba>\x0f\x15\x00>\x8f\x9e\xa0\xbfpz\xc5?\xec\xf4\x12\xbfP\x1a\x95=\x83\xb1\xbc?\xa9?(\xc0\x14@\\\xbf4\xf5\xd5\xbf\x84\xb1\xee>Z\xb1\x8e?DU\x83\xbcQv\xc2?\xf0\x9a\x11@M0\r>\x9e\xd2\x84>\xbdK\x08?\xca\x86\xb4?\x04i"\xbe\xff\xec\x96?[\x84$\xc0\xfb\xcdx\xbf\xdf\x02\x9f\xbf\x18\xdb\xce\xbfY\x86\x83>\t(\x96\xbf\xda\xc7\x00\xc0"`\x9f\xbe.\xe0\xee\xbev(w\xbf\xafY\x8f\xbe\xbc\xd5\x86\xbe;\xc7\xf5\xbf+M \xbf8\xd3$\xc0\xf4@\x9d\xbe\x80\x18\xe1\xbf\xdbC:\xc02v\x1d\xbf\x80\xde\x0b\xc0d\xf9\xfb\xbfB\xceJ\xbfQ\x92k>\xe1\x15\xe0\xbf]\xcf\xa3\xbf\x0b\x92\x99\xbf\xb7L3?\xc5\xa1\xba\xbe|\xfd\x08@\xa3\xd5\xe9?\xa5\tW?\x08\xcdU?@5\xcd\xbc\xc0\x14{;\xe2\xf5\xb5?\x982\xf5?i<b\xbf|\xda\x86\xbf\xbb`\x88\xbf\xa8\x1e"@\x1a1~\xbf\xb7S\xcb?r\xfa\xd0\xbf\x0c\xf3\x96\xbe\xd1\x16\xc2?\xf7\xc7\xfc\xbf\x92\xe2\x8c\xbf\xe1\x12\xea\xbe>\xf6\xe1\xbf\xbaG\xeb\xbe\x80\xbb\x03\xc0\x00D\xd1>fX\x91\xbf\xf0\x14\xb0>\xee\xae\xc0\xbf!\xb8#?q2\xdc\xbe~\xa2\x03\xc0*\x0e\x95\xbf\x15\xaf7?@f>;\xe9y\xea?58\x1a@\x9am\xca\xc0F\xcb\xaa\xbe$> \xbf\x88\xde\x0e?!"\x1c?\xe0\xfav\xbe^\xbc\xed\xbf\xe1\xef\x95\xbf8-\x0e\xc0\xfd\xe2\xba?\xe0L\x93\xbb\xfc+\x96\xbf\xbc\xb4\xd0?$\xe5J\xbfM9B?d\x19[\xc0k\xb4\xcf?\xfbw\x1c\xc0\xfb\xd9\xc7\xbfLn\xe0\xbe\x08L\x8f?\xcc\xdb#>\x80\x13\x82\xbfT|\x88>{\x1eA?\xd4\x0c\x84\xbe\xe0o\xe4\xbe\xa3\x89\xfd\xbf\xb0q\x03\xc04\xdb\x08@\x12\x1b}\xbf\xf6\x1e\xdb=\xcdQ\x07\xc0u\x86\xa2>\xed\xe3o@\xc0K\x05?\xac\xa6\t?\xa3\xd26?\xa9\x80\x95?V\xd6\x83?\'\xb1\xcb?H\xae\xe9?O\xd2\x14\xc0g\xf3+?\xa7\xad\xd3>\x17m\x0f@d\x1b\x84@_\xb68\xbe\xb9\x17\xc0>\x96\x88\x82\xbe\xc3\xe2U\xbf\xd8E\x7f<\xf8\xcc\xd5?v\xe5Z?\x8b5\x91\xbfL\xd8u\xbf\xc7\x08M\xbf\x03\x92\xb0?_E\xbd\xbfl\xe61\xc0\x83 >@S\xe9\xb3?\xd1\x7f\x04\xc0\xca;\x17?\xea\x83\x10?\xfa!\xb0?\xd6E\xef>\xfa\x0c\xca\xbcy\xf1\xe6?:\x98\xbc\xbf\xf4\xd6\xf6\xbd\xfe\x99Z\xbf\x97\xca\xb6\xbf.\xe3\xe7\xbfU&\xf1>Z\x8au@`\xc7\x9a\xbe6xH?S\xd8Q?\xb1\x84\xac\xbf\x8c\xaf\x04?8\xa6\xa8?\xcbl\xe8\xbf7\x07\xd0>\xec\xd7\x85\xbe\xf3\xe20\xc0\xc1N\xdd\xbf\xcd\xb3\x13\xbe\xa4\xd4\x19?p~H@\x85\x8a\x17@\xe9e\x97?r\xfa\xb4?U\x12=?H\xcf\x84?\\s\x0f\xbf\x91\xae\xf8?\xc0Z\xdc\xbd\xd62\xd9?]\xf3\xd1>Y\xf91@XY\x83>\x80+]@<\xcd5\xc0Z\xda\x9a?\x86[Z?\xb2\xa7\xe0\xbf?\x803\xbf-\x84\xf8>\x10\r\x15?\x87\xca\x85\xbf\xef\xe2$=Q\xaa\x06@vRz\xbd\x86\x95B\xbd\x86~\xa3\xc0\x1d\x17O?\t\xd8\xc8\xbf%\xa6\xb3\xbfr#\xb8?Xo\xcc\xbf\x1b\x1f/\xbf\xc3\x0cS@U\\\xab?\xf9:\x0f@/<\xd1?\x00\xe6\x0b?\xdf\x8a\xf4\xbc\xbe\x8b\xaf?s\x0cH?\xa9R.\xc0B\xda\xc6\xbf\xc9\x0b\xcf?\xde\x18\xf5>\xed\xba8@\xa6\x8a(?$4E\xbfV*\xc4\xbe\xc3\xd9\xce\xbe\xec\x11\xd3\xbf76\xe6\xbf\xa1\x9fu\xbfhP/=i}\xab\xbf\xd7\x92\x04@\x12\x97\x17@4\xaa\x0e\xc0R\xa2\xea=\xf6\xaa\x9c?\xe4\xbb\x03@Q\x95\xf6\xbf\x84\x08\xec\xbf\xafTs>69\xaf?\xbd\x11\xed?\xbe\xe3\xa2?\xa8\xca\x8d\xbf\x83o*@\x85\xdf\xac\xbf\xe0@\x7f\xbf<\xec\xdf\xbe\t\xce\xe1?\xfc\xad\x1d\xbf\xd9\xc5\xc2>k\x9a\xe8>N\x84\x96?\x1f\x18R\xbfO5\xd0>\xe1q\x82>\xe7\x7f(?B\x16\n\xbf\x13\xc5\xb6?sg\x00\xbf\xab\xa8\x06>v\x99\xaf>\xe7\xb4\xbc\xbf0\xd0\xb3\xc0\x96\xbe\x99>\x0ee\x95?H@x>\x99\x8a\x0c?\x1f\xd0=\xc0\x17\xfb\xf8>\x16\n\x8c>\x8d\xf4\xb3\xbf\x18.\x16>\x88\xc6\x05\xc0P\xc7\xac>8\xfe\xc6?\xcc\x97\x89\xbf\xebL\xa1?\xb7\x92\x92?\xbcJ\x00\xbf\xd9lI\xc0\x9f*\x85?j\x06\xe0?\xe6"e\xbf\xc0\xd9\x1d@f\xaf\xac>\x01)\x85\xc0\x92C\xa5?\xf9\xeeL>`\xb9\xeb;\x8a=x\xbf\xa1\xa0\xf2??[\x0c\xbf\xe9\x94\xeb>_\xdc\xc5>9\x02\xa6>\x1d\xba\xe8=\xf7\x16\x9f\xbe6St\xbf0\x0e:>\x19e\x12\xbf\xb6W\x8f>+\xc3\x14\xc0\xefd\x8b@\xc6\xa2M>\x044n@PLr\xbf;d\x87>x\x05\xd8\xbdc\x0f\xcf>F\xce\x81\xbf\xc9Me?]\xf6\xfd>\x02\\\x87\xbe"u\xb2?\x0e\x93\xba?\x06\xc4\x04@k\x9b-@\xb2P\x83?NF\x1d>{\xdc(?\xd0\x17\x01\xbf\x93\xe9\xb6?\x90\xeb\xde?\xb8\x13\xae?\xf7i!\xc0\xbe\x00`@\xa5\xa4\xa3?\x90\x10y\xbe_\xffd\xbe\x99\x9fM>\xd8\xa7\n\xc0\x0c\xc3\xe3?{<\x96\xbe\xb4\\\xbc\xbf\xb2\x0f\xc9>D\x02\xc0\xbf\xb3\xbb\xbb>]\xac$\xc0\xc5\x8bj?X.\xb7\xbfT\xb0\rA\xc3a+\xc0C\xd6\x0f\xbf\xfe\xfc8@\x0f\x99\xf0>c\x11\xcf<\x83gm\xbf\x0e\x89T?\xec\xdf\xea\xbfc\xb6W?\xc9\'\xb0?\x17\xf6\xbf>I\x125\xc0B\xef/@\xf3\x93\xe2?\x8f\xbd\x00\xbf\x8d\x05C\xc0\xc4\xda\x8d>S#;?\xc7\xcc\xf1\xbf9\xbbc\xc0C\xbf\x1c\xc0o\x93t?\x8ap\xff?G\xc8\xd7>\xdc\xe8\xed\xbf&&\xcf\xbe\xcc\xc2\x93?<Y\x12\xc0\xc3\xd9\x88\xbe\xdeBV>&v\x05\xbe{\x17\xb1@\xa9\xf4\x97?\xf1m\x91?f\x99d\xbf\x1a\xb4\xb4\xbf\x1f\xe3X?\xa8<\x05>a\x8f\xb9\xbf\x97;\xd4>\xa4\x13\xfe?b@"@_\xf3\xde?r\xc3\xa7>V\xb6W\xbf+\xa2\xbf?fp\xe4>-e\xc9\xbf\x16\xe9N?\xca\xe2\xa6?(\xf9k@K@\xbb>\x1c\xb6\x9c=j\x98\xbd=\xf3\xa1$?\xbe\xe2??\x1c\xee\xcf\xbf4\xa1\x85\xbf\x92<N\xbf[i\xcb\xbf\x9d\x96\x99?\x14\xc0\xf4\xbe\x9e|\xc2\xbe\xf62\x9f@\xae\x02r\xbfZ\xd8\x95\xbd\x8b\xf2\xeb?Y{\r\xbe\xd0G+>\xca\x8e\xb1?\xcd;M\xc0Pm\xac\xbf;\x1d\x01\xc0\x9f\xed\xa0?_\xca\xa3>n\x16\x1b\xbf']
07/15/2021 16:10:19 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:10:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:10:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:10:24 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:10:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:10:25 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:10:25 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:10:25 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:10:29 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:10:32 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:10:32 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:10:32 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:10:32 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:10:32 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:10:32 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:10:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:10:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:10:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:10:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:10:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:10:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:10:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:10:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:10:38 - INFO - __main__ - Finished.
07/15/2021 16:10:38 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:10:38 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:11:22 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:11:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:11:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:11:27 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:11:27 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:11:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:11:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:11:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:11:32 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:11:35 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:11:35 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:11:35 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:11:35 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:11:35 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:11:35 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:11:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:11:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:11:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:11:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:11:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:11:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:11:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:11:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:11:41 - INFO - __main__ - Finished.
07/15/2021 16:11:41 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:11:41 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:14:28 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:14:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:14:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:14:33 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:14:33 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:14:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:14:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:14:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:14:37 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:14:40 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:14:40 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:14:40 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:14:40 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:14:40 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:14:40 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:14:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:14:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:14:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:14:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:14:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:14:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:14:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:14:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:14:46 - INFO - __main__ - Finished.
07/15/2021 16:14:46 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:14:46 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:17:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:17:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:17:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:18:00 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:18:00 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:18:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:18:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:18:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:18:05 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:18:08 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:18:08 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:18:08 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:18:08 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:18:08 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:18:08 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:18:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:18:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:18:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:18:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:18:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:18:10 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:18:10 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:18:10 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:18:14 - INFO - __main__ - Finished.
07/15/2021 16:18:14 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:18:14 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:19:37 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_8_result.json', predict_batch_size=40, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:19:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:19:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:19:41 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:19:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:19:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:19:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:19:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:19:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:19:49 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:19:49 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:19:49 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:19:49 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:19:49 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:19:49 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:19:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:19:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:19:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:19:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:19:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:19:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:19:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:19:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:19:55 - INFO - __main__ - Finished.
07/15/2021 16:19:55 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:19:55 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:20:21 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:20:21 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:20:21 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:20:38 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:20:38 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:20:38 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:20:53 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:20:53 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:20:53 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:21:08 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:21:08 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:21:08 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:21:23 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:21:23 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:21:23 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:21:38 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:21:38 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:21:38 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:21:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:21:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:21:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:22:09 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:22:09 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:22:09 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:22:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:22:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:22:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:22:41 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:22:41 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:22:41 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:22:57 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:22:57 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:22:57 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:23:12 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:23:12 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:23:12 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:23:28 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:23:28 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:23:28 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:23:44 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:23:44 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:23:44 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:24:00 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:24:00 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:24:00 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:24:16 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:24:16 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:24:16 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:24:31 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:24:31 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:24:31 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:24:47 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:24:47 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:24:47 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:25:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:25:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:25:02 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:25:18 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:25:18 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:25:18 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:25:34 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:25:34 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:25:34 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:25:50 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:25:50 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:25:50 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:26:06 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:26:06 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:26:06 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:26:22 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:26:22 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:26:22 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:26:37 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:26:37 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:26:37 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:26:53 - INFO - __main__ - Start the Overall Error-Fixing Results....Done
07/15/2021 16:26:53 - INFO - __main__ - Start the Overall Forgetting Results (Knowledge Retain Acc)....
07/15/2021 16:27:01 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:27:01 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:27:01 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:27:15 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:27:15 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:27:15 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:27:30 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:27:30 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:27:30 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:27:44 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:27:44 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:27:44 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:27:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:27:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:27:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:28:13 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:28:13 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:28:13 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:28:28 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:28:28 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:28:28 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:28:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:28:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:28:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:28:54 - INFO - __main__ - Start the Overall Forgetting Results (Knowledge Retain Acc)....Done
07/15/2021 16:28:54 - INFO - __main__ - Start Error-Fixing performance on the Next batch of errors.....
07/15/2021 16:28:55 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:28:55 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:28:55 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:29:03 - INFO - __main__ - Start Error-Fixing performance on the Next batch of errors.....Done
07/15/2021 16:29:03 - INFO - __main__ - Starting the offline evaluation of 1
07/15/2021 16:29:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_001.pt for facebook/bart-base .....
07/15/2021 16:29:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:29:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:29:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:29:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_001.pt for facebook/bart-base ..... Done!
07/15/2021 16:29:10 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:29:10 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:29:10 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:29:10 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:29:10 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:29:10 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:29:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:29:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:29:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:29:16 - INFO - __main__ - Finished.
07/15/2021 16:29:16 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:29:16 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:29:47 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:29:47 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:29:47 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:30:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:30:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:30:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:30:35 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:30:35 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:30:35 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:30:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:30:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:30:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:31:23 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:31:23 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:31:23 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:31:47 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:31:47 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:31:47 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:32:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:32:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:32:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:32:35 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:32:35 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:32:35 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:32:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:32:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:32:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:33:22 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:33:22 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:33:22 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:33:47 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:33:47 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:33:47 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:34:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:34:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:34:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:34:36 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:34:36 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:34:36 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:35:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:35:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:35:02 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:35:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:35:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:35:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:35:49 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:35:49 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:35:49 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:36:13 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:36:13 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:36:13 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:36:37 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:36:37 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:36:37 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:36:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:36:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:36:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:37:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:37:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:37:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:37:49 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:37:49 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:37:49 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:38:14 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:38:14 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:38:14 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:38:37 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:38:37 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:38:37 - INFO - __main__ - Debugger Setup ...... Done!
epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_10_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=12, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_12_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=2, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_2_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=13, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_13_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=3, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_3_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=5, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_5_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=8, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_8_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=14, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_14_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=7, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_7_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=1, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_1_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=15, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_15_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=11, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_11_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=6, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_6_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=4, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_4_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:30 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=9, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_9_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:38:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:38:41 - INFO - __main__ - Starting the offline evaluation of 12
07/15/2021 16:38:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base .....
07/15/2021 16:38:41 - INFO - __main__ - Starting the offline evaluation of 8
07/15/2021 16:38:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base .....
07/15/2021 16:38:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:43 - INFO - __main__ - Starting the offline evaluation of 45
07/15/2021 16:38:43 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/15/2021 16:38:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:44 - INFO - __main__ - Starting the offline evaluation of 18
07/15/2021 16:38:44 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base .....
07/15/2021 16:38:44 - INFO - __main__ - Starting the offline evaluation of 15
07/15/2021 16:38:44 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base .....
07/15/2021 16:38:45 - INFO - __main__ - Starting the offline evaluation of 24
07/15/2021 16:38:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base .....
07/15/2021 16:38:45 - INFO - __main__ - Starting the offline evaluation of 36
07/15/2021 16:38:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base .....
07/15/2021 16:38:46 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:38:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:38:46 - INFO - __main__ - Starting the offline evaluation of 48
07/15/2021 16:38:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base .....
07/15/2021 16:38:47 - INFO - __main__ - Starting the offline evaluation of 27
07/15/2021 16:38:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/15/2021 16:38:47 - INFO - __main__ - Starting the offline evaluation of 4
07/15/2021 16:38:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base .....
07/15/2021 16:38:47 - INFO - __main__ - Starting the offline evaluation of 30
07/15/2021 16:38:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base .....
07/15/2021 16:38:48 - INFO - __main__ - Starting the offline evaluation of 39
07/15/2021 16:38:48 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/15/2021 16:38:48 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:48 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:48 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:48 - INFO - __main__ - Starting the offline evaluation of 21
07/15/2021 16:38:48 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/15/2021 16:38:48 - INFO - __main__ - Starting the offline evaluation of 33
07/15/2021 16:38:48 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/15/2021 16:38:48 - INFO - __main__ - Starting the offline evaluation of 42
07/15/2021 16:38:48 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base .....
07/15/2021 16:38:50 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:50 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:50 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:50 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:50 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:50 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:52 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base ..... Done!
07/15/2021 16:38:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base ..... Done!
07/15/2021 16:38:53 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:53 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:53 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:53 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:53 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:53 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:55 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/15/2021 16:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:38:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:38:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:38:58 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:04 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:05 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:05 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:05 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:05 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:05 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:05 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:05 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:05 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:05 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:05 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:05 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:05 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:05 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:05 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:08 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:08 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:09 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:09 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:09 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:09 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:09 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:09 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:09 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:09 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/15/2021 16:39:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:11 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:11 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:11 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:12 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:12 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:12 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:12 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:12 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:12 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:14 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:14 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:14 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:14 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:14 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:14 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:14 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:14 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:16 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:16 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:16 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:16 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:16 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:16 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:18 - INFO - __main__ - Finished.
07/15/2021 16:39:18 - INFO - __main__ - Finished.
07/15/2021 16:39:18 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:18 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:18 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:18 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:18 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:18 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:18 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:18 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:18 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:18 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:19 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:19 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:19 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:19 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:19 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:19 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:19 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:19 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:19 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:19 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:19 - INFO - __main__ - Finished.
07/15/2021 16:39:19 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:19 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:20 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:20 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:20 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:20 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:20 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:20 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:20 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:20 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ...... Done!
0eb
07/15/2021 16:39:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:21 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:21 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:21 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:21 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:21 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:21 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:21 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:21 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:21 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:21 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:21 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:21 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:21 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:22 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:23 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:23 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:23 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:23 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:23 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:23 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:23 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:24 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:24 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:24 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:24 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:24 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:24 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:24 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:24 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:24 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:24 - INFO - __main__ - Finished.
07/15/2021 16:39:24 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:24 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:25 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:25 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:25 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:39:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:39:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:39:25 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:39:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:39:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:39:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:39:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:39:27 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:27 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:27 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:39:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:39:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:39:35 - INFO - __main__ - Finished.
07/15/2021 16:39:35 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:35 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:39:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:39:38 - INFO - __main__ - Finished.
07/15/2021 16:39:38 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:38 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:39:40 - INFO - __main__ - Finished.
07/15/2021 16:39:40 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:40 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:40 - INFO - __main__ - Finished.
07/15/2021 16:39:40 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:40 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:43 - INFO - __main__ - Finished.
07/15/2021 16:39:43 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:43 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:44 - INFO - __main__ - Finished.
07/15/2021 16:39:44 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:44 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:46 - INFO - __main__ - Finished.
07/15/2021 16:39:46 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:47 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:48 - INFO - __main__ - Finished.
07/15/2021 16:39:48 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:48 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:51 - INFO - __main__ - Finished.
07/15/2021 16:39:51 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:51 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:39:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:39:51 - INFO - __main__ - Finished.
07/15/2021 16:39:51 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:39:51 - INFO - __main__ - Start the Overall Error-Fixing Results....
                                                                                                                                                                                                                                                        07/15/2021 16:40:05 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:08 - INFO - __main__ - Finished.
07/15/2021 16:40:08 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:40:08 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:40:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:12 - INFO - __main__ - Finished.
07/15/2021 16:40:12 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:40:12 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:40:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:25 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
                                                                                                                                                                                                                                                                                                                                                                                                                     07/15/2021 16:40:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
                                                                                                                                                                                                                                                                                                                                                                                                                     07/15/2021 16:40:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:57 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:40:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:10 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:41:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
                                                                                                            07/15/2021 16:41:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:26 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:45 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:47 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:41:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:41:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:17 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:42:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:26 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:32 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:42:47 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:42:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               07/15/2021 16:43:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:04 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
om/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:43:22 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:43:22 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:43:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:43:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
 INFO - __main__ - Moving to the GPUs.
07/15/2021 16:43:26 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:43:26 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:43:26 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:43:26 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:43:26 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:43:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:43:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:43:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:43:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:43:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:43:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:43:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:43:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:43:31 - INFO - __main__ - Finished.
07/15/2021 16:43:31 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:43:31 - INFO - __main__ - Start the Overall Error-Fixing Results....
                                                                                                                                                                                                                                                                                                                                                                                                                                    07/15/2021 16:44:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:44:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:44:02 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:44:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:44:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:44:24 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:44:44 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:44:44 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:44:44 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:04 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:04 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:04 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:25 - INFO - __main__ - Debugger Setup ...... Done!
pochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_5_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=7, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_7_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=6, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_6_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=4, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_4_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=14, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_14_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=8, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_8_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=11, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_11_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=13, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_13_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=1, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_1_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=10, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_10_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=15, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_15_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=2, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_2_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=3, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_3_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=12, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_12_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:10 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=9, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_9_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:46 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:46 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:46 - INFO - __main__ - Debugger Setup ...... Done!
chenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:24 - INFO - __main__ - Starting the offline evaluation of 18
07/15/2021 16:45:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base .....
07/15/2021 16:45:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:24 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:45:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:45:24 - INFO - __main__ - Starting the offline evaluation of 45
07/15/2021 16:45:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/15/2021 16:45:25 - INFO - __main__ - Starting the offline evaluation of 39
07/15/2021 16:45:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/15/2021 16:45:25 - INFO - __main__ - Starting the offline evaluation of 24
07/15/2021 16:45:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base .....
07/15/2021 16:45:25 - INFO - __main__ - Starting the offline evaluation of 12
07/15/2021 16:45:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base .....
07/15/2021 16:45:26 - INFO - __main__ - Starting the offline evaluation of 27
07/15/2021 16:45:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/15/2021 16:45:26 - INFO - __main__ - Starting the offline evaluation of 15
07/15/2021 16:45:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base .....
07/15/2021 16:45:26 - INFO - __main__ - Starting the offline evaluation of 8
07/15/2021 16:45:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base .....
07/15/2021 16:45:28 - INFO - __main__ - Starting the offline evaluation of 4
07/15/2021 16:45:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base .....
07/15/2021 16:45:28 - INFO - __main__ - Starting the offline evaluation of 36
07/15/2021 16:45:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base .....
07/15/2021 16:45:28 - INFO - __main__ - Starting the offline evaluation of 33
07/15/2021 16:45:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/15/2021 16:45:28 - INFO - __main__ - Starting the offline evaluation of 21
07/15/2021 16:45:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/15/2021 16:45:29 - INFO - __main__ - Starting the offline evaluation of 30
07/15/2021 16:45:29 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base .....
07/15/2021 16:45:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:30 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:31 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:31 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:35 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:39 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:45:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:39 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:39 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:45:39 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:45:39 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:45:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:39 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:39 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:45:39 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:45:39 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:45:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:45:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:41 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:41 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:41 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:41 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:42 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:49 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:49 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:51 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:51 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:51 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base ..... Done!
07/15/2021 16:45:52 - INFO - __main__ - Finished.
07/15/2021 16:45:52 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:45:52 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:45:52 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:45:52 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:52 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:52 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:52 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:45:52 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:45:53 - INFO - __main__ - Finished.
07/15/2021 16:45:53 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:45:53 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:45:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:45:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:45:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:45:56 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:45:56 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:45:56 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:45:56 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:45:56 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:45:56 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:45:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:45:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:45:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:45:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:45:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:45:58 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:45:58 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:45:58 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:45:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:02 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:02 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:02 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:02 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:03 - INFO - __main__ - Finished.
07/15/2021 16:46:03 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:03 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:04 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:04 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:04 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:04 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:04 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:04 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:04 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:06 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:06 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:06 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:06 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:06 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:06 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:07 - INFO - __main__ - Finished.
07/15/2021 16:46:07 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:07 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:07 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:07 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:07 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:07 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:07 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:09 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:09 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:09 - INFO - __main__ - Finished.
07/15/2021 16:46:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:09 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:09 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:09 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:09 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:09 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:09 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:10 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:10 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:10 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:10 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:10 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:10 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:11 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:11 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:11 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:11 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:11 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:11 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:11 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:11 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:11 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:11 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:11 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:12 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:12 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:12 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:12 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:12 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:12 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:12 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:12 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:12 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:46:12 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:46:12 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:46:12 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:46:12 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:46:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:46:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:14 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:14 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:14 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:15 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:15 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:15 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:46:15 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:46:15 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:15 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:46:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:21 - INFO - __main__ - Finished.
07/15/2021 16:46:21 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:21 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:24 - INFO - __main__ - Finished.
07/15/2021 16:46:24 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:24 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:26 - INFO - __main__ - Finished.
07/15/2021 16:46:26 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:26 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:27 - INFO - __main__ - Finished.
07/15/2021 16:46:27 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:27 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:31 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:46:32 - INFO - __main__ - Finished.
07/15/2021 16:46:32 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:32 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:35 - INFO - __main__ - Finished.
07/15/2021 16:46:35 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:35 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:41 - INFO - __main__ - Finished.
07/15/2021 16:46:41 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:41 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:53 - INFO - __main__ - Finished.
07/15/2021 16:46:53 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:53 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:54 - INFO - __main__ - Finished.
07/15/2021 16:46:54 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:54 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:46:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:46:59 - INFO - __main__ - Finished.
07/15/2021 16:46:59 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:46:59 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:47:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:01 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:47:01 - INFO - __main__ - Finished.
07/15/2021 16:47:01 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:47:01 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:47:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:11 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:47:30 - INFO - __main__ - Retrieved 320 examplesulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:47:33 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            07/15/2021 16:47:53 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:47:53 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:47:53 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:48:17 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:48:17 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:48:17 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      07/15/2021 16:48:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:48:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:48:39 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                             07/15/2021 16:48:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples  __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:48:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:49:19 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:49:19 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:49:19 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                          07/15/2021 16:49:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:49:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:49:39 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            07/15/2021 16:50:00 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:50:00 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:50:00 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:50:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:50:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:50:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:50:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:50:19 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:50:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:50:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:50:42 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         07/15/2021 16:51:03 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:51:03 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:51:03 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:51:25 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:51:25 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:51:25 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:51:47 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:51:47 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:51:47 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       07/15/2021 16:51:57 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:52:07 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:52:07 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:52:27 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:52:27 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:52:27 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:52:49 - INFO - __main__ - Start the Overall Error-Fixing Results....Done
07/15/2021 16:52:49 - INFO - __main__ - Start the Overall Forgetting Results (Knowledge Retain Acc)....
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                07/15/2021 16:52:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:52:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:52:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=11, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_11_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=9, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_9_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=12, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_12_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=5, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_5_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=15, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_15_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=6, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_6_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=2, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_2_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=13, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_13_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=8, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_8_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=1, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_1_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=14, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_14_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=10, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_10_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=3, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_3_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=4, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_4_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:05 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=7, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_7_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:53:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:16 - INFO - __main__ - Starting the offline evaluation of 39
07/15/2021 16:53:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/15/2021 16:53:16 - INFO - __main__ - Starting the offline evaluation of 27
07/15/2021 16:53:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/15/2021 16:53:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:19 - INFO - __main__ - Starting the offline evaluation of 21
07/15/2021 16:53:19 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/15/2021 16:53:19 - INFO - __main__ - Starting the offline evaluation of 18
07/15/2021 16:53:19 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base .....
07/15/2021 16:53:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:19 - INFO - __main__ - Starting the offline evaluation of 45
07/15/2021 16:53:19 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 30
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 42
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 48
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 24
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 8
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base .....
07/15/2021 16:53:20 - INFO - __main__ - Starting the offline evaluation of 4
07/15/2021 16:53:20 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base .....
07/15/2021 16:53:23 - INFO - __main__ - Starting the offline evaluation of 15
07/15/2021 16:53:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base .....
07/15/2021 16:53:23 - INFO - __main__ - Starting the offline evaluation of 12
07/15/2021 16:53:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base .....
07/15/2021 16:53:23 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:53:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:53:24 - INFO - __main__ - Starting the offline evaluation of 33
07/15/2021 16:53:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/15/2021 16:53:24 - INFO - __main__ - Starting the offline evaluation of 36
07/15/2021 16:53:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base .....
07/15/2021 16:53:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:27 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:27 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:27 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:30 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:30 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:31 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:31 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:31 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:35 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:35 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:35 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:35 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:35 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:35 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:35 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:39 - INFO - __main__ - Debugger Setup ...... Done!
21 16:53:36 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:36 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:37 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:37 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:37 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:38 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:38 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:38 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:38 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:42 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:42 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:44 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:44 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:46 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base ..... Done!
07/15/2021 16:53:48 - INFO - __main__ - Finished.
07/15/2021 16:53:48 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:53:48 - INFO - __main__ - Finished.
07/15/2021 16:53:48 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:53:48 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:53:48 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:53:49 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:49 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:49 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:49 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:49 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:49 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:51 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:51 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:51 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:51 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:51 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:51 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:52 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:52 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:52 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:52 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:52 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:52 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:52 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:52 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:52 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:52 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:52 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:53 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:53 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:53 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:53 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:53 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:53 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:53 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:53 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:53 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:53 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:53 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:53 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:53 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:53 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:53 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:54 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:54 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:54 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:54 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:54 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:55 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:55 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:55 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:55 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:55 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:55 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:53:55 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:55 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:55 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:53:55 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:53:55 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:53:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:53:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:53:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:53:59 - INFO - __main__ - Finished.
07/15/2021 16:53:59 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:53:59 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:53:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:53:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='b07/15/2021 16:54:05 - INFO - __main__ - Finished.
07/15/2021 16:54:05 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:05 - INFO - __main__ - Start the Overall Error-Fixing Results....
otal_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:53:59 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:54:06 - INFO - __main__ - Finished.
07/15/2021 16:54:06 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:06 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:06 - INFO - __main__ - Finished.
07/15/2021 16:54:06 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:06 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:06 - INFO - __main__ - Finished.
07/15/2021 16:54:06 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:06 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:09 - INFO - __main__ - Finished.
07/15/2021 16:54:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:09 - INFO - __main__ - Finished.
07/15/2021 16:54:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:09 - INFO - __main__ - Finished.
07/15/2021 16:54:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:09 - INFO - __main__ - Finished.
07/15/2021 16:54:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:10 - INFO - __main__ - Finished.
07/15/2021 16:54:10 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:10 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:10 - INFO - __main__ - Finished.
07/15/2021 16:54:10 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:10 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:10 - INFO - __main__ - Finished.
07/15/2021 16:54:10 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:10 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:10 - INFO - __main__ - Finished.
07/15/2021 16:54:10 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:54:10 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:54:20 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:54:20 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:54:20 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:54:40 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:54:40 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:54:40 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=14, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_14_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=2, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_2_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=10, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_10_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=11, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_11_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=5, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_5_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=0, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_0_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=4, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_4_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=15, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_15_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=12, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_12_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=6, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_6_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=8, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_8_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=7, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_7_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=9, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_9_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=1, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_1_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='mbpa++', current_thread_id=13, do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_13_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:54:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:54:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:54:59 - INFO - __main__ - Debugger Setup ...... Done!
pochs=1, num_beams=3, num_threads_eval=16, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_offline_eval/thread_3_of_16_result.json', predict_batch_size=20, prefix='nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5', replay_frequency=1, replay_size=16, result_file='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_result.json', sampled_upstream_json_path='bug_data/mrqa_naturalquestions.sampled_upstream.jsonl', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False, weight_decay=0.01)
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:11 - INFO - __main__ - Starting the offline evaluation of 48
07/15/2021 16:55:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base .....
07/15/2021 16:55:11 - INFO - __main__ - Starting the offline evaluation of 30
07/15/2021 16:55:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base .....
07/15/2021 16:55:11 - INFO - __main__ - Starting the offline evaluation of 15
07/15/2021 16:55:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base .....
07/15/2021 16:55:11 - INFO - __main__ - Starting the offline evaluation of 0
07/15/2021 16:55:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base .....
07/15/2021 16:55:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:13 - INFO - __main__ - Starting the offline evaluation of 21
07/15/2021 16:55:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/15/2021 16:55:14 - INFO - __main__ - Starting the offline evaluation of 45
07/15/2021 16:55:14 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/15/2021 16:55:14 - INFO - __main__ - Starting the offline evaluation of 18
07/15/2021 16:55:14 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base .....
07/15/2021 16:55:14 - INFO - __main__ - Starting the offline evaluation of 4
07/15/2021 16:55:14 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base .....
07/15/2021 16:55:14 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:14 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:14 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:15 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:15 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:15 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:15 - INFO - __main__ - Starting the offline evaluation of 36
07/15/2021 16:55:15 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base .....
07/15/2021 16:55:15 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:15 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:15 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:16 - INFO - __main__ - Starting the offline evaluation of 8
07/15/2021 16:55:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base .....
07/15/2021 16:55:16 - INFO - __main__ - Starting the offline evaluation of 12
07/15/2021 16:55:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base .....
07/15/2021 16:55:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:16 - INFO - __main__ - Starting the offline evaluation of 27
07/15/2021 16:55:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/15/2021 16:55:17 - INFO - __main__ - Starting the offline evaluation of 33
07/15/2021 16:55:17 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/15/2021 16:55:17 - INFO - __main__ - Starting the offline evaluation of 42
07/15/2021 16:55:17 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base .....
07/15/2021 16:55:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:18 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:18 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:18 - INFO - __main__ - Debugger Setup ...... Done!
ention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:18 - INFO - __main__ - Starting the offline evaluation of 24
07/15/2021 16:55:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base .....
07/15/2021 16:55:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:18 - INFO - __main__ - Starting the offline evaluation of 39
07/15/2021 16:55:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/15/2021 16:55:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:24 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:25 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:27 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:28 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:29 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_000.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:29 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:31 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:31 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:31 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:36 - INFO - __main__ - Start the Overall Forgetting Results (Knowledge Retain Acc)....Done
07/15/2021 16:55:36 - INFO - __main__ - Start Error-Fixing performance on the Current batch of errors.....
07/15/2021 16:55:37 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:37 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:37 - INFO - __main__ - Debugger Setup ...... Done!
ain__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base ..... Done!
07/15/2021 16:55:38 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:38 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:38 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:38 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:38 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:38 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:39 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:39 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:39 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:39 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:39 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:39 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:39 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:39 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:39 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:40 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:40 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:40 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:40 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:40 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:40 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:40 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:40 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:40 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:40 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:41 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:41 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:41 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:41 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:41 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:41 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:41 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:41 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:41 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:41 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:41 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:41 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:41 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:41 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:41 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:42 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:42 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:42 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:42 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:42 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:42 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:42 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:42 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:42 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:42 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:42 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:42 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:42 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:43 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:43 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:43 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:43 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:43 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:43 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:43 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:43 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:43 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:43 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:43 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:43 - INFO - __main__ - Moving to the GPUs.
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:55:43 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:55:43 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:55:43 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:55:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:55:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:55:49 - INFO - __main__ - Finished.
07/15/2021 16:55:49 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:49 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:49 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:49 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:55:51 - INFO - __main__ - Finished.
07/15/2021 16:55:51 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:51 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:55:53 - INFO - __main__ - Finished.
07/15/2021 16:55:54 - INFO - __main__ - Loa07/15/2021 16:55:59 - INFO - __main__ - Start Error-Fixing performance on the Next batch of errors.....Done
07/15/2021 16:55:59 - INFO - __main__ - Starting the offline evaluation of 3
07/15/2021 16:55:59 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/model_ckpt_003.pt for facebook/bart-base .....
 - Finished.
07/15/2021 16:55:54 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:54 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:55:56 - INFO - __main__ - Finished.
07/15/2021 16:55:56 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:56 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:56 - INFO - __main__ - Finished.
07/15/2021 16:55:56 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:56 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:55:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:55:56 - INFO - __main__ - Finished.
07/15/2021 16:55:56 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:55:56 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:55:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:55:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:06 - INFO - __main__ - Finished.
07/15/2021 16:56:06 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:06 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:06 - INFO - __main__ - Finished.
07/15/2021 16:56:06 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:06 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:06 - INFO - __main__ - Encoding the examples to evaluate...
"decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:56:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:56:09 - INFO - __main__ - Finished.
07/15/2021 16:56:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:09 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:09 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:09 - INFO - __main__ - Finished.
07/15/2021 16:56:09 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:09 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:09 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:09 - INFO - __main__ - Encoding the examples to evaluate...
lse, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:56:05 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 16:56:05 - INFO - __main__ - Starting to load the key encoder (facebook/bart-base) for the memory module.
07/15/2021 16:56:05 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.
07/15/2021 16:56:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/15/2021 16:56:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/15/2021 16:56:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None
07/15/2021 16:56:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None
07/15/2021 16:56:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None
07/15/2021 16:56:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/15/2021 16:56:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/15/2021 16:56:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/15/2021 16:56:12 - INFO - __main__ - Finished.
07/15/2021 16:56:12 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:12 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:13 - INFO - __main__ - Finished.
07/15/2021 16:56:13 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:13 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:13 - INFO - __main__ - Finished.
07/15/2021 16:56:13 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:13 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:16 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:17 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:56:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:20 - INFO - __main__ - Finished.
07/15/2021 16:56:20 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:20 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:30 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:30 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:41 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:56:41 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:56:41 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:40 - INFO - __main__ - Finished.
07/15/2021 16:56:40 - INFO - __main__ - Loading the memory from bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl
07/15/2021 16:56:40 - INFO - __main__ - Start the Overall Error-Fixing Results....
07/15/2021 16:56:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:44 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:49 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:49 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:56:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:56:51 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:56:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:56:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:56:59 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:56:59 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:56:59 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     07/15/2021 16:57:16 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:57:16 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:57:16 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               07/15/2021 16:57:32 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:57:32 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:57:32 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:33 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:34 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:34 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:36 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:36 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:37 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:37 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:49 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:57:49 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:57:49 - INFO - __main__ - Debugger07/15/2021 16:57:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:57:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:57:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:57:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:57:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:05 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 16:58:06 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:58:06 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:58:06 - INFO - __main__ - Debugger Setup ...... Done!
o get the KNN examples for local adaptation...
07/15/2021 16:58:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:09 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:09 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:09 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:09 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:16 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:16 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:58:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:58:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:58:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:58:24 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:58:24 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:58:24 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    07/15/2021 16:58:41 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:58:41 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:58:41 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 07/15/2021 16:58:58 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:58:58 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:58:58 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   07/15/2021 16:59:15 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:59:15 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:59:15 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:24 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:30 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:33 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:59:33 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:59:33 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:34 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:39 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:39 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 16:59:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 16:59:47 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 16:59:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 16:59:50 - INFO - __main__ - Debugger Setup ......
07/15/2021 16:59:50 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 16:59:50 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                07/15/2021 17:00:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 17:00:08 - INFO - __main__ - Debugger Setup ...... Done!
07/15/2021 17:00:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:15 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:00:15 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:15 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:16 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:24 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:26 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:00:26 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_deca07/15/2021 17:00:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:35 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:44 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:00:44 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e07/15/2021 17:00:46 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:47 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:53 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:54 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:00:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:00:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:00:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:00:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:02 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:01:02 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 17:01:02 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:03 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:03 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:18 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:01:18 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_di07/15/2021 17:01:24 - INFO - _, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 17:01:18 - INFO - __main__ - Debugger Setup ...... Done!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          07/15/2021 17:01:35 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:01:35 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/', replay_frequency=1, replay_size=16, save_all_ckpts=0, total_steps=10000, use_sampled_upstream=False, warmup_steps=0, weight_decay=0.01) ......
07/15/2021 17:01:35 - INFO - __main__ - Debugger Setup ...... Done!
- INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:38 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:01:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:39 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:39 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:45 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:52 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:01:52 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e5_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=1, num_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0714_mbpapp_rsz32_rf30_3e-5_e07/15/2021 17:01:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:01:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:01:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:01:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:01:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:03 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:03 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:10 - INFO - __main__ - Debugger Setup ......
07/15/2021 17:02:10 - INFO - __main__ - debugger_args: Namespace(adam_epsilon07/15/2021 17:02:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:15 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:15 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:25 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:02:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:36 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:37 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:37 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:48 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:54 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:02:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:02:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:02:57 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:02:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:02 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:02 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:06 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:07 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:07 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:09 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:09 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:09 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:03:10 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:26 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:32 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:34 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:34 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:36 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:36 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:51 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:03:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:03:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:03:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:03:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:03:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:03 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:03 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:04 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:11 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:16 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:27 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:04:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:31 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:32 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:34 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:34 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:35 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:35 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:44 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:44 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:47 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:47 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:04:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:04:57 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:57 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:58 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:04:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:04:59 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:05:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:02 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:02 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:10 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:23 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:23 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:33 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:37 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:37 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:43 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:05:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:48 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:57 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:05:58 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:05:58 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:05:58 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:05:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:05 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:05 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:09 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:11 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:16 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:16 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:24 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:24 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:06:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:35 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:35 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:45 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:45 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:47 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:47 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:48 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:48 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:48 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:48 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:48 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:48 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:06:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:06:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:06:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:06:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:02 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:02 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:03 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:07:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:09 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:23 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:23 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:33 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:33 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:36 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:36 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:39 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:07:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:54 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:57 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:07:57 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:07:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:59 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:59 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:07:59 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:07:59 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:05 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:09 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:10 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:11 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:11 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:11 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:11 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:08:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:16 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:16 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:34 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:34 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:47 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:47 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:47 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:08:51 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:08:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:08:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:08:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:08:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:04 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:06 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:07 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:07 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:16 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:16 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:23 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:23 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:35 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:35 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:09:36 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:36 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:37 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:37 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:39 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:39 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:48 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:49 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:49 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:09:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:09:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:09:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:09:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:04 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:04 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:05 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:11 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:11 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:18 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:10:20 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:23 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:23 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:43 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:43 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:47 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:47 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:48 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:53 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:10:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:10:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:10:58 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:10:58 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:02 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:02 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:02 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:04 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:05 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:11:06 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:07 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:07 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:10 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:16 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:17 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:17 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:28 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:28 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:30 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:30 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:31 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:36 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:36 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:41 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:11:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:44 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:44 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:48 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:48 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:48 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:48 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:49 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:11:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:11:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:11:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:11:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:02 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:13 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:16 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:16 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:18 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:18 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:18 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:23 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:26 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:12:26 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:26 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:33 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:35 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:35 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:36 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:42 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:42 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:46 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:47 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:47 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:49 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:50 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:51 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:51 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:52 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:52 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:53 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:53 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:54 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:54 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:55 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:55 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:56 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:56 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:56 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:56 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:12:57 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:12:58 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:12:58 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:58 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:12:58 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:12:58 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:04 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:04 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:06 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:09 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:11 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:11 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:15 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:15 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:18 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:19 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:21 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:21 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:23 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:23 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:25 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:25 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:28 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:32 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:33 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:33 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:33 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:33 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:13:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:36 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:36 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:36 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:36 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:37 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:37 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:38 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:38 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:40 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:41 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:41 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:46 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:47 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:48 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:48 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:53 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:57 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:57 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:13:57 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:13:57 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:13:59 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:13:59 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:00 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:00 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:03 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:03 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:05 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:06 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:06 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:06 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:06 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:07 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:07 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:07 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:14:08 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:08 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:10 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:10 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:12 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:12 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:12 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:12 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:13 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:13 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:13 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:19 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:19 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:22 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:22 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:26 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:27 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:27 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:28 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:29 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:29 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:30 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:30 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:31 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:31 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:32 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:33 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:33 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:33 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:35 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:35 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:37 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:37 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:38 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:38 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:42 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:42 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:43 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:43 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:44 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:44 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:45 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:45 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:14:45 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:45 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:46 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:47 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:47 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:49 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:49 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:50 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:50 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:50 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:51 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:51 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:52 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:52 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:53 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:14:53 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:14:54 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:54 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:14:55 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:14:55 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:00 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:00 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:01 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:01 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:01 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:01 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:05 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:05 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:08 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:08 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:10 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:10 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:14 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:14 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:14 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:14 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:15 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:15 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:15 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:15 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:16 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:16 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:17 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:17 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:19 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:20 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:20 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:20 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:21 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:21 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:22 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:22 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:23 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:23 - INFO - __main__ - Retrieved 300 examples from memory; 15.0 examples per key.
07/15/2021 17:15:24 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:24 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:24 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:24 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:24 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:25 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:25 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:26 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:27 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:27 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:28 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:28 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:29 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:29 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:30 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:30 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:31 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:31 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:32 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:32 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:39 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:39 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:40 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:40 - INFO - __main__ - Encoding the examples to evaluate...
07/15/2021 17:15:40 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:41 - INFO - __main__ - Reading memory to get the KNN examples for local adaptation...
07/15/2021 17:15:41 - INFO - __main__ - Retrieved 320 examples from memory; 16.0 examples per key.
07/15/2021 17:15:46 - INFO - __main__ - Memory Retrieving ...
07/15/2021 17:15:46 - INFO - __main__ - Encoding the examples to evaluate...
