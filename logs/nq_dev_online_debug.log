06/24/2021 14:56:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
06/24/2021 14:56:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
06/24/2021 14:56:36 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
06/24/2021 14:56:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
06/24/2021 14:56:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

06/24/2021 14:56:37 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
06/24/2021 14:56:41 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
06/24/2021 14:56:45 - INFO - __main__ - Moving to the GPUs.
06/24/2021 14:56:45 - INFO - __main__ - Debugger Setup ......
06/24/2021 14:56:45 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
06/24/2021 14:56:45 - INFO - __main__ - Debugger Setup ...... Done!
06/24/2021 14:56:45 - INFO - __main__ - Start Online Debugging
06/24/2021 14:56:45 - INFO - __main__ - Number of Batches of Bugs: 50
06/24/2021 14:56:45 - INFO - __main__ - Bug Batch Size: 20
06/24/2021 14:56:48 - INFO - __main__ - ----------Timecode: 0----------
06/24/2021 14:56:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-0 = {'EM': 0.0, 'QA-F1': 0.4711170762317054}
06/24/2021 14:56:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 1.0, 'QA-F1': 1.0}
06/24/2021 14:56:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:57:00 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:57:03 - INFO - __main__ - After Bug-fixing the results on bug-batch-0 = {'EM': 0.3, 'QA-F1': 0.6614275007632253}
06/24/2021 14:57:11 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9778645833333333}
06/24/2021 14:57:11 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 10
06/24/2021 14:57:11 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 6
06/24/2021 14:57:11 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 14:57:14 - INFO - __main__ - ----------Timecode: 1----------
06/24/2021 14:57:14 - INFO - __main__ - Before Bug-fixing the results on bug-batch-1 = {'EM': 0.05, 'QA-F1': 0.46715623981753013}
06/24/2021 14:57:14 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9778645833333333}
06/24/2021 14:57:14 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:57:15 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:57:19 - INFO - __main__ - After Bug-fixing the results on bug-batch-1 = {'EM': 0.2, 'QA-F1': 0.5656889269371737}
06/24/2021 14:57:25 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.99609375}
06/24/2021 14:57:25 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 14:57:25 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 14:57:25 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 14:57:29 - INFO - __main__ - ----------Timecode: 2----------
06/24/2021 14:57:29 - INFO - __main__ - Before Bug-fixing the results on bug-batch-2 = {'EM': 0.0, 'QA-F1': 0.4602006688963211}
06/24/2021 14:57:29 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.99609375}
06/24/2021 14:57:29 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:57:31 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:57:35 - INFO - __main__ - After Bug-fixing the results on bug-batch-2 = {'EM': 0.25, 'QA-F1': 0.5666666666666667}
06/24/2021 14:57:40 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 1.0, 'QA-F1': 1.0}
06/24/2021 14:57:40 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 5
06/24/2021 14:57:40 - INFO - __main__ - Number of em_fixed_bugs = 5; Number of f1_fixed_bugs = 5
06/24/2021 14:57:40 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 14:57:43 - INFO - __main__ - ----------Timecode: 3----------
06/24/2021 14:57:43 - INFO - __main__ - Before Bug-fixing the results on bug-batch-3 = {'EM': 0.15, 'QA-F1': 0.502196523918492}
06/24/2021 14:57:43 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 1.0, 'QA-F1': 1.0}
06/24/2021 14:57:43 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:57:45 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:57:48 - INFO - __main__ - After Bug-fixing the results on bug-batch-3 = {'EM': 0.3, 'QA-F1': 0.5756226568183089}
06/24/2021 14:57:55 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.99609375}
06/24/2021 14:57:55 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 14:57:55 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 14:57:55 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 14:57:57 - INFO - __main__ - ----------Timecode: 4----------
06/24/2021 14:57:57 - INFO - __main__ - Before Bug-fixing the results on bug-batch-4 = {'EM': 0.05, 'QA-F1': 0.44109910961903387}
06/24/2021 14:57:57 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.99609375}
06/24/2021 14:57:57 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:57:59 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:58:02 - INFO - __main__ - After Bug-fixing the results on bug-batch-4 = {'EM': 0.2, 'QA-F1': 0.5406837606837608}
06/24/2021 14:58:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9841889880952381}
06/24/2021 14:58:10 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 14:58:10 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 2
06/24/2021 14:58:10 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 14:58:12 - INFO - __main__ - ----------Timecode: 5----------
06/24/2021 14:58:12 - INFO - __main__ - Before Bug-fixing the results on bug-batch-5 = {'EM': 0.0, 'QA-F1': 0.4211111111111111}
06/24/2021 14:58:12 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9841889880952381}
06/24/2021 14:58:12 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:58:14 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:58:16 - INFO - __main__ - After Bug-fixing the results on bug-batch-5 = {'EM': 0.1, 'QA-F1': 0.4332367149758454}
06/24/2021 14:58:23 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.965723079004329}
06/24/2021 14:58:23 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 2
06/24/2021 14:58:23 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 14:58:23 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 14:58:26 - INFO - __main__ - ----------Timecode: 6----------
06/24/2021 14:58:26 - INFO - __main__ - Before Bug-fixing the results on bug-batch-6 = {'EM': 0.15, 'QA-F1': 0.4889897432787926}
06/24/2021 14:58:26 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.965723079004329}
06/24/2021 14:58:26 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:58:27 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:58:30 - INFO - __main__ - After Bug-fixing the results on bug-batch-6 = {'EM': 0.35, 'QA-F1': 0.622742673992674}
06/24/2021 14:58:36 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9776278409090909}
06/24/2021 14:58:36 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 8
06/24/2021 14:58:36 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 4
06/24/2021 14:58:36 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 14:58:39 - INFO - __main__ - ----------Timecode: 7----------
06/24/2021 14:58:39 - INFO - __main__ - Before Bug-fixing the results on bug-batch-7 = {'EM': 0.1, 'QA-F1': 0.4337121212121212}
06/24/2021 14:58:39 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9776278409090909}
06/24/2021 14:58:39 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:58:42 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:58:45 - INFO - __main__ - After Bug-fixing the results on bug-batch-7 = {'EM': 0.05, 'QA-F1': 0.39132326007326}
06/24/2021 14:58:52 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.9688137383449884}
06/24/2021 14:58:52 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 3
06/24/2021 14:58:52 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 14:58:52 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 14:58:56 - INFO - __main__ - ----------Timecode: 8----------
06/24/2021 14:58:56 - INFO - __main__ - Before Bug-fixing the results on bug-batch-8 = {'EM': 0.05, 'QA-F1': 0.3323749277981702}
06/24/2021 14:58:56 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.9688137383449884}
06/24/2021 14:58:56 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:58:58 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:59:02 - INFO - __main__ - After Bug-fixing the results on bug-batch-8 = {'EM': 0.1, 'QA-F1': 0.4165640421791005}
06/24/2021 14:59:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9412839764402265}
06/24/2021 14:59:10 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 14:59:10 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 14:59:10 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 14:59:13 - INFO - __main__ - ----------Timecode: 9----------
06/24/2021 14:59:13 - INFO - __main__ - Before Bug-fixing the results on bug-batch-9 = {'EM': 0.1, 'QA-F1': 0.4711539791122369}
06/24/2021 14:59:13 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9412839764402265}
06/24/2021 14:59:13 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:59:15 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:59:18 - INFO - __main__ - After Bug-fixing the results on bug-batch-9 = {'EM': 0.3, 'QA-F1': 0.5748111990852462}
06/24/2021 14:59:25 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.904230405011655}
06/24/2021 14:59:25 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 8
06/24/2021 14:59:25 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 3
06/24/2021 14:59:25 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 14:59:29 - INFO - __main__ - ----------Timecode: 10----------
06/24/2021 14:59:29 - INFO - __main__ - Before Bug-fixing the results on bug-batch-10 = {'EM': 0.05, 'QA-F1': 0.37619556221933137}
06/24/2021 14:59:29 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.904230405011655}
06/24/2021 14:59:29 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:59:30 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:59:34 - INFO - __main__ - After Bug-fixing the results on bug-batch-10 = {'EM': 0.2, 'QA-F1': 0.46550375939849625}
06/24/2021 14:59:42 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8783890588578088}
06/24/2021 14:59:42 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 14:59:42 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 14:59:42 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 14:59:45 - INFO - __main__ - ----------Timecode: 11----------
06/24/2021 14:59:45 - INFO - __main__ - Before Bug-fixing the results on bug-batch-11 = {'EM': 0.05, 'QA-F1': 0.40692263028426023}
06/24/2021 14:59:45 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8783890588578088}
06/24/2021 14:59:45 - INFO - __main__ - Start bug-fixing ....
06/24/2021 14:59:47 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 14:59:50 - INFO - __main__ - After Bug-fixing the results on bug-batch-11 = {'EM': 0.15, 'QA-F1': 0.4802128269297201}
06/24/2021 14:59:58 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8318617250982181}
06/24/2021 14:59:58 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 14:59:58 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 14:59:58 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 15:00:02 - INFO - __main__ - ----------Timecode: 12----------
06/24/2021 15:00:02 - INFO - __main__ - Before Bug-fixing the results on bug-batch-12 = {'EM': 0.15, 'QA-F1': 0.4710139479132615}
06/24/2021 15:00:02 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8318617250982181}
06/24/2021 15:00:02 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:00:03 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:00:07 - INFO - __main__ - After Bug-fixing the results on bug-batch-12 = {'EM': 0.3, 'QA-F1': 0.5764418097927362}
06/24/2021 15:00:17 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.65625, 'QA-F1': 0.8039504003118932}
06/24/2021 15:00:17 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 10
06/24/2021 15:00:17 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 15:00:17 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 15:00:20 - INFO - __main__ - ----------Timecode: 13----------
06/24/2021 15:00:20 - INFO - __main__ - Before Bug-fixing the results on bug-batch-13 = {'EM': 0.2, 'QA-F1': 0.4756169693852568}
06/24/2021 15:00:20 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.65625, 'QA-F1': 0.8039504003118932}
06/24/2021 15:00:20 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:00:22 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:00:26 - INFO - __main__ - After Bug-fixing the results on bug-batch-13 = {'EM': 0.15, 'QA-F1': 0.4826335907567169}
06/24/2021 15:00:34 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.625, 'QA-F1': 0.7816289717404648}
06/24/2021 15:00:34 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 7
06/24/2021 15:00:34 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:00:34 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 15:00:37 - INFO - __main__ - ----------Timecode: 14----------
06/24/2021 15:00:37 - INFO - __main__ - Before Bug-fixing the results on bug-batch-14 = {'EM': 0.0, 'QA-F1': 0.29140699714229124}
06/24/2021 15:00:37 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.625, 'QA-F1': 0.7816289717404648}
06/24/2021 15:00:37 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:00:39 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:00:42 - INFO - __main__ - After Bug-fixing the results on bug-batch-14 = {'EM': 0.0, 'QA-F1': 0.3086239283592224}
06/24/2021 15:00:50 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.6875, 'QA-F1': 0.8179421989544272}
06/24/2021 15:00:50 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 2
06/24/2021 15:00:50 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 15:00:50 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:00:53 - INFO - __main__ - ----------Timecode: 15----------
06/24/2021 15:00:53 - INFO - __main__ - Before Bug-fixing the results on bug-batch-15 = {'EM': 0.05, 'QA-F1': 0.33427272388101575}
06/24/2021 15:00:53 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.6875, 'QA-F1': 0.8179421989544272}
06/24/2021 15:00:53 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:00:55 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:00:58 - INFO - __main__ - After Bug-fixing the results on bug-batch-15 = {'EM': 0.05, 'QA-F1': 0.3249555704462152}
06/24/2021 15:01:06 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8465880322877606}
06/24/2021 15:01:06 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 15:01:06 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:01:06 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:01:10 - INFO - __main__ - ----------Timecode: 16----------
06/24/2021 15:01:10 - INFO - __main__ - Before Bug-fixing the results on bug-batch-16 = {'EM': 0.1, 'QA-F1': 0.3364405531546967}
06/24/2021 15:01:10 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8465880322877606}
06/24/2021 15:01:10 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:01:11 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:01:14 - INFO - __main__ - After Bug-fixing the results on bug-batch-16 = {'EM': 0.3, 'QA-F1': 0.5360713063568785}
06/24/2021 15:01:21 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8540090985403486}
06/24/2021 15:01:21 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 10
06/24/2021 15:01:21 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 5
06/24/2021 15:01:21 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:01:25 - INFO - __main__ - ----------Timecode: 17----------
06/24/2021 15:01:25 - INFO - __main__ - Before Bug-fixing the results on bug-batch-17 = {'EM': 0.05, 'QA-F1': 0.293570118760696}
06/24/2021 15:01:25 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8540090985403486}
06/24/2021 15:01:25 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:01:27 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:01:30 - INFO - __main__ - After Bug-fixing the results on bug-batch-17 = {'EM': 0.1, 'QA-F1': 0.3480456432362205}
06/24/2021 15:01:38 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.842922789016539}
06/24/2021 15:01:38 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 15:01:38 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 15:01:38 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:01:41 - INFO - __main__ - ----------Timecode: 18----------
06/24/2021 15:01:41 - INFO - __main__ - Before Bug-fixing the results on bug-batch-18 = {'EM': 0.1, 'QA-F1': 0.3326382385730212}
06/24/2021 15:01:41 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.842922789016539}
06/24/2021 15:01:41 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:01:43 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:01:47 - INFO - __main__ - After Bug-fixing the results on bug-batch-18 = {'EM': 0.1, 'QA-F1': 0.33703752556054345}
06/24/2021 15:01:54 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8392769556832057}
06/24/2021 15:01:54 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 4
06/24/2021 15:01:54 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:01:54 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:01:58 - INFO - __main__ - ----------Timecode: 19----------
06/24/2021 15:01:58 - INFO - __main__ - Before Bug-fixing the results on bug-batch-19 = {'EM': 0.05, 'QA-F1': 0.23725450012950017}
06/24/2021 15:01:58 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8392769556832057}
06/24/2021 15:01:58 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:01:59 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:02:03 - INFO - __main__ - After Bug-fixing the results on bug-batch-19 = {'EM': 0.1, 'QA-F1': 0.32735473322973324}
06/24/2021 15:02:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.885110289016539}
06/24/2021 15:02:10 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 15:02:10 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 15:02:10 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:02:13 - INFO - __main__ - ----------Timecode: 20----------
06/24/2021 15:02:13 - INFO - __main__ - Before Bug-fixing the results on bug-batch-20 = {'EM': 0.0, 'QA-F1': 0.12979872694829458}
06/24/2021 15:02:13 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.885110289016539}
06/24/2021 15:02:13 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:02:15 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:02:18 - INFO - __main__ - After Bug-fixing the results on bug-batch-20 = {'EM': 0.15, 'QA-F1': 0.28578245284127635}
06/24/2021 15:02:25 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.914202550921301}
06/24/2021 15:02:25 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 4
06/24/2021 15:02:25 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 15:02:25 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:02:28 - INFO - __main__ - ----------Timecode: 21----------
06/24/2021 15:02:28 - INFO - __main__ - Before Bug-fixing the results on bug-batch-21 = {'EM': 0.05, 'QA-F1': 0.26998140146221344}
06/24/2021 15:02:28 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.914202550921301}
06/24/2021 15:02:28 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:02:30 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:02:34 - INFO - __main__ - After Bug-fixing the results on bug-batch-21 = {'EM': 0.2, 'QA-F1': 0.39012029035110235}
06/24/2021 15:02:40 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9833369755244756}
06/24/2021 15:02:40 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 15:02:40 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 3
06/24/2021 15:02:40 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:02:44 - INFO - __main__ - ----------Timecode: 22----------
06/24/2021 15:02:44 - INFO - __main__ - Before Bug-fixing the results on bug-batch-22 = {'EM': 0.15, 'QA-F1': 0.3651637769936051}
06/24/2021 15:02:44 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9833369755244756}
06/24/2021 15:02:44 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:02:45 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:02:49 - INFO - __main__ - After Bug-fixing the results on bug-batch-22 = {'EM': 0.2, 'QA-F1': 0.3643941445792358}
06/24/2021 15:02:56 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9370200112387612}
06/24/2021 15:02:56 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 6
06/24/2021 15:02:56 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 15:02:56 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 15:03:00 - INFO - __main__ - ----------Timecode: 23----------
06/24/2021 15:03:00 - INFO - __main__ - Before Bug-fixing the results on bug-batch-23 = {'EM': 0.0, 'QA-F1': 0.08264896354598872}
06/24/2021 15:03:00 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9370200112387612}
06/24/2021 15:03:00 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:03:01 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:03:05 - INFO - __main__ - After Bug-fixing the results on bug-batch-23 = {'EM': 0.05, 'QA-F1': 0.23095723422268044}
06/24/2021 15:03:13 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.9179227890165391}
06/24/2021 15:03:13 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 4
06/24/2021 15:03:13 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 4
06/24/2021 15:03:13 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 15:03:16 - INFO - __main__ - ----------Timecode: 24----------
06/24/2021 15:03:16 - INFO - __main__ - Before Bug-fixing the results on bug-batch-24 = {'EM': 0.0, 'QA-F1': 0.13504943727769816}
06/24/2021 15:03:16 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.9179227890165391}
06/24/2021 15:03:16 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:03:17 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:03:21 - INFO - __main__ - After Bug-fixing the results on bug-batch-24 = {'EM': 0.1, 'QA-F1': 0.22984168654575385}
06/24/2021 15:03:29 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.881224071067821}
06/24/2021 15:03:29 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 3
06/24/2021 15:03:29 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 15:03:29 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 15:03:33 - INFO - __main__ - ----------Timecode: 25----------
06/24/2021 15:03:33 - INFO - __main__ - Before Bug-fixing the results on bug-batch-25 = {'EM': 0.05, 'QA-F1': 0.329881377529544}
06/24/2021 15:03:33 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.881224071067821}
06/24/2021 15:03:33 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:03:35 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:03:38 - INFO - __main__ - After Bug-fixing the results on bug-batch-25 = {'EM': 0.1, 'QA-F1': 0.3768596401663815}
06/24/2021 15:03:46 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.877317821067821}
06/24/2021 15:03:46 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 8
06/24/2021 15:03:46 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 15:03:46 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:03:51 - INFO - __main__ - ----------Timecode: 26----------
06/24/2021 15:03:51 - INFO - __main__ - Before Bug-fixing the results on bug-batch-26 = {'EM': 0.15, 'QA-F1': 0.15854545454545454}
06/24/2021 15:03:51 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.877317821067821}
06/24/2021 15:03:51 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:03:53 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:03:57 - INFO - __main__ - After Bug-fixing the results on bug-batch-26 = {'EM': 0.15, 'QA-F1': 0.15899999999999997}
06/24/2021 15:04:05 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8945453851703851}
06/24/2021 15:04:05 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 3
06/24/2021 15:04:05 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:04:05 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:04:08 - INFO - __main__ - ----------Timecode: 27----------
06/24/2021 15:04:08 - INFO - __main__ - Before Bug-fixing the results on bug-batch-27 = {'EM': 0.15, 'QA-F1': 0.20535714285714285}
06/24/2021 15:04:08 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8945453851703851}
06/24/2021 15:04:08 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:04:10 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:04:12 - INFO - __main__ - After Bug-fixing the results on bug-batch-27 = {'EM': 0.25, 'QA-F1': 0.2958333333333333}
06/24/2021 15:04:19 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.9036599685037184}
06/24/2021 15:04:19 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 5
06/24/2021 15:04:19 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 1
06/24/2021 15:04:19 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:04:22 - INFO - __main__ - ----------Timecode: 28----------
06/24/2021 15:04:22 - INFO - __main__ - Before Bug-fixing the results on bug-batch-28 = {'EM': 0.1, 'QA-F1': 0.13923001949317737}
06/24/2021 15:04:22 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.9036599685037184}
06/24/2021 15:04:22 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:04:24 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:04:27 - INFO - __main__ - After Bug-fixing the results on bug-batch-28 = {'EM': 0.15, 'QA-F1': 0.18227513227513228}
06/24/2021 15:04:34 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9316113573926075}
06/24/2021 15:04:34 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 4
06/24/2021 15:04:34 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 15:04:34 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 15:04:38 - INFO - __main__ - ----------Timecode: 29----------
06/24/2021 15:04:38 - INFO - __main__ - Before Bug-fixing the results on bug-batch-29 = {'EM': 0.05, 'QA-F1': 0.06538461538461539}
06/24/2021 15:04:38 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9316113573926075}
06/24/2021 15:04:38 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:04:40 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:04:44 - INFO - __main__ - After Bug-fixing the results on bug-batch-29 = {'EM': 0.15, 'QA-F1': 0.1733846153846154}
06/24/2021 15:04:51 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.926403024059274}
06/24/2021 15:04:51 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 15:04:51 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 15:04:51 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:04:55 - INFO - __main__ - ----------Timecode: 30----------
06/24/2021 15:04:55 - INFO - __main__ - Before Bug-fixing the results on bug-batch-30 = {'EM': 0.05, 'QA-F1': 0.075}
06/24/2021 15:04:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.926403024059274}
06/24/2021 15:04:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:04:57 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:05:00 - INFO - __main__ - After Bug-fixing the results on bug-batch-30 = {'EM': 0.1, 'QA-F1': 0.15833333333333333}
06/24/2021 15:05:07 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9278234786047286}
06/24/2021 15:05:07 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 15:05:07 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 15:05:07 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:05:10 - INFO - __main__ - ----------Timecode: 31----------
06/24/2021 15:05:10 - INFO - __main__ - Before Bug-fixing the results on bug-batch-31 = {'EM': 0.15, 'QA-F1': 0.15}
06/24/2021 15:05:10 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9278234786047286}
06/24/2021 15:05:10 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:05:13 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:05:17 - INFO - __main__ - After Bug-fixing the results on bug-batch-31 = {'EM': 0.35, 'QA-F1': 0.36818181818181817}
06/24/2021 15:05:23 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9440104166666666}
06/24/2021 15:05:23 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 15:05:23 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 4
06/24/2021 15:05:23 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:05:27 - INFO - __main__ - ----------Timecode: 32----------
06/24/2021 15:05:27 - INFO - __main__ - Before Bug-fixing the results on bug-batch-32 = {'EM': 0.25, 'QA-F1': 0.29087301587301584}
06/24/2021 15:05:27 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9440104166666666}
06/24/2021 15:05:27 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:05:29 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:05:31 - INFO - __main__ - After Bug-fixing the results on bug-batch-32 = {'EM': 0.3, 'QA-F1': 0.3825396825396825}
06/24/2021 15:05:38 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9738399621212122}
06/24/2021 15:05:38 - INFO - __main__ - Number of em_prefixed_bugs = 5; Number of f1_prefixed_bugs = 8
06/24/2021 15:05:38 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 15:05:38 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:05:40 - INFO - __main__ - ----------Timecode: 33----------
06/24/2021 15:05:40 - INFO - __main__ - Before Bug-fixing the results on bug-batch-33 = {'EM': 0.1, 'QA-F1': 0.15833333333333333}
06/24/2021 15:05:40 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9738399621212122}
06/24/2021 15:05:40 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:05:42 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:05:44 - INFO - __main__ - After Bug-fixing the results on bug-batch-33 = {'EM': 0.25, 'QA-F1': 0.3083333333333333}
06/24/2021 15:05:51 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9678303467365967}
06/24/2021 15:05:51 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 6
06/24/2021 15:05:51 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 15:05:51 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:05:54 - INFO - __main__ - ----------Timecode: 34----------
06/24/2021 15:05:54 - INFO - __main__ - Before Bug-fixing the results on bug-batch-34 = {'EM': 0.15, 'QA-F1': 0.19}
06/24/2021 15:05:54 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9678303467365967}
06/24/2021 15:05:54 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:05:56 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:06:01 - INFO - __main__ - After Bug-fixing the results on bug-batch-34 = {'EM': 0.2, 'QA-F1': 0.2}
06/24/2021 15:06:07 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9738399621212122}
06/24/2021 15:06:07 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 4
06/24/2021 15:06:07 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 0
06/24/2021 15:06:07 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:06:11 - INFO - __main__ - ----------Timecode: 35----------
06/24/2021 15:06:11 - INFO - __main__ - Before Bug-fixing the results on bug-batch-35 = {'EM': 0.1, 'QA-F1': 0.218525641025641}
06/24/2021 15:06:11 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9738399621212122}
06/24/2021 15:06:11 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:06:14 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:06:17 - INFO - __main__ - After Bug-fixing the results on bug-batch-35 = {'EM': 0.15, 'QA-F1': 0.33277777777777773}
06/24/2021 15:06:24 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9524279250841751}
06/24/2021 15:06:24 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 8
06/24/2021 15:06:24 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 15:06:24 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 15:06:27 - INFO - __main__ - ----------Timecode: 36----------
06/24/2021 15:06:27 - INFO - __main__ - Before Bug-fixing the results on bug-batch-36 = {'EM': 0.15, 'QA-F1': 0.23125}
06/24/2021 15:06:27 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9524279250841751}
06/24/2021 15:06:27 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:06:30 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:06:33 - INFO - __main__ - After Bug-fixing the results on bug-batch-36 = {'EM': 0.2, 'QA-F1': 0.32398715415019763}
06/24/2021 15:06:40 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9211779250841751}
06/24/2021 15:06:40 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 15:06:40 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 15:06:40 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 15:06:43 - INFO - __main__ - ----------Timecode: 37----------
06/24/2021 15:06:43 - INFO - __main__ - Before Bug-fixing the results on bug-batch-37 = {'EM': 0.15, 'QA-F1': 0.22567226890756306}
06/24/2021 15:06:43 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9211779250841751}
06/24/2021 15:06:43 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:06:45 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:06:49 - INFO - __main__ - After Bug-fixing the results on bug-batch-37 = {'EM': 0.25, 'QA-F1': 0.3337218045112782}
06/24/2021 15:06:56 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8814051978114478}
06/24/2021 15:06:56 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 6
06/24/2021 15:06:56 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 15:06:56 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 15:06:59 - INFO - __main__ - ----------Timecode: 38----------
06/24/2021 15:06:59 - INFO - __main__ - Before Bug-fixing the results on bug-batch-38 = {'EM': 0.1, 'QA-F1': 0.12}
06/24/2021 15:06:59 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8814051978114478}
06/24/2021 15:06:59 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:07:02 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:07:06 - INFO - __main__ - After Bug-fixing the results on bug-batch-38 = {'EM': 0.2, 'QA-F1': 0.24857142857142858}
06/24/2021 15:07:13 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9189051978114477}
06/24/2021 15:07:13 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 5
06/24/2021 15:07:13 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 3
06/24/2021 15:07:13 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:07:16 - INFO - __main__ - ----------Timecode: 39----------
06/24/2021 15:07:16 - INFO - __main__ - Before Bug-fixing the results on bug-batch-39 = {'EM': 0.05, 'QA-F1': 0.13270609318996418}
06/24/2021 15:07:16 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9189051978114477}
06/24/2021 15:07:16 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:07:18 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:07:21 - INFO - __main__ - After Bug-fixing the results on bug-batch-39 = {'EM': 0.15, 'QA-F1': 0.267296113847838}
06/24/2021 15:07:28 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9178635311447811}
06/24/2021 15:07:28 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 15:07:28 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 15:07:28 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:07:32 - INFO - __main__ - ----------Timecode: 40----------
06/24/2021 15:07:32 - INFO - __main__ - Before Bug-fixing the results on bug-batch-40 = {'EM': 0.0, 'QA-F1': 0.005555555555555555}
06/24/2021 15:07:32 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9178635311447811}
06/24/2021 15:07:32 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:07:34 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:07:38 - INFO - __main__ - After Bug-fixing the results on bug-batch-40 = {'EM': 0.05, 'QA-F1': 0.13101010101010102}
06/24/2021 15:07:45 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9022385311447811}
06/24/2021 15:07:45 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 3
06/24/2021 15:07:45 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 15:07:45 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 15:07:48 - INFO - __main__ - ----------Timecode: 41----------
06/24/2021 15:07:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-41 = {'EM': 0.05, 'QA-F1': 0.11969696969696968}
06/24/2021 15:07:48 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9022385311447811}
06/24/2021 15:07:48 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:07:50 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:07:52 - INFO - __main__ - After Bug-fixing the results on bug-batch-41 = {'EM': 0.1, 'QA-F1': 0.2158508158508158}
06/24/2021 15:07:58 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8944260311447811}
06/24/2021 15:07:58 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 15:07:58 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 15:07:58 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:08:00 - INFO - __main__ - ----------Timecode: 42----------
06/24/2021 15:08:00 - INFO - __main__ - Before Bug-fixing the results on bug-batch-42 = {'EM': 0.05, 'QA-F1': 0.12785714285714284}
06/24/2021 15:08:00 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8944260311447811}
06/24/2021 15:08:00 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:08:02 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:08:05 - INFO - __main__ - After Bug-fixing the results on bug-batch-42 = {'EM': 0.25, 'QA-F1': 0.3964285714285714}
06/24/2021 15:08:11 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8981770833333333}
06/24/2021 15:08:11 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 9
06/24/2021 15:08:11 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 6
06/24/2021 15:08:11 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:08:14 - INFO - __main__ - ----------Timecode: 43----------
06/24/2021 15:08:14 - INFO - __main__ - Before Bug-fixing the results on bug-batch-43 = {'EM': 0.0, 'QA-F1': 0.005263157894736843}
06/24/2021 15:08:14 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8981770833333333}
06/24/2021 15:08:14 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:08:17 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:08:20 - INFO - __main__ - After Bug-fixing the results on bug-batch-43 = {'EM': 0.05, 'QA-F1': 0.05526315789473685}
06/24/2021 15:08:26 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8928503787878788}
06/24/2021 15:08:26 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 1
06/24/2021 15:08:26 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 15:08:26 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 15:08:29 - INFO - __main__ - ----------Timecode: 44----------
06/24/2021 15:08:29 - INFO - __main__ - Before Bug-fixing the results on bug-batch-44 = {'EM': 0.2, 'QA-F1': 0.22000000000000003}
06/24/2021 15:08:29 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8928503787878788}
06/24/2021 15:08:29 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:08:31 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:08:33 - INFO - __main__ - After Bug-fixing the results on bug-batch-44 = {'EM': 0.35, 'QA-F1': 0.4166666666666667}
06/24/2021 15:08:39 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9084753787878788}
06/24/2021 15:08:39 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 8
06/24/2021 15:08:39 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 15:08:39 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:08:42 - INFO - __main__ - ----------Timecode: 45----------
06/24/2021 15:08:42 - INFO - __main__ - Before Bug-fixing the results on bug-batch-45 = {'EM': 0.15, 'QA-F1': 0.17777777777777776}
06/24/2021 15:08:42 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9084753787878788}
06/24/2021 15:08:42 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:08:44 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:08:46 - INFO - __main__ - After Bug-fixing the results on bug-batch-45 = {'EM': 0.2, 'QA-F1': 0.22777777777777777}
06/24/2021 15:08:53 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9006628787878788}
06/24/2021 15:08:53 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 4
06/24/2021 15:08:53 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 15:08:53 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 15:08:55 - INFO - __main__ - ----------Timecode: 46----------
06/24/2021 15:08:55 - INFO - __main__ - Before Bug-fixing the results on bug-batch-46 = {'EM': 0.05, 'QA-F1': 0.05}
06/24/2021 15:08:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9006628787878788}
06/24/2021 15:08:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:08:58 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:09:01 - INFO - __main__ - After Bug-fixing the results on bug-batch-46 = {'EM': 0.05, 'QA-F1': 0.08333333333333333}
06/24/2021 15:09:08 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8758049242424242}
06/24/2021 15:09:08 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 2
06/24/2021 15:09:08 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 15:09:08 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 15:09:10 - INFO - __main__ - ----------Timecode: 47----------
06/24/2021 15:09:10 - INFO - __main__ - Before Bug-fixing the results on bug-batch-47 = {'EM': 0.1, 'QA-F1': 0.12692307692307692}
06/24/2021 15:09:10 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8758049242424242}
06/24/2021 15:09:10 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:09:12 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:09:15 - INFO - __main__ - After Bug-fixing the results on bug-batch-47 = {'EM': 0.05, 'QA-F1': 0.12406593406593407}
06/24/2021 15:09:23 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8508049242424243}
06/24/2021 15:09:23 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 3
06/24/2021 15:09:23 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:09:23 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 15:09:25 - INFO - __main__ - ----------Timecode: 48----------
06/24/2021 15:09:25 - INFO - __main__ - Before Bug-fixing the results on bug-batch-48 = {'EM': 0.0, 'QA-F1': 0.05711722488038277}
06/24/2021 15:09:25 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8508049242424243}
06/24/2021 15:09:25 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:09:27 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:09:30 - INFO - __main__ - After Bug-fixing the results on bug-batch-48 = {'EM': 0.0, 'QA-F1': 0.024617224880382774}
06/24/2021 15:09:37 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8664299242424243}
06/24/2021 15:09:37 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 0
06/24/2021 15:09:37 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 15:09:37 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 15:09:41 - INFO - __main__ - ----------Timecode: 49----------
06/24/2021 15:09:41 - INFO - __main__ - Before Bug-fixing the results on bug-batch-49 = {'EM': 0.1, 'QA-F1': 0.18503663003663}
06/24/2021 15:09:41 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8664299242424243}
06/24/2021 15:09:41 - INFO - __main__ - Start bug-fixing ....
06/24/2021 15:09:43 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 15:09:47 - INFO - __main__ - After Bug-fixing the results on bug-batch-49 = {'EM': 0.25, 'QA-F1': 0.3162750172532781}
06/24/2021 15:09:54 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8664299242424243}
06/24/2021 15:09:54 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 5
06/24/2021 15:09:54 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 2
06/24/2021 15:09:54 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:51:29 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
06/24/2021 21:51:29 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
06/24/2021 21:51:35 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
06/24/2021 21:51:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
06/24/2021 21:51:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

06/24/2021 21:51:37 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
06/24/2021 21:51:41 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
06/24/2021 21:51:45 - INFO - __main__ - Moving to the GPUs.
06/24/2021 21:51:45 - INFO - __main__ - Debugger Setup ......
06/24/2021 21:51:45 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
06/24/2021 21:51:45 - INFO - __main__ - Debugger Setup ...... Done!
06/24/2021 21:51:45 - INFO - __main__ - Start Online Debugging
06/24/2021 21:51:45 - INFO - __main__ - Number of Batches of Bugs: 50
06/24/2021 21:51:45 - INFO - __main__ - Bug Batch Size: 20
06/24/2021 21:51:48 - INFO - __main__ - ----------Timecode: 0----------
06/24/2021 21:51:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-0 = {'EM': 0.0, 'QA-F1': 0.4711170762317054}
06/24/2021 21:51:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 1.0, 'QA-F1': 1.0}
06/24/2021 21:51:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:52:00 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:52:03 - INFO - __main__ - After Bug-fixing the results on bug-batch-0 = {'EM': 0.3, 'QA-F1': 0.6614275007632253}
06/24/2021 21:52:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.96875, 'QA-F1': 0.9805194805194806}
06/24/2021 21:52:10 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 10
06/24/2021 21:52:10 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 6
06/24/2021 21:52:10 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:52:13 - INFO - __main__ - ----------Timecode: 1----------
06/24/2021 21:52:13 - INFO - __main__ - Before Bug-fixing the results on bug-batch-1 = {'EM': 0.05, 'QA-F1': 0.46715623981753013}
06/24/2021 21:52:13 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.96875, 'QA-F1': 0.9805194805194806}
06/24/2021 21:52:13 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:52:14 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:52:17 - INFO - __main__ - After Bug-fixing the results on bug-batch-1 = {'EM': 0.2, 'QA-F1': 0.5656889269371737}
06/24/2021 21:52:25 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.984375}
06/24/2021 21:52:25 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 21:52:25 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 21:52:25 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:52:29 - INFO - __main__ - ----------Timecode: 2----------
06/24/2021 21:52:29 - INFO - __main__ - Before Bug-fixing the results on bug-batch-2 = {'EM': 0.0, 'QA-F1': 0.4602006688963211}
06/24/2021 21:52:29 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.984375, 'QA-F1': 0.984375}
06/24/2021 21:52:29 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:52:32 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:52:35 - INFO - __main__ - After Bug-fixing the results on bug-batch-2 = {'EM': 0.25, 'QA-F1': 0.5666666666666667}
06/24/2021 21:52:42 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.96875, 'QA-F1': 0.97875}
06/24/2021 21:52:42 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 5
06/24/2021 21:52:42 - INFO - __main__ - Number of em_fixed_bugs = 5; Number of f1_fixed_bugs = 5
06/24/2021 21:52:42 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:52:45 - INFO - __main__ - ----------Timecode: 3----------
06/24/2021 21:52:45 - INFO - __main__ - Before Bug-fixing the results on bug-batch-3 = {'EM': 0.15, 'QA-F1': 0.502196523918492}
06/24/2021 21:52:45 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.96875, 'QA-F1': 0.97875}
06/24/2021 21:52:45 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:52:47 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:52:50 - INFO - __main__ - After Bug-fixing the results on bug-batch-3 = {'EM': 0.3, 'QA-F1': 0.5756226568183089}
06/24/2021 21:52:57 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.963125}
06/24/2021 21:52:57 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 21:52:57 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 21:52:57 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:53:00 - INFO - __main__ - ----------Timecode: 4----------
06/24/2021 21:53:00 - INFO - __main__ - Before Bug-fixing the results on bug-batch-4 = {'EM': 0.05, 'QA-F1': 0.44109910961903387}
06/24/2021 21:53:00 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.963125}
06/24/2021 21:53:00 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:53:01 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:53:04 - INFO - __main__ - After Bug-fixing the results on bug-batch-4 = {'EM': 0.2, 'QA-F1': 0.5406837606837608}
06/24/2021 21:53:12 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9648944805194806}
06/24/2021 21:53:12 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 21:53:12 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 2
06/24/2021 21:53:12 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:53:15 - INFO - __main__ - ----------Timecode: 5----------
06/24/2021 21:53:15 - INFO - __main__ - Before Bug-fixing the results on bug-batch-5 = {'EM': 0.0, 'QA-F1': 0.4211111111111111}
06/24/2021 21:53:15 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9648944805194806}
06/24/2021 21:53:15 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:53:16 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:53:19 - INFO - __main__ - After Bug-fixing the results on bug-batch-5 = {'EM': 0.1, 'QA-F1': 0.4332367149758454}
06/24/2021 21:53:27 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9648944805194806}
06/24/2021 21:53:27 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 2
06/24/2021 21:53:27 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 21:53:27 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:53:29 - INFO - __main__ - ----------Timecode: 6----------
06/24/2021 21:53:29 - INFO - __main__ - Before Bug-fixing the results on bug-batch-6 = {'EM': 0.15, 'QA-F1': 0.4889897432787926}
06/24/2021 21:53:29 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9648944805194806}
06/24/2021 21:53:29 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:53:31 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:53:33 - INFO - __main__ - After Bug-fixing the results on bug-batch-6 = {'EM': 0.35, 'QA-F1': 0.622742673992674}
06/24/2021 21:53:41 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9663825757575757}
06/24/2021 21:53:41 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 8
06/24/2021 21:53:41 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 4
06/24/2021 21:53:41 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:53:44 - INFO - __main__ - ----------Timecode: 7----------
06/24/2021 21:53:44 - INFO - __main__ - Before Bug-fixing the results on bug-batch-7 = {'EM': 0.1, 'QA-F1': 0.4337121212121212}
06/24/2021 21:53:44 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9663825757575757}
06/24/2021 21:53:44 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:53:46 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:53:49 - INFO - __main__ - After Bug-fixing the results on bug-batch-7 = {'EM': 0.05, 'QA-F1': 0.39132326007326}
06/24/2021 21:53:57 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9596861471861472}
06/24/2021 21:53:57 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 3
06/24/2021 21:53:57 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 21:53:57 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:54:01 - INFO - __main__ - ----------Timecode: 8----------
06/24/2021 21:54:01 - INFO - __main__ - Before Bug-fixing the results on bug-batch-8 = {'EM': 0.05, 'QA-F1': 0.3323749277981702}
06/24/2021 21:54:02 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9596861471861472}
06/24/2021 21:54:02 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:54:04 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:54:08 - INFO - __main__ - After Bug-fixing the results on bug-batch-8 = {'EM': 0.1, 'QA-F1': 0.4165640421791005}
06/24/2021 21:54:16 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.9493920295390883}
06/24/2021 21:54:16 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 21:54:16 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 21:54:16 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:54:19 - INFO - __main__ - ----------Timecode: 9----------
06/24/2021 21:54:19 - INFO - __main__ - Before Bug-fixing the results on bug-batch-9 = {'EM': 0.1, 'QA-F1': 0.4711539791122369}
06/24/2021 21:54:19 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.9493920295390883}
06/24/2021 21:54:19 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:54:20 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:54:24 - INFO - __main__ - After Bug-fixing the results on bug-batch-9 = {'EM': 0.3, 'QA-F1': 0.5748111990852462}
06/24/2021 21:54:33 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9316142517613106}
06/24/2021 21:54:33 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 8
06/24/2021 21:54:33 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 3
06/24/2021 21:54:33 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:54:36 - INFO - __main__ - ----------Timecode: 10----------
06/24/2021 21:54:36 - INFO - __main__ - Before Bug-fixing the results on bug-batch-10 = {'EM': 0.05, 'QA-F1': 0.37619556221933137}
06/24/2021 21:54:36 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9316142517613106}
06/24/2021 21:54:36 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:54:38 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:54:41 - INFO - __main__ - After Bug-fixing the results on bug-batch-10 = {'EM': 0.2, 'QA-F1': 0.46550375939849625}
06/24/2021 21:54:48 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9159892517613106}
06/24/2021 21:54:48 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 21:54:48 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 21:54:48 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:54:52 - INFO - __main__ - ----------Timecode: 11----------
06/24/2021 21:54:52 - INFO - __main__ - Before Bug-fixing the results on bug-batch-11 = {'EM': 0.05, 'QA-F1': 0.40692263028426023}
06/24/2021 21:54:52 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9159892517613106}
06/24/2021 21:54:52 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:54:53 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:54:57 - INFO - __main__ - After Bug-fixing the results on bug-batch-11 = {'EM': 0.15, 'QA-F1': 0.4802128269297201}
06/24/2021 21:55:04 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9175517517613105}
06/24/2021 21:55:04 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 21:55:04 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 21:55:04 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:55:08 - INFO - __main__ - ----------Timecode: 12----------
06/24/2021 21:55:08 - INFO - __main__ - Before Bug-fixing the results on bug-batch-12 = {'EM': 0.15, 'QA-F1': 0.4710139479132615}
06/24/2021 21:55:08 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9175517517613105}
06/24/2021 21:55:08 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:55:09 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:55:13 - INFO - __main__ - After Bug-fixing the results on bug-batch-12 = {'EM': 0.3, 'QA-F1': 0.5764418097927362}
06/24/2021 21:55:21 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8867752366097954}
06/24/2021 21:55:21 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 10
06/24/2021 21:55:21 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 21:55:21 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 21:55:25 - INFO - __main__ - ----------Timecode: 13----------
06/24/2021 21:55:25 - INFO - __main__ - Before Bug-fixing the results on bug-batch-13 = {'EM': 0.2, 'QA-F1': 0.4756169693852568}
06/24/2021 21:55:25 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8867752366097954}
06/24/2021 21:55:25 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:55:26 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:55:30 - INFO - __main__ - After Bug-fixing the results on bug-batch-13 = {'EM': 0.15, 'QA-F1': 0.4826335907567169}
06/24/2021 21:55:38 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8867752366097954}
06/24/2021 21:55:38 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 7
06/24/2021 21:55:38 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 21:55:38 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:55:41 - INFO - __main__ - ----------Timecode: 14----------
06/24/2021 21:55:41 - INFO - __main__ - Before Bug-fixing the results on bug-batch-14 = {'EM': 0.0, 'QA-F1': 0.29140699714229124}
06/24/2021 21:55:41 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8867752366097954}
06/24/2021 21:55:41 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:55:43 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:55:46 - INFO - __main__ - After Bug-fixing the results on bug-batch-14 = {'EM': 0.0, 'QA-F1': 0.3086239283592224}
06/24/2021 21:55:54 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8933093275188864}
06/24/2021 21:55:54 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 2
06/24/2021 21:55:54 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 21:55:54 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:55:58 - INFO - __main__ - ----------Timecode: 15----------
06/24/2021 21:55:58 - INFO - __main__ - Before Bug-fixing the results on bug-batch-15 = {'EM': 0.05, 'QA-F1': 0.33427272388101575}
06/24/2021 21:55:58 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8933093275188864}
06/24/2021 21:55:58 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:55:59 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:56:02 - INFO - __main__ - After Bug-fixing the results on bug-batch-15 = {'EM': 0.05, 'QA-F1': 0.3249555704462152}
06/24/2021 21:56:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9140858426704015}
06/24/2021 21:56:10 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 21:56:10 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 21:56:10 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:56:13 - INFO - __main__ - ----------Timecode: 16----------
06/24/2021 21:56:13 - INFO - __main__ - Before Bug-fixing the results on bug-batch-16 = {'EM': 0.1, 'QA-F1': 0.3364405531546967}
06/24/2021 21:56:13 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9140858426704015}
06/24/2021 21:56:13 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:56:15 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:56:19 - INFO - __main__ - After Bug-fixing the results on bug-batch-16 = {'EM': 0.3, 'QA-F1': 0.5360713063568785}
06/24/2021 21:56:26 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9412202380952381}
06/24/2021 21:56:26 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 10
06/24/2021 21:56:26 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 5
06/24/2021 21:56:26 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:56:30 - INFO - __main__ - ----------Timecode: 17----------
06/24/2021 21:56:30 - INFO - __main__ - Before Bug-fixing the results on bug-batch-17 = {'EM': 0.05, 'QA-F1': 0.293570118760696}
06/24/2021 21:56:30 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9412202380952381}
06/24/2021 21:56:30 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:56:32 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:56:36 - INFO - __main__ - After Bug-fixing the results on bug-batch-17 = {'EM': 0.1, 'QA-F1': 0.3480456432362205}
06/24/2021 21:56:44 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.926068722943723}
06/24/2021 21:56:44 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 21:56:44 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 21:56:44 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:56:48 - INFO - __main__ - ----------Timecode: 18----------
06/24/2021 21:56:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-18 = {'EM': 0.1, 'QA-F1': 0.3326382385730212}
06/24/2021 21:56:48 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.926068722943723}
06/24/2021 21:56:48 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:56:50 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:56:54 - INFO - __main__ - After Bug-fixing the results on bug-batch-18 = {'EM': 0.1, 'QA-F1': 0.33703752556054345}
06/24/2021 21:57:02 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9021971951659451}
06/24/2021 21:57:02 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 4
06/24/2021 21:57:02 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 21:57:02 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:57:06 - INFO - __main__ - ----------Timecode: 19----------
06/24/2021 21:57:06 - INFO - __main__ - Before Bug-fixing the results on bug-batch-19 = {'EM': 0.05, 'QA-F1': 0.23725450012950017}
06/24/2021 21:57:06 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9021971951659451}
06/24/2021 21:57:06 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:57:07 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:57:11 - INFO - __main__ - After Bug-fixing the results on bug-batch-19 = {'EM': 0.1, 'QA-F1': 0.32735473322973324}
06/24/2021 21:57:19 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9295409451659451}
06/24/2021 21:57:19 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 21:57:19 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 21:57:19 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:57:23 - INFO - __main__ - ----------Timecode: 20----------
06/24/2021 21:57:23 - INFO - __main__ - Before Bug-fixing the results on bug-batch-20 = {'EM': 0.0, 'QA-F1': 0.12979872694829458}
06/24/2021 21:57:23 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9295409451659451}
06/24/2021 21:57:23 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:57:24 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:57:28 - INFO - __main__ - After Bug-fixing the results on bug-batch-20 = {'EM': 0.15, 'QA-F1': 0.28578245284127635}
06/24/2021 21:57:36 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9479166666666667}
06/24/2021 21:57:36 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 4
06/24/2021 21:57:36 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 21:57:36 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:57:39 - INFO - __main__ - ----------Timecode: 21----------
06/24/2021 21:57:39 - INFO - __main__ - Before Bug-fixing the results on bug-batch-21 = {'EM': 0.05, 'QA-F1': 0.26998140146221344}
06/24/2021 21:57:39 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9479166666666667}
06/24/2021 21:57:39 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:57:41 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:57:44 - INFO - __main__ - After Bug-fixing the results on bug-batch-21 = {'EM': 0.2, 'QA-F1': 0.39012029035110235}
06/24/2021 21:57:51 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9635416666666667}
06/24/2021 21:57:51 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 6
06/24/2021 21:57:51 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 3
06/24/2021 21:57:51 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:57:55 - INFO - __main__ - ----------Timecode: 22----------
06/24/2021 21:57:55 - INFO - __main__ - Before Bug-fixing the results on bug-batch-22 = {'EM': 0.15, 'QA-F1': 0.3651637769936051}
06/24/2021 21:57:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.953125, 'QA-F1': 0.9635416666666667}
06/24/2021 21:57:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:57:57 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:58:00 - INFO - __main__ - After Bug-fixing the results on bug-batch-22 = {'EM': 0.2, 'QA-F1': 0.3643941445792358}
06/24/2021 21:58:08 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.95}
06/24/2021 21:58:08 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 6
06/24/2021 21:58:08 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 21:58:08 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:58:11 - INFO - __main__ - ----------Timecode: 23----------
06/24/2021 21:58:11 - INFO - __main__ - Before Bug-fixing the results on bug-batch-23 = {'EM': 0.0, 'QA-F1': 0.08264896354598872}
06/24/2021 21:58:11 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.95}
06/24/2021 21:58:11 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:58:12 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:58:16 - INFO - __main__ - After Bug-fixing the results on bug-batch-23 = {'EM': 0.05, 'QA-F1': 0.23095723422268044}
06/24/2021 21:58:24 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9019367784992784}
06/24/2021 21:58:24 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 4
06/24/2021 21:58:24 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 4
06/24/2021 21:58:24 - INFO - __main__ - Number of em_forgotten_passes = 5.
06/24/2021 21:58:27 - INFO - __main__ - ----------Timecode: 24----------
06/24/2021 21:58:27 - INFO - __main__ - Before Bug-fixing the results on bug-batch-24 = {'EM': 0.0, 'QA-F1': 0.13504943727769816}
06/24/2021 21:58:27 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9019367784992784}
06/24/2021 21:58:27 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:58:29 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:58:32 - INFO - __main__ - After Bug-fixing the results on bug-batch-24 = {'EM': 0.1, 'QA-F1': 0.22984168654575385}
06/24/2021 21:58:40 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8880302019580038}
06/24/2021 21:58:40 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 3
06/24/2021 21:58:40 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 21:58:40 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:58:44 - INFO - __main__ - ----------Timecode: 25----------
06/24/2021 21:58:44 - INFO - __main__ - Before Bug-fixing the results on bug-batch-25 = {'EM': 0.05, 'QA-F1': 0.329881377529544}
06/24/2021 21:58:44 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8880302019580038}
06/24/2021 21:58:44 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:58:45 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:58:49 - INFO - __main__ - After Bug-fixing the results on bug-batch-25 = {'EM': 0.1, 'QA-F1': 0.3768596401663815}
06/24/2021 21:58:57 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8724052019580038}
06/24/2021 21:58:57 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 8
06/24/2021 21:58:57 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 21:58:57 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:59:01 - INFO - __main__ - ----------Timecode: 26----------
06/24/2021 21:59:01 - INFO - __main__ - Before Bug-fixing the results on bug-batch-26 = {'EM': 0.15, 'QA-F1': 0.15854545454545454}
06/24/2021 21:59:01 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8724052019580038}
06/24/2021 21:59:01 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:59:03 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:59:07 - INFO - __main__ - After Bug-fixing the results on bug-batch-26 = {'EM': 0.15, 'QA-F1': 0.15899999999999997}
06/24/2021 21:59:15 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8807633627946128}
06/24/2021 21:59:15 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 3
06/24/2021 21:59:15 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 21:59:15 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 21:59:17 - INFO - __main__ - ----------Timecode: 27----------
06/24/2021 21:59:17 - INFO - __main__ - Before Bug-fixing the results on bug-batch-27 = {'EM': 0.15, 'QA-F1': 0.20535714285714285}
06/24/2021 21:59:17 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8807633627946128}
06/24/2021 21:59:17 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:59:19 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:59:21 - INFO - __main__ - After Bug-fixing the results on bug-batch-27 = {'EM': 0.25, 'QA-F1': 0.2958333333333333}
06/24/2021 21:59:29 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.919854797979798}
06/24/2021 21:59:29 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 5
06/24/2021 21:59:29 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 1
06/24/2021 21:59:29 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 21:59:31 - INFO - __main__ - ----------Timecode: 28----------
06/24/2021 21:59:31 - INFO - __main__ - Before Bug-fixing the results on bug-batch-28 = {'EM': 0.1, 'QA-F1': 0.13923001949317737}
06/24/2021 21:59:31 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.919854797979798}
06/24/2021 21:59:31 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:59:33 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:59:36 - INFO - __main__ - After Bug-fixing the results on bug-batch-28 = {'EM': 0.15, 'QA-F1': 0.18227513227513228}
06/24/2021 21:59:44 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9096861471861473}
06/24/2021 21:59:44 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 4
06/24/2021 21:59:44 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 21:59:44 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 21:59:47 - INFO - __main__ - ----------Timecode: 29----------
06/24/2021 21:59:47 - INFO - __main__ - Before Bug-fixing the results on bug-batch-29 = {'EM': 0.05, 'QA-F1': 0.06538461538461539}
06/24/2021 21:59:47 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9096861471861473}
06/24/2021 21:59:47 - INFO - __main__ - Start bug-fixing ....
06/24/2021 21:59:49 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 21:59:52 - INFO - __main__ - After Bug-fixing the results on bug-batch-29 = {'EM': 0.15, 'QA-F1': 0.1733846153846154}
06/24/2021 22:00:00 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9120535714285714}
06/24/2021 22:00:00 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 22:00:00 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 22:00:00 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:00:03 - INFO - __main__ - ----------Timecode: 30----------
06/24/2021 22:00:03 - INFO - __main__ - Before Bug-fixing the results on bug-batch-30 = {'EM': 0.05, 'QA-F1': 0.075}
06/24/2021 22:00:03 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9120535714285714}
06/24/2021 22:00:03 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:00:05 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:00:09 - INFO - __main__ - After Bug-fixing the results on bug-batch-30 = {'EM': 0.1, 'QA-F1': 0.15833333333333333}
06/24/2021 22:00:16 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9120535714285714}
06/24/2021 22:00:16 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 3
06/24/2021 22:00:16 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 22:00:16 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:00:19 - INFO - __main__ - ----------Timecode: 31----------
06/24/2021 22:00:19 - INFO - __main__ - Before Bug-fixing the results on bug-batch-31 = {'EM': 0.15, 'QA-F1': 0.15}
06/24/2021 22:00:19 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9120535714285714}
06/24/2021 22:00:19 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:00:21 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:00:24 - INFO - __main__ - After Bug-fixing the results on bug-batch-31 = {'EM': 0.35, 'QA-F1': 0.36818181818181817}
06/24/2021 22:00:32 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.91875}
06/24/2021 22:00:32 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 22:00:32 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 4
06/24/2021 22:00:32 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:00:35 - INFO - __main__ - ----------Timecode: 32----------
06/24/2021 22:00:35 - INFO - __main__ - Before Bug-fixing the results on bug-batch-32 = {'EM': 0.25, 'QA-F1': 0.29087301587301584}
06/24/2021 22:00:35 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.91875}
06/24/2021 22:00:35 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:00:37 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:00:39 - INFO - __main__ - After Bug-fixing the results on bug-batch-32 = {'EM': 0.3, 'QA-F1': 0.3825396825396825}
06/24/2021 22:00:47 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.91875}
06/24/2021 22:00:47 - INFO - __main__ - Number of em_prefixed_bugs = 5; Number of f1_prefixed_bugs = 8
06/24/2021 22:00:47 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 22:00:47 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:00:50 - INFO - __main__ - ----------Timecode: 33----------
06/24/2021 22:00:50 - INFO - __main__ - Before Bug-fixing the results on bug-batch-33 = {'EM': 0.1, 'QA-F1': 0.15833333333333333}
06/24/2021 22:00:50 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.90625, 'QA-F1': 0.91875}
06/24/2021 22:00:50 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:00:52 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:00:54 - INFO - __main__ - After Bug-fixing the results on bug-batch-33 = {'EM': 0.25, 'QA-F1': 0.3083333333333333}
06/24/2021 22:01:01 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9053571428571429}
06/24/2021 22:01:01 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 6
06/24/2021 22:01:01 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
06/24/2021 22:01:01 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:01:04 - INFO - __main__ - ----------Timecode: 34----------
06/24/2021 22:01:04 - INFO - __main__ - Before Bug-fixing the results on bug-batch-34 = {'EM': 0.15, 'QA-F1': 0.19}
06/24/2021 22:01:04 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9053571428571429}
06/24/2021 22:01:04 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:01:07 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:01:10 - INFO - __main__ - After Bug-fixing the results on bug-batch-34 = {'EM': 0.2, 'QA-F1': 0.2}
06/24/2021 22:01:18 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9053571428571429}
06/24/2021 22:01:18 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 4
06/24/2021 22:01:18 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 0
06/24/2021 22:01:18 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:01:21 - INFO - __main__ - ----------Timecode: 35----------
06/24/2021 22:01:21 - INFO - __main__ - Before Bug-fixing the results on bug-batch-35 = {'EM': 0.1, 'QA-F1': 0.218525641025641}
06/24/2021 22:01:21 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9053571428571429}
06/24/2021 22:01:21 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:01:24 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:01:27 - INFO - __main__ - After Bug-fixing the results on bug-batch-35 = {'EM': 0.15, 'QA-F1': 0.33277777777777773}
06/24/2021 22:01:35 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8603203781512605}
06/24/2021 22:01:35 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 8
06/24/2021 22:01:35 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 22:01:35 - INFO - __main__ - Number of em_forgotten_passes = 4.
06/24/2021 22:01:38 - INFO - __main__ - ----------Timecode: 36----------
06/24/2021 22:01:38 - INFO - __main__ - Before Bug-fixing the results on bug-batch-36 = {'EM': 0.15, 'QA-F1': 0.23125}
06/24/2021 22:01:38 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8603203781512605}
06/24/2021 22:01:38 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:01:40 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:01:44 - INFO - __main__ - After Bug-fixing the results on bug-batch-36 = {'EM': 0.2, 'QA-F1': 0.32398715415019763}
06/24/2021 22:01:52 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8603203781512605}
06/24/2021 22:01:52 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 7
06/24/2021 22:01:52 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 22:01:52 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:01:55 - INFO - __main__ - ----------Timecode: 37----------
06/24/2021 22:01:55 - INFO - __main__ - Before Bug-fixing the results on bug-batch-37 = {'EM': 0.15, 'QA-F1': 0.22567226890756306}
06/24/2021 22:01:55 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8603203781512605}
06/24/2021 22:01:55 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:01:56 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:02:00 - INFO - __main__ - After Bug-fixing the results on bug-batch-37 = {'EM': 0.25, 'QA-F1': 0.3337218045112782}
06/24/2021 22:02:08 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.847406642581275}
06/24/2021 22:02:08 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 6
06/24/2021 22:02:08 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 22:02:08 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 22:02:12 - INFO - __main__ - ----------Timecode: 38----------
06/24/2021 22:02:12 - INFO - __main__ - Before Bug-fixing the results on bug-batch-38 = {'EM': 0.1, 'QA-F1': 0.12}
06/24/2021 22:02:12 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.847406642581275}
06/24/2021 22:02:12 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:02:14 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:02:18 - INFO - __main__ - After Bug-fixing the results on bug-batch-38 = {'EM': 0.2, 'QA-F1': 0.24857142857142858}
06/24/2021 22:02:26 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8313600155971479}
06/24/2021 22:02:26 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 5
06/24/2021 22:02:26 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 3
06/24/2021 22:02:26 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:02:30 - INFO - __main__ - ----------Timecode: 39----------
06/24/2021 22:02:30 - INFO - __main__ - Before Bug-fixing the results on bug-batch-39 = {'EM': 0.05, 'QA-F1': 0.13270609318996418}
06/24/2021 22:02:30 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8313600155971479}
06/24/2021 22:02:30 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:02:31 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:02:35 - INFO - __main__ - After Bug-fixing the results on bug-batch-39 = {'EM': 0.15, 'QA-F1': 0.267296113847838}
06/24/2021 22:02:42 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.868307616607249}
06/24/2021 22:02:42 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 4
06/24/2021 22:02:42 - INFO - __main__ - Number of em_fixed_bugs = 2; Number of f1_fixed_bugs = 2
06/24/2021 22:02:42 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:02:46 - INFO - __main__ - ----------Timecode: 40----------
06/24/2021 22:02:46 - INFO - __main__ - Before Bug-fixing the results on bug-batch-40 = {'EM': 0.0, 'QA-F1': 0.005555555555555555}
06/24/2021 22:02:46 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.868307616607249}
06/24/2021 22:02:46 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:02:49 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:02:53 - INFO - __main__ - After Bug-fixing the results on bug-batch-40 = {'EM': 0.05, 'QA-F1': 0.13101010101010102}
06/24/2021 22:03:00 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.856588866607249}
06/24/2021 22:03:00 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 3
06/24/2021 22:03:00 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 3
06/24/2021 22:03:00 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:03:03 - INFO - __main__ - ----------Timecode: 41----------
06/24/2021 22:03:03 - INFO - __main__ - Before Bug-fixing the results on bug-batch-41 = {'EM': 0.05, 'QA-F1': 0.11969696969696968}
06/24/2021 22:03:03 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.856588866607249}
06/24/2021 22:03:03 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:03:04 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:03:07 - INFO - __main__ - After Bug-fixing the results on bug-batch-41 = {'EM': 0.1, 'QA-F1': 0.2158508158508158}
06/24/2021 22:03:14 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8368592039088363}
06/24/2021 22:03:14 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 5
06/24/2021 22:03:14 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 2
06/24/2021 22:03:14 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 22:03:16 - INFO - __main__ - ----------Timecode: 42----------
06/24/2021 22:03:16 - INFO - __main__ - Before Bug-fixing the results on bug-batch-42 = {'EM': 0.05, 'QA-F1': 0.12785714285714284}
06/24/2021 22:03:16 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8368592039088363}
06/24/2021 22:03:16 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:03:18 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:03:21 - INFO - __main__ - After Bug-fixing the results on bug-batch-42 = {'EM': 0.25, 'QA-F1': 0.3964285714285714}
06/24/2021 22:03:28 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8420675372421697}
06/24/2021 22:03:28 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 9
06/24/2021 22:03:28 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 6
06/24/2021 22:03:28 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:03:31 - INFO - __main__ - ----------Timecode: 43----------
06/24/2021 22:03:31 - INFO - __main__ - Before Bug-fixing the results on bug-batch-43 = {'EM': 0.0, 'QA-F1': 0.005263157894736843}
06/24/2021 22:03:31 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8420675372421697}
06/24/2021 22:03:31 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:03:34 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:03:37 - INFO - __main__ - After Bug-fixing the results on bug-batch-43 = {'EM': 0.05, 'QA-F1': 0.05526315789473685}
06/24/2021 22:03:44 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8638557316866141}
06/24/2021 22:03:44 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 1
06/24/2021 22:03:44 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 22:03:44 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:03:47 - INFO - __main__ - ----------Timecode: 44----------
06/24/2021 22:03:47 - INFO - __main__ - Before Bug-fixing the results on bug-batch-44 = {'EM': 0.2, 'QA-F1': 0.22000000000000003}
06/24/2021 22:03:47 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8638557316866141}
06/24/2021 22:03:47 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:03:49 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:03:51 - INFO - __main__ - After Bug-fixing the results on bug-batch-44 = {'EM': 0.35, 'QA-F1': 0.4166666666666667}
06/24/2021 22:03:58 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8854982718894009}
06/24/2021 22:03:58 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 8
06/24/2021 22:03:58 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 4
06/24/2021 22:03:58 - INFO - __main__ - Number of em_forgotten_passes = 0.
06/24/2021 22:04:01 - INFO - __main__ - ----------Timecode: 45----------
06/24/2021 22:04:01 - INFO - __main__ - Before Bug-fixing the results on bug-batch-45 = {'EM': 0.15, 'QA-F1': 0.17777777777777776}
06/24/2021 22:04:01 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8854982718894009}
06/24/2021 22:04:01 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:04:02 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:04:05 - INFO - __main__ - After Bug-fixing the results on bug-batch-45 = {'EM': 0.2, 'QA-F1': 0.22777777777777777}
06/24/2021 22:04:12 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8854982718894009}
06/24/2021 22:04:12 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 4
06/24/2021 22:04:12 - INFO - __main__ - Number of em_fixed_bugs = 1; Number of f1_fixed_bugs = 1
06/24/2021 22:04:12 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:04:15 - INFO - __main__ - ----------Timecode: 46----------
06/24/2021 22:04:15 - INFO - __main__ - Before Bug-fixing the results on bug-batch-46 = {'EM': 0.05, 'QA-F1': 0.05}
06/24/2021 22:04:15 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8854982718894009}
06/24/2021 22:04:15 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:04:18 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:04:20 - INFO - __main__ - After Bug-fixing the results on bug-batch-46 = {'EM': 0.05, 'QA-F1': 0.08333333333333333}
06/24/2021 22:04:28 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8689062367371191}
06/24/2021 22:04:28 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 2
06/24/2021 22:04:28 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 1
06/24/2021 22:04:28 - INFO - __main__ - Number of em_forgotten_passes = 2.
06/24/2021 22:04:31 - INFO - __main__ - ----------Timecode: 47----------
06/24/2021 22:04:31 - INFO - __main__ - Before Bug-fixing the results on bug-batch-47 = {'EM': 0.1, 'QA-F1': 0.12692307692307692}
06/24/2021 22:04:31 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8689062367371191}
06/24/2021 22:04:31 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:04:32 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:04:36 - INFO - __main__ - After Bug-fixing the results on bug-batch-47 = {'EM': 0.05, 'QA-F1': 0.12406593406593407}
06/24/2021 22:04:43 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.85825282764621}
06/24/2021 22:04:43 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 3
06/24/2021 22:04:43 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 22:04:43 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:04:46 - INFO - __main__ - ----------Timecode: 48----------
06/24/2021 22:04:46 - INFO - __main__ - Before Bug-fixing the results on bug-batch-48 = {'EM': 0.0, 'QA-F1': 0.05711722488038277}
06/24/2021 22:04:46 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.85825282764621}
06/24/2021 22:04:46 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:04:47 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:04:50 - INFO - __main__ - After Bug-fixing the results on bug-batch-48 = {'EM': 0.0, 'QA-F1': 0.024617224880382774}
06/24/2021 22:04:58 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8437957569391392}
06/24/2021 22:04:58 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 0
06/24/2021 22:04:58 - INFO - __main__ - Number of em_fixed_bugs = 0; Number of f1_fixed_bugs = 0
06/24/2021 22:04:58 - INFO - __main__ - Number of em_forgotten_passes = 3.
06/24/2021 22:05:01 - INFO - __main__ - ----------Timecode: 49----------
06/24/2021 22:05:01 - INFO - __main__ - Before Bug-fixing the results on bug-batch-49 = {'EM': 0.1, 'QA-F1': 0.18503663003663}
06/24/2021 22:05:01 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8437957569391392}
06/24/2021 22:05:01 - INFO - __main__ - Start bug-fixing ....
06/24/2021 22:05:03 - INFO - __main__ - Start bug-fixing .... Done!
06/24/2021 22:05:07 - INFO - __main__ - After Bug-fixing the results on bug-batch-49 = {'EM': 0.25, 'QA-F1': 0.3162750172532781}
06/24/2021 22:05:14 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8361611506772797}
06/24/2021 22:05:14 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 5
06/24/2021 22:05:14 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 2
06/24/2021 22:05:15 - INFO - __main__ - Number of em_forgotten_passes = 1.
06/24/2021 22:07:29 - INFO - __main__ - Final Bug-fixing Results = {'EM': 0.343, 'QA-F1': 0.5059138088352088}
09/28/2021 16:54:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:54:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:54:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:55:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:55:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:55:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:55:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:55:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:55:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:55:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:55:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:55:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 16:55:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 16:55:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 16:55:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 16:55:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 16:56:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 16:56:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 1000 examples.
09/28/2021 16:57:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:57:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:57:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:57:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:57:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:57:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 16:57:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 16:57:02 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 16:57:02 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 16:57:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 16:57:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 16:57:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 1000 examples.
09/28/2021 16:57:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:57:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:57:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:57:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:57:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:57:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 16:57:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 16:57:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 16:57:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 16:58:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 16:58:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 16:58:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 1000 examples.
09/28/2021 16:58:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:58:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:58:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:58:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:58:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:58:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 16:58:20 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 16:58:20 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 16:58:20 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 16:58:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 16:58:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 16:58:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 1000 examples.
09/28/2021 16:59:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 16:59:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:59:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:59:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 16:59:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 16:59:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 16:59:04 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 16:59:04 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 16:59:04 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 16:59:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 16:59:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 16:59:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 1000 examples.
09/28/2021 17:02:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:02:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:02:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:02:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:02:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:02:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:02:56 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:02:56 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:02:56 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:03:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:03:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:03:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:03:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:17:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:17:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:17:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:17:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:17:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:17:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:17:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:17:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:17:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:17:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:17:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:17:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:17:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:18:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:18:09 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:18:09 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:18:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:18:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:18:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:18:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:18:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:18:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:18:38 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:18:38 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:18:38 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:18:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:18:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:18:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 17:18:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 17:18:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:18:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:18:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:18:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:18:52 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:18:52 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:18:52 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:18:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:18:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:18:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:18:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 17:18:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 17:20:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:20:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:20:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:20:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:20:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:20:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:20:10 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:20:10 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:20:10 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:20:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 17:20:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (4, 768)
09/28/2021 17:20:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:20:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:20:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:20:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:20:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:20:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:20:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:20:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:20:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:20:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 17:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (4, 768)
09/28/2021 17:21:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:21:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:21:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:21:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:21:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:21:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:21:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:21:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:21:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:21:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 17:21:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (4, 1536)
09/28/2021 17:54:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 17:54:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:54:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:54:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 17:54:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 17:54:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 17:54:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 17:54:02 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 17:54:02 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 17:54:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 17:54:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 17:54:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 17:54:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:03:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:03:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:03:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:03:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:03:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:03:38 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:03:38 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:03:38 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:03:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:03:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:03:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:05:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:05:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:05:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:05:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:05:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:05:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:05:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:05:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:05:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:05:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:05:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:05:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:05:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:05:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:05:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:05:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:05:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:05:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:05:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:05:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:05:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:05:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:06:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:06:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:06:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:06:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:06:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:06:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:06:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:06:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:06:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:06:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:06:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:06:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:07:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:07:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:07:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:07:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:07:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:07:23 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:07:23 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:07:23 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:07:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:07:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:07:49 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:07:49 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:07:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:07:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:07:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:07:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:07:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:07:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:07:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:07:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:07:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:08:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:08:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:08:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:08:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:08:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:08:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:08:23 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:08:23 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:08:23 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:08:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:08:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:08:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:09:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:09:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:09:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:09:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:09:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:09:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:09:35 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:09:35 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:09:35 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:09:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:09:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:09:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:09:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:10:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:10:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:10:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:11:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:11:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:11:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:11:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:11:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:11:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:11:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:11:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:11:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:11:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:11:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:11:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:11:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:11:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:11:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:11:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:11:59 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:11:59 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:11:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:12:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:12:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:12:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:12:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:12:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:13:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:13:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:13:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:13:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:13:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:13:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:13:02 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:13:02 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:13:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:13:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:13:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:13:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:13:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:13:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:13:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:13:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:13:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:13:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:13:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:13:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:13:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:13:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (16, 768)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (16, 1536)
09/28/2021 18:13:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (4, 768)
09/28/2021 18:13:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (4, 768)
09/28/2021 18:13:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (4, 1536)
09/28/2021 18:14:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:14:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:14:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:14:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:14:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:14:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:14:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:14:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:14:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:14:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:14:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:14:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:14:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (8, 768)
09/28/2021 18:16:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (8, 1536)
09/28/2021 18:16:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - input_vectors.shape = (5, 768)
09/28/2021 18:16:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - output_vectors.shape = (5, 768)
09/28/2021 18:16:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - vectors.shape = (5, 1536)
09/28/2021 18:18:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:18:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:18:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:18:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:18:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:18:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:18:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:18:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:18:27 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:18:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:18:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:18:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:19:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:19:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:19:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:19:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:19:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:19:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:19:22 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:19:22 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:19:22 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:19:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:19:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:19:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:20:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:20:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:20:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:20:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:20:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:20:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:20:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:20:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:20:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:20:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:20:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:21:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:21:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:21:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:21:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:21:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:21:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:21:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:21:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:21:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:21:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:21:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:21:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:22:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:22:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:22:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:22:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:22:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:22:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:22:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:22:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:22:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:22:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:22:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:22:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:24:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:24:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:24:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:24:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:24:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:24:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:24:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:24:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:24:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:24:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:24:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:24:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:27:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:27:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:27:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:27:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:27:21 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:27:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:27:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:27:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:27:21 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:27:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:27:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:27:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:28:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:28:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:28:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:28:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:28:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:28:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:28:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:28:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:28:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:28:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:28:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:28:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/28/2021 18:29:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:29:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:29:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:29:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:29:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:29:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:29:39 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:29:39 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:29:39 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:29:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:29:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:29:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:42:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:42:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:42:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:42:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:42:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:42:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:42:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:42:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:42:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:42:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:42:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:42:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:42:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:42:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:42:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:42:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:42:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:42:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:42:58 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:42:58 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:42:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:43:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:43:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:43:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:45:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:45:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:45:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:45:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:45:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:45:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:45:05 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:45:05 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:45:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:45:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:45:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:45:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:45:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:45:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:45:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:45:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:45:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:45:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:45:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:45:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:45:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:45:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:45:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:45:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:46:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:46:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:46:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:46:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:46:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:46:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:46:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:46:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:46:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:46:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:46:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:46:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 18:46:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 18:46:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:46:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:46:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 18:46:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 18:46:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 18:46:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 18:46:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 18:46:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 18:46:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 18:46:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 18:46:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 21:40:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 21:40:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:40:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:40:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:40:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:40:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 21:40:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 21:40:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 21:40:35 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 21:40:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 21:41:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 21:41:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:41:09 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:41:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:41:10 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:41:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 21:41:11 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 21:41:11 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 21:41:11 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 21:41:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 21:41:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 21:41:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/28/2021 21:42:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_cache_path='bug_data/memory_key_cache.pkl', memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/28/2021 21:42:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:42:53 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:42:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/28/2021 21:42:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/28/2021 21:42:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/28/2021 21:42:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/28/2021 21:42:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/28/2021 21:42:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/28/2021 21:42:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/28/2021 21:43:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/28/2021 21:43:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 500 examples.
09/29/2021 12:15:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:15:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:15:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:15:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:15:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:15:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:15:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:15:02 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:15:02 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:15:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:15:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:15:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:15:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:15:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:15:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:15:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:15:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:15:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:15:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:15:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:15:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:19:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:19:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:19:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:19:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:19:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:19:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:19:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:19:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:19:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:20:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:20:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:20:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:21:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:21:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:21:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:21:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:21:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:21:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:21:38 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:21:38 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:21:38 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:21:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:21:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:21:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:22:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:22:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:22:01 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:22:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:22:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:22:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:22:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:22:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:22:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:22:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:22:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:22:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:22:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:22:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:22:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:22:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:22:47 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:22:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:22:48 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:22:48 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:22:48 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:22:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:22:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:22:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:22:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:24:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:24:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:24:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:24:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:24:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:24:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:24:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:24:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:24:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:24:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:24:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:24:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:24:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:24:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:24:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:24:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:24:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:24:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:24:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:24:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:24:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:24:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:24:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:24:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:26:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Saved the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:26:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:27:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:27:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:27:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:27:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:27:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:27:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:27:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:27:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:27:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:27:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:27:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:27:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
09/29/2021 12:27:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:27:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:27:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:27:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:27:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:27:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:27:59 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:27:59 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:27:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:28:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:28:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:28:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:29:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:29:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:29:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:29:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:29:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:29:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:29:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:29:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:29:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:29:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:29:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:29:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
09/29/2021 12:30:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
09/29/2021 12:30:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:30:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:30:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
09/29/2021 12:30:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
09/29/2021 12:30:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
09/29/2021 12:30:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
09/29/2021 12:30:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

09/29/2021 12:30:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
09/29/2021 12:30:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
09/29/2021 12:30:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
09/29/2021 12:30:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/init_memory.pkl
10/14/2021 20:15:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/14/2021 20:15:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/14/2021 20:15:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/14/2021 20:15:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/14/2021 20:15:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/14/2021 20:15:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/14/2021 20:15:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/14/2021 20:15:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/14/2021 20:15:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/14/2021 20:15:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/14/2021 20:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/14/2021 20:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/14/2021 20:15:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/14/2021 20:15:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/14/2021 20:15:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/14/2021 20:15:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/14/2021 20:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/14/2021 20:16:00 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/14/2021 20:16:00 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/14/2021 20:16:00 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/14/2021 20:16:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/14/2021 20:16:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/14/2021 20:16:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/14/2021 20:17:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Saved the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 12:58:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 12:58:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 12:58:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 12:58:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 12:58:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 12:58:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 12:58:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 12:58:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 12:58:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 12:58:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 12:58:57 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 12:58:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 12:58:58 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 12:58:58 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 12:58:58 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 12:59:02 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 12:59:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 12:59:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 12:59:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 12:59:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 12:59:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 12:59:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 12:59:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 12:59:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 12:59:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 12:59:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 12:59:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 12:59:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 12:59:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 12:59:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 13:01:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 13:01:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 13:01:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 13:01:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 13:01:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 13:01:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 13:01:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 13:01:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 13:01:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 13:01:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 13:01:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 13:03:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 13:03:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 13:03:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 13:03:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 13:03:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 13:03:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 13:03:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 13:04:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 13:04:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 13:04:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 13:04:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 13:07:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 13:07:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 13:07:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 13:07:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 13:07:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 13:07:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 13:07:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 13:07:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 13:07:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 13:07:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 13:07:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 13:07:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 13:07:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Initial memory size: 10000
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Not creating the replay-stream for evaluation.
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ......
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3.0, overtime_ckpt_dir=None, save_all_ckpts=0, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ...... Done!
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start Mining Distant Supervision (as online debugging).
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Number of Batches of Data: 100
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Data Batch Size: 16;
10/19/2021 13:07:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 0
10/19/2021 13:07:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Done!
10/19/2021 13:07:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Randomly retrieve from the memory. `query_examples` not used
10/19/2021 13:07:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Get an instance for supervision at 1
10/19/2021 13:07:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Save 16 examples to the memory.
10/19/2021 13:07:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 1
10/19/2021 13:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Done!
10/19/2021 13:07:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Randomly retrieve from the memory. `query_examples` not used
10/19/2021 13:07:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Get an instance for supervision at 2
10/19/2021 13:07:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Save 16 examples to the memory.
10/19/2021 13:07:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 2
10/19/2021 13:07:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Done!
10/19/2021 13:07:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Randomly retrieve from the memory. `query_examples` not used
10/19/2021 13:07:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Get an instance for supervision at 3
10/19/2021 13:07:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Save 16 examples to the memory.
10/19/2021 13:07:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 3
10/19/2021 13:07:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Done!
10/19/2021 13:07:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Randomly retrieve from the memory. `query_examples` not used
10/19/2021 15:28:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 15:28:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 15:28:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 15:28:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 15:28:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 15:28:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 15:28:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 15:28:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 15:28:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 15:41:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, negative_size=8, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, positive_size=8, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 15:41:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 15:41:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 15:41:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 15:41:04 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 15:41:05 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 15:41:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 15:41:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 15:41:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, negative_size=8, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, positive_size=8, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 15:41:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 15:41:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 15:41:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 15:41:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 15:41:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 15:41:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 15:41:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 15:41:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 15:41:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 15:41:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 15:41:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 15:41:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Initial memory size: 10000
10/19/2021 15:42:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Not creating the replay-stream for evaluation.
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ......
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3.0, overtime_ckpt_dir=None, save_all_ckpts=0, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ...... Done!
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start Mining Distant Supervision (as online debugging).
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Number of Batches of Data: 100
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Data Batch Size: 16;
10/19/2021 15:42:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 0
10/19/2021 15:44:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, negative_size=8, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, positive_size=8, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 15:44:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 15:44:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 15:44:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 15:44:09 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 15:44:09 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 15:44:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 15:44:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 15:44:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 15:44:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 15:44:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 15:44:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 15:44:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Initial memory size: 10000
10/19/2021 15:44:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Not creating the replay-stream for evaluation.
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ......
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3.0, overtime_ckpt_dir=None, save_all_ckpts=0, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ...... Done!
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start Mining Distant Supervision (as online debugging).
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Number of Batches of Data: 100
10/19/2021 15:44:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Data Batch Size: 16;
10/19/2021 15:44:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 0
10/19/2021 15:51:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_ds_mine', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', dev_memory='exp_results/data_streams/mrqa.nq_train.memory.jsonl', dev_stream='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', init_memory_size=10000, learning_rate=1e-05, local_adapt_lr=1e-05, long_term_delta=False, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', mir_buffer_size=256, negative_size=8, num_adapt_epochs=1, num_beams=4, num_rounds=1, num_threads_eval=0, num_train_epochs=3.0, output_supervision=None, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, positive_size=8, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, save_all_hiddens=False, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, train_stream_episode_size=16, train_stream_length=100, upstream_data_file='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', upstream_data_prediction_file='bug_data/mrqa_naturalquestions_train.predictions.jsonl', use_dev_stream=True, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 15:51:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 15:51:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 15:51:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 15:51:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 15:51:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 15:51:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 15:51:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 15:51:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 15:51:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Starting Round 0 ....
10/19/2021 15:51:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Active Seed = 9505
10/19/2021 15:51:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 15:51:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Initial memory size: 10000
10/19/2021 15:51:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Not creating the replay-stream for evaluation.
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ......
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=3.0, overtime_ckpt_dir=None, save_all_ckpts=0, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Debugger Setup ...... Done!
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start Mining Distant Supervision (as online debugging).
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Number of Batches of Data: 100
10/19/2021 15:51:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Data Batch Size: 16;
10/19/2021 15:52:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Timecode: 0
10/19/2021 15:52:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Start bug-fixing .... Done!
10/19/2021 15:52:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Randomly retrieve from the memory. `query_examples` not used
10/19/2021 16:09:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:09:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:09:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:09:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:09:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:09:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:09:39 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:09:39 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:09:39 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:09:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:09:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:09:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:10:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:10:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:10:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:10:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:10:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:10:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:10:33 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:10:33 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:10:33 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:10:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:10:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:10:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:10:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:10:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:10:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:10:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:10:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:10:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:10:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:11:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:11:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:11:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:11:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:11:49 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:11:49 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:11:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:11:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:11:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:11:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:11:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:11:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:11:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:11:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:11:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:13:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:13:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:13:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:13:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:13:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:13:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:13:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:13:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:13:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:13:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:13:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:13:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:13:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:13:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:13:32 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:13:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:13:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:13:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:13:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:13:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:13:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:13:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:13:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:13:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:15:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:15:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:15:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:15:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:15:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:15:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:15:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:15:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:15:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:15:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:15:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 16:16:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:16:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:16:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:16:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:16:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:16:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:16:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:16:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:16:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:16:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:16:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:16:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 16:21:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:21:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:21:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:21:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:21:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:21:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:21:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:21:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:21:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:21:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:21:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:21:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 16:29:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:29:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:29:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:29:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:29:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:29:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:29:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:29:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:29:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:29:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:29:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:29:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 16:32:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:32:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:32:02 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:32:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:32:03 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:32:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:32:04 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:32:04 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:32:04 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:32:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:32:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:32:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 16:33:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 16:33:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:33:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:33:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 16:33:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 16:33:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 16:33:52 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 16:33:52 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 16:33:52 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 16:33:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 16:33:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 16:33:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 17:02:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:02:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:02:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:02:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:02:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:02:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:02:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:02:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:02:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:02:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:04:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:04:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:04:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:04:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:04:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:04:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:04:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:04:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:04:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:04:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:04:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:04:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:04:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:04:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:04:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:04:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:04:44 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:04:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:04:45 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:04:45 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:04:45 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:04:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:04:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:04:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:05:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:05:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:05:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:05:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:05:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:05:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:05:51 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:05:51 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:05:51 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:05:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:05:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:05:57 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:06:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:06:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:06:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:06:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:06:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:06:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:06:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:06:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:06:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:06:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:06:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:06:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:08:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:08:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:08:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:08:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:08:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:08:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:08:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:08:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:08:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:08:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:08:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:08:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:09:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:09:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:09:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:09:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:09:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:09:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:09:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:09:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:09:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:09:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:09:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:09:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:09:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:09:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:09:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:09:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:09:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:09:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:09:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:09:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:09:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:09:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:09:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:09:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:11:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:11:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:11:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:11:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:11:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:11:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:11:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:11:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:11:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:11:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:11:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:11:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Load the cache to exp_results/data_streams/bart_index.init_memory.pkl
10/19/2021 17:26:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:26:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:26:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:26:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:26:33 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:26:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:26:34 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:26:34 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:26:34 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:26:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:26:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:27:03 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:27:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:27:04 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:27:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:27:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:27:05 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:27:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:27:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:27:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:27:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:27:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:27:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:27:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:27:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:27:59 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:28:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:28:00 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:28:00 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:28:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:28:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:28:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:28:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:28:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:28:09 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:29:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:29:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:29:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:29:12 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:29:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:29:13 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:29:13 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:29:13 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:29:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:29:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:29:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:36:04 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:36:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:36:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:36:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:36:05 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:36:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:36:06 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:36:06 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:36:06 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:36:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:36:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:36:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:38:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:38:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:38:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:38:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:38:26 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:38:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:38:27 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:38:27 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:38:27 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:38:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:38:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:38:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:39:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:39:22 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:39:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:39:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:39:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:39:24 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:39:24 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:39:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:39:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:39:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:42:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:42:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:42:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:42:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:42:31 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:42:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:42:32 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:42:32 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:42:32 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:42:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:42:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:42:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:45:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:45:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:45:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:45:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:45:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:45:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:45:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:45:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:45:43 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:45:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:45:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:45:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:47:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:47:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:47:37 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:47:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:47:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:47:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:47:39 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:47:39 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:47:39 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:47:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:47:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:47:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 17:48:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:48:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:48:15 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:48:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:48:16 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:48:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:48:17 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:48:17 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:48:17 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:48:21 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:48:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:48:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 17:48:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:48:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:48:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:48:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:48:54 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:48:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:48:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:48:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:48:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:48:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:49:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:49:01 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 17:49:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:49:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:49:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:49:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:49:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:49:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:49:25 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:49:25 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:49:25 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:49:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:49:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:49:31 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 17:50:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:50:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:50:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:50:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:50:27 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:50:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:50:28 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:50:28 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:50:28 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:50:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:50:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:50:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 17:59:34 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 17:59:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:59:34 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:59:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 17:59:35 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 17:59:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 17:59:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 17:59:36 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 17:59:36 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 17:59:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 17:59:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 17:59:42 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 18:00:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:00:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:00:42 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:00:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:00:43 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:00:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:00:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:00:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:00:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:00:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:00:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:00:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 18:01:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:01:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:01:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:01:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:01:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:01:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:01:18 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:01:18 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:01:18 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:01:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:01:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:01:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:02:06 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:02:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:02:06 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:02:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:02:07 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:02:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:02:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:02:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:02:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:02:12 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:02:14 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:02:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:09:40 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:09:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:09:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:09:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:09:41 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:09:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:09:42 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:09:42 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:09:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:09:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:09:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:09:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:11:07 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:11:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:11:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:11:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:11:08 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:11:08 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:11:09 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:11:09 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:11:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:11:13 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:11:15 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:11:16 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:11:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:11:48 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:11:48 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:11:48 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:11:48 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:11:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:11:49 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:11:49 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:11:49 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:11:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:11:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:11:56 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:13:24 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:13:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:13:24 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:13:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:13:25 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:13:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:13:26 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:13:26 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:13:26 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:13:30 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:13:32 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:13:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:14:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:14:45 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:14:45 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:14:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:14:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:14:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:14:46 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:14:46 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:14:47 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:14:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:14:52 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:14:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:15:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:15:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:15:50 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:15:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:15:51 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:15:51 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:15:52 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:15:52 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:15:52 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:15:55 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:15:58 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:15:59 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:30:38 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:30:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:30:38 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:30:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:30:39 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:30:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:30:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:30:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:30:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:30:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:30:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:30:48 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:35:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:35:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:35:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:35:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:35:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:35:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:35:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:35:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:35:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:35:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:35:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:35:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:41:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:41:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:41:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:41:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:41:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:41:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:41:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:41:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:41:21 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:41:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:41:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:41:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:41:39 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:41:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:41:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:41:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:41:40 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:41:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:41:41 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:41:41 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:41:42 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:41:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:41:47 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:41:49 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:43:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:43:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:43:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:43:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:43:36 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:43:36 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:43:37 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:43:37 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:43:37 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:43:41 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:43:43 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:43:45 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:45:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:45:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:45:28 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:45:29 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:45:29 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:45:29 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:45:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:45:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:45:30 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:45:33 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:45:35 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:45:37 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:47:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:47:45 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:47:45 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:47:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:47:46 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:47:46 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:47:47 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:47:47 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:47:47 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:47:50 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:47:53 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:47:54 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:50:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:50:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:50:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:50:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:50:20 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:50:20 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:50:21 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:50:21 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:50:21 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:50:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:50:27 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:50:28 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:51:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:51:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:51:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:51:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:51:19 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:51:19 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:51:20 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:51:20 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:51:20 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:51:23 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:51:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:51:26 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 88251 examples.
10/19/2021 18:55:10 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:55:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:55:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:55:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:55:11 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:55:11 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:55:12 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:55:12 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:55:12 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:55:17 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Namespace(adam_epsilon=1e-08, adapter_dim=32, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', cl_method_name='simple_cl', current_thread_id=None, data_stream_json_path='bug_data/mrqa_naturalquestions_dev.data_stream.test.json', do_lowercase=False, ewc_gamma=1, ewc_lambda=0.5, example_encoder_name='roberta-base', freeze_embeds=False, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_index', inference_query_size=1, init_memory_cache_path='bug_data/memory_key_cache.pkl', learning_rate=1e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=-1, memory_key_encoder='facebook/bart-base', memory_path='', memory_store_rate=1.0, mir_abalation_args='none', num_adapt_epochs=1, num_beams=4, num_threads_eval=0, num_train_epochs=3.0, overtime_ckpt_dir=None, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.sampled_pass.jsonl', path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev', replay_candidate_size=8, replay_frequency=1, replay_size=8, replay_stream_json_path='bug_data/mrqa_naturalquestions_dev.replay_stream.test.json', result_file='bug_data/results.json', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', save_all_ckpts=0, seed=42, skip_instant_eval=False, stream_mode='dynamic', task_emb_dim=768, task_name='mrqa_naturalquestions', train_batch_size=8, use_mir=False, use_replay_mix=False, use_sampled_upstream=False, weight_decay=0.01)
10/19/2021 18:55:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:55:17 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:55:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/19/2021 18:55:18 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/19/2021 18:55:18 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
10/19/2021 18:55:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
10/19/2021 18:55:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

10/19/2021 18:55:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
10/19/2021 18:55:22 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
10/19/2021 18:55:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Moving to the GPUs.
10/19/2021 18:55:25 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Set up the initial memory with 10000 examples.
10/19/2021 18:56:44 - INFO - semanticdebugger.debug_algs.run_lifelong_finetune - Saved the cache to exp_results/data_streams/bart_io_index.init_memory.pkl
