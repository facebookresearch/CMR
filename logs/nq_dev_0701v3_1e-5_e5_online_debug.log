07/01/2021 08:25:52 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=None, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=None, num_beams=3, num_threads_eval=0, num_train_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result=None, predict_batch_size=16, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=1, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 08:25:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 08:25:52 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 08:25:56 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base .....
07/01/2021 08:26:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 08:26:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 08:26:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 08:26:06 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt for facebook/bart-base ..... Done!
07/01/2021 08:26:10 - INFO - __main__ - Moving to the GPUs.
07/01/2021 08:26:10 - INFO - __main__ - Debugger Setup ......
07/01/2021 08:26:10 - INFO - __main__ - debugger_args: Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, num_epochs=5.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, save_all_ckpts=1, total_steps=10000, warmup_steps=0, weight_decay=0.01) ......
07/01/2021 08:26:10 - INFO - __main__ - Debugger Setup ...... Done!
07/01/2021 08:26:10 - INFO - __main__ - Start Online Debugging
07/01/2021 08:26:10 - INFO - __main__ - Number of Batches of Bugs: 50
07/01/2021 08:26:10 - INFO - __main__ - Bug Batch Size: 20
07/01/2021 08:26:13 - INFO - __main__ - ----------Timecode: 0----------
07/01/2021 08:26:13 - INFO - __main__ - Before Bug-fixing the results on bug-batch-0 = {'EM': 0.0, 'QA-F1': 0.4711170762317054}
07/01/2021 08:26:19 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 1.0, 'QA-F1': 1.0}
07/01/2021 08:26:19 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:26:21 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:26:23 - INFO - __main__ - After Bug-fixing the results on bug-batch-0 = {'EM': 0.55, 'QA-F1': 0.827879940480371}
07/01/2021 08:26:30 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9573261919532081}
07/01/2021 08:26:30 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 16
07/01/2021 08:26:30 - INFO - __main__ - Number of em_fixed_bugs = 11; Number of f1_fixed_bugs = 13
07/01/2021 08:26:30 - INFO - __main__ - Number of em_forgotten_passes = 8.
07/01/2021 08:26:32 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_001.pt.
07/01/2021 08:26:35 - INFO - __main__ - ----------Timecode: 1----------
07/01/2021 08:26:35 - INFO - __main__ - Before Bug-fixing the results on bug-batch-1 = {'EM': 0.05, 'QA-F1': 0.4891115067727971}
07/01/2021 08:26:35 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9573261919532081}
07/01/2021 08:26:35 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:26:36 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:26:39 - INFO - __main__ - After Bug-fixing the results on bug-batch-1 = {'EM': 0.55, 'QA-F1': 0.7854568238778764}
07/01/2021 08:26:45 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9585700757575758}
07/01/2021 08:26:45 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 15
07/01/2021 08:26:45 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 10
07/01/2021 08:26:45 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:26:47 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_002.pt.
07/01/2021 08:26:49 - INFO - __main__ - ----------Timecode: 2----------
07/01/2021 08:26:49 - INFO - __main__ - Before Bug-fixing the results on bug-batch-2 = {'EM': 0.1, 'QA-F1': 0.5023809523809524}
07/01/2021 08:26:49 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9585700757575758}
07/01/2021 08:26:49 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:26:53 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:26:55 - INFO - __main__ - After Bug-fixing the results on bug-batch-2 = {'EM': 0.6, 'QA-F1': 0.8017094017094017}
07/01/2021 08:27:01 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9399889946764947}
07/01/2021 08:27:01 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 13
07/01/2021 08:27:01 - INFO - __main__ - Number of em_fixed_bugs = 11; Number of f1_fixed_bugs = 9
07/01/2021 08:27:01 - INFO - __main__ - Number of em_forgotten_passes = 4.
07/01/2021 08:27:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_003.pt.
07/01/2021 08:27:05 - INFO - __main__ - ----------Timecode: 3----------
07/01/2021 08:27:05 - INFO - __main__ - Before Bug-fixing the results on bug-batch-3 = {'EM': 0.2, 'QA-F1': 0.5236835748792271}
07/01/2021 08:27:05 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9399889946764947}
07/01/2021 08:27:05 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:27:07 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:27:10 - INFO - __main__ - After Bug-fixing the results on bug-batch-3 = {'EM': 0.55, 'QA-F1': 0.7798522167487685}
07/01/2021 08:27:16 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8568842088373338}
07/01/2021 08:27:16 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 14
07/01/2021 08:27:16 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 8
07/01/2021 08:27:16 - INFO - __main__ - Number of em_forgotten_passes = 8.
07/01/2021 08:27:18 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_004.pt.
07/01/2021 08:27:21 - INFO - __main__ - ----------Timecode: 4----------
07/01/2021 08:27:21 - INFO - __main__ - Before Bug-fixing the results on bug-batch-4 = {'EM': 0.1, 'QA-F1': 0.45361122770390727}
07/01/2021 08:27:21 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8568842088373338}
07/01/2021 08:27:21 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:27:23 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:27:25 - INFO - __main__ - After Bug-fixing the results on bug-batch-4 = {'EM': 0.5, 'QA-F1': 0.7102631578947369}
07/01/2021 08:27:31 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8710582386363637}
07/01/2021 08:27:31 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 11
07/01/2021 08:27:31 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 7
07/01/2021 08:27:31 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:27:33 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_005.pt.
07/01/2021 08:27:36 - INFO - __main__ - ----------Timecode: 5----------
07/01/2021 08:27:36 - INFO - __main__ - Before Bug-fixing the results on bug-batch-5 = {'EM': 0.05, 'QA-F1': 0.4351111111111111}
07/01/2021 08:27:36 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8710582386363637}
07/01/2021 08:27:36 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:27:38 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:27:39 - INFO - __main__ - After Bug-fixing the results on bug-batch-5 = {'EM': 0.65, 'QA-F1': 0.8223976608187135}
07/01/2021 08:27:45 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9568452380952381}
07/01/2021 08:27:45 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 15
07/01/2021 08:27:45 - INFO - __main__ - Number of em_fixed_bugs = 12; Number of f1_fixed_bugs = 13
07/01/2021 08:27:45 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:27:48 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_006.pt.
07/01/2021 08:27:50 - INFO - __main__ - ----------Timecode: 6----------
07/01/2021 08:27:50 - INFO - __main__ - Before Bug-fixing the results on bug-batch-6 = {'EM': 0.1, 'QA-F1': 0.42239055299539174}
07/01/2021 08:27:50 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.9375, 'QA-F1': 0.9568452380952381}
07/01/2021 08:27:50 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:27:52 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:27:54 - INFO - __main__ - After Bug-fixing the results on bug-batch-6 = {'EM': 0.65, 'QA-F1': 0.8093444486547934}
07/01/2021 08:28:00 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.9040371087246089}
07/01/2021 08:28:00 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 15
07/01/2021 08:28:00 - INFO - __main__ - Number of em_fixed_bugs = 11; Number of f1_fixed_bugs = 11
07/01/2021 08:28:00 - INFO - __main__ - Number of em_forgotten_passes = 8.
07/01/2021 08:28:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_007.pt.
07/01/2021 08:28:05 - INFO - __main__ - ----------Timecode: 7----------
07/01/2021 08:28:05 - INFO - __main__ - Before Bug-fixing the results on bug-batch-7 = {'EM': 0.0, 'QA-F1': 0.39447425381635903}
07/01/2021 08:28:05 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.9040371087246089}
07/01/2021 08:28:05 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:28:08 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:28:11 - INFO - __main__ - After Bug-fixing the results on bug-batch-7 = {'EM': 0.35, 'QA-F1': 0.6739072112098428}
07/01/2021 08:28:17 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8564908293990955}
07/01/2021 08:28:17 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 12
07/01/2021 08:28:17 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 8
07/01/2021 08:28:17 - INFO - __main__ - Number of em_forgotten_passes = 6.
07/01/2021 08:28:19 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_008.pt.
07/01/2021 08:28:22 - INFO - __main__ - ----------Timecode: 8----------
07/01/2021 08:28:22 - INFO - __main__ - Before Bug-fixing the results on bug-batch-8 = {'EM': 0.1, 'QA-F1': 0.36854851031321617}
07/01/2021 08:28:22 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8564908293990955}
07/01/2021 08:28:22 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:28:24 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:28:27 - INFO - __main__ - After Bug-fixing the results on bug-batch-8 = {'EM': 0.35, 'QA-F1': 0.5884180035650624}
07/01/2021 08:28:34 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8937959721729883}
07/01/2021 08:28:34 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 9
07/01/2021 08:28:34 - INFO - __main__ - Number of em_fixed_bugs = 5; Number of f1_fixed_bugs = 5
07/01/2021 08:28:34 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:28:36 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_009.pt.
07/01/2021 08:28:38 - INFO - __main__ - ----------Timecode: 9----------
07/01/2021 08:28:38 - INFO - __main__ - Before Bug-fixing the results on bug-batch-9 = {'EM': 0.3, 'QA-F1': 0.5434798534798536}
07/01/2021 08:28:38 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8937959721729883}
07/01/2021 08:28:38 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:28:40 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:28:42 - INFO - __main__ - After Bug-fixing the results on bug-batch-9 = {'EM': 0.55, 'QA-F1': 0.7483154725895198}
07/01/2021 08:28:49 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8759911963036964}
07/01/2021 08:28:49 - INFO - __main__ - Number of em_prefixed_bugs = 6; Number of f1_prefixed_bugs = 13
07/01/2021 08:28:49 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 6
07/01/2021 08:28:49 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:28:51 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_010.pt.
07/01/2021 08:28:53 - INFO - __main__ - ----------Timecode: 10----------
07/01/2021 08:28:53 - INFO - __main__ - Before Bug-fixing the results on bug-batch-10 = {'EM': 0.05, 'QA-F1': 0.3806327916565608}
07/01/2021 08:28:53 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8759911963036964}
07/01/2021 08:28:53 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:28:55 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:28:58 - INFO - __main__ - After Bug-fixing the results on bug-batch-10 = {'EM': 0.65, 'QA-F1': 0.7764864433811802}
07/01/2021 08:29:04 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8604978354978354}
07/01/2021 08:29:04 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 13
07/01/2021 08:29:04 - INFO - __main__ - Number of em_fixed_bugs = 12; Number of f1_fixed_bugs = 10
07/01/2021 08:29:04 - INFO - __main__ - Number of em_forgotten_passes = 3.
07/01/2021 08:29:06 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_011.pt.
07/01/2021 08:29:09 - INFO - __main__ - ----------Timecode: 11----------
07/01/2021 08:29:09 - INFO - __main__ - Before Bug-fixing the results on bug-batch-11 = {'EM': 0.1, 'QA-F1': 0.434610183958656}
07/01/2021 08:29:09 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8604978354978354}
07/01/2021 08:29:09 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:29:11 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:29:14 - INFO - __main__ - After Bug-fixing the results on bug-batch-11 = {'EM': 0.4, 'QA-F1': 0.7254385745833114}
07/01/2021 08:29:20 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.640625, 'QA-F1': 0.7970188231906982}
07/01/2021 08:29:20 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 13
07/01/2021 08:29:20 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 8
07/01/2021 08:29:20 - INFO - __main__ - Number of em_forgotten_passes = 8.
07/01/2021 08:29:22 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_012.pt.
07/01/2021 08:29:25 - INFO - __main__ - ----------Timecode: 12----------
07/01/2021 08:29:25 - INFO - __main__ - Before Bug-fixing the results on bug-batch-12 = {'EM': 0.15, 'QA-F1': 0.45477034503458424}
07/01/2021 08:29:25 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.640625, 'QA-F1': 0.7970188231906982}
07/01/2021 08:29:25 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:29:27 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:29:30 - INFO - __main__ - After Bug-fixing the results on bug-batch-12 = {'EM': 0.4, 'QA-F1': 0.6776484132579209}
07/01/2021 08:29:37 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.671875, 'QA-F1': 0.820530727952603}
07/01/2021 08:29:37 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 13
07/01/2021 08:29:37 - INFO - __main__ - Number of em_fixed_bugs = 5; Number of f1_fixed_bugs = 6
07/01/2021 08:29:37 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:29:39 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_013.pt.
07/01/2021 08:29:42 - INFO - __main__ - ----------Timecode: 13----------
07/01/2021 08:29:42 - INFO - __main__ - Before Bug-fixing the results on bug-batch-13 = {'EM': 0.1, 'QA-F1': 0.448316711163946}
07/01/2021 08:29:42 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.671875, 'QA-F1': 0.820530727952603}
07/01/2021 08:29:42 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:29:44 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:29:47 - INFO - __main__ - After Bug-fixing the results on bug-batch-13 = {'EM': 0.55, 'QA-F1': 0.7573215772655862}
07/01/2021 08:29:54 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.703125, 'QA-F1': 0.8021727838134087}
07/01/2021 08:29:54 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 14
07/01/2021 08:29:54 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 7
07/01/2021 08:29:54 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:29:55 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_014.pt.
07/01/2021 08:29:58 - INFO - __main__ - ----------Timecode: 14----------
07/01/2021 08:29:58 - INFO - __main__ - Before Bug-fixing the results on bug-batch-14 = {'EM': 0.0, 'QA-F1': 0.3140573648917302}
07/01/2021 08:29:58 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.703125, 'QA-F1': 0.8021727838134087}
07/01/2021 08:29:58 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:30:01 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:30:04 - INFO - __main__ - After Bug-fixing the results on bug-batch-14 = {'EM': 0.35, 'QA-F1': 0.6398359727407894}
07/01/2021 08:30:10 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8482980994699745}
07/01/2021 08:30:10 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 12
07/01/2021 08:30:10 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 9
07/01/2021 08:30:10 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:30:12 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_015.pt.
07/01/2021 08:30:14 - INFO - __main__ - ----------Timecode: 15----------
07/01/2021 08:30:14 - INFO - __main__ - Before Bug-fixing the results on bug-batch-15 = {'EM': 0.1, 'QA-F1': 0.30733607607749486}
07/01/2021 08:30:14 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8482980994699745}
07/01/2021 08:30:14 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:30:17 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:30:19 - INFO - __main__ - After Bug-fixing the results on bug-batch-15 = {'EM': 0.4, 'QA-F1': 0.6126887732150891}
07/01/2021 08:30:26 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8885127459346209}
07/01/2021 08:30:26 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 10
07/01/2021 08:30:26 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 8
07/01/2021 08:30:26 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:30:29 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_016.pt.
07/01/2021 08:30:31 - INFO - __main__ - ----------Timecode: 16----------
07/01/2021 08:30:31 - INFO - __main__ - Before Bug-fixing the results on bug-batch-16 = {'EM': 0.05, 'QA-F1': 0.3168874449195327}
07/01/2021 08:30:31 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8885127459346209}
07/01/2021 08:30:31 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:30:34 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:30:37 - INFO - __main__ - After Bug-fixing the results on bug-batch-16 = {'EM': 0.4, 'QA-F1': 0.666076987475152}
07/01/2021 08:30:43 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.917028370934621}
07/01/2021 08:30:43 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 13
07/01/2021 08:30:43 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 8
07/01/2021 08:30:43 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:30:45 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_017.pt.
07/01/2021 08:30:48 - INFO - __main__ - ----------Timecode: 17----------
07/01/2021 08:30:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-17 = {'EM': 0.1, 'QA-F1': 0.31545121037862967}
07/01/2021 08:30:48 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.917028370934621}
07/01/2021 08:30:48 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:30:50 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:30:53 - INFO - __main__ - After Bug-fixing the results on bug-batch-17 = {'EM': 0.25, 'QA-F1': 0.46376999344741276}
07/01/2021 08:30:59 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8450842993811744}
07/01/2021 08:30:59 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 8
07/01/2021 08:30:59 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 5
07/01/2021 08:30:59 - INFO - __main__ - Number of em_forgotten_passes = 8.
07/01/2021 08:31:01 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_018.pt.
07/01/2021 08:31:04 - INFO - __main__ - ----------Timecode: 18----------
07/01/2021 08:31:04 - INFO - __main__ - Before Bug-fixing the results on bug-batch-18 = {'EM': 0.05, 'QA-F1': 0.33692809795111583}
07/01/2021 08:31:04 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8450842993811744}
07/01/2021 08:31:04 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:31:07 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:31:10 - INFO - __main__ - After Bug-fixing the results on bug-batch-18 = {'EM': 0.2, 'QA-F1': 0.5098656778004604}
07/01/2021 08:31:16 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.917714414841431}
07/01/2021 08:31:16 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 8
07/01/2021 08:31:16 - INFO - __main__ - Number of em_fixed_bugs = 3; Number of f1_fixed_bugs = 3
07/01/2021 08:31:16 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:31:19 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_019.pt.
07/01/2021 08:31:22 - INFO - __main__ - ----------Timecode: 19----------
07/01/2021 08:31:22 - INFO - __main__ - Before Bug-fixing the results on bug-batch-19 = {'EM': 0.05, 'QA-F1': 0.23369950152186997}
07/01/2021 08:31:22 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.917714414841431}
07/01/2021 08:31:22 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:31:24 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:31:26 - INFO - __main__ - After Bug-fixing the results on bug-batch-19 = {'EM': 0.4, 'QA-F1': 0.579000387702974}
07/01/2021 08:31:33 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9396256633151794}
07/01/2021 08:31:33 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 11
07/01/2021 08:31:33 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 9
07/01/2021 08:31:33 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:31:35 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_020.pt.
07/01/2021 08:31:38 - INFO - __main__ - ----------Timecode: 20----------
07/01/2021 08:31:38 - INFO - __main__ - Before Bug-fixing the results on bug-batch-20 = {'EM': 0.05, 'QA-F1': 0.18537303769501912}
07/01/2021 08:31:38 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9396256633151794}
07/01/2021 08:31:38 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:31:40 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:31:43 - INFO - __main__ - After Bug-fixing the results on bug-batch-20 = {'EM': 0.5, 'QA-F1': 0.6159798534798535}
07/01/2021 08:31:49 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9367847542242703}
07/01/2021 08:31:49 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 11
07/01/2021 08:31:49 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 10
07/01/2021 08:31:49 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:31:51 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_021.pt.
07/01/2021 08:31:54 - INFO - __main__ - ----------Timecode: 21----------
07/01/2021 08:31:54 - INFO - __main__ - Before Bug-fixing the results on bug-batch-21 = {'EM': 0.1, 'QA-F1': 0.3010778926902836}
07/01/2021 08:31:54 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9367847542242703}
07/01/2021 08:31:54 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:31:56 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:31:59 - INFO - __main__ - After Bug-fixing the results on bug-batch-21 = {'EM': 0.4, 'QA-F1': 0.6154520736290685}
07/01/2021 08:32:05 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.884701420890937}
07/01/2021 08:32:05 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 12
07/01/2021 08:32:05 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 9
07/01/2021 08:32:05 - INFO - __main__ - Number of em_forgotten_passes = 4.
07/01/2021 08:32:07 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_022.pt.
07/01/2021 08:32:10 - INFO - __main__ - ----------Timecode: 22----------
07/01/2021 08:32:10 - INFO - __main__ - Before Bug-fixing the results on bug-batch-22 = {'EM': 0.15, 'QA-F1': 0.3572669515967797}
07/01/2021 08:32:10 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.884701420890937}
07/01/2021 08:32:10 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:32:12 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:32:15 - INFO - __main__ - After Bug-fixing the results on bug-batch-22 = {'EM': 0.55, 'QA-F1': 0.7025857879032321}
07/01/2021 08:32:21 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.845399955946831}
07/01/2021 08:32:21 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 14
07/01/2021 08:32:21 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 9
07/01/2021 08:32:21 - INFO - __main__ - Number of em_forgotten_passes = 7.
07/01/2021 08:32:23 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_023.pt.
07/01/2021 08:32:26 - INFO - __main__ - ----------Timecode: 23----------
07/01/2021 08:32:26 - INFO - __main__ - Before Bug-fixing the results on bug-batch-23 = {'EM': 0.0, 'QA-F1': 0.18388964291595872}
07/01/2021 08:32:26 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.845399955946831}
07/01/2021 08:32:26 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:32:29 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:32:31 - INFO - __main__ - After Bug-fixing the results on bug-batch-23 = {'EM': 0.2, 'QA-F1': 0.4584892798050693}
07/01/2021 08:32:38 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8953047498536411}
07/01/2021 08:32:38 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 8
07/01/2021 08:32:38 - INFO - __main__ - Number of em_fixed_bugs = 4; Number of f1_fixed_bugs = 5
07/01/2021 08:32:38 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:32:41 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_024.pt.
07/01/2021 08:32:44 - INFO - __main__ - ----------Timecode: 24----------
07/01/2021 08:32:44 - INFO - __main__ - Before Bug-fixing the results on bug-batch-24 = {'EM': 0.1, 'QA-F1': 0.18996480416887146}
07/01/2021 08:32:44 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8953047498536411}
07/01/2021 08:32:44 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:32:46 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:32:49 - INFO - __main__ - After Bug-fixing the results on bug-batch-24 = {'EM': 0.4, 'QA-F1': 0.54620238597231}
07/01/2021 08:32:55 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.871991257790149}
07/01/2021 08:32:55 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 11
07/01/2021 08:32:55 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 9
07/01/2021 08:32:55 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:32:58 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_025.pt.
07/01/2021 08:33:01 - INFO - __main__ - ----------Timecode: 25----------
07/01/2021 08:33:01 - INFO - __main__ - Before Bug-fixing the results on bug-batch-25 = {'EM': 0.05, 'QA-F1': 0.25473934707898355}
07/01/2021 08:33:01 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.871991257790149}
07/01/2021 08:33:01 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:33:03 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:33:06 - INFO - __main__ - After Bug-fixing the results on bug-batch-25 = {'EM': 0.3, 'QA-F1': 0.6854874831527645}
07/01/2021 08:33:12 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8331468990239153}
07/01/2021 08:33:12 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 14
07/01/2021 08:33:12 - INFO - __main__ - Number of em_fixed_bugs = 5; Number of f1_fixed_bugs = 10
07/01/2021 08:33:12 - INFO - __main__ - Number of em_forgotten_passes = 7.
07/01/2021 08:33:14 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_026.pt.
07/01/2021 08:33:17 - INFO - __main__ - ----------Timecode: 26----------
07/01/2021 08:33:17 - INFO - __main__ - Before Bug-fixing the results on bug-batch-26 = {'EM': 0.05, 'QA-F1': 0.07675058275058275}
07/01/2021 08:33:17 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.71875, 'QA-F1': 0.8331468990239153}
07/01/2021 08:33:17 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:33:20 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:33:23 - INFO - __main__ - After Bug-fixing the results on bug-batch-26 = {'EM': 0.5, 'QA-F1': 0.5649350649350648}
07/01/2021 08:33:29 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9231459624604785}
07/01/2021 08:33:29 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 12
07/01/2021 08:33:29 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 11
07/01/2021 08:33:29 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:33:31 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_027.pt.
07/01/2021 08:33:33 - INFO - __main__ - ----------Timecode: 27----------
07/01/2021 08:33:33 - INFO - __main__ - Before Bug-fixing the results on bug-batch-27 = {'EM': 0.15, 'QA-F1': 0.2324561403508772}
07/01/2021 08:33:33 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9231459624604785}
07/01/2021 08:33:33 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:33:35 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:33:37 - INFO - __main__ - After Bug-fixing the results on bug-batch-27 = {'EM': 0.65, 'QA-F1': 0.7452380952380953}
07/01/2021 08:33:43 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9105044261294262}
07/01/2021 08:33:43 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 15
07/01/2021 08:33:43 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 11
07/01/2021 08:33:43 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:33:45 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_028.pt.
07/01/2021 08:33:47 - INFO - __main__ - ----------Timecode: 28----------
07/01/2021 08:33:47 - INFO - __main__ - Before Bug-fixing the results on bug-batch-28 = {'EM': 0.1, 'QA-F1': 0.1287037037037037}
07/01/2021 08:33:47 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9105044261294262}
07/01/2021 08:33:47 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:33:50 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:33:52 - INFO - __main__ - After Bug-fixing the results on bug-batch-28 = {'EM': 0.55, 'QA-F1': 0.5785714285714285}
07/01/2021 08:33:58 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.916580815018315}
07/01/2021 08:33:58 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 12
07/01/2021 08:33:58 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 9
07/01/2021 08:33:58 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:34:01 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_029.pt.
07/01/2021 08:34:03 - INFO - __main__ - ----------Timecode: 29----------
07/01/2021 08:34:03 - INFO - __main__ - Before Bug-fixing the results on bug-batch-29 = {'EM': 0.1, 'QA-F1': 0.13076923076923075}
07/01/2021 08:34:03 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.916580815018315}
07/01/2021 08:34:03 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:34:06 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:34:08 - INFO - __main__ - After Bug-fixing the results on bug-batch-29 = {'EM': 0.45, 'QA-F1': 0.4756470588235294}
07/01/2021 08:34:14 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.916580815018315}
07/01/2021 08:34:14 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 9
07/01/2021 08:34:14 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 7
07/01/2021 08:34:14 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:34:17 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_030.pt.
07/01/2021 08:34:19 - INFO - __main__ - ----------Timecode: 30----------
07/01/2021 08:34:19 - INFO - __main__ - Before Bug-fixing the results on bug-batch-30 = {'EM': 0.05, 'QA-F1': 0.05}
07/01/2021 08:34:19 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.916580815018315}
07/01/2021 08:34:19 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:34:22 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:34:23 - INFO - __main__ - After Bug-fixing the results on bug-batch-30 = {'EM': 0.55, 'QA-F1': 0.5958333333333333}
07/01/2021 08:34:30 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.924393315018315}
07/01/2021 08:34:30 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 12
07/01/2021 08:34:30 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 11
07/01/2021 08:34:30 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:34:32 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_031.pt.
07/01/2021 08:34:35 - INFO - __main__ - ----------Timecode: 31----------
07/01/2021 08:34:35 - INFO - __main__ - Before Bug-fixing the results on bug-batch-31 = {'EM': 0.2, 'QA-F1': 0.24500000000000002}
07/01/2021 08:34:35 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.924393315018315}
07/01/2021 08:34:35 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:34:38 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:34:39 - INFO - __main__ - After Bug-fixing the results on bug-batch-31 = {'EM': 0.8, 'QA-F1': 0.8}
07/01/2021 08:34:46 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9099702380952381}
07/01/2021 08:34:46 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 16
07/01/2021 08:34:46 - INFO - __main__ - Number of em_fixed_bugs = 12; Number of f1_fixed_bugs = 11
07/01/2021 08:34:46 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:34:48 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_032.pt.
07/01/2021 08:34:50 - INFO - __main__ - ----------Timecode: 32----------
07/01/2021 08:34:50 - INFO - __main__ - Before Bug-fixing the results on bug-batch-32 = {'EM': 0.1, 'QA-F1': 0.10976190476190477}
07/01/2021 08:34:50 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.875, 'QA-F1': 0.9099702380952381}
07/01/2021 08:34:50 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:34:52 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:34:54 - INFO - __main__ - After Bug-fixing the results on bug-batch-32 = {'EM': 0.85, 'QA-F1': 0.85}
07/01/2021 08:35:01 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9166753291753291}
07/01/2021 08:35:01 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 17
07/01/2021 08:35:01 - INFO - __main__ - Number of em_fixed_bugs = 15; Number of f1_fixed_bugs = 15
07/01/2021 08:35:01 - INFO - __main__ - Number of em_forgotten_passes = 3.
07/01/2021 08:35:03 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_033.pt.
07/01/2021 08:35:05 - INFO - __main__ - ----------Timecode: 33----------
07/01/2021 08:35:05 - INFO - __main__ - Before Bug-fixing the results on bug-batch-33 = {'EM': 0.15, 'QA-F1': 0.20833333333333331}
07/01/2021 08:35:05 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.9166753291753291}
07/01/2021 08:35:05 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:35:07 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:35:09 - INFO - __main__ - After Bug-fixing the results on bug-batch-33 = {'EM': 0.7, 'QA-F1': 0.792463768115942}
07/01/2021 08:35:15 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.9080846255241417}
07/01/2021 08:35:15 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 16
07/01/2021 08:35:15 - INFO - __main__ - Number of em_fixed_bugs = 11; Number of f1_fixed_bugs = 11
07/01/2021 08:35:15 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:35:17 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_034.pt.
07/01/2021 08:35:19 - INFO - __main__ - ----------Timecode: 34----------
07/01/2021 08:35:19 - INFO - __main__ - Before Bug-fixing the results on bug-batch-34 = {'EM': 0.1, 'QA-F1': 0.125}
07/01/2021 08:35:19 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.9080846255241417}
07/01/2021 08:35:19 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:35:22 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:35:25 - INFO - __main__ - After Bug-fixing the results on bug-batch-34 = {'EM': 0.6, 'QA-F1': 0.6058823529411764}
07/01/2021 08:35:31 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8915481671908083}
07/01/2021 08:35:31 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 12
07/01/2021 08:35:31 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 9
07/01/2021 08:35:31 - INFO - __main__ - Number of em_forgotten_passes = 4.
07/01/2021 08:35:33 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_035.pt.
07/01/2021 08:35:36 - INFO - __main__ - ----------Timecode: 35----------
07/01/2021 08:35:36 - INFO - __main__ - Before Bug-fixing the results on bug-batch-35 = {'EM': 0.1, 'QA-F1': 0.24734848484848482}
07/01/2021 08:35:36 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.796875, 'QA-F1': 0.8915481671908083}
07/01/2021 08:35:36 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:35:39 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:35:41 - INFO - __main__ - After Bug-fixing the results on bug-batch-35 = {'EM': 0.6, 'QA-F1': 0.691111111111111}
07/01/2021 08:35:47 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8530577947160609}
07/01/2021 08:35:47 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 14
07/01/2021 08:35:47 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 8
07/01/2021 08:35:47 - INFO - __main__ - Number of em_forgotten_passes = 4.
07/01/2021 08:35:49 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_036.pt.
07/01/2021 08:35:51 - INFO - __main__ - ----------Timecode: 36----------
07/01/2021 08:35:51 - INFO - __main__ - Before Bug-fixing the results on bug-batch-36 = {'EM': 0.15, 'QA-F1': 0.24471153846153845}
07/01/2021 08:35:51 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8530577947160609}
07/01/2021 08:35:51 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:35:54 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:35:57 - INFO - __main__ - After Bug-fixing the results on bug-batch-36 = {'EM': 0.5, 'QA-F1': 0.5421900161030596}
07/01/2021 08:36:02 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8964657738095239}
07/01/2021 08:36:02 - INFO - __main__ - Number of em_prefixed_bugs = 3; Number of f1_prefixed_bugs = 11
07/01/2021 08:36:02 - INFO - __main__ - Number of em_fixed_bugs = 7; Number of f1_fixed_bugs = 6
07/01/2021 08:36:02 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:36:05 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_037.pt.
07/01/2021 08:36:07 - INFO - __main__ - ----------Timecode: 37----------
07/01/2021 08:36:07 - INFO - __main__ - Before Bug-fixing the results on bug-batch-37 = {'EM': 0.0, 'QA-F1': 0.0998329156223893}
07/01/2021 08:36:07 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8964657738095239}
07/01/2021 08:36:07 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:36:10 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:36:12 - INFO - __main__ - After Bug-fixing the results on bug-batch-37 = {'EM': 0.8, 'QA-F1': 0.8333333333333333}
07/01/2021 08:36:18 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8975074404761905}
07/01/2021 08:36:18 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 17
07/01/2021 08:36:18 - INFO - __main__ - Number of em_fixed_bugs = 16; Number of f1_fixed_bugs = 14
07/01/2021 08:36:18 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:36:21 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_038.pt.
07/01/2021 08:36:23 - INFO - __main__ - ----------Timecode: 38----------
07/01/2021 08:36:23 - INFO - __main__ - Before Bug-fixing the results on bug-batch-38 = {'EM': 0.1, 'QA-F1': 0.1}
07/01/2021 08:36:23 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8975074404761905}
07/01/2021 08:36:23 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:36:27 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:36:29 - INFO - __main__ - After Bug-fixing the results on bug-batch-38 = {'EM': 0.5, 'QA-F1': 0.6011904761904762}
07/01/2021 08:36:35 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9192708333333333}
07/01/2021 08:36:35 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 12
07/01/2021 08:36:35 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 10
07/01/2021 08:36:35 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:36:38 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_039.pt.
07/01/2021 08:36:40 - INFO - __main__ - ----------Timecode: 39----------
07/01/2021 08:36:40 - INFO - __main__ - Before Bug-fixing the results on bug-batch-39 = {'EM': 0.1, 'QA-F1': 0.18548387096774194}
07/01/2021 08:36:40 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9192708333333333}
07/01/2021 08:36:40 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:36:42 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:36:44 - INFO - __main__ - After Bug-fixing the results on bug-batch-39 = {'EM': 0.5, 'QA-F1': 0.5912643678160919}
07/01/2021 08:36:49 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9505208333333333}
07/01/2021 08:36:49 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 11
07/01/2021 08:36:49 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 8
07/01/2021 08:36:49 - INFO - __main__ - Number of em_forgotten_passes = 0.
07/01/2021 08:36:51 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_040.pt.
07/01/2021 08:36:54 - INFO - __main__ - ----------Timecode: 40----------
07/01/2021 08:36:54 - INFO - __main__ - Before Bug-fixing the results on bug-batch-40 = {'EM': 0.05, 'QA-F1': 0.06}
07/01/2021 08:36:54 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.921875, 'QA-F1': 0.9505208333333333}
07/01/2021 08:36:54 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:36:58 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:37:00 - INFO - __main__ - After Bug-fixing the results on bug-batch-40 = {'EM': 0.45, 'QA-F1': 0.5387878787878788}
07/01/2021 08:37:05 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9192708333333333}
07/01/2021 08:37:05 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 11
07/01/2021 08:37:05 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 10
07/01/2021 08:37:05 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:37:07 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_041.pt.
07/01/2021 08:37:09 - INFO - __main__ - ----------Timecode: 41----------
07/01/2021 08:37:09 - INFO - __main__ - Before Bug-fixing the results on bug-batch-41 = {'EM': 0.1, 'QA-F1': 0.14761904761904762}
07/01/2021 08:37:09 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.890625, 'QA-F1': 0.9192708333333333}
07/01/2021 08:37:09 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:37:11 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:37:13 - INFO - __main__ - After Bug-fixing the results on bug-batch-41 = {'EM': 0.55, 'QA-F1': 0.7189177489177488}
07/01/2021 08:37:18 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8958333333333333}
07/01/2021 08:37:18 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 15
07/01/2021 08:37:18 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 12
07/01/2021 08:37:18 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:37:19 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_042.pt.
07/01/2021 08:37:21 - INFO - __main__ - ----------Timecode: 42----------
07/01/2021 08:37:21 - INFO - __main__ - Before Bug-fixing the results on bug-batch-42 = {'EM': 0.1, 'QA-F1': 0.21142857142857144}
07/01/2021 08:37:21 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.859375, 'QA-F1': 0.8958333333333333}
07/01/2021 08:37:21 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:37:24 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:37:26 - INFO - __main__ - After Bug-fixing the results on bug-batch-42 = {'EM': 0.5, 'QA-F1': 0.6301428571428571}
07/01/2021 08:37:31 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.897235576923077}
07/01/2021 08:37:31 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 13
07/01/2021 08:37:31 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 9
07/01/2021 08:37:31 - INFO - __main__ - Number of em_forgotten_passes = 3.
07/01/2021 08:37:33 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_043.pt.
07/01/2021 08:37:35 - INFO - __main__ - ----------Timecode: 43----------
07/01/2021 08:37:35 - INFO - __main__ - Before Bug-fixing the results on bug-batch-43 = {'EM': 0.0, 'QA-F1': 0.05694444444444444}
07/01/2021 08:37:35 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.897235576923077}
07/01/2021 08:37:35 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:37:38 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:37:40 - INFO - __main__ - After Bug-fixing the results on bug-batch-43 = {'EM': 0.5, 'QA-F1': 0.5777777777777777}
07/01/2021 08:37:45 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8894230769230769}
07/01/2021 08:37:45 - INFO - __main__ - Number of em_prefixed_bugs = 0; Number of f1_prefixed_bugs = 12
07/01/2021 08:37:45 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 11
07/01/2021 08:37:45 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:37:47 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_044.pt.
07/01/2021 08:37:49 - INFO - __main__ - ----------Timecode: 44----------
07/01/2021 08:37:49 - INFO - __main__ - Before Bug-fixing the results on bug-batch-44 = {'EM': 0.2, 'QA-F1': 0.25333333333333335}
07/01/2021 08:37:49 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.8125, 'QA-F1': 0.8894230769230769}
07/01/2021 08:37:49 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:37:52 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:37:54 - INFO - __main__ - After Bug-fixing the results on bug-batch-44 = {'EM': 0.75, 'QA-F1': 0.8366666666666667}
07/01/2021 08:37:59 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8998397435897436}
07/01/2021 08:37:59 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 17
07/01/2021 08:37:59 - INFO - __main__ - Number of em_fixed_bugs = 11; Number of f1_fixed_bugs = 12
07/01/2021 08:37:59 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:38:01 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_045.pt.
07/01/2021 08:38:04 - INFO - __main__ - ----------Timecode: 45----------
07/01/2021 08:38:04 - INFO - __main__ - Before Bug-fixing the results on bug-batch-45 = {'EM': 0.2, 'QA-F1': 0.22222222222222224}
07/01/2021 08:38:04 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.84375, 'QA-F1': 0.8998397435897436}
07/01/2021 08:38:04 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:38:06 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:38:08 - INFO - __main__ - After Bug-fixing the results on bug-batch-45 = {'EM': 0.6, 'QA-F1': 0.6761111111111111}
07/01/2021 08:38:13 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8282051282051281}
07/01/2021 08:38:13 - INFO - __main__ - Number of em_prefixed_bugs = 4; Number of f1_prefixed_bugs = 14
07/01/2021 08:38:13 - INFO - __main__ - Number of em_fixed_bugs = 8; Number of f1_fixed_bugs = 10
07/01/2021 08:38:13 - INFO - __main__ - Number of em_forgotten_passes = 6.
07/01/2021 08:38:15 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_046.pt.
07/01/2021 08:38:18 - INFO - __main__ - ----------Timecode: 46----------
07/01/2021 08:38:18 - INFO - __main__ - Before Bug-fixing the results on bug-batch-46 = {'EM': 0.05, 'QA-F1': 0.06428571428571428}
07/01/2021 08:38:18 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.75, 'QA-F1': 0.8282051282051281}
07/01/2021 08:38:18 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:38:21 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:38:23 - INFO - __main__ - After Bug-fixing the results on bug-batch-46 = {'EM': 0.65, 'QA-F1': 0.65}
07/01/2021 08:38:29 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8310821123321124}
07/01/2021 08:38:29 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 13
07/01/2021 08:38:29 - INFO - __main__ - Number of em_fixed_bugs = 12; Number of f1_fixed_bugs = 12
07/01/2021 08:38:29 - INFO - __main__ - Number of em_forgotten_passes = 4.
07/01/2021 08:38:31 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_047.pt.
07/01/2021 08:38:33 - INFO - __main__ - ----------Timecode: 47----------
07/01/2021 08:38:33 - INFO - __main__ - Before Bug-fixing the results on bug-batch-47 = {'EM': 0.05, 'QA-F1': 0.09714285714285716}
07/01/2021 08:38:33 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.734375, 'QA-F1': 0.8310821123321124}
07/01/2021 08:38:33 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:38:35 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:38:37 - INFO - __main__ - After Bug-fixing the results on bug-batch-47 = {'EM': 0.5, 'QA-F1': 0.5375776397515528}
07/01/2021 08:38:43 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8545940170940172}
07/01/2021 08:38:43 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 11
07/01/2021 08:38:43 - INFO - __main__ - Number of em_fixed_bugs = 9; Number of f1_fixed_bugs = 9
07/01/2021 08:38:43 - INFO - __main__ - Number of em_forgotten_passes = 1.
07/01/2021 08:38:45 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_048.pt.
07/01/2021 08:38:48 - INFO - __main__ - ----------Timecode: 48----------
07/01/2021 08:38:48 - INFO - __main__ - Before Bug-fixing the results on bug-batch-48 = {'EM': 0.05, 'QA-F1': 0.11054159462828195}
07/01/2021 08:38:48 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.765625, 'QA-F1': 0.8545940170940172}
07/01/2021 08:38:48 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:38:50 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:38:52 - INFO - __main__ - After Bug-fixing the results on bug-batch-48 = {'EM': 0.35, 'QA-F1': 0.49101349630761393}
07/01/2021 08:38:57 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8455605158730158}
07/01/2021 08:38:57 - INFO - __main__ - Number of em_prefixed_bugs = 1; Number of f1_prefixed_bugs = 9
07/01/2021 08:38:57 - INFO - __main__ - Number of em_fixed_bugs = 6; Number of f1_fixed_bugs = 8
07/01/2021 08:38:57 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:38:59 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_049.pt.
07/01/2021 08:39:02 - INFO - __main__ - ----------Timecode: 49----------
07/01/2021 08:39:02 - INFO - __main__ - Before Bug-fixing the results on bug-batch-49 = {'EM': 0.1, 'QA-F1': 0.16638888888888886}
07/01/2021 08:39:02 - INFO - __main__ - Before Bug-fixing the results on the sampled pass cases = {'EM': 0.78125, 'QA-F1': 0.8455605158730158}
07/01/2021 08:39:02 - INFO - __main__ - Start bug-fixing ....
07/01/2021 08:39:05 - INFO - __main__ - Start bug-fixing .... Done!
07/01/2021 08:39:07 - INFO - __main__ - After Bug-fixing the results on bug-batch-49 = {'EM': 0.6, 'QA-F1': 0.686130717108978}
07/01/2021 08:39:12 - INFO - __main__ - After Bug-fixing the results on the sampled pass cases = {'EM': 0.828125, 'QA-F1': 0.8871678743961353}
07/01/2021 08:39:12 - INFO - __main__ - Number of em_prefixed_bugs = 2; Number of f1_prefixed_bugs = 14
07/01/2021 08:39:12 - INFO - __main__ - Number of em_fixed_bugs = 10; Number of f1_fixed_bugs = 11
07/01/2021 08:39:12 - INFO - __main__ - Number of em_forgotten_passes = 2.
07/01/2021 08:39:14 - INFO - __main__ - Model saved to bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_050.pt.
07/01/2021 08:40:44 - INFO - __main__ - Final Overall Bug-fixing Results = {'EM': 0.582, 'QA-F1': 0.712871565770253}
07/01/2021 08:40:44 - INFO - __main__ - Finished. Results saved to bug_data/output/nq_dev_0701v3_1e-5_e5_result.json
07/01/2021 09:34:54 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=7, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_7_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:54 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=1, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_1_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=4, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_4_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=5, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_5_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=3, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_3_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=8, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_8_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=0, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_0_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=2, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_2_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=1, base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', base_model_type='facebook/bart-base', bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', current_thread_id=6, do_lowercase=False, freeze_embeds=False, gradient_accumulation_steps=1, learning_rate=1e-05, max_grad_norm=0.1, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, num_threads_eval=8, num_train_epochs=3.0, overtime_ckpt_dir='bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/', overtime_overall_bug_eval=0, pass_pool_jsonl_path='bug_data/mrqa_naturalquestions_dev.pass.jsonl', pass_sample_size=64, path_to_thread_result='bug_data/output/nq_dev_0701v3_1e-5_e5_offline_eval/thread_6_result.json', predict_batch_size=168, prefix='nq_dev_0701v3_1e-5_e5', result_file='bug_data/output/nq_dev_0701v3_1e-5_e5_result.json', save_all_ckpts=0, seed=42, task_name='mrqa_naturalquestions', train_batch_size=8, weight_decay=0.01)
07/01/2021 09:34:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:55 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/01/2021 09:34:56 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/01/2021 09:35:00 - INFO - __main__ - Starting the offline evaluation of 21
07/01/2021 09:35:00 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base .....
07/01/2021 09:35:00 - INFO - __main__ - Starting the offline evaluation of 33
07/01/2021 09:35:00 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base .....
07/01/2021 09:35:03 - INFO - __main__ - Starting the offline evaluation of 45
07/01/2021 09:35:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base .....
07/01/2021 09:35:03 - INFO - __main__ - Starting the offline evaluation of 8
07/01/2021 09:35:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base .....
07/01/2021 09:35:03 - INFO - __main__ - Starting the offline evaluation of 1
07/01/2021 09:35:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_001.pt for facebook/bart-base .....
07/01/2021 09:35:03 - INFO - __main__ - Starting the offline evaluation of 27
07/01/2021 09:35:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base .....
07/01/2021 09:35:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:04 - INFO - __main__ - Starting the offline evaluation of 15
07/01/2021 09:35:04 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base .....
07/01/2021 09:35:04 - INFO - __main__ - Starting the offline evaluation of 39
07/01/2021 09:35:04 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base .....
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:07 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:07 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:35:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:35:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:35:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_033.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_021.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:15 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_008.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:15 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_039.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_045.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_001.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:16 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_027.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_015.pt for facebook/bart-base ..... Done!
07/01/2021 09:35:16 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:21 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:21 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:21 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:22 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:22 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:35:22 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:36:40 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.299, 'QA-F1': 0.4070610167719057} at Timecode=21
07/01/2021 09:36:40 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 21, "results": {"EM": 0.299, "QA-F1": 0.4070610167719057}}}
07/01/2021 09:36:40 - INFO - __main__ - Starting the offline evaluation of 22
07/01/2021 09:36:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_022.pt for facebook/bart-base .....
07/01/2021 09:36:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:36:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:36:43 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:36:47 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.34, 'QA-F1': 0.4716398523898579} at Timecode=27
07/01/2021 09:36:47 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 27, "results": {"EM": 0.34, "QA-F1": 0.4716398523898579}}}
07/01/2021 09:36:47 - INFO - __main__ - Starting the offline evaluation of 28
07/01/2021 09:36:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_028.pt for facebook/bart-base .....
07/01/2021 09:36:49 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:36:49 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:36:49 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:36:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_022.pt for facebook/bart-base ..... Done!
07/01/2021 09:36:50 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:36:54 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.45, 'QA-F1': 0.5583311220090988} at Timecode=33
07/01/2021 09:36:54 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 33, "results": {"EM": 0.45, "QA-F1": 0.5583311220090988}}}
07/01/2021 09:36:54 - INFO - __main__ - Starting the offline evaluation of 34
07/01/2021 09:36:54 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_034.pt for facebook/bart-base .....
07/01/2021 09:36:57 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_028.pt for facebook/bart-base ..... Done!
07/01/2021 09:36:57 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:36:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:36:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:36:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:00 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.569, 'QA-F1': 0.688903491865882} at Timecode=45
07/01/2021 09:37:00 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 45, "results": {"EM": 0.569, "QA-F1": 0.688903491865882}}}
07/01/2021 09:37:00 - INFO - __main__ - Starting the offline evaluation of 46
07/01/2021 09:37:00 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_046.pt for facebook/bart-base .....
07/01/2021 09:37:02 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.501, 'QA-F1': 0.6200791769958734} at Timecode=39
07/01/2021 09:37:02 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 39, "results": {"EM": 0.501, "QA-F1": 0.6200791769958734}}}
07/01/2021 09:37:02 - INFO - __main__ - Starting the offline evaluation of 40
07/01/2021 09:37:02 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_040.pt for facebook/bart-base .....
07/01/2021 09:37:03 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:37:03 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:37:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:04 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_034.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:04 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:37:05 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.206, 'QA-F1': 0.3444822388729716} at Timecode=15
07/01/2021 09:37:05 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 15, "results": {"EM": 0.206, "QA-F1": 0.3444822388729716}}}
07/01/2021 09:37:05 - INFO - __main__ - Starting the offline evaluation of 16
07/01/2021 09:37:05 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_016.pt for facebook/bart-base .....
07/01/2021 09:37:05 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:37:05 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:37:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:07 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.142, 'QA-F1': 0.29191777773380373} at Timecode=8
07/01/2021 09:37:07 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 8, "results": {"EM": 0.142, "QA-F1": 0.29191777773380373}}}
07/01/2021 09:37:07 - INFO - __main__ - Starting the offline evaluation of 9
07/01/2021 09:37:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_009.pt for facebook/bart-base .....
07/01/2021 09:37:07 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.049, 'QA-F1': 0.20876137216131793} at Timecode=1
07/01/2021 09:37:07 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 1, "results": {"EM": 0.049, "QA-F1": 0.20876137216131793}}}
07/01/2021 09:37:07 - INFO - __main__ - Starting the offline evaluation of 2
07/01/2021 09:37:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_002.pt for facebook/bart-base .....
07/01/2021 09:37:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:37:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:37:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:10 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:37:10 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:37:10 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_046.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:10 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:10 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:37:11 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:37:11 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:37:11 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:37:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_040.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:13 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:37:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_016.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:17 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:37:18 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_009.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:19 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:37:19 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_002.pt for facebook/bart-base ..... Done!
07/01/2021 09:37:19 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:38:16 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.312, 'QA-F1': 0.41613250728335277} at Timecode=22
07/01/2021 09:38:16 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 22, "results": {"EM": 0.312, "QA-F1": 0.41613250728335277}}}
07/01/2021 09:38:16 - INFO - __main__ - Starting the offline evaluation of 23
07/01/2021 09:38:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_023.pt for facebook/bart-base .....
07/01/2021 09:38:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_023.pt for facebook/bart-base ..... Done!
07/01/2021 09:38:26 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:38:36 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.374, 'QA-F1': 0.48536585189830733} at Timecode=28
07/01/2021 09:38:36 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 28, "results": {"EM": 0.374, "QA-F1": 0.48536585189830733}}}
07/01/2021 09:38:36 - INFO - __main__ - Starting the offline evaluation of 29
07/01/2021 09:38:36 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_029.pt for facebook/bart-base .....
07/01/2021 09:38:38 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:38 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:38 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:41 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.451, 'QA-F1': 0.5657775728939793} at Timecode=34
07/01/2021 09:38:41 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 34, "results": {"EM": 0.451, "QA-F1": 0.5657775728939793}}}
07/01/2021 09:38:41 - INFO - __main__ - Starting the offline evaluation of 35
07/01/2021 09:38:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_035.pt for facebook/bart-base .....
07/01/2021 09:38:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_029.pt for facebook/bart-base ..... Done!
07/01/2021 09:38:45 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:38:50 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.16, 'QA-F1': 0.29732731315794453} at Timecode=9
07/01/2021 09:38:50 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 9, "results": {"EM": 0.16, "QA-F1": 0.29732731315794453}}}
07/01/2021 09:38:50 - INFO - __main__ - Starting the offline evaluation of 10
07/01/2021 09:38:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_010.pt for facebook/bart-base .....
07/01/2021 09:38:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_035.pt for facebook/bart-base ..... Done!
07/01/2021 09:38:52 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:38:52 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.569, 'QA-F1': 0.6962342837956933} at Timecode=46
07/01/2021 09:38:52 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 46, "results": {"EM": 0.569, "QA-F1": 0.6962342837956933}}}
07/01/2021 09:38:52 - INFO - __main__ - Starting the offline evaluation of 47
07/01/2021 09:38:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_047.pt for facebook/bart-base .....
07/01/2021 09:38:52 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.512, 'QA-F1': 0.6311996162739318} at Timecode=40
07/01/2021 09:38:52 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 40, "results": {"EM": 0.512, "QA-F1": 0.6311996162739318}}}
07/01/2021 09:38:52 - INFO - __main__ - Starting the offline evaluation of 41
07/01/2021 09:38:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_041.pt for facebook/bart-base .....
07/01/2021 09:38:53 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:53 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:53 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:55 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:55 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.081, 'QA-F1': 0.22048969050612505} at Timecode=2
07/01/2021 09:38:55 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 2, "results": {"EM": 0.081, "QA-F1": 0.22048969050612505}}}
07/01/2021 09:38:55 - INFO - __main__ - Starting the offline evaluation of 3
07/01/2021 09:38:55 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_003.pt for facebook/bart-base .....
07/01/2021 09:38:56 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.226, 'QA-F1': 0.3558093763397422} at Timecode=16
07/01/2021 09:38:56 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 16, "results": {"EM": 0.226, "QA-F1": 0.3558093763397422}}}
07/01/2021 09:38:56 - INFO - __main__ - Starting the offline evaluation of 17
07/01/2021 09:38:56 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_017.pt for facebook/bart-base .....
07/01/2021 09:38:59 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:59 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:59 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:38:59 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:38:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:38:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:39:01 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_010.pt for facebook/bart-base ..... Done!
07/01/2021 09:39:01 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:39:01 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_047.pt for facebook/bart-base ..... Done!
07/01/2021 09:39:01 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:39:03 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_041.pt for facebook/bart-base ..... Done!
07/01/2021 09:39:03 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:39:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_003.pt for facebook/bart-base ..... Done!
07/01/2021 09:39:07 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:39:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_017.pt for facebook/bart-base ..... Done!
07/01/2021 09:39:07 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:13 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.26, 'QA-F1': 0.3954829216269924} at Timecode=23
07/01/2021 09:40:13 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 23, "results": {"EM": 0.26, "QA-F1": 0.3954829216269924}}}
07/01/2021 09:40:13 - INFO - __main__ - Starting the offline evaluation of 24
07/01/2021 09:40:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base .....
07/01/2021 09:40:16 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:16 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:16 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:17 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.426, 'QA-F1': 0.5580279566908528} at Timecode=35
07/01/2021 09:40:17 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 35, "results": {"EM": 0.426, "QA-F1": 0.5580279566908528}}}
07/01/2021 09:40:17 - INFO - __main__ - Starting the offline evaluation of 36
07/01/2021 09:40:17 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base .....
07/01/2021 09:40:20 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:20 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:20 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:22 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_024.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:23 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_036.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:26 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:26 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.569, 'QA-F1': 0.7015959379349527} at Timecode=47
07/01/2021 09:40:26 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 47, "results": {"EM": 0.569, "QA-F1": 0.7015959379349527}}}
07/01/2021 09:40:26 - INFO - __main__ - Starting the offline evaluation of 48
07/01/2021 09:40:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base .....
07/01/2021 09:40:26 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.391, 'QA-F1': 0.5099246330680971} at Timecode=29
07/01/2021 09:40:26 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 29, "results": {"EM": 0.391, "QA-F1": 0.5099246330680971}}}
07/01/2021 09:40:26 - INFO - __main__ - Starting the offline evaluation of 30
07/01/2021 09:40:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base .....
07/01/2021 09:40:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:29 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:29 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:29 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:37 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_048.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:37 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:37 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_030.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:37 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:41 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.528, 'QA-F1': 0.6452001799442383} at Timecode=41
07/01/2021 09:40:41 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 41, "results": {"EM": 0.528, "QA-F1": 0.6452001799442383}}}
07/01/2021 09:40:41 - INFO - __main__ - Starting the offline evaluation of 42
07/01/2021 09:40:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base .....
07/01/2021 09:40:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:45 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.106, 'QA-F1': 0.24334170813627595} at Timecode=3
07/01/2021 09:40:45 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 3, "results": {"EM": 0.106, "QA-F1": 0.24334170813627595}}}
07/01/2021 09:40:45 - INFO - __main__ - Starting the offline evaluation of 4
07/01/2021 09:40:45 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base .....
07/01/2021 09:40:47 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.168, 'QA-F1': 0.3055573954742082} at Timecode=10
07/01/2021 09:40:47 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 10, "results": {"EM": 0.168, "QA-F1": 0.3055573954742082}}}
07/01/2021 09:40:47 - INFO - __main__ - Starting the offline evaluation of 11
07/01/2021 09:40:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_011.pt for facebook/bart-base .....
07/01/2021 09:40:47 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:47 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:47 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:50 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:50 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:50 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:52 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.245, 'QA-F1': 0.3657580116939723} at Timecode=17
07/01/2021 09:40:52 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 17, "results": {"EM": 0.245, "QA-F1": 0.3657580116939723}}}
07/01/2021 09:40:52 - INFO - __main__ - Starting the offline evaluation of 18
07/01/2021 09:40:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base .....
07/01/2021 09:40:52 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_042.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:52 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:40:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:40:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:40:56 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_004.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:56 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:40:58 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_011.pt for facebook/bart-base ..... Done!
07/01/2021 09:40:58 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:41:02 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_018.pt for facebook/bart-base ..... Done!
07/01/2021 09:41:02 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:41:54 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.455, 'QA-F1': 0.5752812904740249} at Timecode=36
07/01/2021 09:41:54 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 36, "results": {"EM": 0.455, "QA-F1": 0.5752812904740249}}}
07/01/2021 09:41:54 - INFO - __main__ - Starting the offline evaluation of 37
07/01/2021 09:41:54 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_037.pt for facebook/bart-base .....
07/01/2021 09:41:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:41:57 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:41:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:02 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.569, 'QA-F1': 0.7019993315288392} at Timecode=48
07/01/2021 09:42:02 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 48, "results": {"EM": 0.569, "QA-F1": 0.7019993315288392}}}
07/01/2021 09:42:02 - INFO - __main__ - Starting the offline evaluation of 49
07/01/2021 09:42:02 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_049.pt for facebook/bart-base .....
07/01/2021 09:42:04 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_037.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:04 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:05 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:05 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:06 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.281, 'QA-F1': 0.415492140028518} at Timecode=24
07/01/2021 09:42:06 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 24, "results": {"EM": 0.281, "QA-F1": 0.415492140028518}}}
07/01/2021 09:42:06 - INFO - __main__ - Starting the offline evaluation of 25
07/01/2021 09:42:06 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_025.pt for facebook/bart-base .....
07/01/2021 09:42:09 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:09 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:09 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:13 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_049.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:13 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:16 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.396, 'QA-F1': 0.5156517440284156} at Timecode=30
07/01/2021 09:42:16 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 30, "results": {"EM": 0.396, "QA-F1": 0.5156517440284156}}}
07/01/2021 09:42:16 - INFO - __main__ - Starting the offline evaluation of 31
07/01/2021 09:42:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_031.pt for facebook/bart-base .....
07/01/2021 09:42:17 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_025.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:17 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:19 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:19 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:19 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:26 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_031.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:26 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:27 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.552, 'QA-F1': 0.6629741867049174} at Timecode=42
07/01/2021 09:42:27 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 42, "results": {"EM": 0.552, "QA-F1": 0.6629741867049174}}}
07/01/2021 09:42:27 - INFO - __main__ - Starting the offline evaluation of 43
07/01/2021 09:42:27 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_043.pt for facebook/bart-base .....
07/01/2021 09:42:30 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:30 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:30 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:37 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_043.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:37 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:41 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.097, 'QA-F1': 0.2541609636226937} at Timecode=4
07/01/2021 09:42:41 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 4, "results": {"EM": 0.097, "QA-F1": 0.2541609636226937}}}
07/01/2021 09:42:41 - INFO - __main__ - Starting the offline evaluation of 5
07/01/2021 09:42:41 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_005.pt for facebook/bart-base .....
07/01/2021 09:42:44 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.187, 'QA-F1': 0.323951196304414} at Timecode=11
07/01/2021 09:42:44 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 11, "results": {"EM": 0.187, "QA-F1": 0.323951196304414}}}
07/01/2021 09:42:44 - INFO - __main__ - Starting the offline evaluation of 12
07/01/2021 09:42:44 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base .....
07/01/2021 09:42:44 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:44 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:44 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:47 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:47 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:47 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:51 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.195, 'QA-F1': 0.3480690108607777} at Timecode=18
07/01/2021 09:42:51 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 18, "results": {"EM": 0.195, "QA-F1": 0.3480690108607777}}}
07/01/2021 09:42:51 - INFO - __main__ - Starting the offline evaluation of 19
07/01/2021 09:42:51 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_019.pt for facebook/bart-base .....
07/01/2021 09:42:53 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_005.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:53 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:42:54 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:42:54 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:42:54 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:42:55 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_012.pt for facebook/bart-base ..... Done!
07/01/2021 09:42:55 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:43:02 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_019.pt for facebook/bart-base ..... Done!
07/01/2021 09:43:02 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:43:40 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.575, 'QA-F1': 0.7077683608153312} at Timecode=49
07/01/2021 09:43:40 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 49, "results": {"EM": 0.575, "QA-F1": 0.7077683608153312}}}
07/01/2021 09:43:40 - INFO - __main__ - Starting the offline evaluation of 50
07/01/2021 09:43:40 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_050.pt for facebook/bart-base .....
07/01/2021 09:43:43 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:43:43 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:43:43 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:43:47 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.462, 'QA-F1': 0.5867763079280014} at Timecode=37
07/01/2021 09:43:47 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 37, "results": {"EM": 0.462, "QA-F1": 0.5867763079280014}}}
07/01/2021 09:43:47 - INFO - __main__ - Starting the offline evaluation of 38
07/01/2021 09:43:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_038.pt for facebook/bart-base .....
07/01/2021 09:43:50 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:43:50 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:43:50 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:43:50 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_050.pt for facebook/bart-base ..... Done!
07/01/2021 09:43:51 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:43:56 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.291, 'QA-F1': 0.4282781655757271} at Timecode=25
07/01/2021 09:43:56 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 25, "results": {"EM": 0.291, "QA-F1": 0.4282781655757271}}}
07/01/2021 09:43:56 - INFO - __main__ - Starting the offline evaluation of 26
07/01/2021 09:43:56 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_026.pt for facebook/bart-base .....
07/01/2021 09:43:57 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_038.pt for facebook/bart-base ..... Done!
07/01/2021 09:43:57 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:43:59 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:43:59 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:43:59 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:05 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.417, 'QA-F1': 0.5297019685368943} at Timecode=31
07/01/2021 09:44:05 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 31, "results": {"EM": 0.417, "QA-F1": 0.5297019685368943}}}
07/01/2021 09:44:05 - INFO - __main__ - Starting the offline evaluation of 32
07/01/2021 09:44:05 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_032.pt for facebook/bart-base .....
07/01/2021 09:44:07 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_026.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:07 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:44:08 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:44:08 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:44:08 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:11 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.546, 'QA-F1': 0.6605327212730231} at Timecode=43
07/01/2021 09:44:11 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 43, "results": {"EM": 0.546, "QA-F1": 0.6605327212730231}}}
07/01/2021 09:44:11 - INFO - __main__ - Starting the offline evaluation of 44
07/01/2021 09:44:11 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_044.pt for facebook/bart-base .....
07/01/2021 09:44:14 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:44:14 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:44:14 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:16 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_032.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:16 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:44:21 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_044.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:21 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:44:23 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.111, 'QA-F1': 0.2576363943137264} at Timecode=5
07/01/2021 09:44:23 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 5, "results": {"EM": 0.111, "QA-F1": 0.2576363943137264}}}
07/01/2021 09:44:23 - INFO - __main__ - Starting the offline evaluation of 6
07/01/2021 09:44:23 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_006.pt for facebook/bart-base .....
07/01/2021 09:44:25 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:44:25 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:44:25 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:33 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_006.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:33 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:44:37 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.167, 'QA-F1': 0.3247044901687882} at Timecode=12
07/01/2021 09:44:37 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 12, "results": {"EM": 0.167, "QA-F1": 0.3247044901687882}}}
07/01/2021 09:44:37 - INFO - __main__ - Starting the offline evaluation of 13
07/01/2021 09:44:37 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_013.pt for facebook/bart-base .....
07/01/2021 09:44:40 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:44:40 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:44:40 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:47 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.242, 'QA-F1': 0.3737069970814607} at Timecode=19
07/01/2021 09:44:47 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 19, "results": {"EM": 0.242, "QA-F1": 0.3737069970814607}}}
07/01/2021 09:44:47 - INFO - __main__ - Starting the offline evaluation of 20
07/01/2021 09:44:47 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_020.pt for facebook/bart-base .....
07/01/2021 09:44:48 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_013.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:48 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:44:50 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:44:50 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:44:50 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:44:58 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_020.pt for facebook/bart-base ..... Done!
07/01/2021 09:44:58 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:45:28 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.471, 'QA-F1': 0.600653913065174} at Timecode=38
07/01/2021 09:45:28 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 38, "results": {"EM": 0.471, "QA-F1": 0.600653913065174}}}
07/01/2021 09:45:28 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.582, 'QA-F1': 0.712871565770253} at Timecode=50
07/01/2021 09:45:28 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 50, "results": {"EM": 0.582, "QA-F1": 0.712871565770253}}}
07/01/2021 09:45:49 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.262, 'QA-F1': 0.41969826922606285} at Timecode=26
07/01/2021 09:45:49 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 26, "results": {"EM": 0.262, "QA-F1": 0.41969826922606285}}}
07/01/2021 09:45:50 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.438, 'QA-F1': 0.5466069725319801} at Timecode=32
07/01/2021 09:45:50 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 32, "results": {"EM": 0.438, "QA-F1": 0.5466069725319801}}}
07/01/2021 09:45:54 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.553, 'QA-F1': 0.6686181041390253} at Timecode=44
07/01/2021 09:45:54 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 44, "results": {"EM": 0.553, "QA-F1": 0.6686181041390253}}}
07/01/2021 09:46:09 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.16, 'QA-F1': 0.2744201043481505} at Timecode=6
07/01/2021 09:46:09 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 6, "results": {"EM": 0.16, "QA-F1": 0.2744201043481505}}}
07/01/2021 09:46:09 - INFO - __main__ - Starting the offline evaluation of 7
07/01/2021 09:46:09 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_007.pt for facebook/bart-base .....
07/01/2021 09:46:11 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:46:11 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:46:11 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:46:15 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_007.pt for facebook/bart-base ..... Done!
07/01/2021 09:46:15 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:46:22 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.177, 'QA-F1': 0.32709906826614366} at Timecode=13
07/01/2021 09:46:22 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 13, "results": {"EM": 0.177, "QA-F1": 0.32709906826614366}}}
07/01/2021 09:46:22 - INFO - __main__ - Starting the offline evaluation of 14
07/01/2021 09:46:22 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_014.pt for facebook/bart-base .....
07/01/2021 09:46:22 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.285, 'QA-F1': 0.3996566213839022} at Timecode=20
07/01/2021 09:46:22 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 20, "results": {"EM": 0.285, "QA-F1": 0.3996566213839022}}}
07/01/2021 09:46:25 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/01/2021 09:46:25 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/01/2021 09:46:25 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/01/2021 09:46:29 - INFO - __main__ - Loading checkpoint from bug_data/output/nq_dev_0701v3_1e-5_e5_ckpts/model_ckpt_014.pt for facebook/bart-base ..... Done!
07/01/2021 09:46:29 - INFO - __main__ - Moving to the GPUs.
07/01/2021 09:47:37 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.149, 'QA-F1': 0.2878052831129658} at Timecode=7
07/01/2021 09:47:37 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 7, "results": {"EM": 0.149, "QA-F1": 0.2878052831129658}}}
07/01/2021 09:47:52 - INFO - __main__ - Current Overall Bug-fixing Results = {'EM': 0.2, 'QA-F1': 0.3400653694516026} at Timecode=14
07/01/2021 09:47:52 - INFO - __main__ - Results: {"overtime_all_bug_eval": {"timecode": 14, "results": {"EM": 0.2, "QA-F1": 0.3400653694516026}}}
