07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=2
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=1
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=6
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=4
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=5
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=0
07/29/2021 11:37:58 - INFO - __main__ - Config args: Namespace(append_another_bos=True, checkpoint='', dataset='mrqa_naturalquestions', debug=False, dev_file='', do_lowercase=False, do_predict=True, do_train=False, max_input_length=888, max_output_length=50, model='facebook/bart-base', num_beams=4, output_dir='out/mrqa_naturalquestions_bart-base_0617v4', predict_batch_size=64, predict_checkpoint='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', prefix='', quiet=False, seed=42, train_file='')
07/29/2021 11:37:58 - INFO - __main__ - dataset_size=4479, num_shards=7, local_shard_id=3
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /private/home/yuchenlin/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
07/29/2021 11:37:58 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /private/home/yuchenlin/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: The song was covered by the American girl group No Secrets in 2003 for the two - disc DVD release , and by Emily Osment in October 2008 for the Platinum Edition release of the film , and also included on the compilation album Princess Disneymania . Lana Del Rey covered it in a `` somber and sinister '' mood for the 2014 film Maleficent . | Question: who sang once upon a dream at the end of maleficent ?
07/29/2021 11:37:58 - INFO - __main__ - ['Lana Del Rey']
07/29/2021 11:37:58 - INFO - __main__ - Context: This is a list of host cities of the Olympic Games , both summer and winter , since the modern Olympics began in 1896 . Since then , summer games have usually -- but not always -- celebrated a four - year period known as an Olympiad . There have been 28 Summer Olympic Games held in 23 cities , and 23 Winter Olympic Games held in 20 cities . In addition , three summer and two winter editions of the Games were scheduled to take place but later cancelled due to war : Berlin ( summer ) in 1916 ; Tokyo / Helsinki ( summer ) and Sapporo / Garmisch - Partenkirchen ( winter ) in 1940 ; and London ( summer ) and Cortina d'Ampezzo , Italy ( winter ) in 1944 . The 1906 Summer Olympics were officially sanctioned and held in Athens . However , in 1949 , the International Olympic Committee ( IOC ) , decided to unrecognize the 1906 Games . Four cities have been chosen by the IOC to host upcoming Olympic Games : Tokyo for the 2020 Summer Olympics , Beijing for the 2022 Winter Olympics , Paris for the 2024 Summer Olympics , and Los Angeles for the 2028 Summer Olympics . | Question: where will be the next olympics be held ?
07/29/2021 11:37:58 - INFO - __main__ - ['Tokyo']
07/29/2021 11:37:58 - INFO - __main__ - Context: The Dodgers -- Yankees rivalry is a Major League Baseball ( MLB ) rivalry between the Los Angeles Dodgers and the New York Yankees . The Dodgers are a member club of the National League ( NL ) West division , and the Yankees are a member club of the American League ( AL ) East division . The rivalry between the Dodgers and Yankees is one of the most well - known rivalries in Major League Baseball . The two teams have met 11 times in the World Series , more times than any other pair of teams from the American and National Leagues . The initial significance was embodied in the two teams ' proximity in New York City , when the Dodgers initially played in Brooklyn . After the Dodgers moved to Los Angeles in 1958 , the rivalry retained its significance as the two teams represented the dominant cities on each coast of the United States , and since the 1980s , the two largest cities in the United States . The Dodgers currently lead the regular season series 7 - 6 . Although the rivalry 's significance arose from the two teams ' numerous World Series meetings , the Yankees and Dodgers have not met in the World Series since 1981 . They would not play each other in a non-exhibition game until 2004 , when they played a 3 - game interleague series . Nevertheless , games between the two teams have become quite popular and draw sellout crowds . | Question: when was the last time the dodgers played yankees in the world series ?
07/29/2021 11:37:58 - INFO - __main__ - ['1981']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: At the 2006 Winter Olympics , White won gold in the half - pipe . After his first run in qualifications , White was almost out of competition , scoring only 37.7 . On his second run , he recorded a score of 45.3 . In the finals , White recorded a score of 46.8 ( 50 is the highest possible score ) to win . Fellow American Danny Kass won the silver with a points total of 44.0 . | Question: how okd was sean white in his first olympics ?
07/29/2021 11:37:58 - INFO - __main__ - ['won gold in the half - pipe']
07/29/2021 11:37:58 - INFO - __main__ - Context: The modern version of the song was first said to have been sung by tobacco workers led by Lucille Simmons during a 1945 strike in Charleston , South Carolina . In 1947 , the song was published under the title `` We Will Overcome '' in an edition of the People 's Songs Bulletin ( a publication of People 's Songs , an organization of which Pete Seeger was the director ) , as a contribution of and with an introduction by Zilphia Horton , then - music director of the Highlander Folk School of Monteagle , Tennessee ( an adult education school that trained union organizers ) . Horton said she had learned the song from Simmons , and she considered it to be her favorite song . She taught it to many others , including Pete Seeger , who included it in his repertoire , as did many other activist singers , such as Frank Hamilton and Joe Glazer , who recorded it in 1950 . | Question: who validated the civil rights movement by proclaiming we shall overcome ?
07/29/2021 11:37:58 - INFO - __main__ - ['Lucille Simmons']
07/29/2021 11:37:58 - INFO - __main__ - Context: Under the Charter , people physically present in Canada have numerous civil and political rights . Most of the rights can be exercised by any legal person ( the Charter does not define the corporation as a `` legal person '' ) , but a few of the rights belong exclusively to natural persons , or ( as in sections 3 and 6 ) only to citizens of Canada . The rights are enforceable by the courts through section 24 of the Charter , which allows courts discretion to award remedies to those whose rights have been denied . This section also allows courts to exclude evidence in trials if the evidence was acquired in a way that conflicts with the Charter and might damage the reputation of the justice system . Section 32 confirms that the Charter is binding on the federal government , the territories under its authority , and the provincial governments . The rights and freedoms enshrined in 34 sections of the Charter include : | Question: who enforces the charter of rights and freedoms ?
07/29/2021 11:37:58 - INFO - __main__ - ['the courts']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: In traditional Western notation , the scale used for a composition is usually indicated by a key signature at the beginning to designate the pitches that make up that scale . As the music progresses , the pitches used may change and introduce a different scale . Music can be transposed from one scale to another for various purposes , often to accommodate the range of a vocalist . Such transposition raises or lowers the overall pitch range , but preserves the intervallic relationships of the original scale . For example , transposition from the key of C major to D major raises all pitches of the scale of C major equally by a whole tone . Since the interval relationships remain unchanged , transposition may be unnoticed by a listener , however other qualities may change noticeably because transposition changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music . This often affects the music 's overall sound , as well as having technical implications for the performers . | Question: if a piece of music is perceived to have changed key then we say the piece has ?
07/29/2021 11:37:58 - INFO - __main__ - ['transposed']
07/29/2021 11:37:58 - INFO - __main__ - Context: In the spring of 1609 , John Smith cited the aphorism to the colonists of Jamestown : | Question: who took control of jamestown and made new rules that made everyone work ?
07/29/2021 11:37:58 - INFO - __main__ - ['John Smith']
07/29/2021 11:37:58 - INFO - __main__ - Context: Nepal is a secular state under the Interim Constitution , which was promulgated on January 15 , 2007 . The Interim Constitution provides for freedom to practice one 's religion . The Interim Constitution also specifically denies the right to convert another person . The now - defunct constitution of 1990 , which was in effect until January 15 , 2007 , described the country as a `` Hindu Kingdom , '' although it did not establish Hinduism as the state religion . The Government generally did not interfere with the practice of other religious groups , and religious tolerance was broadly observed ; however , there were some restrictions . | Question: when was nepal declared a secular state in bs ?
07/29/2021 11:37:58 - INFO - __main__ - ['January 15 , 2007']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: In accounting , minority interest ( or non-controlling interest ) is the portion of a subsidiary corporation 's stock that is not owned by the parent corporation . The magnitude of the minority interest in the subsidiary company is generally less than 50 % of outstanding shares , or the corporation would generally cease to be a subsidiary of the parent . | Question: what is non controlling interest on balance sheet ?
07/29/2021 11:37:58 - INFO - __main__ - ["the portion of a subsidiary corporation 's stock that is not owned by the parent corporation"]
07/29/2021 11:37:58 - INFO - __main__ - Context: The fourth season of Chicago Fire , an American drama television series with executive producer Dick Wolf , and producers Derek Haas , Michael Brandt , and Matt Olmstead , was ordered on February 5 , 2015 , by NBC , and premiered on October 13 , 2015 and concluded on May 17 , 2016 . The season contained 23 episodes . | Question: how many episodes are in chicago fire season 4 ?
07/29/2021 11:37:58 - INFO - __main__ - ['23']
07/29/2021 11:37:58 - INFO - __main__ - Context: `` Love Will Keep Us Alive '' is a song written by Jim Capaldi , Paul Carrack , and Peter Vale , and produced by the Eagles , Elliot Scheiner , and Rob Jacobs . It was first performed by the Eagles in 1994 , during their `` Hell Freezes Over '' reunion tour , with lead vocals by bassist Timothy B. Schmit . | Question: who sings love will keep us alive by the eagles ?
07/29/2021 11:37:58 - INFO - __main__ - ['Timothy B. Schmit']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: Jason Ritter as Kevin Finn | Question: who stars in kevin probably save the world ?
07/29/2021 11:37:58 - INFO - __main__ - ['Jason Ritter']
07/29/2021 11:37:58 - INFO - __main__ - Context: Mexico is one of the world 's most seismically active regions , sitting atop several intersecting tectonic plates . The border between the Cocos Plate and North American Plate , along the Pacific Coast of Mexico , creates a subduction zone that generates large seismic events . Activity along the edges of the Rivera and Caribbean plates also generate seismic events . All together , these seismic forces cause an average of 40 earthquakes a day in Mexico . | Question: what type of boundary was the mexico earthquake ?
07/29/2021 11:37:58 - INFO - __main__ - ['a subduction zone']
07/29/2021 11:37:58 - INFO - __main__ - Context: For example , in the United States , a standard drink contains about 14 grams of alcohol . This corresponds to a 12 - US - fluid - ounce ( 350 ml ) glass of beer , a 5 - US - fluid - ounce ( 150 ml ) glass of 12 % wine , or a 1.5 - US - fluid - ounce ( 44 ml ) glass of spirit . | Question: how many grams of alcohol in one beer ?
07/29/2021 11:37:58 - INFO - __main__ - ['about 14 grams of alcohol']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 639 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: Food at various stages of digestion has been found in the intestines of several woolly mammoths , giving a good picture of their diet . Woolly mammoths sustained themselves on plant food , mainly grass and sedges , which were supplemented with herbaceous plants , flowering plants , shrubs , mosses , and tree matter . The composition and exact varieties differed from location to location . Woolly mammoths needed a varied diet to support their growth , like modern elephants . An adult of six tonnes would need to eat 180 kg ( 397 lb ) daily , and may have foraged as long as twenty hours every day . The two - fingered tip of the trunk was probably adapted for picking up the short grasses of the last ice age ( Quaternary glaciation , 2.58 million years ago to present ) by wrapping around them , whereas modern elephants curl their trunks around the longer grass of their tropical environments . The trunk could also be used for pulling off large grass tufts , delicately picking buds and flowers , and tearing off leaves and branches where trees and shrubs were present . The `` Yukagir mammoth '' had ingested plant matter that contained spores of dung fungus . Isotope analysis shows that woolly mammoths fed mainly on C3 plants , unlike horses and rhinos . | Question: what kind of food did the woolly mammoth eat ?
07/29/2021 11:37:58 - INFO - __main__ - ['plant food , mainly grass and sedges , which were supplemented with herbaceous plants , flowering plants , shrubs , mosses , and tree matter']
07/29/2021 11:37:58 - INFO - __main__ - Context: Canadian ice dancers Tessa Virtue and Scott Moir are the only figure skaters to win five Olympic medals ( 3 gold , 2 silver ) . Swedish figure skater Gillis Grafström ( 3 gold , 1 silver ) and Russian figure skater Evgeni Plushenko ( 2 gold , 2 silver ) each have four medals . Seventeen figure skaters have won three medals . | Question: who has the most olympic medals in figure skating ?
07/29/2021 11:37:58 - INFO - __main__ - ['Canadian ice dancers Tessa Virtue and Scott Moir']
07/29/2021 11:37:58 - INFO - __main__ - Context: Rocky Dzidzornu -- congas | Question: who plays bongos on sympathy for the devil ?
07/29/2021 11:37:58 - INFO - __main__ - ['Rocky Dzidzornu']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:37:58 - INFO - __main__ - Start tokenizing ... 640 instances
07/29/2021 11:37:58 - INFO - __main__ - Printing 3 examples
07/29/2021 11:37:58 - INFO - __main__ - Context: Dilwale Dulhania Le Jayenge was filmed in several 5 - , 10 - and 20 - day schedules between September 1994 and August 1995 . The first sequence filmed was for the song `` Ho Gaya Hai Tujhko '' with Kajol and Shah Rukh in Switzerland . The European journey scenes and songs were mainly filmed in Saanen , Montbovon and Gstaad , Switzerland . Other scenes were shot in England , at locations including Trafalgar Square , King 's Cross railway station and Angel Underground station . Film 's cinematographer Manmohan Singh , a regular collaborator with Chopra , shot the song `` Tujhe Dekha To '' , including the iconic mustard fields scenes with Shah Rukh and Kajol in the mustard fields in Gurgaon on the outskirts of the National Capital Region Delhi . | Question: tujhe dekha toh yeh jana sanam movie name ?
07/29/2021 11:37:58 - INFO - __main__ - ['Dilwale Dulhania Le Jayenge']
07/29/2021 11:37:58 - INFO - __main__ - Context: The railway system of Great Britain , the principal territory of the United Kingdom , is the oldest in the world . It was started with the building of local isolated wooden wagonways starting in 1560s . The system was later built as a patchwork of local rail links operated by small private railway companies in late 18th century . These isolated links developed during the railway boom of the 1840s into a national network , although still run by dozens of competing companies . Over the course of the 19th and early 20th centuries , these amalgamated or were bought by competitors until only a handful of larger companies remained ( see railway mania ) . The entire network was brought under government control during the First World War and a number of advantages of amalgamation and planning were revealed . However , the government resisted calls for the nationalisation of the network . In 1923 , almost all the remaining companies were grouped into the `` big four '' , the Great Western Railway , the London and North Eastern Railway , the London , Midland and Scottish Railway and the Southern Railway . The `` Big Four '' were joint - stock public companies and they continued to run the railway system until 31 December 1947 . | Question: when did the first train run in england ?
07/29/2021 11:37:58 - INFO - __main__ - ['1560s']
07/29/2021 11:37:58 - INFO - __main__ - Context: The Epistle to the Galatians , often shortened to Galatians , is the ninth book of the New Testament . It is a letter from Paul the Apostle to a number of Early Christian communities in Galatia . Scholars have suggested that this is either the Roman province of Galatia in southern Anatolia , or a large region defined by an ethnic group of Celtic people in central Anatolia . | Question: who is the book of galatians written to ?
07/29/2021 11:37:58 - INFO - __main__ - ['a number of Early Christian communities in Galatia']
07/29/2021 11:37:58 - INFO - __main__ - Tokenizing Input ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Loaded 639 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Input ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ...
07/29/2021 11:38:00 - INFO - __main__ - Tokenizing Output ... Done!
07/29/2021 11:38:00 - INFO - __main__ - Loaded 640 examples from dev data
07/29/2021 11:38:00 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt ....
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /private/home/yuchenlin/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb
07/29/2021 11:38:01 - INFO - transformers.configuration_utils - Model config BartConfig {
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel",
    "BartForConditionalGeneration",
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "scale_embedding": false,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "vocab_size": 50265
}

07/29/2021 11:38:01 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /private/home/yuchenlin/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c
07/29/2021 11:38:07 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:08 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:09 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:09 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:09 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:09 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:09 - INFO - __main__ - Loading checkpoint from out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt .... Done!
07/29/2021 11:38:12 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:38:14 - INFO - __main__ - Starting inference ...
07/29/2021 11:39:14 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:14 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:19 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:19 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:22 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:22 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:39:23 - INFO - __main__ - Starting inference ... Done
07/29/2021 11:40:02 - INFO - root - Evaluation results: {'EM': 0.5831658852422416, 'QA-F1': 0.7363685533634763}
